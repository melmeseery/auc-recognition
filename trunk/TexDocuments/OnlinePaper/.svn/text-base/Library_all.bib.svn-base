Automatically generated by Mendeley 0.9.8.2
Any changes to this file will be lost if it is regenerated by Mendeley.

@inproceedings{Chen2005,
author = {Chen, Xiangrong and Yuille, AL},
booktitle = {Computer Vision and Pattern Recognition-Workshops, 2005. CVPR Workshops. IEEE Computer Society Conference on},
file = {:D$\backslash$:/Papers/Documents/2005/Chen, Yuille - 2005.pdf:pdf},
isbn = {0769523722},
issn = {1063-6919},
pages = {28},
publisher = {IEEE},
title = {{A time-efficient cascade for real-time object detection: With applications for the visually impaired}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1565325},
year = {2005}
}
@article{Meseery2009,
abstract = {Sketch recognition is defined as the process of identifying symbols that users draw using single or multiple strokes. Users draw strokes using a pen and the system immediately interprets their strokes as objects that can be easily manipulated. This paper uses Particle Swarm Optimization Algorithm (PSO) to divide the strokes the user draws into meaningful geometric primitives. These geometric primitives are grouped to formulate symbols which are further identified. The results show that using PSO improves segmentation results which guide the symbol recognition phase. This paper uses Support Vector Machines (SVM) classifier which further improves the final recognition accuracy.},
author = {Meseery, Maha El and Din, Mahmoud Fakhr El and Mashali, Samia and Fayek, Magda and Darwish, Nevin},
issn = {1522-4880},
journal = {Proceedings of the 16th IEEE international conference on Image processing},
pages = {1997--2000},
title = {{Sketch recognition using particle swarm algorithms}},
url = {http://portal.acm.org/citation.cfm?id=1819282},
year = {2009}
}
@inproceedings{M\\argner2006,
author = {M$\backslash$$\backslash$"argner, V. and {El Abed}, H.},
booktitle = {Proceedings of the 2006 conference on Arabic and Chinese handwriting recognition},
file = {:D$\backslash$:/Papers/Documents/2006/Margner, El Abed - 2006.pdf:pdf},
isbn = {3540781986},
pages = {82--103},
publisher = {Springer-Verlag},
title = {{Databases and competitions: strategies to improve Arabic recognition systems}},
url = {http://portal.acm.org/citation.cfm?id=1792262.1792268},
year = {2006}
}
@inproceedings{Xu2002,
author = {Xu, Q. and Lam, L. and Suen, CY},
booktitle = {Document Analysis and Recognition, 2001. Proceedings. Sixth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2002/Xu, Lam, Suen - 2002.pdf:pdf},
isbn = {0769512631},
pages = {384--388},
publisher = {IEEE},
title = {{A knowledge-based segmentation system for handwritten dates on bank cheques}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=953818},
year = {2002}
}
@inproceedings{Li2008,
author = {Li, Fang and Zhu, Qunxiong},
booktitle = {Intelligent Networks and Intelligent Systems, 2008. ICINIS'08. First International Conference on},
doi = {10.1109/ICINIS.2008.117},
file = {:D$\backslash$:/Papers/Documents/2008/Li, Zhu - 2008.pdf:pdf},
pages = {725--728},
publisher = {IEEE},
title = {{Study on Association Rules Mining Based Chinese Text Representation}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4683327},
year = {2008}
}
@article{Conery2005,
author = {Conery, John S and Catchen, Julian M and Lynch, Michael},
doi = {10.1007/s00778-005-0153-9},
file = {:D$\backslash$:/Papers/Documents/2005/Conery, Catchen, Lynch - 2005.pdf:pdf},
journal = {Vldb Journal},
keywords = {bioinformatics,rule-based system,workflow},
pages = {318--329},
title = {{Rule-based workflow management for bioinformatics}},
volume = {14},
year = {2005}
}
@inproceedings{Said2002,
author = {Said, F.N. and Yacoub, A. and Suen, C.Y.},
booktitle = {Proceedings of the Fifth International Conference on Document Analysis and Recognition, 1999. ICDAR'99.},
file = {:D$\backslash$:/Papers/Documents/2002/Said, Yacoub, Suen - 2002.pdf:pdf},
isbn = {0769503187},
keywords = {character recognition,english and},
pages = {237--240},
publisher = {IEEE},
title = {{Recognition of English and Arabic numerals using a dynamic number of hidden neurons}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=791768},
year = {2002}
}
@article{Brown2005,
author = {Brown, Gavin and Wyatt, Jeremy and Harris, Rachel and Yao, Xin},
file = {:D$\backslash$:/Papers/Documents/2005/Brown et al. - 2005.pdf:pdf},
issn = {1566-2535},
journal = {Information Fusion},
keywords = {diversity,ensemble,neural networks,survey,taxonomy},
number = {1},
pages = {5--20},
publisher = {Elsevier},
title = {{Diversity creation methods: A survey and categorisation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1566253504000375},
volume = {6},
year = {2005}
}
@book{Shengfeng,
abstract = {This paper presents an intelligent method for classifying pen strokes in an on-line sketching system. The method, based on adaptive threshold and fuzzy knowledge with respect to curve's linearity and convexity, can identify sketch strokes (curves) into lines, circles, arcs, ellipses, elliptical arcs, loop lines, spring lines and free-form B-spline curves. The proposed method has proven to be fast, suitable for real-time classification and identification},
author = {Shengfeng, Qin},
booktitle = {EUROCON 2005 - The International Conference on "Computer as a Tool"},
doi = {10.1109/EURCON.2005.1630216},
isbn = {1-4244-0049-X},
pages = {1374--1377},
publisher = {IEEE},
title = {{Intelligent Classification of Sketch Strokes}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=1630216}
}
@article{Brubaker2006,
author = {Brubaker, S. and Mullin, M. and Rehg, J.},
file = {:D$\backslash$:/Papers/Documents/2006/Brubaker, Mullin, Rehg - 2006.pdf:pdf},
journal = {Computer Vision–ECCV 2006},
pages = {325--337},
publisher = {Springer},
title = {{Towards optimal training of cascaded detectors}},
url = {http://www.springerlink.com/index/y758258873h51870.pdf},
year = {2006}
}
@article{Khorsheed2007,
abstract = {This paper presents a cursive Arabic text recognition system. The system decomposes the document image into text line images and extracts a set of simple statistical features from a narrow window which is sliding a long that text line. It then injects the resulting feature vectors to the Hidden Markov Model Toolkit (HTK). HTK is a portable toolkit for speech recognition system. The proposed system is applied to a data corpus which includes Arabic text of more than 600 A4-size sheets typewritten in multiple computer-generated fonts.},
author = {Khorsheed, M. S.},
issn = {0167-8655},
journal = {Pattern Recognition Letters},
keywords = {Arabic OCR,Document analysis,HTK,Machine vision,Pattern analysis and recognition},
number = {12},
pages = {1563--1571},
title = {{Offline recognition of omnifont Arabic text using the HMM ToolKit (HTK)}},
url = {http://portal.acm.org/citation.cfm?id=1274444},
volume = {28},
year = {2007}
}
@misc{TheMendeleySupportTeam2010,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2010}
}
@inproceedings{Bhat2009,
abstract = {Most sketch recognition systems are accurate in re- cognizing either text or shape (graphic) ink strokes, but not both. Distinguishing between shape and text strokes is, therefore, a critical task in recogniz- ing hand-drawn digital ink diagrams that contain text labels and annotations. We have found the ‘en- tropy rate’ to be an accurate criterion of classifica- tion. We found that the entropy rate is significantly higher for text strokes compared to shape strokes and can serve as a distinguishing factor between the two. Using a single feature – zero-order entropy rate – our system produced a correct classification rate of 92.06\% on test data belonging to diagram- matic domain for which the threshold was trained on. It also performed favorably on an unseen do- main for which no training examples were sup- plied.},
annote = {Index is : Bhat2009

        
The system main goel is differenate between text and shape. The system uses Entropy of zero order( measure of degree of randomess as a symbol is more random OR how much information in strokes as the text has more information). The angle of  each point in a storke is coded using an alphabet. (for example A represnet angle of 0 to pi/6. B represnt from pi/6 to pi/3....)
this makes the stroke into a series of alphabeet  whree a rectangle is coded like DDFFFFFFFFFFDDFFFFFFFFFDDFFFFFFFF.....
and a text is coded with more information. A grouping algorithm is used based on temporal and spatical nearess where they are groupd if they are bellow a threshold. three types of classification is done ( text, sybmol, unclassiifid)  the classification is done by using convendence values form the Entropy measure.  Tests was done on diagrams collected by Sousa and COA diagrams. The system achieve 92\% correctness in the  91\% of casses that was classified. },
author = {Bhat, Akshay and Hammond, Tracy},
booktitle = {Proceedings of the 21st international jont conference on Artifical intelligence},
file = {:D$\backslash$:/Papers/Documents/2009/Bhat, Hammond - 2009.pdf:pdf},
keywords = {Sketch Research},
mendeley-tags = {Sketch Research},
pages = {1395--1400},
publisher = {Morgan Kaufmann Publishers Inc.},
title = {{Using entropy to distinguish shape versus text in hand-drawn diagrams}},
url = {http://www.aaai.org/ocs/index.php/IJCAI/IJCAI-09/paper/download/592/906},
year = {2009}
}
@article{ZENG2006,
abstract = {We introduce a novel feature extraction scheme for online handwritten characters based on utilizing Delaunay triangles for describing each stroke segment. Central to the proposed approach is the idea of associating a unique topological structure with the handwritten shape using the Delaunay triangulation. This allows more ‘meaningful’ groups (i.e., triangles) to be chosen for representing global features, and makes full use of the rich temporal and topological characteristics of handwritten shapes. The Delaunay triangles used for feature extraction, called the Delaunay triangle descriptor, have good discrimination power since they are the only ones satisfying the properties of the Delaunay triangulation. A discrete HMM-based recognition system is used, as the test platform, and shows that the proposed representation can achieve good performance on the chosen data collection, improve recognition accuracy, elevate stability and robustness, and outperform other alternative feature combinations implemented for comparison.},
author = {ZENG, W and MENG, X and YANG, C and HUANG, L},
doi = {10.1016/j.cag.2006.07.007},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {delaunay triangulation,feature extraction,online handwritten characters},
month = oct,
number = {5},
pages = {779--786},
title = {{Feature extraction for online handwritten characters using Delaunay triangulation}},
url = {http://dx.doi.org/10.1016/j.cag.2006.07.007},
volume = {30},
year = {2006}
}
@inproceedings{Hammond2010,
abstract = {Military course-of-action (COA) diagrams are used to depict battle scenarios and include thousands of unique symbols, complete with additional textual and designator modifiers. We have created a real-time sketch recognition interface that recognizes 485 freely-drawn military course-of-action sym- bols. When the variations (not allowable by other systems) are factored in, our system is several orders of magnitude larger than the next biggest system. On 5,900 hand-drawn symbols, the system achieves an accuracy of 90\% when con- sidering the top 3 interpretations and requiring every aspect of the shape (variations, text, symbol, location, orientation) to be correct. Introduction},
annote = {The index of this paper: Hammond2010
it contains high level explanation of the system of defining over 400 symbols for course of action diagrams. The system  can recognize symbols and text and combination of both. 
 the system uses an extended version of Pelosketch (more primitives) as low level recognizier then ladder then a symoble recognizier based on the ladder discription.  It can handle dashed primitve using algorithms that groups dashed lines then group each dashed of orientation together to see if a primitive is formed from it.  it discribe CALVIN a heuristic driven geometric based recognizier based on LADDER.  It is concerned with the interface of the system to make it as symbol as pssible.  correct interpertaion of drawn symbol is achived on 84.4\% of the test cases. },
author = {Hammond, T and Logsdon, D and Paulson, B and Johnston, J and Peschel, J and Wolin, A and Taele, P},
booktitle = {Artificial Intelligence},
file = {:D$\backslash$:/Papers/Documents/2010/Hammond et al. - 2010.pdf:pdf},
keywords = {Course of Action,High Level,Ladder,PaleoSketch,Read,Summarized,application},
mendeley-tags = {Read,Summarized,application},
title = {{A Sketch Recognition System for Recognizing Free-Hand Course of Action Diagrams}},
url = {http://www.aaai.org/ocs/index.php/IAAI/IAAI10/paper/download/1581/2355},
year = {2010}
}
@article{Sahbi2006,
abstract = {We introduce a computational design for pattern detection based on a tree-structured network of support vector machines (SVMs). An SVM is associated with each cell in a recursive partitioning of the space of patterns (hypotheses) into increasingly finer subsets. The hierarchy is traversed coarse-to-fine and each chain of positive responses from the root to a leaf constitutes a detection. Our objective is to design and build a network which balances overall error and computation. Initially, SVMs are constructed for each cell with no constraints. This “free network” is then perturbed, cell by cell, into another network, which is “graded” in two ways: first, the number of support vectors of each SVM is reduced (by clustering) in order to adjust to a pre-determined, increasing function of cell depth; second, the decision boundaries are shifted to preserve all positive responses from the original set of training data. The limits on the numbers of clusters (virtual support vectors) result from minimizing the mean computational cost of collecting all detections subject to a bound on the expected number of false positives. When applied to detecting faces in cluttered scenes, the patterns correspond to poses and the free network is already faster and more accurate than applying a single pose-specific SVM many times. The graded network promotes very rapid processing of background regions while maintain- ing the discriminatory power of the free network. Keywords:},
author = {Sahbi, Hichem and Geman, D.},
file = {:D$\backslash$:/Papers/Documents/2006/Sahbi, Geman - 2006.pdf:pdf},
issn = {1532-4435},
journal = {The Journal of Machine Learning Research},
pages = {2087--2123},
publisher = {JMLR. org},
title = {{A hierarchy of support vector machines for pattern detection}},
url = {http://portal.acm.org/citation.cfm?id=1248547.1248622},
volume = {7},
year = {2006}
}
@article{CONNELL2001,
abstract = {Handwriting is a common, natural form of communication for humans, and therefore it is useful to utilize this modality as a means of input to machines. One well-known method of classifying individual characters or words is template matching. We demonstrate a template-based system for online character recognition where the number of representative templates is determined automatically. These templates can be viewed as representing different styles of writing a particular character. The templates are then used as a reference for efficient classification using decision trees. Overall, our classifier achieves an 86.9\% accuracy on a set of 17,928 alphanumeric characters (36 classes; 10 digits and 26 lowercase letters) with a throughput of over 8 characters per second on a 296 MHz Sun UltraSparc.},
author = {CONNELL, S},
doi = {10.1016/S0031-3203(99)00197-1},
issn = {00313203},
journal = {Pattern Recognition},
month = jan,
number = {1},
pages = {1--14},
title = {{Template-based online character recognition}},
url = {http://dx.doi.org/10.1016/S0031-3203(99)00197-1},
volume = {34},
year = {2001}
}
@article{Elrefaei2007,
author = {Elrefaei, Hatem and Aboelfadel, Tamer and Elmeseery, Maha and Elmofty, Ali and Shafee, Marwah},
keywords = {e-learning,engineering education,scientific models},
title = {{Online Library of Scientific Models - A New Way to Teach, Learn, and Share Learning Experience}},
url = {http://halshs.archives-ouvertes.fr/hal-00257139/},
year = {2007}
}
@phdthesis{Paulson2010,
abstract = {Online sketch recognition uses machine learning and artificial intelligence tech- niques to interpret markings made by users via an electronic stylus or pen. The goal of sketch recognition is to understand the intention and meaning of a partic- ular user’s drawing. Diagramming applications have been the primary beneficiaries of sketch recognition technology, as it is commonplace for the users of these tools to first create a rough sketch of a diagram on paper before translating it into a machine understandable model, using computer-aided design tools, which can then be used to perform simulations or other meaningful tasks. Traditional methods for performing sketch recognition can be broken down into three distinct categories: appearance-based, gesture-based, and geometric-based. Al- though each approach has its advantages and disadvantages, geometric-based methods have proven to be the most generalizable for multi-domain recognition. Tools, such as the LADDER symbol description language, have shown to be capable of recognizing sketches from over 30 different domains using generalizable, geometric techniques. The LADDER system is limited, however, in the fact that it uses a low-level rec- ognizer that supports only a few primitive shapes, the building blocks for describing higher-level symbols. Systems which support a larger number of primitive shapes have been shown to have questionable accuracies as the number of primitives increase, or they place constraints on how users must input shapes (e.g. circles can only be drawn in a clockwise motion; rectangles must be drawn starting at the top-left corner). This dissertation allows for a significant growth in the possibility of free-sketch recognition systems, those which place little to no drawing constraints on users. In this dissertation, we describe multiple techniques to recognize upwards of 18 primi- tive shapes while maintaining high accuracy. We also provide methods for producing confidence values and generating multiple interpretations, and explore the difficulties of recognizing multi-stroke primitives. In addition, we show the need for a standard- ized data repository for sketch recognition algorithm testing and propose SOUSA (sketch-based online user study application), our online system for performing and sharing user study sketch data. Finally, we will show how the principles we have learned through our work extend to other domains, including activity recognition using trained hand posture cues.},
author = {Paulson, Brandon Chase},
booktitle = {Office},
file = {:D$\backslash$:/Papers/Documents/2010/Paulson - 2010.pdf:pdf},
number = {May},
pages = {0},
school = {Texas A and M University},
title = {{RETHINKING PEN INPUT INTERACTION: ENABLING FREEHAND SKETCHING THROUGH IMPROVED PRIMITIVE RECOGNITION}},
type = {Doctor of Philosophy},
year = {2010}
}
@inproceedings{DSMadasu2005b,
author = {Madasu, V and Lovell, B C},
booktitle = {Digital Image Computing: Technqiues and Applications, 2005. DICTA ' 05. Proceedings},
doi = {10.1109/DICTA.2005.1578131},
file = {:D$\backslash$:/Papers/Documents/2005/Madasu, Lovell - 2005(2).pdf:pdf},
pages = {223--228},
title = {{Automatic Segmentation and Recognition of Bank Cheque Fields}},
year = {2005}
}
@mastersthesis{Foltz1998Designing,
author = {Foltz, Mark},
school = {Massachusetts Institute of Technology},
title = {{Designing Navigable Information Spaces}},
year = {1998}
}
@article{Oh1995,
abstract = {Viewing a handwritten word as an alternating sequence of characters and ligatures, we proposed a circularly interconnected network of hidden Markov models to model handwritten English words of indefinite length. The recognition problem is then regarded as finding the most probable path in the network for a given input. For the search, Viterbi algorithm is applied with lexicon lookup. To overcome directional sensitivity of the path search, a back-tracking technique is employed that keeps plausible path candidates dynamically within limited storage space.},
author = {Oh, Se-chang and HA, Jin Young and Kim, Jin-H},
file = {:D$\backslash$:/Papers/Documents/1995/Oh, HA, Kim - 1995.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Lexicon lookup,Network search,Unconstrained handwriting recognition,back tracking,hidden markov model,ligature model},
number = {11},
pages = {163--1704},
title = {{Pergamon CONTEXT Depended Search in interconnected Hidden markov Model for unconstrained handwriting recognition.}},
volume = {28},
year = {1995}
}
@inproceedings{Wenyin2002,
author = {Wenyin, L. and Dori, D.},
booktitle = {Pattern Recognition, 1998. Proceedings. Fourteenth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2002/Wenyin, Dori - 2002.pdf:pdf},
isbn = {0818685123},
keywords = {2,a set of one,as a set of,graphics recognition,interesting metrics,on the output data,performance evaluation,that a system implementing,the performance evaluation protocol,we view the performance},
pages = {1180--1182},
publisher = {IEEE},
title = {{Performance evaluation of graphics recognition algorithms: principles and applications}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=711907},
volume = {2},
year = {2002}
}
@article{Subrahmonia2000,
author = {Subrahmonia, J. and Zimmerman, T.},
doi = {10.1109/ICPR.2000.906018},
file = {:D$\backslash$:/Papers/Documents/2000/Subrahmonia, Zimmerman - 2000.pdf:pdf},
isbn = {0-7695-0750-6},
journal = {Proceedings 15th International Conference on Pattern Recognition. ICPR-2000},
pages = {60--66},
publisher = {IEEE Comput. Soc},
title = {{Pen computing: challenges and applications}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=906018},
year = {2000}
}
@inproceedings{Zhang2009b,
author = {Zhang, Yang and Shi, Guangshun and Yang, Jufeng},
booktitle = {Document Analysis and Recognition, 2009. ICDAR'09. 10th International Conference on},
doi = {10.1109/ICDAR.2009.99},
file = {:D$\backslash$:/Papers/Documents/2009/Zhang, Shi, Yang - 2009.pdf:pdf},
issn = {1520-5363},
pages = {1255--1259},
publisher = {IEEE},
title = {{HMM-Based Online Recognition of Handwritten Chemical Symbols}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5277669},
year = {2009}
}
@inproceedings{Huang2004,
author = {Huang, Xiangsheng and Li, S.Z. and Wang, Yangsheng},
booktitle = {Conference on Computer Vision and Pattern Recognition Workshop, 2004. CVPRW'04},
file = {:D$\backslash$:/Papers/Documents/2004/Huang, Li, Wang - 2004.pdf:pdf},
pages = {66--66},
title = {{Learning with cascade for classification of non-convex manifolds}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1384859},
year = {2004}
}
@article{Amara2003,
author = {Amara, Najoua Essoukri Ben},
doi = {10.1007/s10032-002-0092-6},
file = {:D$\backslash$:/Papers/Documents/2003/Amara - 2003.pdf:pdf},
journal = {International Journal on Document Analysis and Recognition},
keywords = {Reference From Doctor,arabic optical character,arabic writing,hybrid features,multiple classifiers,recognition-aocr},
mendeley-tags = {Reference From Doctor},
month = jul,
number = {4},
pages = {195--212},
title = {{Classification of Arabic script using multiple sources of information: State of the art and perspectives}},
volume = {5},
year = {2003}
}
@article{DSFarah2006,
abstract = {Automatic handwriting recognition has a variety of applications in
real world problems, such as mail sorting and check processing. Recently,
it has been demonstrated that combining the decisions of several
classifiers and integrating multiple information sources can lead
to better recognition results. This article presents an approach
for recognizing handwritten Arabic literal (legal) amounts. The proposed
system uses a set of holistic structural features to describe the
words. These features are presented to three classifiers: multilayer
neural network, k nearest neighbor, and fuzzy k nearest neighbor.
The classification results are then combined using several schemes;
we retained the score summation one for this work. A syntactic post-classification
process is then carried out to find the best match among the candidate
words. The performance of this approach is superior to the system
which ignores all contextual information and simply relies on the
recognition scores of the recognizers.},
author = {Farah, Nadir and Souici, Labiba and Sellami, Mokhtar},
doi = {DOI: 10.1016/j.engappai.2005.05.005},
file = {:D$\backslash$:/Papers/Documents/2006/Farah, Souici, Sellami - 2006.pdf:pdf},
issn = {0952-1976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {Arabic word recognition},
number = {1},
pages = {29--39},
title = {{Classifiers combination and syntax analysis for Arabic literal amount recognition}},
url = {http://www.sciencedirect.com/science/article/B6V2M-4GHBP7C-1/2/bc87267a3a3a694e878d339e250b5e34},
volume = {19},
year = {2006}
}
@article{FE8Trier1996,
abstract = {This paper presents an overview of feature extraction methods for
off-line recognition of segmented (isolated) characters. Selection
of a feature extraction method is probably the single most important
factor in achieving high recognition performance in character recognition
systems. Different feature extraction methods are designed for different
representations 6f the characters, such as solid binary characters,
character contours, skeletons (thinned characters) or gray-level
subimages of each individual character. The feature extraction methods
are discussed in terms of invariance properties, reconstructability
and expected distortions and variability of the characters. The problem
of choosing the appropriate feature extraction method for a given
application is also discussed. When a few promising feature extraction
methods have been identified, they need to be evaluated experimentally
to find the best method for the given application},
author = {Trier, \O ivind Due and Jain, Anil K and Taxt, Torfinn},
doi = {http://dx.doi.org/10.1016/0031-3203(95)00118-2},
file = {:D$\backslash$:/Papers/Documents/1996/Due Trier, Jain, Taxt - 1996.pdf:pdf},
journal = {Pattern Recognition},
keywords = { Character Recognition, Features Extraction,Survey},
number = {4},
pages = {641--662},
title = {{Feature extraction methods for character recognition-A survey.}},
volume = {29},
year = {1996}
}
@article{Mokhtarian1997,
author = {Mokhtarian, Farzin},
file = {:D$\backslash$:/Papers/Documents/1997/Mokhtarian - 1997.pdf:pdf},
issn = {1077-3142},
journal = {Computer Vision and Image Understanding},
number = {1},
pages = {1--17},
publisher = {Elsevier},
title = {{A theory of multiscale, torsion-based shape representation for space curves}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1077314297905440},
volume = {68},
year = {1997}
}
@article{Alvarado1999,
author = {Alvarado, Christine},
file = {:D$\backslash$:/Papers/Documents/1999/Alvarado - 1999.pdf:pdf},
journal = {October},
number = {October},
pages = {1--17},
publisher = {Citeseer},
title = {{Robust Recognition and Interpretation of Mechanical Design Sketches}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.23.3234\&amp;rep=rep1\&amp;type=pdf},
year = {1999}
}
@conference{ARMaddouri2008,
abstract = {Baseline extraction is hailed as an important step in handwriting
primitive extraction process, seen the insights it proffers into
the position and the length of the word. It further facilitates feature
extraction. As regards Arabic words, tow baselines can be extracted:
an upper baseline and a lower one. These tow lines divide the word
into three parts, namely, Ascender and upper diacritic points above
the upper baseline, Descender and lower diacritic points under the
lower baseline. The main content of the word lies between the two
baselines, it generally involves loops. In this paper we start with
a presentation of six baseline extraction methods. These methods
are developed and evaluated with reference to IFN/ENIT-database .
Some of them are combined in order to improve baseline position.
A comparison between these methods is made on the basis of the IFN/ENIT-database.
Results on the set a of IFN/ENIT-database evince that the Skeletonbased
method and the Min-Max \& Primitives achieve very promising results
reaching about 77\% of good results and about 87\% of acceptable results},
author = {Maddouri, Samia Snoussi and Samoud, Fadoua Bouafif and Bouriel, Kaouthar and Ellouze, Noureddine and Abed, Haikal El},
booktitle = {The 11th International Conference on Frontiers in Handwriting Recognition},
file = {:D$\backslash$:/Papers/Documents/2008/Maddouri et al. - 2008.pdf:pdf},
keywords = { Entropy, Hough transform., Skeleton, projection,Baseline},
title = {{Baseline Extraction: Comparison of Six Methods on IFN/ENIT Database}},
year = {2008}
}
@inproceedings{PDBAthitsos2005,
abstract = {This paper proposes a method for efficient nearest neighbor classification
in non-Euclidean spaces with computationally expensive similarity/distance
measures. Efficient approximations of such measures are obtained
using the BoostMap algorithm, which produces embeddings into a real
vector space. A modification to the BoostMap algorithm is proposed,
which uses an optimization cost that is more appropriate when our
goal is classification accuracy as opposed to nearest neighbor retrieval
accuracy. Using the modified algorithm, multiple approximate nearest
neighbor classifiers are obtained, that provide a wide range of trade-offs
between accuracy and efficiency. The approximations are automatically
combined to form a cascade classifier, which applies the slower and
more accurate approximations only to the hardest cases. The proposed
method is experimentally evaluated in the domain of handwritten digit
recognition using shape context matching. Results on theMNIST database
indicate that a speed-up of two to three orders of magnitude is gained
over brute force search, with minimal losses in classification accuracy.},
address = {San Diego, CA, USA},
author = {Athitsos, Vassilis and Alon, Jonathan and Sclaroff, Stan},
booktitle = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2005)},
doi = {http://dx.doi.org/10.1109/CVPR.2005.141},
file = {:D$\backslash$:/Papers/Documents/2005/Athitsos, Alon, Sclaroff - 2005.pdf:pdf},
isbn = {0-7695-2372-2},
keywords = { Classifier Cascade,MNIST},
pages = {486--493},
publisher = {IEEE Computer Society},
title = {{Efficient Nearest Neighbor Classification Using a Cascade of Approximate Similarity Measures.}},
year = {2005}
}
@article{Wohlstadter2009,
author = {Wohlstadter, Eric and Li, Peng and Cannon, Brett},
doi = {10.1109/ICWS.2009.102},
file = {:D$\backslash$:/Papers/Documents/2009/Wohlstadter, Li, Cannon - 2009.pdf:pdf},
isbn = {978-0-7695-3709-2},
journal = {2009 IEEE International Conference on Web Services},
keywords = {Software Engineering,UBC},
mendeley-tags = {Software Engineering,UBC},
month = jul,
pages = {91--98},
publisher = {Ieee},
title = {{Web Service Mashup Middleware with Partitioning of XML Pipelines}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5175811},
year = {2009}
}
@article{Gorbe2009,
author = {Gorbe, M.J.C.S.E.J. and Zamora, F. and Prat, D.L.A.M.F. and Vilar, JM},
doi = {10.1109/ICDAR.2009.209},
file = {:D$\backslash$:/Papers/Documents/2009/Gorbe et al. - 2009.pdf:pdf},
journal = {cafre.dsic.upv.es},
pages = {1260--1264},
title = {{Improving a DTW-based recognition engine for on-line handwritten characters by using MLPs}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Improving+a+DTW-based+Recognition+Engine+for+On-line+Handwritten+Characters+by+Using+MLPs\#0},
year = {2009}
}
@article{Markowska-Kaczmar2005,
author = {Markowska-Kaczmar, U. and Kubacki, P.},
file = {:D$\backslash$:/Papers/Documents/2005/Markowska-Kaczmar, Kubacki - 2005.pdf:pdf},
journal = {Design},
publisher = {IEEE Computer Society},
title = {{Support vector machines in handwritten digits classification}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ISDA.2005.87},
year = {2005}
}
@article{Hammond2001,
author = {Hammond, Tracy},
file = {:D$\backslash$:/Papers/Documents/2001/Hammond - 2001.pdf:pdf},
journal = {Artificial Intelligence},
title = {{Automatically Generating Sketch Interfaces from Shape Descriptions}},
year = {2001}
}
@conference{ARElAbed2009,
abstract = {The recognition of handwritten characters, words, and text arouses
great interest today. To develop the best working system is subject
of many papers published. With this paper, methods to improve the
performance of existing word recognition systems are discussed. The
availability of a sufficient data sets for training and testing the
system assumed, optimization algorithms are presented. The usage
of different feature sets and the combination of different recognizers
are proposed. Tests with Arabic handwriting recognition systems using
the reference IfN/ENIT-database show the usefulness of the proposed
methods. An improvement of the recognition rate of up to 28\% of the
best single system is achieved.},
author = {Abed, Haikal El and Margner, Volker},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Abed, Margner - 2009.pdf:pdf},
title = {{How to Improve a Handwriting Recognition System}},
year = {2009}
}
@article{Blumenstein2007,
abstract = {This paper describes and analyses the performance of a novel feature extraction technique for the recognition of segmented/cursive characters that may be used in the context of a segmentation-based handwritten word recognition system. The Modified Direction Feature (MDF) extraction technique builds upon the Direction Feature (DF) technique proposed previously that extracts direction information from the structure of character contours. This principal was extended so that the direction information is integrated with a technique for detecting transitions between background and foreground pixels in the character image. In order to improve on the DF extraction technique, a number of modifications were undertaken. With a view to describe the character contour more effectively, a re-design of the direction number determination technique was performed. Also, an additional global feature was introduced to improve the recognition accuracy for those characters that were most frequently confused with patterns of similar appearance. MDF was tested using a neural network-based classifier and compared to the DF and Transition Feature (TF) extraction techniques. MDF outperformed both DF and TF techniques using a benchmark dataset and compared favourably with the top results in the literature. A recognition accuracy of above 89\% is reported on characters from the CEDAR dataset.},
author = {Blumenstein, M and Liu, X Y},
file = {:D$\backslash$:/Papers/Documents/2007/Blumenstein, Liu - 2007.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Handwritten Character Recognition,Image Processing and Computer Vision,Neural Networks.,Pattern Recognition,Reference From Doctor},
mendeley-tags = {Reference From Doctor},
number = {2},
pages = {376--388},
title = {{An Investigation of the Modified Direction Feature for Cursive Character Recognition An Investigation of the Modified Direction Feature for Cursive Character Recognition}},
volume = {40},
year = {2007}
}
@article{DSAlMuhtaseb2009,
abstract = {This paper presents a minimal Arabic text that covers

the different basic shapes of Arabic alphabet (viz. standalone, initial,

medial, and terminal). It is designed with minimal repetition of

character shapes in the minimal text. The novelty of the suggested

script could be seen from different perspectives. It enables the

collection of handwritten text from different writers with minimized

effort and time. It is enough for a writer to write three lines of

meaningful Arabic text to cover all possible character shapes, a total

of 125 shapes. The written text is designed to have even distribution

of letter frequencies. This assures enough samples of all character

shapes when text is collected from enough number of writers. The

same is true for printed Arabic text. This is especially useful when

using large number of features with classifiers that require large

number of samples for each category. Hidden Markov Models and

Neural networks are two examples of these classifiers. The use of
the

minimal text enables proper training, as all Arabic character shapes

are present with adequate frequency, hence resulting in higher

recognition rates. This is not the case with natural text where the

frequency of some Arabic characters differ widely, where in some

cases 100 folds or more. The proposed minimal text may be used to

build a data base of handwritten Arabic text collected of many

writers. This covers the need for a database in the research of Arabic

handwritten text recognition and benchmarking.

In addition, this paper presents statistical analysis of Arabic

corpora for estimating the number of occurrences of the different

shapes of Arabic characters in large corpora. The frequency of Arabic

characters could be used in different applications. In this research

work, it was utilized in enhancing the search for the minimal Arabic

text.},
author = {Al-Muhtaseb, Husni A and Mahmoud, Sabri A and Qahwahi, Rami S},
file = {:D$\backslash$:/Papers/Documents/2009/Al-Muhtaseb, Mahmoud, Qahwahi - 2009.pdf:pdf},
journal = {INTERNATIONAL JOURNAL OF CIRCUITS, SYSTEMS AND SIGNAL PROCESSING},
keywords = { Arabic OCR databases, Minimal Arabic script.,Arabic text recognition},
number = {3},
pages = {142--153},
title = {{A Novel Minimal Script for Arabic Text Recognition Databases and Benchmarks}},
volume = {3},
year = {2009}
}
@article{MCZhang2006,
abstract = {In this paper, we propose a novel local steerable phase (LSP) feature
extracted from the face image using steerable filters for face recognition.
The new type of local feature is semi-invariant under common image
deformations and distinctive enough to provide useful identity information.
Phase information provided by steerable filters is locally stable
with respect to scale changes, noise and brightness changes. Phase
features from multiple scales and orientations are concatenated to
an augmented feature vector which is used to evaluate similarity
between face images. We use a nearest-neighbor classifier based on
the local weighted phase-correlation for final classification. The
experimental results on FERET dataset show an encouraging recognition
performance.},
author = {Zhang, Xiaoxun and Jia, Yunde},
file = {:D$\backslash$:/Papers/Documents/2006/Zhang, Jia - 2006.pdf:pdf},
journal = {Pattern Recognition Letters},
keywords = {Steerable filters; Phase feature; Face recognition},
pages = {1927�1933},
title = {{Face recognition with local steerable phase feature}},
volume = {27},
year = {2006}
}
@article{Lorigo2006,
abstract = {The automatic recognition of text on scanned images has enabled many applications such as searching for words in large volumes of documents, automatic sorting of postal mail, and convenient editing of previously printed documents. The domain of handwriting in the Arabic script presents unique technical challenges and has been addressed more recently than other domains. Many different methods have been proposed and applied to various types of images. This paper provides a comprehensive review of these methods. It is the first survey to focus on Arabic handwriting recognition and the first Arabic character recognition survey to provide recognition rates and descriptions of test data for the approaches discussed. It includes background on the field, discussion of the methods, and future research directions.},
author = {Lorigo, Liana M and Govindaraju, Venu},
doi = {10.1109/TPAMI.2006.102},
file = {:D$\backslash$:/Papers/Documents/2006/Lorigo, Govindaraju - 2006.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Arabs,Artificial Intelligence,Documentation,Documentation: methods,Handwriting,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Models, Statistical,Online Systems,Pattern Recognition, Automated,Pattern Recognition, Automated: methods},
month = may,
number = {5},
pages = {712--24},
pmid = {16640258},
title = {{Offline Arabic handwriting recognition: a survey.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16640258},
volume = {28},
year = {2006}
}
@article{Khorsheed2002,
abstract = {Off-line recognition requires transferring the text under consideration into an image file. This represents the only available solution to bring the printed materials to the electronic media. However, the transferring process causes the system to lose the temporal information of that text. Other complexities that an off-line recognition system has to deal with are the lower resolution of the document and the poor binarisation, which can contribute to readability when essential features of the characters are deleted or obscured. Recognising Arabic script presents two additional challenges: orthography is cursive and letter shape is context sensitive. Certain character combinations form new ligature shapes, which are often font-dependent. Some ligatures involve vertical stacking of characters. Since not all letters connect, word boundary location becomes an interesting problem, as spacing may separate not only words, but also certain characters within a word. Various techniques have been implemented to achieve high recognition rates. These techniques have tackled different aspects of the recognition system. This review is organised into five major sections, covering a general overview, Arabic writing characteristics, Arabic text recognition system, Arabic OCR software and conclusions.},
author = {Khorsheed, M. S.},
doi = {10.1007/s100440200004},
file = {:D$\backslash$:/Papers/Documents/2002/Khorsheed - 2002.pdf:pdf},
issn = {1433-7541},
journal = {Pattern Analysis \& Applications},
keywords = {Reference From Doctor,arabic ocr,feature extraction,fourier transform,hidden markov models,horizontal projection,hough transform,networks,neural,off-line recognition,preprocessing segmentation,vertical projection},
mendeley-tags = {Reference From Doctor},
month = may,
number = {1},
pages = {31--45},
title = {{Off-Line Arabic Character Recognition - A Review}},
url = {http://www.springerlink.com/openurl.asp?genre=article\&id=doi:10.1007/s100440200004},
volume = {5},
year = {2002}
}
@article{Willems2009,
abstract = {Many handwritten gestures, characters, and symbols comprise multiple pendown strokes separated by penup strokes. In this paper, a large number of features known from the literature are explored for the recognition of such multi-stroke gestures. Features are computed from a global gesture shape. From its constituent strokes, the mean and standard deviation of each feature are computed. We show that using these new stroke-based features, significant improvements in classification accuracy can be obtained between 10\% and 50\% compared to global feature representations. These results are consistent over four different databases, containing iconic pen gestures, handwritten symbols, and upper-case characters. Compared to two other multi-stroke recognition techniques, improvements between 25\% and 39\% are achieved, averaged over all four databases.},
author = {Willems, Don and Niels, Ralph and van Gerven, Marcel and Vuurpijl, Louis},
doi = {10.1016/j.patcog.2009.01.030},
file = {:D$\backslash$:/Papers/Documents/2009/Willems et al. - 2009.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {feature selection,iconic gestures,multi-stroke gesture recognition},
month = dec,
number = {12},
pages = {3303--3312},
title = {{Iconic and multi-stroke gesture recognition}},
url = {http://dx.doi.org/10.1016/j.patcog.2009.01.030},
volume = {42},
year = {2009}
}
@inproceedings{Hammond2002Agent,
author = {Hammond, Tracy and Gajos, Krzysztof and Davis, Randall and Shrobe, Howard},
booktitle = {Proceedings of International Workshop on Agents In Design, WAID'02},
title = {{An Agent-Based System For Capturing and Indexing Software Design Meetings}},
year = {2002}
}
@inproceedings{DSXu2003,
abstract = {This paper describes a system being developed to recognize date information
handwritten on Canadian bank cheques. A segmentation based strategy
is adopted in this system. In order to achieve high performances
in terms of efficiency and reliability, a knowledge-based module
is proposed for the date segmentation and a cursive month word recognition
module is implemented based on a combination of classifiers. The
interaction between the segmentation and recognition stages is properly
established by using multihypotheses generation and evaluation modules.
As a result, promising performance is obtained on a test set from
a real life standard cheque database},
annote = {Edited in 2 march 2010},
author = {Xu, Qizhi and Lam, Louisa and Suen, C Y},
booktitle = {Document Analysis and Recognition, 2003. Proceedings. Seventh International Conference on},
file = {:D$\backslash$:/Papers/Documents/2003/Xu, Lam, Suen - 2003.pdf:pdf},
pages = {704--708},
title = {{Automatic segmentation and recognition system for handwritten dates on Canadian bank cheques}},
year = {2003}
}
@inproceedings{Nishimura2002,
abstract = {The purpose of our research is to improve the recogni- tion rate of off-line character recognition systems using the HMM (Hidden Markov Model) without increasing a num- ber of HMM parameters too much. Some 2-dimensional HMM character recognition systems have been proposed to increase representational power. However, since 2–D HMM has much more complex structure and thus requires much more parameters than 1-dimensional HMM, it be- comes very hard to gather sufficient samples in order to guarantee the successful generalization. To overcome the problem, we propose amethod for character recognition us- ing 1–D HMMs in multiple directions with 2-dimensional feature extraction. To further improve the performance, some voting method useing bagging algorithmare also ex- ploited. In our experiment, the recognition rate is increased by about 1\% with the multiple directional HMM charac- ter recognition system compared to the 1–D HMMcharac- ter recognition system. The recognition rate is further in- creased by about 1\% with the HMM character recognition system using bagging algorithm.},
author = {Nishimura, Hiromitsu and Kobayashi, Makoto and Maruyama, Minoru and Nakano, Yasuaki},
booktitle = {Document Analysis and Recognition, 1999. ICDAR'99. Proceedings of the Fifth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2002/Nishimura et al. - 2002.pdf:pdf},
isbn = {0769503187},
pages = {49--52},
publisher = {IEEE},
title = {{Off-line character recognition using HMM by multiple directional feature extraction and voting with bagging algorithm}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=791722},
year = {2002}
}
@inproceedings{Han2007,
abstract = {This paper presents a systematic multi-path HMM topology design algorithm to better model online handwriting of East Asian characters. This data-driven algorithm solves three key problems in HMM topology design. First, HMM path number determination is formalized as a clustering problem using Subsequence Direction Histogram Vector (SDHV) as feature of both writing order and style. Second, Curvature Scale Space-based (CSS-based) substroke segmentation is used to calculate the optimal state number and initial state parameters. Third, Self-rotation restricted corner state and imaginary stroke state are designed to determine state connectivity and Gaussian mixture number in order to achieve better state alignment. Experiments on large character sets demonstrate both a significant relative error reduction rate and high recognition accuracy using the proposed algorithm.},
author = {Han, Shi and Chang, Ming and Zou, Yu and Chen, Xinjian and Zhang, Dongmei},
booktitle = {Document Analysis and Recognition, 2007. ICDAR 2007. Ninth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2007/Han et al. - 2007.pdf:pdf},
issn = {1520-5363},
pages = {604--608},
publisher = {IEEE},
title = {{Systematic Multi-Path HMM Topology Design for Online Handwriting Recognition of East Asian Characters}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4376986},
volume = {2},
year = {2007}
}
@inproceedings{ARBroumandnia2007,
abstract = {This paper presents a novel holistic Handwritten Farsi /Arabic Word
Recognition scheme in situation where we face with word rotation
and scale change. Image words features are extracted by exploiting
rotation and scale invariance characteristics of M-Band packet wavelet
transform performed on polar transform version of images of handwritten
Farsi/Arabic words. The extracted features construct a feature vector
for each word image. This vector is employed in recognition phase
by finding the similar words based on the least Mahalanobis distance
of feature vectors. This scheme is robust against rotation and scaling.
Experimental results, obtained from testing different handwritten
texts with various orientations and scales, show that proposed scheme
outperforms Fourier-wavelet and Zernike moments algorithms. The robustness
of new scheme has been tested with images corrupted by Gaussian noise
and compared with similar schemes. Experimental results show that
the accuracy of our algorithm reaches 95.8 percents.},
author = {Broumandnia, A and Shanbehzadeh, J and Nourani, M},
booktitle = {AICCSA '07. IEEE/ACS International Conference on Computer Systems and Applications, 2007.},
file = {:D$\backslash$:/Papers/Documents/2007/Broumandnia, Shanbehzadeh, Nourani - 2007.pdf:pdf},
keywords = { Farsi/Arabic Handwritings Recognition, Wavelet Transform,Pattern Recognition},
publisher = {IEEE},
title = {{Handwritten Farsi/Arabic Word Recognition}},
year = {2007}
}
@inproceedings{Augimeri2006,
abstract = {In this paper, we describe the efficient imple- mentation of M-Sparrow, an adaptive flocking algorithm based on the biology-inspired paradigm of a flock of birds. We extended the classical flock model of Reynolds with two new characteristics: the movement in a multi-dimensional space and different kinds of birds. The birds, in this con- text, are used to discovery point having some desired char- acteristics in a multidimensional space. A critical point of the algorithm is the efficient search of the k-neighbors in a multidimensional space. This search was efficiently imple- mented using the ANN libraries.},
author = {Augimeri, Antonio and Folino, Gianluigi and Forestiero, Agostino and Spezzano, Giandomenico},
booktitle = {Proceedings of the 7th WOA 2006 Workshop, From Objects to Agents (Dagli Oggetti Agli Agenti), Catania, Italy, September 26-27},
file = {:D$\backslash$:/Papers/Documents/2006/Augimeri et al. - 2006.pdf:pdf},
pages = {16--20},
title = {{A multidimensional flocking algorithm for clustering spatial data}},
year = {2006}
}
@article{Dehghan2001,
abstract = {{A holistic system for the recognition of handwritten Farsi/Arabic words using right\}left discrete hidden Markov models (HMM)and Kohonen self-organizing vector quantization is presented. The histogram of chain-code directions of the image strips, scanned from right to left by a sliding window, is used as feature vectors. The neighborhood information preserved in the self-organizing feature map (SOFM), is used for smoothing the observation probability distributions of trained HMMs. Experiments carried out on test samples show promising performance results.  2001 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved},
author = {Dehghan, M},
doi = {10.1016/S0031-3203(00)00051-0},
file = {:D$\backslash$:/Papers/Documents/2001/Dehghan - 2001.pdf:pdf},
journal = {Pattern Recognition},
keywords = {arabic,farsi,handwriting recognition,handwritten word recognition,hidden markov model,parameter smoothing,self-organizing feature map},
month = may,
number = {5},
pages = {1057--1065},
title = {{Handwritten Farsi (Arabic) word recognition: a holistic approach using discrete HMM}},
volume = {34},
year = {2001}
}
@incollection{ARBelaid2008,
abstract = {This paper summarizes techniques proposed for off-line Arabic word recognition. This point of view concerns the human reading favoring an interactive mechanism between global memorization and local verification sim- plifying the recognition of complex scripts such as Arabic. According to this consideration, specific papers are analyzed with comments on strategies.},
author = {Belaid, Abdel and Choisy, Christophe},
booktitle = {SACH},
file = {:D$\backslash$:/Papers/Documents/2008/Belaid, Choisy - 2008.pdf:pdf},
keywords = {Read},
mendeley-tags = {Read},
pages = {36�56},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Human Reading Based Strategies for Off-Line Arabic Word Recognition}},
year = {2008}
}
@article{FE9Shi2002,
abstract = {In this paper, the authors study on the use ofgradient and curvature
ofthe gray scale character image to improve the accuracy ofhandwritten
numeral recognition. Three procedures, based on curvature coe2cient,
bi-quadratic interpolation and gradient vector interpolation, are
proposed for calculating the curvature ofthe equi-gray scale curves
ofan input image. Then two procedures to compose a feature vector
ofthe gradient and the curvature are described. The e2ciency ofthe
feature vectors are tested by recognition experiments for the handwritten
numeral database IPTP CDROM1 and NIST SD3 and SD7. The experimental
results show the usefulness of the curvature feature and recognition
rate of 99.49\% and 98.25\%, which are one ofthe highest rates ever
reported for these databases (H. Kato et al., Technical Report ofIEICE,
PRU95-3, 1995, p. 17; R.A. Wilkinson et al., Technical Report NISTIR
4912, August 1992; J. Geist et al., Technical Report NISTIR 5452,
June 1994), are achieved, respectively},
author = {Shi, Meng and Fujisawa, Yoshiharu and Wakabayashi, Tetsushi and Kimura, Fumitaka},
doi = {http://dx.doi.org/10.1016/S0031-3203(01)00203-5},
file = {:D$\backslash$:/Papers/Documents/2002/Shi et al. - 2002.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Handwritten digits},
number = {10},
pages = {2051--2059},
title = {{Handwritten numeral recognition using gradient and curvature of gray scale image.}},
volume = {35},
year = {2002}
}
@article{Kurlander1993,
address = {New York, New York, USA},
author = {Kurlander, David},
doi = {10.1145/169059.169524},
file = {:D$\backslash$:/Papers/Documents/1993/Kurlander - 1993.pdf:pdf},
isbn = {0897915755},
journal = {Proceedings of the SIGCHI conference on Human factors in computing systems - CHI '93},
pages = {529},
publisher = {ACM Press},
title = {{Graphical editing by example (abstract)}},
url = {http://portal.acm.org/citation.cfm?doid=169059.169524},
year = {1993}
}
@article{Alma'adeed2002,
abstract = {Hidden Markov Models (HMM) have been used with some success in recognizing printed Arabic words. In this paper, a complete scheme for torallj, unconstrained Arabic handwritten word recognition based on a Model discriminant HMM is presented. A complere svstem able to classiJj Arabic-Handwritten words of one hundred different writers is proposed and discussed. The system first attempts to remove some of variation in the images that do nor affect the identity of the handwritten word. Next, the system codes the skeleton and edge of rhe word so that feature i!rformation about the lines in the skeleton is extracted. Then a classification process based on the HMM approach is used. The output is a word in the dicrionary A detaiedl experimenr is carried out and successful recognition results are reported},
author = {Alma'adeed, S. and Higgens, C. and Elliman, D.},
doi = {10.1109/ICPR.2002.1047981},
file = {:D$\backslash$:/Papers/Documents/2002/Alma'adeed, Higgens, Elliman - 2002.pdf:pdf},
isbn = {0-7695-1695-X},
journal = {Object recognition supported by user interaction for service robots},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {481--484},
publisher = {IEEE Comput. Soc},
title = {{Recognition of off-line handwritten Arabic words using hidden Markov model approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1047981},
year = {2002}
}
@inproceedings{Ouyang2007,
author = {Ouyang, T.Y. and Davis, Randall},
booktitle = {Proceedings of the national conference on artificial intelligence},
file = {:D$\backslash$:/Papers/Documents/2007/Ouyang, Davis - 2007.pdf:pdf},
keywords = {Applications,Multidisciplinary,Technical Papers},
number = {1},
pages = {846},
publisher = {Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999},
title = {{Recognition of hand drawn chemical diagrams}},
url = {http://www.aaai.org/Papers/AAAI/2007/AAAI07-134.pdf},
volume = {22},
year = {2007}
}
@article{DueTrier1996,
abstract = {-This paper presents an overview of feature extraction methods for off-line recognition of segmented (isolated) characters. Selection of a feature extraction method is probably the single most important factor in achieving high recognition performance in character recognition systems. Different feature extraction methods are designed for different representations 6f the characters, such as solid binary characters, character contours, skeletons (thinned characters) or gray-level subimages of each individual character. The feature extraction methods are discussed in terms of invariance properties, reconstructability and expected distortions and variability of the characters. The problem of choosing the appropriate feature extraction method for a given application is also discussed. When a few promising feature extraction methods have been identified, they need to be evaluated experimentally to find the best method for the given application.},
author = {{Due Trier}, Oivind R. and Jain, Anil.K. and Taxt, Torfinn.},
file = {:D$\backslash$:/Papers/Documents/1996/Due Trier, Jain, Taxt - 1996.pdf:pdf},
journal = {Pattern recognition},
keywords = {Character representation Invariance,Feature extraction,Optical character recognition,Reconstructability},
number = {4},
pages = {641--662},
publisher = {Elsevier},
title = {{Feature extraction methods for character recognition-a survey}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0031320395001182},
volume = {29},
year = {1996}
}
@article{Burrow2004,
author = {Burrow, Peter},
file = {:D$\backslash$:/Papers/Documents/2004/Burrow - 2004.pdf:pdf},
journal = {Report of Master of Science School of Informatics, University of Edinburgh},
publisher = {Citeseer},
title = {{Arabic handwriting recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.404\&amp;rep=rep1\&amp;type=pdf},
year = {2004}
}
@inproceedings{Hammond2006a,
author = {Hammond, Tracy and Davis, Randall},
booktitle = {ACM SIGGRAPH 2006 Courses},
file = {:D$\backslash$:/Papers/Documents/2006/Hammond, Davis - 2006.pdf:pdf},
isbn = {1595933646},
pages = {25},
publisher = {ACM},
title = {{Tahuti: A geometrical sketch recognition system for uml class diagrams}},
url = {http://portal.acm.org/citation.cfm?id=1185786},
year = {2006}
}
@article{Stutzle2000,
author = {Stutzle, Thomas and Linke, Sebastian},
file = {:D$\backslash$:/Papers/Documents/2000/Stutzle, Linke - 2000.pdf:pdf},
journal = {Mathware and soft computing},
number = {1},
pages = {1--14},
title = {{Experiments with variants of ant algorithms}},
volume = {7},
year = {2000}
}
@article{Gander1994,
author = {Gander, Walter},
doi = {10.1007/BF01934268},
file = {:D$\backslash$:/Papers/Documents/1994/Gander - 1994.pdf:pdf},
journal = {Bit},
month = dec,
number = {2},
pages = {317--578},
title = {{Least-squares fitting of circles and ellipses}},
volume = {88/89},
year = {1994}
}
@article{Graves2009,
abstract = {Recognizing lines of unconstrained handwritten text is a challenging task. The difficulty of segmenting cursive or overlapping characters; and analyze its use of context. Last; combined with the need to exploit surrounding context; despite their well-known shortcomings. This paper proposes an alternative approach based on a novel type of recurrent neural network; has led to low recognition rates for even the best current recognizers. Most recent progress in the field has been made either through improved preprocessing or through advances in language modeling. Relatively little work has been done on the basic recognition algorithms. Indeed; measure the individual influence of its hidden layers; most systems rely on the same hidden Markov models that have been used for decades in speech and handwriting recognition; our approach achieves word recognition accuracies of 79.7 percent on online data and 74.1 percent on offline data; significantly outperforming a state-of-the-art HMM-based system. In addition; specifically designed for sequence labeling tasks where the data is hard to segment and contains long-range bidirectional interdependencies. In experiments on two large unconstrained handwriting databases; suggesting reasons for the network’s superior performance.; we demonstrate the network’s robustness to lexicon size; we provide an in-depth discussion of the differences between the network and HMMs},
author = {Graves, Alex and Liwicki, Marcus and Fern\'{a}ndez, S. and Bertolami, Roman and Bunke, Horst and Schmidhuber, J.},
file = {:D$\backslash$:/Papers/Documents/2008/Graves et al. - 2008.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {HMM,Handwriting recognition,bidirectional long short-term memory,connectionist temporal classification,hidden Markov model.,offline handwriting,online handwriting,recurrent neural networks},
mendeley-tags = {HMM},
number = {5},
pages = {855--868},
publisher = {Published by the IEEE Computer Society},
title = {{A novel connectionist system for unconstrained handwriting recognition}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/TPAMI.2008.137},
volume = {31},
year = {2008}
}
@article{Mahmoud2008,
abstract = {This paper describes a technique for the recognition of optical off-line handwritten Arabic (Indian) numerals using hidden Markov models (HMM). The success of HMM in speech recognition encouraged researchers to apply it to text recognition. In this work we did not follow the general trend of using sliding windows in the direction of the writing line to generate features. Instead we generated features based on the digit as a unit. Angle-, distance-, horizontal-, and vertical-span features are extracted from Arabic (Indian) numerals and used in training and testing the HMM. These features proved to be simple and effective. In addition to the HMM the nearest neighbor classifier is used. The results of both classifiers are then compared. Several experiments were conducted for estimating the suitable number of states for the HMM. The best results were achieved with an HMM model with 10 states. In addition, we experimented with different number of features. The best results were achieved with 120 feature vector representing a digit. A database of 44 writers, each writer wrote 48 samples of each digit resulting in a database of 21,120 samples. The data were size normalized to enable the technique to be size invariant. In extracting the features the center of gravity of the digit is used to make the technique translation invariant. The randomization technique was used to generate Arabic (Indian) numbers for training and testing the HMM classifier. The randomization was done on the number of digits per number and on the digit sequence. About 2171 Arabic (Indian) numbers were generated, totaling 21,120 digits. 1700 numbers (totaling 16,657 digits) were used in training the HMM and 471 numbers (totaling 4463 digits) are used in testing the HMM. The samples of the first 24 writers were used in training the nearest neighbor classifier and the remaining 20 writers' samples were used in testing. The achieved average recognition rates are 97.99\% and 94.35\% using the HMM and the nearest neighbor classifiers, respectively. The classification errors were analyzed and it was clear that some errors may be attributed to bad data, some to deformation and unbalanced proportion of digit segments, different writing styles of some digits, errors between digit pairs were specified and analyzed, and genuine errors. It was clear that the real misclassification of genuine data, in the case of HMM was nearly 1\%. This proves the effectiveness of the presented technique to writer-independent off-line Arabic (Indian) handwritten digit recognition. The technique is writer independent as separate writers' data were used in training of the classifiers and other writers' data were used in the testing phase.},
annote = {=================================  Review Template ===========================================
          
Paper Index : Mahmoud2008
          
Date:15 - Nov- 2010 

        
          
Why read paper ?
        
HMM background - digit recognition. 

        
          
Paper overview?
        

        
offline diigts 
no sliding windows, counting pixels for featrues. 

        
          
What is these paper about ? (Summary)
        

        
1) features extraction using 
a) angular span 
which draw lines to dsegment digit from center of gravity of digt to cover every alpha then count number of pixel in slice/ no. of pixel in digit. (pixel density)
b) distance 
draw concentric circles from center of gravity then compute density in each circle 
c) horizontal and vertical 
divide the cdigit into 20- vertical and horizontal strip then compute density in each strip. 
2) HMM traing by giving 20 features in sequence to get 120 obersvation fo 10 features for each digit. Each digit have his HMM model and each has 5 state model. 
3) a comparison with KNN and HMM 
To test the numerical string a randomizied order is generated from a images in the dataset. 

        
the data is collected from 44 writer X 48 tiems with result in 21000 sampels 

        
different feature vector lenght is test but best is 120 features. 
best result with HMM with 10 state for each digit is 98.8 \% 
Knn result is 94.35\% 
          
1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?
        
Simple features are only counting black pixels. 
          
2. What can we take from this work  ? what do we learn ? What can be incorporated into our own work ?
        
 The division of features into sequence of vectors for each digits, HMM model of training and building for each digit. 
          
3. What are the problems of the paper ?
        

        

        
          
4. what is lacking from the work ? why does this work knot be the final  research in this subject ?
        
Improvement on recognition rate can be done if using more robosut features. 

        
          
5. what about the methods causes this lack ? is there a fundamental reason ?
        

        
          
6. Could incremental Changes Fix this lack ? if so, what changes ? 
        
Some more robosut features. 

        
Is there is any question you had about the paper ? 

        

        
          
The final conclusion..........
        

        
Good paper can use the features and method to present feature vector to hmm. 

        
==========================================================================},
author = {Mahmoud, Sabri},
file = {:D$\backslash$:/Papers/Documents/2008/Mahmoud - 2008.pdf:pdf},
issn = {0165-1684},
journal = {Signal Processing},
keywords = {Arabic (Indian) numeral recognition,Arabic Handwritting recognition,HMM,Handwritten digit recognition,Independent writer recognition,Normalization,OCR,Read,Summarized},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
number = {4},
pages = {844--857},
title = {{Recognition of writer-independent off-line handwritten Arabic (Indian) numerals using hidden Markov models}},
url = {http://portal.acm.org/citation.cfm?id=1330786},
volume = {88},
year = {2008}
}
@article{Weijer2001,
author = {Weijer, Joost Van De and Vliet, Lucas J Van and Verbeek, Piet W and Ginkel, Michael Van},
file = {:D$\backslash$:/Papers/Documents/2001/Weijer et al. - 2001.pdf:pdf},
journal = {IEEE transactions on pattern analysis and machine intelligence},
number = {9},
pages = {1035--1043},
title = {{Curvature Estimation in Oriented Patterns Using Curvilinear Models Applied to Gradient Vector Fields}},
volume = {23},
year = {2001}
}
@article{Sezgin2003RecognitionSOW,
author = {Sezgin, Tevfik Metin},
journal = {Proceedings of the MIT Student Oxygen Workshop},
title = {{Recognition efficiency issues for freehand sketches}},
year = {2003}
}
@inproceedings{PDB17Domeniconi2001,
abstract = {SVMs suffer from the problem of large memory requirement and CPU time
when trained in batch mode on large data sets. We overcome these
limitations,and at the same time make SVMs suitable for learning
with data streams,by constructing incremental learning algorithms.
We first introduce and compare different incremental learning techniques,and
show that they are capable of producing performance results similar
to the batch algorithm, and in some cases superior condensation properties.
We then consider the problem of training SVMs using stream data.
Our objective is to maintain an updated representation of recent
batches of data. We apply incremental schemes to the problem and
show that their accuracy is comparable to the batch algorithm.},
address = {San Jose, California, USA},
author = {Domeniconi, Carlotta and Gunopulos, Dimitrios},
booktitle = {Proceedings of the 2001 IEEE International Conference on Data Mining},
editor = {Cercone, Nick and Lin, Tsau Young and Wu, Xindong},
file = {:D$\backslash$:/Papers/Documents/2001/Domeniconi, Gunopulos - 2001.pdf:pdf},
isbn = {0-7695-1119-8},
pages = {589--592},
publisher = {IEEE Computer Society},
title = {{Incremental Support Vector Machine Construction.}},
year = {2001}
}
@inproceedings{Hammond2009,
author = {Hammond, Tracy and Davis, Randall},
booktitle = {Proceedings of Graphics Interface 2009},
file = {:D$\backslash$:/Papers/Documents/2009/Hammond, Davis - 2009.pdf:pdf},
pages = {157--166},
publisher = {Canadian Information Processing Society},
title = {{Recognizing interspersed sketches quickly}},
url = {http://portal.acm.org/citation.cfm?id=1555880.1555917},
year = {2009}
}
@inproceedings{Mane2009,
author = {Mane, Vanita and Ragha, Lena},
booktitle = {Proceedings of the International Conference on Advances in Computing, Communication and Control},
file = {:D$\backslash$:/Papers/Documents/2009/Mane, Ragha - 2009.pdf:pdf},
pages = {410--415},
publisher = {ACM},
title = {{Handwritten character recognition using elastic matching and PCA}},
url = {http://portal.acm.org/citation.cfm?id=1523103.1523184},
year = {2009}
}
@inproceedings{DSXu2001,
abstract = {Segmenting handwritten date fields on bank cheque images into three
subimages corresponding to the day, month and year is the first and
critical step of our date recognition system. The paper describes
a knowledge-based segmentation system, which introduces different
kinds of knowledge at different segmentation stages to improve the
performance. The knowledge includes information on the writing style,
syntactic and semantic constraints, etc. Results have shown that
the system is very effective compared with a previous structural
feature based method},
author = {Xu, Qizhi and Lam, L and Suen, C Y},
booktitle = {Document Analysis and Recognition, 2001. Proceedings. Sixth International Conference on},
doi = {10.1109ICDAR.2001.953818},
file = {:D$\backslash$:/Papers/Documents/2001/Xu, Lam, Suen - 2001.pdf:pdf},
keywords = {bank cheque images;date recognition system;handwri},
pages = {384--388},
title = {{A knowledge-based segmentation system for handwritten dates on bank cheques}},
year = {2001}
}
@article{Zhang2009c,
abstract = {Particle swarm optimization (PSO) is adapted to simulate dynamic economic games. The robustness and speed of the PSO algorithm is compared to a genetic algorithm (GA) in a Cournot oligopsony market. Artificial agents with the PSO learning algorithm find the optimal strategies that are predicted by theory. PSO is simpler and more robust to changes in algorithm parameters than GA. PSO also converges faster and gives more precise answers than the GA method which was used by some previous economic studies.},
author = {Zhang, T. and Brorsen, B.W.},
file = {:D$\backslash$:/Papers/Documents/2009/Zhang, Brorsen - 2009.pdf:pdf},
issn = {0927-7099},
journal = {Computational Economics},
keywords = {agent-based market particle swarm,algorithm simulation,optimization genetic},
number = {4},
pages = {399--417},
publisher = {Springer},
title = {{Particle Swarm Optimization Algorithm for Agent-Based Artificial Markets}},
url = {http://www.springerlink.com/index/t15x34772k356pvx.pdf},
volume = {34},
year = {2009}
}
@inproceedings{Hammond2002c,
author = {Hammond, Tracy Anne and Davis, Randall},
booktitle = {AAAI Spring Symposium: Sketch Recognition.},
file = {:D$\backslash$:/Papers/Documents/2002/Hammond, Davis - 2002(3).pdf:pdf},
pages = {1},
title = {{Tahuti: A Geometrical Sketch Recognition System for UML Class Diagrams}},
year = {2002}
}
@article{ARPlamondon2006,
abstract = {The study of rapid strokes is a direct or indirect prerequisite in many fundamental research projects, as well as in the design of many practical applications dealing with handwriting. This paper outlines a family of models, derived from the Kinematic Theory of Human Movements. It explains how the nested models in this family can be used coherently, in the context of a multi-level representation paradigm, to analyze both the trajectory and the velocity of strokes with a progressive amount of detail. In the context of a comprehensive survey of previously published work, this paper highlights many new features of stroke production, when the vectorial version of the theory is fully exploited. In this perspective, the Kinematic Theory is depicted as a potential tool to facilitate communications among researchers working in the multi-disciplinary field of Graphonomics.},
author = {Plamondon, Re�jean and Djioua, Moussa},
file = {:D$\backslash$:/Papers/Documents/2006/Plamondon, Djioua - 2006.pdf:pdf},
journal = {Human Movement Science},
keywords = {Delta�logno,Handwriting strokes,Kinematic Theory},
pages = {586--607},
title = {{A multi-level representation paradigm for handwriting stroke generation}},
volume = {25},
year = {2006}
}
@article{Oltmans,
author = {Oltmans, Michael and Davis, Randall},
file = {:D$\backslash$:/Papers/Documents/Unknown/Oltmans, Davis - Unknown.pdf:pdf},
journal = {Mechanical Engineering},
title = {{Behaviour Annotated Designs: A multi modal approach to design rational capture and intelligent design enviroments}}
}
@article{ARAbdullah2008,
author = {Abdulla, Shubair and Nassiri, Amer Al and Salam, Rosalina Abdul},
file = {:D$\backslash$:/Papers/Documents/2008/Abdulla, Nassiri, Salam - 2008.pdf:pdf},
journal = {The international Jornal of Information Technology},
pages = {200--210},
title = {{Off-line Arabic Handwritten Word Segmentation Using Rational Invariant Segments Features}},
volume = {5},
year = {2008}
}
@article{Valveny2007,
abstract = {Performanceevaluation is receiving increas- ing interest in graphics recognition. In this paper,we dis- cuss somequestions regarding the definition of a general framework for evaluation of symbol recognition meth- ods. The discussion is centered on three key elements in performance evaluation: test data, evaluationmetrics and protocols of evaluation. As a result of this discus- sion we state some general principles to be taken into account for the definition of such a framework. Finally, we describe the application of this framework to the organization of the first contest on symbol recognition in GREC’03, along with the results obtained by the par- ticipants.},
author = {Valveny, E. and Dosch, P. and Winstanley, Adam and Zhou, Yu and Yang, Su and Yan, Luo and Wenyin, Liu and Elliman, Dave and Delalandre, Mathieu and Trupin, Eric and Others},
doi = {10.1007/s10032-006-0033-x},
file = {:D$\backslash$:/Papers/Documents/2007/Valveny et al. - 2007.pdf:pdf},
issn = {1433-2833},
journal = {International journal on document analysis and recognition},
keywords = {performance evaluation,symbol},
number = {1},
pages = {59--74},
publisher = {Springer},
title = {{A general framework for the evaluation of symbol recognition methods}},
url = {http://www.springerlink.com/index/4333M880786K1717.pdf},
volume = {9},
year = {2007}
}
@phdthesis{Cates2009,
author = {Cates, S.J.},
booktitle = {Perception},
file = {:D$\backslash$:/Papers/Documents/2009/Cates - 2009.pdf:pdf},
publisher = {Citeseer},
title = {{Combining representations for improved sketch recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.158.5532\&amp;rep=rep1\&amp;type=pdf},
year = {2009}
}
@inproceedings{Lam,
abstract = {In the business transactions of large corporations such as utility companies and banks, many cheques must be processed on a regular basis. In this paper, we describe algorithms currently under development to automatically process the information contained on them. These procedures are designed to preprocess the scanned image of a cheque, locate and extract different items of information from it, and produce recognition results for these items by classifiers developed for each function},
author = {Lam, L. and Suen, C.Y. and Guillevic, D. and Strathy, N.W. and Cheriet, M. and Liu, K. and Said, J.N.},
booktitle = {1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century},
doi = {10.1109/ICSMC.1995.538133},
file = {:D$\backslash$:/Papers/Documents/1995/Lam et al. - 1995.pdf:pdf},
isbn = {0-7803-2559-1},
pages = {2353--2358},
publisher = {Ieee},
title = {{Automatic processing of information on cheques}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=538133},
year = {1995}
}
@article{ARVellasques2008,
abstract = {In this paper we propose a method to evaluate segmentation cuts for
handwritten touching digits. The idea of this method is to work as
a filter in segmentation-based recognition system. This kind of system
usually rely on over-segmentation methods, where several segmentation
hypotheses are created for each touching group of digits and then
assessed by a general-purpose classifier. The novelty of the proposed
methodology lies in the fact that unnecessary segmentation cuts can
be identified without any attempt of classification by a general-purpose
classifier, reducing the number of paths in a segmentation graph,
what can consequently lead to a reduction in computational cost.
An cost-based approach using ROC (receiver operating characteristics)
was deployed to optimize the filter. Experimental results show that
the filter can eliminate up to 83\% of the unnecessary segmentation
hypothesis and increase the overall performance of the system.},
author = {Vellasquesa, E and Oliveiraa, L S and Jr.a, A S Britto and Koericha, A L and Sabourinb, R},
file = {:D$\backslash$:/Papers/Documents/2008/Vellasquesa et al. - 2008.pdf:pdf},
journal = {Pattern Recognition},
keywords = { Filtering, Segmentation,Handwriting recognition},
pages = {3044--3053},
title = {{Filtering segmentation cuts for digit string recognition}},
volume = {41},
year = {2008}
}
@incollection{Adler2002Mutual,
author = {Adler, Aaron and Davis, Randall and Shrobe, Howard},
booktitle = {MIT Artificial Intelligence Laboratory Annual Abstract},
month = sep,
publisher = {MIT AI Lab},
title = {{Mutual \{D\}isambiguation of \{V\}erbal and \{S\}ketching \{I\}nputs in a \{D\}esign \{E\}nvironment}},
year = {2002}
}
@article{Hyun2006,
author = {Hyun, Dae and Kim, Myoung-jun},
doi = {10.1016/j.cad.2005.10.006},
file = {:D$\backslash$:/Papers/Documents/2006/Hyun, Kim - 2006.pdf:pdf},
journal = {Computer-Aided Design},
keywords = {curvature,local shape information,pen-input displays,segmentation},
number = {3},
pages = {238--248},
title = {{A curvature estimation for pen input segmentation in sketch-based modeling}},
volume = {38},
year = {2006}
}
@article{Hua2003,
address = {New York, New York, USA},
author = {Hua, Jing and Qin, Hong},
doi = {10.1145/781606.781660},
file = {:D$\backslash$:/Papers/Documents/2003/Hua, Qin - 2003.pdf:pdf},
isbn = {1581137060},
journal = {Proceedings of the eighth ACM symposium on Solid modeling and applications - SM '03},
keywords = {deformations,interaction techniques,scalar fields},
pages = {328},
publisher = {ACM Press},
title = {{Free-form deformations via sketching and manipulating scalar fields}},
url = {http://portal.acm.org/citation.cfm?doid=781606.781660},
year = {2003}
}
@article{Wobbrock2007,
address = {New York, New York, USA},
author = {Wobbrock, Jacob O. and Wilson, Andrew D. and Li, Yang},
doi = {10.1145/1294211.1294238},
file = {:D$\backslash$:/Papers/Documents/2007/Wobbrock, Wilson, Li - 2007.pdf:pdf},
isbn = {9781595936792},
journal = {Proceedings of the 20th annual ACM symposium on User interface software and technology - UIST '07},
keywords = {all or part of,dynamic time warping,gesture recognition,marks,or hard copies of,permission to make digital,rapid prototyping,recognition rates,rubine,statistical classifiers,strokes,symbols,this work for,unistrokes,user interfaces},
pages = {159},
publisher = {ACM Press},
title = {{Gestures without libraries, toolkits or training: a \$1 recognizer for user interface prototypes}},
url = {http://portal.acm.org/citation.cfm?doid=1294211.1294238},
year = {2007}
}
@inproceedings{Michalik2002,
author = {Michalik, Paul and Kim, D.H. and Bruderlin, B.D.},
booktitle = {Proceedings of the seventh ACM symposium on Solid modeling and applications},
file = {:D$\backslash$:/Papers/Documents/2002/Michalik, Kim, Bruderlin - 2002.pdf:pdf},
keywords = {constraints,curve,free-form sculpting,sketch,surface},
pages = {304},
publisher = {ACM},
title = {{Sketch-and constraint-based design of B-spline surfaces}},
url = {http://portal.acm.org/citation.cfm?id=566325},
year = {2002}
}
@article{ARSrihari2008,
abstract = {Searching handwritten documents is a relatively unexplored frontier
for documents in any language. Traditional approaches use either
image-based or text-based techniques. This paper describes a framework
for versatile search where the query can be either text or image,
and the retrieval method fuses text and image retrieval methods.
A UNICODE and an image query are maintained throughout the search,
with the results being combined by a neural network. Preliminary
results show positive results that can be further improved by refining
the component pieces of the framework (text transcription and image
search).},
author = {Srihari, Sargur N and Ball, Gregory R and Srinivasan, Harish},
file = {:D$\backslash$:/Papers/Documents/2006/Srihari, Ball, Srinivasan - 2006.pdf:pdf},
journal = {LECTURE NOTES IN COMPUTER SCIENCE},
pages = {57--69},
title = {{Versatile Search of Scanned Arabic Handwriting}},
volume = {NUMB 4768},
year = {2008}
}
@inproceedings{Das2006,
author = {Das, Swagatam and Abraham, Ajith and Sarkar, S.K.},
booktitle = {Hybrid Intelligent Systems, 2006. HIS'06. Sixth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2006/Das, Abraham, Sarkar - 2006.pdf:pdf},
isbn = {0769526624},
pages = {26},
publisher = {IEEE},
title = {{A Hybrid Rough Set–Particle Swarm Algorithm for Image Pixel Classification}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4041406},
year = {2006}
}
@misc{Pick2005,
author = {Pick, G},
file = {:D$\backslash$:/Papers/Documents/2005/Pick - 2005.pdf:pdf},
number = {February},
pages = {1--12},
title = {{Lecture 12: Properties of 2D Regions}},
volume = {27},
year = {2005}
}
@inproceedings{Okumur2005,
abstract = {An on-line handwritten character recognition technique based on a new HMM is proposed. In the proposed HMM, not only pen-direction feature but also pen-coordinate fea- ture are separately utilized for describing the shape vari- ation of on-line characters accurately. Specijcally speak- ing, the proposed HMM outputs a pen-coordinate feature at each inter-state transition and outputs a pen-direction fea- ture at each intra-state transition, i.e., self-transition. Thus, each state of the proposed HMM can specify the starting position and the direction of a line segment by its incoming inter-state transition and intra-state transition, respectively. The results of recognition experiments on 10-stroke Chinese characters show that the proposed HMM outperforms the conventional HMM which does not use the pen-coordinate feature because of its non-stationarit},
author = {Okumur, D. and Uchida, Seiichi and Sakoe, Hiroaki},
booktitle = {2005 Eight International Conference on Document Analysis and Recognition.},
file = {:D$\backslash$:/Papers/Documents/2005/Okumur, Uchida, Sakoe - 2005.pdf:pdf},
publisher = {IEEE Computer Society},
title = {{An hmm implementation for on-line handwriting recognition-based on pen-coordinate feature and pen-direction feature}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICDAR.2005.50},
year = {2005}
}
@inproceedings{DSChandra2008,
abstract = {Preprocessing is an important step for automatic check processing
in Indian scenario where there is huge variation in writing style,
especially the way in which Courtesy Amount is terminated and the
fractional (Paisa) amount is written. Courtesy Amount Recognition
(CAR) and Legal Amount Recognition (LAR) form the core of automated
check processing system. For CAR identification, a number of approaches
have been suggested. However, most of these do not provide strong
and comprehensive preprocessing techniques. We propose an algorithm
that automatically detects the courtesy amount region, preprocesses
this region, segments the courtesy amount into individual characters
before feeding it to an ICR engine. For detecting the courtesy-amount
region, a Most Probable Region (MPR) is detected, based on configurable
rules and semantic analysis. The presented algorithm intelligently
removes currency symbols (dasiaRs.psila), terminal characters (dasia/psila,
dasia=psila, dasia/-psila), and delimiters (dasia,psila, dasia.psila)
with a high degree of accuracy. Results show that the ICR rates have
increased from 51\% to 90\% using our algorithm.},
author = {Chandra, L and Gupta, R and Kumar, P and Ganotra, D},
booktitle = {TENCON 2008 - 2008 IEEE Region 10 Conference},
doi = {10.1109/TENCON.2008.4766626},
file = {:D$\backslash$:/Papers/Documents/2008/Chandra et al. - 2008.pdf:pdf},
keywords = {automatic bank check processing;courtesy amount re},
pages = {1--5},
title = {{Automatic courtesy amount recognition for Indian banks checks}},
year = {2008}
}
@article{Hammond2002Domain,
author = {Hammond, Tracy},
file = {:D$\backslash$:/Papers/Documents/2002/Hammond, Davis - 2002.pdf:pdf},
journal = {Proceedings of the 2nd Annual MIT Student Oxygen Workshop},
title = {{A Domain Description Language for Sketch Recognition}},
year = {2002}
}
@conference{ARDreuw2009,
abstract = {We present a writer adaptive training and writer clus- tering approach
for an HMM based Arabic handwriting recognition system to handle
different handwriting styles and their variations. Additionally,
a writing variant model refinement for specific writing variants
is proposed. Current approaches try to compensate the impact of dif-
ferent writing styles during preprocessing and normaliza- tion steps.
Writer adaptive training with a CMLLR based feature adaptation is
used to train writer dependent models. An unsupervised writer clustering
with Bayesian information criterion based stopping condition for
a CMLLR based fea- ture adaptation during a two-pass decoding process
is used to cluster different handwriting styles of unknown test writ-
ers. The proposed methods are evaluated on the IFN/ENIT Arabic handwriting
database.},
author = {Dreuw, Philippe and Rybach, David and Gollan, Christian and Ney, Hermann},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Dreuw et al. - 2009.pdf:pdf},
title = {{Writer Adaptive Training and Writing Variant Model Refinement for Offline Arabic Handwriting Recognition}},
year = {2009}
}
@article{Chen2009,
author = {Chen, Jin and Wang, Cheng and Wang, Runsheng},
doi = {10.1016/j.neucom.2009.03.013},
file = {:D$\backslash$:/Papers/Documents/2009/Chen, Wang, Wang - 2009.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Binary tree,Computational complexity,multiclass classification,support vector machine},
month = aug,
number = {13-15},
pages = {3370--3375},
publisher = {Elsevier},
title = {{Adaptive binary tree for fast SVM multiclass classification}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231209001106},
volume = {72},
year = {2009}
}
@book{Mackenzie2003,
author = {Mackenzie, Graham and Nottingham, University},
booktitle = {Evaluation},
file = {:D$\backslash$:/Papers/Documents/2003/Mackenzie, Nottingham - 2003.pdf:pdf},
number = {August},
publisher = {Citeseer},
title = {{Agent-based sketch recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.5908\&amp;rep=rep1\&amp;type=pdf},
year = {2003}
}
@article{Gagvani2000,
author = {Gagvani, N and Silver, Deborah},
file = {:D$\backslash$:/Papers/Documents/2000/Gagvani, Silver - 2000.pdf:pdf},
journal = {of the 2000 IEEE symposium on Volume},
keywords = {collision detection,virtual reality,volume graphics},
title = {{Shape-based volumetric collision detection}},
url = {http://portal.acm.org/citation.cfm?id=353888.353899},
year = {2000}
}
@article{Cannon2010,
address = {New York, New York, USA},
author = {Cannon, Brett and Wohlstadter, Eric},
doi = {10.1145/1772690.1772711},
file = {:D$\backslash$:/Papers/Documents/2010/Cannon, Wohlstadter - 2010.pdf:pdf},
isbn = {9781605587998},
journal = {Proceedings of the 19th international conference on World wide web - WWW '10},
keywords = {Software Engineering,UBC},
mendeley-tags = {Software Engineering,UBC},
pages = {191},
publisher = {ACM Press},
title = {{Automated object persistence for JavaScript}},
url = {http://portal.acm.org/citation.cfm?doid=1772690.1772711},
year = {2010}
}
@article{Loncaric1998,
author = {Loncaric, Sven},
file = {:D$\backslash$:/Papers/Documents/1998/Loncaric - 1998.pdf:pdf},
issn = {0031-3203},
journal = {Pattern recognition},
keywords = {Survey},
mendeley-tags = {Survey},
number = {8},
pages = {983--1001},
publisher = {Elsevier},
title = {{A survey of shape analysis techniques}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031202397001222},
volume = {31},
year = {1998}
}
@inproceedings{DSKim2001,
abstract = {A sophisticated methodology of legal amount recognition based on the
word segmentation hypotheses is introduced for automatic bank check
processing. Word segmentation hypotheses are derived according to
the grapheme level segmentation results of the legal amount. Novel
hybrid schemes of HMM-MLP classifiers are also introduced for producing
the ordered legal word recognition results with reliable decision
values. These values can be used for obtaining an optimal word segmentation
path of over-segmentation hypotheses as well as an efficient rejection
criterion of word recognition result. Simulation was performed with
CENPARMI bank check database and shows quite encouraging results},
author = {Kim, Kye Kyung and Kim, Jin Ho and Chung, Yun Koo and Suen, C Y},
booktitle = {Document Analysis and Recognition, 2001. Proceedings. Sixth International Conference on},
doi = {10.1109/ICDAR.2001.953928},
file = {:D$\backslash$:/Papers/Documents/2001/Kim et al. - 2001.pdf:pdf},
keywords = { ;, ;hidden Markov models;image segmentation;multilay,CENPARMI;HMM;bank check database;bank check proces},
pages = {964--967},
title = {{Legal amount recognition based on the segmentation hypotheses for bank check processing}},
year = {2001}
}
@misc{Jr1910,
author = {Jr, Joseph J Laviola},
file = {:D$\backslash$:/Papers/Documents/2000/Jr - 2000.pdf:pdf},
pages = {1--21},
title = {{An Introduction to Sketch-Based Interfaces}},
year = {2000}
}
@article{Verma2004,
author = {Verma, B and Blumenstein, M and Ghosh, M},
doi = {10.1016/j.patrec.2004.02.013},
file = {:D$\backslash$:/Papers/Documents/2004/Verma, Blumenstein, Ghosh - 2004.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = jul,
number = {9},
pages = {975--988},
title = {{A novel approach for structural feature extraction: Contour vs. direction}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865504000558},
volume = {25},
year = {2004}
}
@inproceedings{Ferguson2002,
author = {Ferguson, R.W. and Forbus, K.D.},
booktitle = {Proceedings of IAAI-2002},
file = {:D$\backslash$:/Papers/Documents/2002/Ferguson, Forbus - 2002.pdf:pdf},
title = {{A cognitive approach to sketch understanding}},
url = {http://www.aaai.org/Papers/Symposia/Spring/2002/SS-02-08/SS02-08-007.pdf},
year = {2002}
}
@article{Maniezzo2001,
author = {Maniezzo, V. and Carbonaro, A.},
file = {:D$\backslash$:/Papers/Documents/2001/Maniezzo, Carbonaro - 2001.pdf:pdf},
journal = {Essays and surveys in metaheuristics},
publisher = {Kluwer},
title = {{Ant colony optimization: An overview}},
url = {http://www3.csr.unibo.it/\~{}maniezzo/didattica/Vienna/ACOintro.pdf},
volume = {44},
year = {2001}
}
@article{Plimmer2002,
author = {Plimmer, Beryl and Apperley, M.},
file = {:D$\backslash$:/Papers/Documents/2002/Plimmer, Apperley - 2002.pdf:pdf},
journal = {Australian Computer Science Communications},
keywords = {computing,design,informal interfaces,large interactive displays,pen,sketching},
number = {4},
pages = {9--12},
publisher = {IEEE Computer Society Press},
title = {{Computer-aided sketching to capture preliminary design}},
url = {http://portal.acm.org/citation.cfm?id=563985.563987},
volume = {24},
year = {2002}
}
@article{Vuori2002,
abstract = {We have considered problems involved in the self-supervised learning process of an on-line handwriting recognition system. Our system is able to recognize isolated characters by comparing them to prototype characters with a method based on the Dynamic Time Warping algorithm. The recognition system is adapted by adding new prototypes, inac- tivating confusing or erroneous ones, and reshaping existing prototypes with a method based on the Learning Vector Quantization. We have analyzed the sources oferroneous learning samples and studied the inuence ofsuch samples on the performance of the recognizer via simulations. In these simulations, two adaptation strategies combined with four methods for inactivating prototypes were applied. The results of the simulations showed that the adaptation strategies are able to improve the system’s recognition rate and the prototype inactivation methods do reduce the harmful eects of erroneous learning samples.? 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.},
author = {Vuori, V},
doi = {10.1016/S0031-3203(01)00083-8},
file = {:D$\backslash$:/Papers/Documents/2002/Vuori - 2002.pdf:pdf},
journal = {Pattern Recognition},
keywords = {adaptation,dtw,dynamic time warping,erroneous learning samples,intelligent user interface,isolated character recognition,k nearest neighbor rule,learning vector quantization,lvq,on-line recognition,unconstrained writing style},
month = apr,
number = {4},
pages = {915--925},
title = {{Influence of erroneous learning samples on adaptation in on-line handwriting recognition}},
volume = {35},
year = {2002}
}
@article{Moran1997,
address = {New York, New York, USA},
author = {Moran, Thomas P. and Chiu, Patrick and van Melle, William},
doi = {10.1145/263407.263508},
file = {:D$\backslash$:/Papers/Documents/1997/Moran, Chiu, van Melle - 1997.pdf:pdf},
isbn = {0897918819},
journal = {Proceedings of the 10th annual ACM symposium on User interface software and technology - UIST '97},
keywords = {emergent structure,freeform,implicit structure,informal systems,ing,interaction,list structures,pen-based systems,recognition-based systems,structural group-,whiteboard metaphor},
pages = {45--54},
publisher = {ACM Press},
title = {{Pen-based interaction techniques for organizing material on an electronic whiteboard}},
url = {http://portal.acm.org/citation.cfm?doid=263407.263508},
volume = {94304},
year = {1997}
}
@article{Baudel1994,
address = {New York, New York, USA},
author = {Baudel, Thomas},
doi = {10.1145/192426.192496},
file = {:D$\backslash$:/Papers/Documents/1994/Baudel - 1994.pdf:pdf},
isbn = {0897916573},
journal = {Proceedings of the 7th annual ACM symposium on User interface software and technology - UIST '94},
pages = {185--192},
publisher = {ACM Press},
title = {{A mark-based interaction paradigm for free-hand drawing}},
url = {http://portal.acm.org/citation.cfm?doid=192426.192496},
year = {1994}
}
@article{JinhaiCai1999,
author = {{Jinhai Cai}},
doi = {10.1109/34.754622},
file = {:D$\backslash$:/Papers/Documents/1999/Jinhai Cai - 1999.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = mar,
number = {6},
pages = {105--270},
title = {{Integration of structural and statistical information for unconstrained handwritten numeral recognition}},
volume = {64},
year = {1999}
}
@inproceedings{Eisenstein2004,
author = {Eisenstein, Jacob and Christoudias, C.M.},
booktitle = {proceedings of HLT-NAACL},
file = {:D$\backslash$:/Papers/Documents/2004/Eisenstein, Christoudias - 2004.pdf:pdf},
pages = {25--32},
title = {{A salience-based approach to gesture-speech alignment}},
url = {http://acl.ldc.upenn.edu/hlt-naacl2004/main/pdf/107\_Paper.pdf},
volume = {4},
year = {2004}
}
@article{DSGorski2001,
abstract = {This paper presents the current state of the A2iA CheckReaderTM �
a commercial bank check recognition system. The system is designed
to process the flow of payment documents associated with the check
clearing process: checks themselves, deposit slips, money orders,
cash tickets, etc. It processes document images and recognizes document
amounts whatever their style and type � cursive, hand- or machine
printed � expressed as numerals or as phrases. The system is adapted
to read payment documents issued in different English- or Frenchspeaking
countries. It is currently in use at more than 100 large sites in
five countries and processes daily over 10 million documents. The
average read rate at the document level varies from 65 to 85\% with
a misread rate corresponding to that of a human operator (1\%).},
author = {{Nikolai Gorski Valery Anisimov}, Emmanuel Augustin Olivier Baret Sergey Maximov},
file = {:D$\backslash$:/Papers/Documents/2001/Nikolai Gorski Valery Anisimov - 2001.pdf:pdf},
journal = {International Journal of Document Analysis and Processing},
keywords = { Automatic reading , Document analysis , Intelligent, Payment systems ,Bank check processing ,Handwriting recognition },
pages = {196�206},
title = {{Industrial bank check processing: the A2iA CheckReaderTM}},
volume = {3},
year = {2001}
}
@inproceedings{El-Hajj2005,
abstract = {In this paper we describe a 1D HMM off-line handwriting recognition system employing an analytical approach. The system is supported by a set of robust language independent features extracted on binary images. Parameters such as lower and upper baselines are used to derive a subset of baseline dependent features. Thus, word variability due to lower and upper parts of words is better taken into account. In addition, the proposed system learns character models without character pre-segmentation. Experiments that have been conducted on the benchmark IFN/ENIT database of Tunisian handwritten country/village names, show the advantage of the proposed approach and of the baseline- dependant features.},
author = {El-Hajj, R. and Likforman-Sulem, L. and Mokbel, C.},
booktitle = {Eighth International Conference on Document Analysis and Recognition (ICDAR'05)},
doi = {10.1109/ICDAR.2005.53},
file = {:D$\backslash$:/Papers/Documents/2005/El-Hajj, Likforman-Sulem, Mokbel - 2005.pdf:pdf},
isbn = {0-7695-2420-6},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {893--897},
publisher = {Ieee},
title = {{Arabic Handwriting Recognition Using Baseline Dependant Features and Hidden Markov Modeling}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1575673},
year = {2005}
}
@article{Pereira2001,
author = {Pereira, JP and Fonseca, MJ and Jorge, JA},
file = {:D$\backslash$:/Papers/Documents/2001/Pereira, Fonseca, Jorge - 2001.pdf:pdf},
journal = {of the 14th Brazilian Symposium on},
title = {{Handling ambiguity and errors: Visual languages for calligraphic interaction}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.7.7806\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
@article{ARKumara2008,
abstract = {This paper proposes a new approach for classifying multivariate time-series
with applications to the problem of writer independent online handwritten
character recognition. Each time-series is approximated by a sum
of piecewise polynomials in a suitably defined Reproducing Kernel
Hilbert Space (RKHS). Using the associated kernel function a large
margin classification formulation is proposed which can discriminate
between two such functions belonging to the RKHS. The associated
problem turns out to be an instance of convex quadratic programming.
The resultant classification scheme applies to many time-series discrimination
tasks and shows encouraging results when applied to online handwriting
recognition tasks.},
author = {Kumara, Karthik and Agrawal, Rahul and Bhattacharyya, Chiranjib},
file = {:D$\backslash$:/Papers/Documents/2008/Kumara, Agrawal, Bhattacharyya - 2008.pdf:pdf},
journal = {Pattern Recognition Letters},
keywords = {Time-series classification; Kernels; Online handwr},
pages = {933�937},
title = {{A large margin approach for writer independent online handwriting classification}},
volume = {29},
year = {2008}
}
@inproceedings{ARAburas2008,
abstract = {Optical Characters Recognition (OCR) is one of the active subjects
of research since the early days of computer science. Even if Arabic
characters are used by more than a half a billion people; Arabic
characters recognition has not received enough interests by the researchers.
Little research progress has been achieved comparing to what has
been done with Latin and Chinese. The cursive nature of the Arabic
characters makes it more difficult to achieve a high accuracy in
character recognition since even printed Arabic characters are in
cursive form. This paper presents the main challenges (difficulties)
researchers are facing and up to dated solutions (the common methods)
are used for Arabic text recognition.},
address = {Kuala Lumpur, Malaysia},
author = {Aburas, Abdurazzag Ali and Gumah, Mohamed E},
booktitle = {ITSim 2008. International Symposium on Information Technology},
file = {:D$\backslash$:/Papers/Documents/2008/Aburas, Gumah - 2008.pdf:pdf},
keywords = { Arabic Handwriting,Survey},
organization = {IEEE},
pages = {1--6},
title = {{Arabic handwriting recognition: Challenges and solutions}},
volume = {2},
year = {2008}
}
@phdthesis{Alvarado2004Multi-Domain,
author = {Alvarado, Christine},
file = {:D$\backslash$:/Papers/Documents/2004/Alvarado - 2004.pdf:pdf},
month = aug,
school = {Massachusetts Institute of Technology},
title = {{Multi-Domain Sketch Understanding}},
year = {2004}
}
@inproceedings{Hammond2004,
author = {Hammond, Tracy and Davis, Randall},
booktitle = {Proceedings of the national conference on artificial intelligence},
file = {:D$\backslash$:/Papers/Documents/2004/Hammond, Davis - 2004.pdf:pdf},
pages = {450--456},
publisher = {Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999},
title = {{Automatically transforming symbolic shape descriptions for use in sketch recognition}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Automatically+Transforming+Symbolic+Shape+Descriptions+for+Use+in+Sketch+Recognition\#0},
year = {2004}
}
@unpublished{Foltz2001DrJones,
annote = {PhD Thesis Proposal, Department of EECS, MIT},
author = {Foltz, Mark},
month = may,
title = {{Dr. Jones: A Software Archaeologist's Magic Lens}},
year = {2001}
}
@inproceedings{Zhu2009,
author = {Zhu, Xiaoyuan and Ge, Y. and Guo, F. and Zhen, L.},
booktitle = {2009 10th International Conference on Document Analysis and Recognition},
doi = {10.1109/ICDAR.2009.6},
file = {:D$\backslash$:/Papers/Documents/2009/Zhu et al. - 2009.pdf:pdf},
pages = {1246--1250},
publisher = {IEEE},
title = {{A Probabilistic Framework for Soft Target Learning in Online Cursive Handwriting Recognition}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICDAR.2009.6},
year = {2009}
}
@inproceedings{PDBFavat1994,
abstract = {this paper outli4es the philosophy, desrgn and implementation of the
Gradient, Structural, bvily (GSC) recognition algorithm, which has
been used successfully in several aGG"d rcading applications at CEDAR.
The GSC algorithm takes a quasi multidio approach to feature generation.
This philosophy coupled with the appropriaie *tf,aatim function results
in a recognizer which has both high accuracy and good -'et-cc behavior.
This allows it to be used in higher level digit string and word ggliti@
algorithms which search for digit/character boundaries. Tests of
the GSC Ner oDs tandardd igit, charactera nd non-characterd atabasesa
rer eported.},
author = {{J.T. FavatA G Srikantan} and Srihari, S N},
booktitle = {Proc. IWFHR},
file = {:D$\backslash$:/Papers/Documents/1994/J.T. FavatA G Srikantan, Srihari - 1994.pdf:pdf},
pages = {57--66},
title = {{Handprinted Character/DigitR ecognitionu singa Multiple Feature/ResolutioPnh itosophy}},
year = {1994}
}
@unpublished{Hammond2003Proposal,
annote = {PhD Thesis Proposal, Massachusetts Institute of Technology,
to be published},
author = {Hammond, Tracy},
title = {{A Domain Description Language for Sketch Recognition}},
year = {2003}
}
@article{Nakai2002a,
abstract = {This paper discusses the use of pen pressure as a fearure in wrirer-independenr on-line handwriting recognirion. We propose hvo kinds of features related io pen pressure: one is the pressure represenring pen ups and downs in a conrin- uous manner: rhe other is rhe rime-derivarive of the pres- sure represenring rhe temporal parrern of rhe pen pressure. Combining eirher of rhem wirh the exisring fearure (velocity vecror), a 3-dimensional fearure is composed for charac- rer recognition. Some techniques of inrerpolaring rhe pen pressure during rhe pen-up inrerval is also proposed for a pre-processing purpose. Through experimenral evaluarion using 1,016 elemenrary Kanji characters compared wirh rhe baseline performance using velociry vecror only, rhe addi- tional use of pen pressure improved rhe performance from 97.5\% IO 98.1\% for careful wrirings and from 91.1\% ro 93. I\% for cursive writings.},
author = {Nakai, M and Sudo, T and Shimodaira, H},
file = {:D$\backslash$:/Papers/Documents/2002/Nakai, Sudo, Shimodaira - 2002.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {220--223},
title = {{Pen Pressure Features for Writer-independent On-line Handwriting Recognition based on substroke HMM}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICPR.2002.1047834},
year = {2002}
}
@article{Al-HajjMohamad2009,
abstract = {The problem addressed in this study is the offline recognition of handwritten Arabic city names. The names are assumed to belong to a fixed lexicon of about 1,000 entries. A state-of-the-art classical right-left hidden Markov model (HMM)-based recognizer (reference system) using the sliding window approach is developed. The feature set includes both baseline-independent and baseline-dependent features. The analysis of the errors made by the recognizer shows that the inclination, overlap, and shifted positions of diacritical marks are major sources of errors. In this paper, we propose coping with these problems. Our approach relies on the combination of three homogeneous HMM-based classifiers. All classifiers have the same topology as the reference system and differ only in the orientation of the sliding window. We compare three combination schemes of these classifiers at the decision level. Our reported results on the benchmark IFN/ENIT database of Arabic Tunisian city names give a recognition rate higher than 90 percent accuracy and demonstrate the superiority of the neural network-based combination. Our results also show that the combination of classifiers performs better than a single classifier dealing with slant-corrected images and that the approach is robust for a wide range of orientation angles.},
author = {{Al-Hajj Mohamad}, Ramy and Likforman-Sulem, Laurence and Mokbel, Chafic},
doi = {10.1109/TPAMI.2008.136},
file = {:D$\backslash$:/Papers/Documents/2009/Al-Hajj Mohamad, Likforman-Sulem, Mokbel - 2009.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automatic Data Processing,Automatic Data Processing: methods,Handwriting,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Markov Chains,Middle East,Models, Statistical,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reading,Subtraction Technique},
month = jul,
number = {7},
pages = {1165--77},
pmid = {19443916},
title = {{Combining slanted-frame classifiers for improved HMM-based Arabic handwriting recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19443916},
volume = {31},
year = {2009}
}
@article{Mozaffari2007,
author = {Mozaffari, Saeed and Faez, Karim and M$\backslash$$\backslash$"argner, V.},
file = {:D$\backslash$:/Papers/Documents/2007/Mozaffari, Faez, Margner - 2007.pdf:pdf},
journal = {Machine Learning and Data Mining in Pattern Recognition},
keywords = {arabic handwritten digit recognition,farsi,fractal theory,iterated function system,on-line and off-line},
pages = {868--882},
publisher = {Springer},
title = {{Application of Fractal Theory for On-Line and Off-Line Farsi Digit Recognition}},
url = {http://www.springerlink.com/index/u7rm04335g487t56.pdf},
year = {2007}
}
@mastersthesis{Oltmans2000Understanding,
address = {Cambridge, MA},
author = {Oltmans, Michael},
file = {:D$\backslash$:/Papers/Documents/2000/Oltmans - 2000.pdf:pdf},
school = {Massachusetts Institute of Technology},
title = {{Understanding Naturally Conveyed Explanations of Device Behavior}},
year = {2000}
}
@article{AR3AlMuhtaseb2008,
abstract = {This paper describes a technique for automatic recognition of off-line printed Arabic text using Hidden Markov Models. In this work different sizes of overlapping and nonoverlapping hierarchical windows are used to generate 16 features from each vertical sliding strip. Eight different Arabic fonts were used for testing (viz. Arial, Tahoma, Akhbar, Thuluth, Naskh, Simplified Arabic, Andalus, and Traditional Arabic). It was experimentally proven that different fonts have their highest recognition rates at different numbers of states (5 or 7) and codebook sizes (128 or 256). Arabic text is cursive, and each character may have up to four different shapes based on its location in a word. This research work considered each shape as a different class, resulting in a total of 126 classes (compared to 28 Arabic letters). The achieved average recognition rates were between 98.08\% and 99.89\% for the eight experimental fonts. The main contributions of this work are the novel hierarchical sliding window technique using only 16 features for each sliding window, considering each shape of Arabic characters as a separate class, bypassing the need for segmenting Arabic text, and its applicability to other languages.},
annote = {Comments:
Different printed Arabic fonts
16 Features extracted from Vertical sliding windows (Mainly number of black pixels).
HMM for recognition and segmentation. 

        
Details:
 The database was extracted from the books of Saheh Al-Bukhari and Saheh Muslem. The training phase, 2500 lines were used for
training and the remaining 266 lines for testing.
 For each file the text was formatted to appear as a white font color in a black background. Moreover, each image in the ‘tif’ file has been side reversed through a mirroring tool to speed up the training and recognition testing processes. Featrues are extracted from overlapping moving vertical window of three-pixel width and a text line of height TLH. from each window, 16 different feature are extracted by dividing the window into parts of non overlapping 8 parts of 1/8 height, 4 parts of 1/4 height and overlapping 1/2 height and one whole window. From each part, the number of black pixel is computed and used as feautres. 

        
The HMM used is in HTK library, its structure allows nonlinear variations in the horizontal position. HTK models the feature vector with a mixture of Gaussians.
It uses the Viterbi algorithm in the recognition phase, which searches for the most likely sequence of a character given the input feature vector. 

        
Result on the arabic text was 99.94 \%, the method was also used on english texts and result was 98.9\%},
author = {Al-Muhtaseb, Husni A and Mahmouda, Sabri A and Qahwaji, Rami S},
file = {:D$\backslash$:/Papers/Documents/2008/Al-Muhtaseb, Mahmouda, Qahwaji - 2008.pdf:pdf},
journal = {Signal Processing},
keywords = {Arabic Handwriting,Arabic Handwritting recognition,HMM,Read,Summarized},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
pages = {2902�2912},
title = {{Recognition of off-line printed Arabic text using Hidden Markov Models}},
volume = {88},
year = {2008}
}
@inproceedings{PDBFumera2003,
abstract = {The aim of this paper is to evaluate the potential usefulness of the
reject option for text categorisation (TC) tasks. The reject option
is a technique used in statistical pattern recognition for improving
classification reliability. Our work is motivated by the fact that,
although the reject option proved to be useful in several pattern
recognition problems, it has not yet been considered for TC tasks.
Since TC tasks differ from usual pattern recognition problems in
the performance measures used and in the fact that documents can
belong to more than one category, we developed a specific rejection
technique for TC problems. The performance improvement achievable
by using the reject option was experimentally evaluated on the Reuters
dataset, which is a standard benchmark for TC systems.},
address = {Mantova, Italy},
author = {Fumera, Giorgio and Pillai, Ignazio and Roli, Fabio},
booktitle = {12th International Conference on Image Analysis and Processing (ICIAP 2003)},
doi = {http://csdl.computer.org/comp/proceedings/iciap/2003/1948/00/19480582abs.htm},
file = {:D$\backslash$:/Papers/Documents/2003/Fumera, Pillai, Roli - 2003.pdf:pdf},
isbn = {0-7695-1948-2},
pages = {582--587},
publisher = {IEEE Computer Society},
title = {{Classification with reject option in text categorisation systems.}},
year = {2003}
}
@misc{PDB4Zadrozny2001,
abstract = {This paper presents a method for obtaining class membership probability
estimates for multiclass classification problems by coupling the
probability estimates produced by binary classifiers. This is an
extension for arbitrary code matrices of a method due to Hastie and
Tibshirani for pairwise coupling of probability estimates. Experimental
results with Boosted Naive Bayes show that our method produces calibrated
class membership probability estimates, while having similar classification
accuracy as loss-based decoding, a method for obtaining the most
likely class that does not generate probability estimates},
author = {Zadrozny, Bianca},
file = {:D$\backslash$:/Papers/Documents/2002/Zadrozny, Elkan - 2002.pdf:pdf},
keywords = {MultiClassifier Systems},
title = {{Reducing Multiclass to Binary By Coupling Probability Estimates}},
year = {2001}
}
@inproceedings{Adler2003Creating,
author = {Adler, Aaron},
booktitle = {Third Annual MIT CSAIL Student Oxygen Workshop},
title = {{Creating a Multimodal Design Environment Using Speech and Sketching}},
year = {2003}
}
@article{ARALEMAMI1990,
abstract = {Arabic characters are always in cursive script. Handwritten words
were entered into an IBM PC via a graphics tablet and a segmentation
process applied to the points; the length and the slope of each segment
was then found, and the slope categorized to one of four directions.
In the learning process, specifications of the strokes of each character
are fed to the computer. In the recognition process, the parameters
of each stroke are found and special rules applied to select the
collection of strokes which best matches the features of one of the
stored characters. The results are promising, and suggestions for
improvements leading to 100\% recognition are proposed.},
author = {AL-EMAMI, SAMIR and USHER, MIKE},
file = {:D$\backslash$:/Papers/Documents/1990/AL-EMAMI, USHER - 1990.pdf:pdf},
journal = {IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,},
number = {12},
pages = {704--710},
title = {{On-Line Recognition of Handwritten Arabic Characters}},
volume = {7},
year = {1990}
}
@article{ARRhee2009,
abstract = {Problems with local ambiguities in handwritten mathematical expressions
(MEs) are often resolved at global level. Therefore, keeping local
ambiguities is desirable for high accuracy, with a hope that they
may be resolved by later global analyses. We propose a layered search
framework for handwritten ME recognition. From given handwritten
input strokes, ME structures are expanded by adding symbol hypotheses
one by one, representing ambiguities of symbol identities and spatial
relationships as numbers of branches in the expansion. We also propose
a novel heuristic predicting how likely the set of remaining input
strokes forms valid spatial relationships with the current partially
interpreted structure. Further complexity reduction is achieved by
delaying the symbol identity decision. The elegance of our approach
is that the search result would be unchanged even if we prune out
unpromising branches of the search. Therefore, we can examine a much
larger number of local hypotheses with a limited amount of computing
resource in making global level decisions. The experimental evaluation
shows promising results of the efficiency of the proposed approach
and the performance of our system, which results from the system's
capacity to examine a large number of possibilities},
author = {Rhee, Taik Heon and Kim, Jin Hyung},
doi = {10.1016/j.patcog.2008.10.036},
file = {:D$\backslash$:/Papers/Documents/2009/Rhee, Kim - 2009.pdf:pdf},
journal = {Pattern Recognition},
keywords = { Admissible heuristic, Layered searchtree, Structural analysis, expression recognition,Delayed decisionofsymbolidentity,Handwritten mathematical},
month = dec,
number = {12},
pages = {3192--3201},
title = {{Efficient search strategy instructural analysis for handwritten mathematical expression recognition}},
volume = {42},
year = {2009}
}
@article{Fernando2003,
author = {Fernando, T. and Tawfik, H.},
doi = {10.1109/GMAG.2003.1219686},
file = {:D$\backslash$:/Papers/Documents/2003/Fernando, Tawfik - 2003.pdf:pdf},
isbn = {0-7695-1985-7},
journal = {2003 International Conference on Geometric Modeling and Graphics, 2003. Proceedings},
keywords = {computer-aided design,deformable modelling,freeform sketching},
pages = {188--194},
publisher = {IEEE Comput. Soc},
title = {{FreeSculptor: a computer-aided freeform design environment}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1219686},
year = {2003}
}
@inproceedings{Fledelius2006,
author = {Fledelius, Walther and Mayoh, B.H.},
booktitle = {Proceedings of the 24th IASTED international conference on Artificial intelligence and applications},
file = {:D$\backslash$:/Papers/Documents/2006/Fledelius, Mayoh - 2006.pdf:pdf},
isbn = {0889865566},
keywords = {distributed artificial intelligence,medical image,swarms},
pages = {150--155},
publisher = {Citeseer},
title = {{A swarm based approach to medical image analysis}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.5141\&amp;rep=rep1\&amp;type=pdf},
year = {2006}
}
@article{Vinciarelli2002,
abstract = {This work presents the application of HMM adaptation techniques to the problem of Off-Line Cursive Script Recognition. Rather than training a new model for each writer,one first creates a unique model with a mixed database and then adapts it for each different writer using his own small dataset. Experiments on a publicly available benchmark database show that an adapted system has an accuracy higher than 80\% even when less than 30 word samples are used during adaptation,while a system trained using the data of the single writer only needs at least 200 words in order to achieve the same performance as the adapted models.  2002 Elsevier Science B.V. All rights reserved.},
author = {Vinciarelli, a},
doi = {10.1016/S0167-8655(02)00021-1},
file = {:D$\backslash$:/Papers/Documents/2002/Vinciarelli - 2002.pdf:pdf},
journal = {Pattern Recognition Letters},
keywords = {hmm,hmm bayesian adaptation,hmm maximum likelihood adaptation,maximum a posteriori adaptation,off-line cursive script recognition},
month = jun,
number = {8},
pages = {905--916},
title = {{Writer adaptation techniques in HMM based Off-Line Cursive Script Recognition}},
volume = {23},
year = {2002}
}
@inproceedings{Kornai,
abstract = {The system described in this paper applies Hidden Markov technology to the task of recognizing the hand- written legal amount on personal checks. We argue that the most significant source of error in handwrit- ing recognition is the segmentation process. In tradi- tional handwriting OCR systems, recognition is per- formed at the character level, using the output of an independent segmentation step. Using a fixed stepsize series of vertical slices from the image, the HMM sys- tem described in this paper avoids taking segmentation decisions early in the recognition process.},
author = {Kornai, a. and Mohiuddin, K.M. and Connell, S.D.},
booktitle = {1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century},
doi = {10.1109/ICSMC.1995.538206},
file = {:D$\backslash$:/Papers/Documents/1995/Kornai, Mohiuddin, Connell - 1995.pdf:pdf},
isbn = {0-7803-2559-1},
pages = {2800--2805},
publisher = {Ieee},
title = {{An HMM-based legal amount field OCR system for checks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=538206},
year = {1995}
}
@article{Abd-Almageed2009,
author = {Abd-Almageed, Wael and Kumar, Jayant and Doermann, David},
doi = {10.1109/ICDAR.2009.276},
file = {:D$\backslash$:/Papers/Documents/2009/Abd-Almageed, Kumar, Doermann - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {768--772},
publisher = {Ieee},
title = {{Page Rule-Line Removal Using Linear Subspaces in Monochromatic Handwritten Arabic Documents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277504},
year = {2009}
}
@inproceedings{DSDing2008,
abstract = {A new courtesy amount recognition module of CENPARMIpsilas check reading
system (CRS) is proposed in this paper. The module consists of 3
main segments: pre-processing, segmentation and recognition, and
post-processing. A new feedback-based segmentation algorithm is adopted
for the segmentation task. Besides one individual numeral recognizer
for numerals from dasia0psila to dasia9psila, one convolutional neural
network(CNN) recognizer for ldquo00rdquo and ldquo000rdquo numeral
strings is also integrated into our module for the recognition task.
The experimental results on the Quebec Bell Check database show that
the recognition rate of the courtesy amount has improved from 41.2\%
to 74.3\%.},
author = {Ding, Wu and Suen, C Y and Krzyzak, A},
booktitle = {Pattern Recognition, 2008. ICPR 2008. 19th International Conference on},
doi = {10.1109/ICPR.2008.4761532},
file = {:D$\backslash$:/Papers/Documents/2008/Ding, Suen, Krzyzak - 2008.pdf:pdf},
issn = {1051-4651},
keywords = { ;image recognition;image segmentation;neural nets,CRS;check reading system;convolutional neural netw},
pages = {1--4},
title = {{A new courtesy amount recognition module of a Check Reading System}},
year = {2008}
}
@inproceedings{Ouyang2009,
author = {Ouyang, T.Y. and Davis, Randall},
booktitle = {Proc. International Joint Conferences on Artificial Intelligence},
file = {:D$\backslash$:/Papers/Documents/2009/Ouyang, Davis - 2009.pdf:pdf},
keywords = {Multidisciplinary Topics and Applications},
pages = {1463--1468},
title = {{A visual approach to sketched symbol recognition}},
url = {http://www.aaai.org/ocs/index.php/IJCAI/IJCAI-09/paper/download/281/918},
year = {2009}
}
@conference{ARSaabni2009b,
abstract = {In this paper, we present a multi-level recognizer for online Arabic
handwriting. In Arabic script (handwritten and printed), cursive
writing � is not a style � it is an inherent part of the script.
In addition, the connection between letters is done with almost no
ligatures, which complicates segmenting a word into individual letters.
In this work, we have adopted the holistic approach and avoided segmenting
words into individual letters. To reduce the search space, we apply
a series of filters in a hierarchicalmanner. The earlier filters
perform light processing on a large number of candidates, and the
later filters perform heavy processing on a small number of candidates.
In the first filter, global features and delayed strokes patterns
are used to reduce candidate word-part models. In the second filter,
local features are used to guide a dynamic time warping (DTW) classification.
The resulting k top ranked candidates are sent for shape-context
based classifier, which determines the recognized word-part. In this
work, we have modified the classic DTW to enable different costs
for the different operations and control their behavior. We have
performed several experimental tests and have received encouraging
results.},
author = {Saabni, Raid and El-Sana, Jihad},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Saabni, El-Sana - 2009(2).pdf:pdf},
title = {{Hierarchical On-line Arabic Handwriting Recognition}},
year = {2009}
}
@article{Gauthier2002,
author = {Gauthier, Nadii and Arti\`{e}res, T and Dorizzi, Bernadette},
file = {:D$\backslash$:/Papers/Documents/2002/Gauthier, Arti\`{e}res, Dorizzi - 2002.pdf:pdf},
journal = {end Recognition, 2001.},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {412--416},
title = {{Strategies for combining on-line and off-line information in an on-line handwriting recognition system}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=953823},
year = {2002}
}
@article{Broumandnia2008,
author = {Broumandnia, a and Shanbehzadeh, J and Rezakhahvarnoosfaderani, M},
doi = {10.1016/j.imavis.2007.09.004},
file = {:D$\backslash$:/Papers/Documents/2008/Broumandnia, Shanbehzadeh, Rezakhahvarnoosfaderani - 2008.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {farsi handwritings,holistic word recognition,m-band packet wavelet,row shift invariant},
month = jun,
number = {6},
pages = {829--842},
title = {{Persian/arabic handwritten word recognition using M-band packet wavelet transform}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885607001643},
volume = {26},
year = {2008}
}
@phdthesis{Rubine1991,
author = {Rubine, Dean},
file = {:D$\backslash$:/Papers/Documents/1991/Rubine - 1991(2).pdf:pdf},
pages = {1--290},
school = {Carnegie Mellon University},
title = {{Automatic Recogntion of Gestures}},
type = {PhD},
year = {1991}
}
@article{LIANG2008,
abstract = {This paper proposes an effective approach for content-based sketch retrieval. It addresses three characteristics as follows. Firstly, both structural relations and global shape descriptors are combined to represent sketch content. Secondly, feature weighting and combination are performed to obtain a reasonable mechanism for similarity calculation. Finally, relevance feedback based on biased SVM (BSVM) algorithm is employed to capture user’s query interests online and thus improve retrieval performance. Experiments prove the effectiveness of our proposed method in sketch retrieval.},
author = {LIANG, S and SUN, Z},
doi = {10.1016/j.patrec.2008.05.004},
file = {:D$\backslash$:/Papers/Documents/2008/LIANG, SUN - 2008.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {biased svm (bsvm),content representation,relevance feedback,similarity matching,sketch retrieval},
month = sep,
number = {12},
pages = {1733--1741},
title = {{Sketch retrieval and relevance feedback with biased SVM classification}},
url = {http://dx.doi.org/10.1016/j.patrec.2008.05.004},
volume = {29},
year = {2008}
}
@incollection{Hammond2002DomainAbstract,
author = {Hammond, Tracy and Davis, Randall},
booktitle = {MIT Artificial Intelligence Laboratory Annual Abstract},
keywords = {multimodal},
month = sep,
publisher = {MIT AI Lab},
title = {{A Domain Description Language for Sketch Recognition}},
year = {2002}
}
@inproceedings{DSFeritas2000,
abstract = {This paper presents a system that is being developed for the recognition
of the handwritten legal amount in Brazilian bank checks. Our strategy
used to approach the handwritten legal amount recognition problem
puts on evidence the keywords: "mil", "reals/real", "centavos/centavo"
which are almost always present in each amount. The recognizer, based
on hidden markov models, does a global word analysis, therefore,
it does not carry out an explicit segmentation of words into characters
or pseudo-characters. In this context, each word image is transformed
into a sequence of observations using pre-processing and feature
extraction stages. Our system, when tested on our database simulating
Brazilian bank checks, shows the viability of our approach.},
address = {Washington, DC, USA},
author = {Freitas, Cinthia Obladen de Almendra and Yacoubi, Abdenaim El and Bortolozzi, Fl\'{a}vio and Sabourin, Robert},
booktitle = {SIBGRAPI '00: Proceedings of the 13th Brazilian Symposium on Computer Graphics and Image Processing},
file = {:D$\backslash$:/Papers/Documents/2000/Freitas et al. - 2000.pdf:pdf},
isbn = {0-7695-0878-2},
pages = {97--104},
publisher = {IEEE Computer Society},
title = {{Brazilian Bank Check Handwritten Legal Amount Recognition}},
year = {2000}
}
@inproceedings{Koerich2004,
abstract = {To support large vocabulary handwriting recognition in standard computer platforms, a fast algorithm for hidden Markov model alignment is necessary. To address this prob- lem, we propose a non–heuristic fast decoding algorithm which is based on hidden Markov model representation of characters. The decoding algorithm breaks up the compu- tation of word likelihoods into two levels: state level and character level. Given an observation sequence, the two level decoding enables the reuse of character likelihoods to decode all words in the lexicon, avoiding repeated compu- tation of state sequences. In an 80,000–word recognition task, the proposed decoding algorithm is about 15 times faster than a conventional Viterbi algorithm, while main- taining the same recognition accuracy},
author = {Koerich, A.L. and Sabourin, Robert and Suen, C.Y.},
booktitle = {Frontiers in Handwriting Recognition, 2004. IWFHR-9 2004. Ninth International Workshop on},
file = {:D$\backslash$:/Papers/Documents/2004/Koerich, Sabourin, Suen - 2004.pdf:pdf},
isbn = {0769521878},
issn = {1550-5235},
pages = {232--237},
publisher = {IEEE},
title = {{Fast two-level HMM decoding algorithm for large vocabulary handwriting recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1363916},
year = {2004}
}
@inproceedings{Santos2009,
abstract = {Different strategies for combination of complementary features in an HMM-based method for handwritten character recognition are evaluated. In addition, a noise reduction method is proposed to deal with the negative impact of low probability symbols in the training database. New sequences of observations are generated based on the original ones, but considering a noise reduction process. The experimental results based on 52 classes of alphabetic characters and more than 23,000 samples have shown that the strategies proposed to optimize the HMM- based recognition method are very promising.},
author = {Santos, Murilo and Ko, Albert and Oliveira, Luis S. and Sabourin, Robert and Koerich, Alessandro L. and Jr., Alceu S. Britto},
booktitle = {2009 10th International Conference on Document Analysis and Recognition},
doi = {10.1109/ICDAR.2009.230},
file = {:D$\backslash$:/Papers/Documents/2009/Santos et al. - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
month = jul,
pages = {666--670},
publisher = {Ieee},
title = {{Evaluation of Different Strategies to Optimize an HMM-Based Character Recognition System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277474},
year = {2009}
}
@article{ARJawahar2009,
abstract = {Search and retrieval is gaining importance in the ink domain due to
the increase in the availability of online handwritten data. However,
the problem is challenging due to variations in handwriting between
various writers, digitizers and writing conditions. In this paper,
we propose a retrieval mechanism for online handwriting, which can
handle different writing styles, specifically for Indian languages.
The proposed approach provides a keyboard-based search interface
that enables to search handwritten data from any platform, in addition
to pen-based and example-based queries. One of the major advantages
of this framework is that information retrieval techniques such as
ranking relevance, detecting stopwords and controlling word forms
can be extended to work with search and retrieval in the ink domain.
The framework also allows cross-lingual document retrieval across
Indian languages.},
address = {New York, NY, USA},
author = {Jawahar, C V and Balasubramanian, A and Meshesha, Million and Namboodiri, Anoop M},
doi = {http://dx.doi.org/10.1016/j.patcog.2008.08.017},
file = {:D$\backslash$:/Papers/Documents/2009/Jawahar et al. - 2009.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recogn.},
keywords = { Handwriting synthesis, Indian language scripts, Information retrieval, Online handwriting,Search and retrieval},
number = {7},
pages = {1445--1457},
publisher = {Elsevier Science Inc.},
title = {{Retrieval of online handwriting by synthesis and matching}},
volume = {42},
year = {2009}
}
@inproceedings{Almaksour2009,
author = {Almaksour, Abdullah and Anquetil, Eric},
booktitle = {Document Analysis and Recognition, 2009. ICDAR'09. 10th International Conference on},
doi = {10.1109/ICDAR.2009.23},
file = {:D$\backslash$:/Papers/Documents/2009/Almaksour, Anquetil - 2009.pdf:pdf},
issn = {1520-5363},
pages = {81--85},
publisher = {IEEE},
title = {{Fast Incremental Learning Strategy Driven by Confusion Reject for Online Handwriting Recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5277781},
year = {2009}
}
@phdthesis{Yang2006,
author = {Yang, Chen},
booktitle = {Interfaces},
file = {:D$\backslash$:/Papers/Documents/2006/Yang - 2006.pdf:pdf},
keywords = {geometric modeling,sketch recognition,sketch-based modeling},
publisher = {Citeseer},
title = {{Sketch-based modeling of parameterized objects}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.86.8638\&amp;rep=rep1\&amp;type=pdf},
year = {2006}
}
@inproceedings{Patel2007,
author = {Patel, Rachel and Plimmer, Beryl and Grundy, John and Ihaka, Ross},
booktitle = {Proceedings of the 4th Eurographics workshop on Sketch-based interfaces and modeling},
file = {:D$\backslash$:/Papers/Documents/2007/Patel et al. - 2007.pdf:pdf},
pages = {131--138},
publisher = {ACM},
title = {{Ink features for diagram recognition}},
url = {http://portal.acm.org/citation.cfm?id=1384429.1384457},
year = {2007}
}
@inproceedings{PDB7Chen2004,
abstract = {This paper presents a new approach called Hierarchical Support Vector
Machines (HSVM), to address multi-class problems. The method solves
a series of max-cut problems to hierarchically and recursively partition
the set of classes into two-subsets, till pure leaf nodes that have
only one class label, are obtained. The SVM is applied at each internal
node to construct the discriminant function for a binary meta-class
classifier. Because max-cut unsupervised decomposition uses distance
measures to investigate the natural class groupings, HSVM has a fast
and intuitive SVM training process that requires little tuning and
yields both high accuracy levels and good generalization. The HSVM
method was applied to Hyperion hyperspectral data collected over
the Okavango Delta of Botswana. Classification accuracies and generalization
capability are compared to those achieved by the Best Basis Binary
Hierarchical Classifier, a Random Forest CART binary decision tree
classifier and Binary Hierarchical Support Vector Machines.},
author = {Chen, Yangchi and Crawford, M M and Ghosh, J},
booktitle = {Geoscience and Remote Sensing Symposium, 2004. IGARSS '04. Proceedings. 2004 IEEE International},
file = {:D$\backslash$:/Papers/Documents/2004/Chen, Crawford, Ghosh - 2004.pdf:pdf},
keywords = {SVM},
month = sep,
pages = {949--952},
publisher = {IEEE International},
title = {{Integrating support vector machines in a hierarchical output space decomposition framework}},
volume = {2},
year = {2004}
}
@inproceedings{DSAlamri2009,
abstract = {In this paper, we propose a new approach on segmentation and recognition
of off-line unconstrained Arabic handwritten numerals, which failed
to be segmented with connected component analysis. In our approach,
the touching numerals are automatically segmented when a set of parameters
is chosen. Models with different sets of parameters for each numeral
pair are designed for recognition. Each image in each model is recognized
as an isolated numeral. After normalizing and binarizing the images,
gradient features are extracted and recognized using SVMs. Finally,
a post-processing is proposed by based on the optimal combinations
of the recognition probabilities for each model. Experiments were
conducted on the CENPARMI Arabic, Dari, and Urdu touching numeral
pair databases [1,12].},
address = {M�nster, Germany},
author = {Alamri, Huda and He, Chun Lei and Suen, Ching Y},
booktitle = {Procedings CAIP (13th International Conference Computer Analysis of Images and Pattern s)},
file = {:D$\backslash$:/Papers/Documents/2009/Alamri, He, Suen - 2009.pdf:pdf},
keywords = { Arabic Digit Recognition, Gradient features.,Numeral pair segmentation},
pages = {165--172},
title = {{A New Approach for Segmentation and Recognition of Arabic Handwritten Touching Numeral Pairs}},
year = {2009}
}
@article{Yin2004,
author = {Yin, P},
doi = {10.1016/j.jvcir.2003.12.001},
file = {:D$\backslash$:/Papers/Documents/2004/Yin - 2004.pdf:pdf},
issn = {10473203},
journal = {Journal of Visual Communication and Image Representation},
keywords = {genetic algorithm,global optimal solution,local optimal,particle swarm optimization,polygonal approximation,solution},
month = jun,
number = {2},
pages = {241--260},
title = {{A discrete particle swarm algorithm for optimal polygonal approximation of digital curves}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1047320303000981},
volume = {15},
year = {2004}
}
@article{Al-Omari2001,
abstract = {A recognition system for identijjing hand-written Indian (Arabic) numerals one to nine (5- 9 has been developed. A graphical user interface was developed using advanced object oriented techniques that incorporates Matlab@ as a technical tool. The process involved extracting a feature vector to represent the handwritten sketch based on the “object” centroid and boundary points. A template vector was derived for each digit by taking the average feature vector of 30 handwritten sketches made by 30 different students. The test sketch is compared against all nine templates and a distance measure is performed to make the recognition. An overall hit ratio of 87.22\% was achieved in the preliminary results. The ratio reached IOO\% for some of the digits. But there was misinterpretation between similar digits like (7 and (9). This study is meant to be a seed toward building a recognition system for Arabic language characters.},
author = {Al-Omari, F.},
doi = {10.1109/AICCSA.2001.933955},
file = {:D$\backslash$:/Papers/Documents/2001/Al-Omari - 2001.pdf:pdf},
isbn = {0-7695-1165-1},
journal = {Proceedings ACS/IEEE International Conference on Computer Systems and Applications},
keywords = {Reference From Doctor,artificial intelligence,character recognition,image segmentation,pattern recognition,template},
mendeley-tags = {Reference From Doctor},
pages = {83--88},
publisher = {IEEE Comput. Soc},
title = {{Handwritten Indian numeral recognition system using template matching approaches}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=933955},
year = {2001}
}
@article{Sattar2008,
address = {New York, New York, USA},
author = {Sattar, Sohail a. and Haque, Shamsul and Pathan, Mahmood K.},
doi = {10.1145/1593105.1593192},
file = {:D$\backslash$:/Papers/Documents/2008/Sattar, Haque, Pathan - 2008.pdf:pdf},
isbn = {9781605581057},
journal = {Proceedings of the 46th Annual Southeast Regional Conference on XX - ACM-SE 46},
pages = {329},
publisher = {ACM Press},
title = {{Nastaliq optical character recognition}},
url = {http://portal.acm.org/citation.cfm?doid=1593105.1593192},
year = {2008}
}
@article{Fischer2001,
author = {Fischer, K.},
file = {:D$\backslash$:/Papers/Documents/2001/Fischer - 2001.pdf:pdf},
journal = {Computer-Aided Design},
publisher = {Citeseer},
title = {{Piecewise Linear Approximation of B\'{e}zier Curves}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.86.162\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
@conference{ARICDAR2007,
abstract = {This paper describes the Arabic handwriting recognition competition
held at ICDAR 2007. This second competition (the first was at ICDAR
2005) again uses the IFN/ENITdatabase with Arabic handwritten Tunisian
town names. Today, more than 54 research groups from universities,
research centers, and industry are working with this database worldwide.
This year, 8 groups with 14 systems are participating in the competition.
The systems were tested on known data and on two datasets which are
unknown to the participants. The systems are compared on the most
important characteristic, the recognition rate. Additionally, the
relative speed of the different systems were compared. A short description
of the participating groups, their systems, and the results achieved
are finally presented.},
author = {Margner, Volker and Abed, Haikal El},
booktitle = {ICDAR},
file = {:D$\backslash$:/Papers/Documents/2007/Margner, Abed - 2007.pdf:pdf},
title = {{ICDAR 2007 - Arabic Handwriting Recognition Competition}},
year = {2007}
}
@inproceedings{Sadri2003,
author = {Sadri, J and Suen, CY and Bui, TD},
booktitle = {Proceedings of Second Iranian Conference on Machine Vision and Image Processing},
file = {:D$\backslash$:/Papers/Documents/2003/Sadri, Suen, Bui - 2003.pdf:pdf},
keywords = {feature extraction,machine learning,mlp neural network,multiple support vector classifiers,ocr,optical character recognition,support,svm,vector machine},
number = {1},
pages = {300--307},
publisher = {Citeseer},
title = {{Application of support vector machines for recognition of handwritten Arabic/Persian digits}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.147.1765\&amp;rep=rep1\&amp;type=pdf},
volume = {1},
year = {2003}
}
@article{Davis2003,
author = {Davis, R. and Foltz, M.A.},
file = {:D$\backslash$:/Papers/Documents/2003/Davis, Foltz - 2003.pdf:pdf},
journal = {Theory and Practice},
number = {September},
pages = {1--2},
publisher = {Massachusetts Institute of Technology},
title = {{Dr. Jones: a software design explorer's crystal ball}},
url = {http://dspace.mit.edu/handle/1721.1/38454},
year = {2003}
}
@article{Apte1993,
author = {Apte, Ajay and Vo, Van and Dan, Takayuki and Science, Paper Technology},
file = {:D$\backslash$:/Papers/Documents/1993/Apte et al. - 1993.pdf:pdf},
journal = {Computing},
pages = {121--128},
title = {{Recognizing Multistroke Geometric shapes: An Experimental Evaluation.}},
year = {1993}
}
@article{Lin2006,
abstract = {In documents, tables are important structured objects that present statistical and relational information. In this paper, we present a robust system which is capable of detecting tables from free style online ink notes and extracting their structure so that they can be further edited in multiple ways. First, the primative structure of tables, i.e., candidates for ruling lines and table bounding boxes, are detected among drawing strokes. Second, the logical structure of tables is determined by normalizing the table skeletons, identifying the skeleton structure, and extracting the cell contents. The detection process is similar to a decision tree so that invalid candidates can be ruled out quickly. Experimental results suggest that our system is robust and accurate in dealing with tables having complex structure or drawn under complex situations.},
author = {Lin, Zhouchen and He, Junfeng and Zhong, Zhicheng and Wang, Rongrong and Shum, Heung-Yeung},
doi = {10.1109/TPAMI.2006.173},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automatic Data Processing,Automatic Data Processing: methods,Computer Graphics,Documentation,Documentation: methods,Handwriting,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Online Systems,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Statistics as Topic,User-Computer Interface,sketch Research},
mendeley-tags = {sketch Research},
month = aug,
number = {8},
pages = {1341--6},
pmid = {16886868},
publisher = {Published by the IEEE Computer Society},
title = {{Table detection in online ink notes.}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/TPAMI.2006.173},
volume = {28},
year = {2006}
}
@article{Fan2003,
author = {Fan, Z. and Chi, M. and Oliveira, M.M.},
doi = {10.1109/SIBGRA.2003.1241000},
file = {:D$\backslash$:/Papers/Documents/2003/Fan, Chi, Oliveira - 2003.pdf:pdf},
isbn = {0-7695-2032-4},
journal = {16th Brazilian Symposium on Computer Graphics and Image Processing (SIBGRAPI 2003)},
pages = {125--131},
publisher = {IEEE Comput. Soc},
title = {{A sketch-based collaborative design system}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1241000},
year = {2003}
}
@article{Olsen2007,
address = {Gent, BELGIUM},
author = {Olsen, Luke and Samavati, Faramarz and {Costa Sousa}, Mario},
doi = {10.4108/ICST.IMMERSCOM2007.2114},
file = {:D$\backslash$:/Papers/Documents/2007/Olsen, Samavati, Costa Sousa - 2007.pdf:pdf},
journal = {Proceedings of the ImmersCom},
keywords = {Doctor Samavati,Scholarships Doctors,To Read,gesture recognition,interaction techniques},
mendeley-tags = {Scholarships Doctors,To Read},
publisher = {Icst},
title = {{Fast Stroke Matching by Angle Quantization}},
url = {http://eudl.eu/?id=2114},
year = {2007}
}
@phdthesis{AndrewCorrea2009,
abstract = {This thesis introduces the idea that combining sketch recognition with contextual data—information about what is being drawn on—can improve the recognition of meaning in sketch and enrich the user interaction experience. I created a language called StepStool that facilitates the description of the re- lationship between digital ink and contextual data, and wrote the corresponding interpreter that enables my system to distinguish between gestural commands is- sued to an autonomous forklift. Auser study was done to compare the correctness of a sketch interface with and without context on the canvas. This thesis coins the phrase “Drawing on theWorld” to mean contextual sketch reconition, describes the implementation and methodology behind “Drawing on theWorld”, describes the forklift’s interface, and discusses other possible uses for a contextual gesture recognizer. Sample code is provided that describes the specifics of the StepStool engine’s implementation and the implementation of the forklift’s interface.},
author = {{Andrew Correa}},
file = {:D$\backslash$:/Papers/Documents/2009/Andrew Correa - 2009.pdf:pdf},
school = {MASSACHUSETTS INSTITUTE OF TECHNOLOGY},
title = {{Drawing on the World : Sketch in Context by Andrew Correa}},
year = {2009}
}
@inproceedings{Gross1996,
author = {Gross, M.D. and Do, E.Y.L.},
booktitle = {Proceedings of the 9th annual ACM symposium on User interface software and technology},
file = {:D$\backslash$:/Papers/Documents/1996/Gross, Do - 1996.pdf:pdf},
isbn = {0897917987},
pages = {183--192},
publisher = {ACM},
title = {{Ambiguous intentions: a paper-like interface for creative design}},
url = {http://portal.acm.org/citation.cfm?id=237091.237119},
year = {1996}
}
@incollection{Sezgin2004EfficientAbstract,
author = {Sezgin, Tevfik Metin and Davis, Randall},
booktitle = {MIT Computer Science and Artificial Intelligence Laboratory Annual Research Abstract},
file = {:D$\backslash$:/Papers/Documents/2004/Sezgin, Davis - 2004(3).pdf:pdf},
publisher = {MIT CSAIL},
title = {{Efficient search space exploration for sketch recognition}},
year = {2004}
}
@article{Blagojevic2008,
author = {Blagojevic, Rachel and Plimmer, Beryl and Grundy, John and Wang, Yong},
doi = {10.1109/VLHCC.2008.4639100},
file = {:D$\backslash$:/Papers/Documents/2008/Blagojevic et al. - 2008.pdf:pdf},
isbn = {978-1-4244-2528-0},
issn = {1943-6092},
journal = {2008 IEEE Symposium on Visual Languages and Human-Centric Computing},
month = sep,
pages = {258--259},
publisher = {Ieee},
title = {{Development of techniques for sketched diagram recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4639100},
year = {2008}
}
@inproceedings{DSZiaratban2007,
abstract = {The study of handwritten words is tied to the development of recognition
methods to be used in real-world applications involving handwritten
words, such as handwritten texts, bank checks, and postal envelopes,
among others. In this paper an approach for Farsi bank checks was
proposed in which the legal amounts are used to aid the recognition
results of courtesy amounts. The legal amounts which are set of some
of 40 specified words are divided into their sub- words. Some if-then
rules are extracted from validation set to validate the recognized
digits. These rules are used to confirm, correct or reject the recognized
digit. The experimental results reveal a recognition rate of 85.33\%
without the legal amounts, and a reliability rate 99.31\% with a rejection
rate of 3.67\%.},
author = {Ziaratban, M and Faez, K and Ezoji, M},
booktitle = {Ninth International Conference on Document Analysis and Recognition, 2007. ICDAR 2007.},
doi = {10.1109/ICDAR.2007.4377090},
file = {:D$\backslash$:/Papers/Documents/2007/Ziaratban, Faez, Ezoji - 2007.pdf:pdf},
issn = {1520-5363},
keywords = { ;,Farsi bank checks;courtesy amount;handwritten text},
pages = {1123--1127},
title = {{Use of Legal Amount to Confirm or Correct the Courtesy Amount on Farsi Bank Checks}},
volume = {2},
year = {2007}
}
@inproceedings{Alvarado2004Sketch,
author = {Alvarado, Christine},
booktitle = {Making Pen-Based Interaction Intelligent and Natural},
file = {:D$\backslash$:/Papers/Documents/2004/Alvarado - 2004(2).pdf:pdf},
publisher = {AAAI Fall Symposium},
title = {{Sketch Recognition User Interfaces: Guidelines for Design and Development}},
year = {2004}
}
@article{Hammond2006,
address = {New York, New York, USA},
author = {Hammond, Tracy and Davis, Randall},
doi = {10.1145/1111449.1111495},
file = {:D$\backslash$:/Papers/Documents/2006/Hammond, Davis - 2006.pdf:pdf},
isbn = {1595932879},
journal = {Proceedings of the 11th international conference on Intelligent user interfaces - IUI '06},
keywords = {active learning,ladder,near-miss,scription,shape de-,sketch recognition,structural description,user},
pages = {210},
publisher = {ACM Press},
title = {{Interactive learning of structural shape descriptions from automatically generated near-miss examples}},
url = {http://portal.acm.org/citation.cfm?doid=1111449.1111495},
year = {2006}
}
@article{Popovic2003,
author = {Popovi\'{c}, Jovan and Seitz, Steven M. and Erdmann, Michael},
doi = {10.1145/944020.944025},
file = {:D$\backslash$:/Papers/Documents/2003/Popovi\'{c}, Seitz, Erdmann - 2003.pdf:pdf},
issn = {07300301},
journal = {ACM Transactions on Graphics},
month = oct,
number = {4},
pages = {1034--1054},
title = {{Motion sketching for control of rigid-body simulations}},
url = {http://portal.acm.org/citation.cfm?doid=944020.944025},
volume = {22},
year = {2003}
}
@article{Tenenbaum2000,
author = {Tenenbaum, Joshua B and Silva, Vin De and Langford, John C},
file = {:D$\backslash$:/Papers/Documents/2000/Tenenbaum, Silva, Langford - 2000.pdf:pdf},
journal = {Science},
number = {December},
pages = {2319--2323},
title = {{A Global Geometric Framework for Nonlinear Dimensionality Reduction}},
volume = {290},
year = {2000}
}
@incollection{Foltz2001Graph,
author = {Foltz, Mark},
booktitle = {MIT Artificial Intelligence Laboratory Annual Abstract},
file = {:D$\backslash$:/Papers/Documents/2001/Foltz - 2001.pdf:pdf},
month = sep,
publisher = {MIT AI Lab},
title = {{Graph Exploration for Software Archeology}},
year = {2001}
}
@inproceedings{FEAbdullah2007,
abstract = {Vehicle license plate recognition has been intensively studied in
many countries. Due to the different types of license plates being
used, the requirement of an automatic license plate recognition system
is different for each country. In this paper, an automatic license
plate recognition system is proposed for Malaysian vehicles with
standard license plates using blob labeling and clustering for segmentation,
seven popular and one proposed edge detectors for feature extraction
and neural networks for classification.There were eight experiments
conducted using eight different edge dectectors: Kirsch, Sobel, Laplacian,
Wallis, Prewitt, Frei Chen and a proposed edge detector. The result
had shown kirsch edge detectors is the best technique for feature
exractor while the proposed achieved better results compared to Prewitt,
Frei Chen and Wallis.},
address = {Washington, DC, USA},
author = {Abdullah, Siti Norul Huda Sheikh and Khalid, Marzuki and Yusof, Rubiyah and Omar, Khairuddin},
booktitle = {AMS '07: Proceedings of the First Asia International Conference on Modelling \& Simulation},
doi = {http://dx.doi.org/10.1109/AMS.2007.25},
file = {:D$\backslash$:/Papers/Documents/2007/Abdullah et al. - 2007.pdf:pdf},
isbn = {0-7695-2845-7},
pages = {502--506},
publisher = {IEEE Computer Society},
title = {{Comparison of Feature Extractors in License Plate Recognition}},
year = {2007}
}
@article{Liwicki2009,
author = {Liwicki, Marcus and Bunke, Horst},
doi = {10.1016/j.patcog.2008.10.030},
file = {:D$\backslash$:/Papers/Documents/2009/Liwicki, Bunke - 2009(2).pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {multiple classifier combination,off-line handwriting recognition,on-line handwriting recognition},
month = dec,
number = {12},
pages = {3254--3263},
title = {{Combining diverse on-line and off-line systems for handwritten text line recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308004652},
volume = {42},
year = {2009}
}
@article{YantingDong2003,
abstract = {—Weconsider the problem of estimating the pose of a target basedon a sequence of scattered waveformsmeasuredat multiple target-sensor orientations. Using a hidden Markov model (HMM) representation of the scattered-waveform sequence, pose estimation reduces to estimating the underlyingHMMstates from a sequence of observations. It is assumed that each scattered waveform must be quantized via an encoding procedure. A distortionDis defined as the error in estimating the underlying HMM states, and the rate R represents the size of the discrete-HMM codebook. Rate-distortion theory is applied to define the minimum rate required to achieve a desired distortion, denoted as RðDÞ. After deriving the rate-distortion function RðDÞ, we demonstrate that discrete-HMMperformance based on Lloyd encoding is far from this bound. Performance is improved via block coding, based on Bayes VQ. Results are presented for acanonicalHMMproblem,andthen for multiaspect acoustic scatteringfrom underwater elastic targets. Although theexamplespresented here are for multiaspect scattering and pose estimation, the results are of general applicability to discrete-HMMstate estimation.},
author = {{Yanting Dong}},
doi = {10.1109/TPAMI.2003.1206516},
file = {:D$\backslash$:/Papers/Documents/2003/Yanting Dong - 2003.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {HMM,Rate distortion,pose estimation,underwater sensing,vector quantization},
month = jul,
number = {1},
pages = {1303--883},
title = {{Rate-distortion analysis of discrete-HMM pose estimation via multiaspect scattering data}},
volume = {81},
year = {2003}
}
@article{Hammond2004Automatically,
address = {San Jose, CA},
author = {Hammond, Tracy and Davis, Randall},
journal = {Proceedings of the Nineteenth National Conference on Artificial Intelligence (AAAI-04)},
title = {{Automatically Transforming Symbolic Shape Descriptions for Use in Sketch Recognition}},
year = {2004}
}
@article{FE3Lauer2007,
abstract = {This article focuses on the problems of feature extraction and the
recognition of handwritten digits. A trainable feature extractor
based on the LeNet5 convolutional neural network architecture is
introduced to solve the first problem in a black box scheme without
prior knowledge on the data. The classification task is performed
by support vector machines to enhance the generalization ability
of LeNet5. In order to increase the recognition rate, new training
samples are generated by affine transformations and elastic distortions.
Experiments are performed on the well-known MNIST database to validate
the method and the results show that the system can outperform both
SVMs and LeNet5 while providing performances comparable to the best
performance on this database. Moreover, an analysis of the errors
is conducted to discuss possible means of enhancement and their limitations.},
author = {Lauer, Fabien and Suen, Ching Y and Bloch, Gerard},
file = {:D$\backslash$:/Papers/Documents/2007/Lauer, Suen, Bloch - 2007.pdf:pdf},
journal = {Pattern Recognition},
keywords = { Handwritten digits,Features Extraction},
pages = {1816--1824},
title = {{A trainable feature extractor for handwritten digit recognition}},
volume = {40},
year = {2007}
}
@inproceedings{Oltmans2001Naturally,
author = {Oltmans, Michael and Davis, Randall},
booktitle = {Workshop on Perceptive User Interfaces},
file = {:D$\backslash$:/Papers/Documents/2006/Oltmans, Davis - 2006.pdf:pdf},
title = {{Naturally Conveyed Explanations of Device Behavior}},
year = {2001}
}
@inproceedings{PDBLi2003,
abstract = {We introduce a new method, called CS4, to construct committees of
decision trees for classification. The method considers different
top-ranked features as the root nodes of member trees. This idea
is particularly suitable for dealing with high-dimensional bio-medical
data as top-ranked features in this type of data usually possess
similar merits for classification. To make a decision, the committee
combines the power of individual trees in a weighted manner. Unlike
Bagging or Boosting which uses bootstrapped training data, our method
builds all the member trees of a committee using exactly the same
set of training data. We have tested these ideas on UCI data sets
as well as recent bio-medical data sets of gene expression or proteomic
profiles that are usually described by more than 10,000 features.
All the experimental results show that our method is efficient and
that the classification performance are superior to C4.5 family algorithms.},
address = {Melbourne, Florida, USA},
author = {Li, Jinyan and Liu, Huiqing},
booktitle = {Proceedings of the 3rd IEEE International Conference on Data Mining (ICDM 2003), 19-22 December 2003},
doi = {http://csdl.computer.org/comp/proceedings/icdm/2003/1978/00/19780585abs.htm},
file = {:D$\backslash$:/Papers/Documents/2003/Li, Liu - 2003.pdf:pdf},
isbn = {0-7695-1978-4},
pages = {585},
publisher = {IEEE Computer Society, Washington, DC, USA},
title = {{Ensembles of Cascading Trees}},
year = {2003}
}
@inproceedings{Huang2006,
abstract = {Many feature selection models have been proposed for online handwriting recognition. However, most of them re- quire expensive computational overhead, or inaccurately find an improper feature set which leads to unacceptable recognition rates. This paper presents a new efficient fea- ture selection model for handwriting symbol recognition by using an improved sequential floating search method cou- pled with a hybrid classifier, which is obtained by combin- ing Hidden Markov Models with Multilayer Forward Net- work. The effectiveness of proposed method is verified by comprehensive experiments based on UNIPEN database.},
author = {Huang, BQ and Kechadi, M-t},
booktitle = {Machine Learning and Applications, 2006. ICMLA'06. 5th International Conference on},
file = {:D$\backslash$:/Papers/Documents/2006/Huang, Kechadi - 2006.pdf:pdf},
isbn = {0769527353},
pages = {251--257},
publisher = {IEEE},
title = {{A fast feature selection model for online handwriting symbol recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4041500},
year = {2006}
}
@inproceedings{Bimber1999,
author = {Bimber, Oliver},
booktitle = {Proceedings of the ACM symposium on Virtual reality software and technology},
file = {:D$\backslash$:/Papers/Documents/1999/Bimber - 1999.pdf:pdf},
keywords = {dynamic gesture recognition,freehand sketching,object creation},
pages = {182--183},
publisher = {ACM},
title = {{Rudiments for a 3D freehand sketch based human-computer interface for immersive virtual enviroments}},
url = {http://portal.acm.org/citation.cfm?id=323700},
year = {1999}
}
@misc{DSChan,
author = {N, WINN IE CHA},
file = {:D$\backslash$:/Papers/Documents/2002/N - 2002.pdf:pdf},
institution = {MIT},
title = {{IMPROVING THE AUTOMATIC PROCESSING OF HANDWRITTEN BANK CHECKS}},
year = {2002}
}
@mastersthesis{Adler2003Segmentation,
address = {Cambridge, MA},
author = {Adler, Aaron},
month = feb,
school = {Massachusetts Institute of Technology},
title = {{Segmentation and Alignment of Speech and Sketching in a Design Environment}},
year = {2003}
}
@article{Xie2002,
author = {Xie, Yonghong and Ji, Q.},
file = {:D$\backslash$:/Papers/Documents/2002/Xie, Ji - 2002.pdf:pdf},
issn = {1051-4651},
journal = {Pattern Recognition},
number = {c},
pages = {20957},
title = {{A new efficient ellipse detection method}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICPR.2002.1048464},
volume = {2},
year = {2002}
}
@article{Oksuz2008,
abstract = {In this paper we present a video based text and equation editor for LaTeX. The system recognizes what is written onto paper and generates the LaTeX code. Text and equations are written on a regular paper using a board marker, and a USB camera attached to a computer is used to capture and record the pen-tip positions in each consecutive image frame. Characters and symbols are represented as separate finite state machines (FSMs). They are written in an isolated manner and they are recognized on-line using the FSMs. In the last step, LaTeX code corresponding to recognized characters and symbols is generated},
author = {Oksuz, Ozcan and Gudukbay, Ugur and Cetin, A Enis},
doi = {10.1016/j.engappai.2007.08.003},
file = {:D$\backslash$:/Papers/Documents/2008/Oksuz, Gudukbay, Cetin - 2008.pdf:pdf},
issn = {0952-1976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {handwritten character recognition,mathematical expression,mathematical notation recognition,on-line recognition,pattern recognition},
number = {6},
pages = {952--960},
publisher = {Elsevier},
title = {{A video-based text and equation editor for LaTeX}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0952197607001121},
volume = {21},
year = {2008}
}
@inproceedings{ARBoussellaa2007,
abstract = {This paper presents a new color document image segmentation system
suitable for historical Arabic manuscripts. Our system is composed
of a hybrid method which couple together background light intensity
normalization algorithm and k-means clustering with maximum likelihood
(ML) estimation, for foreground/ background separation. Firstly,
the background normalization algorithm performs separation between
foreground and background. This foreground is used in later steps.
Secondly, our algorithm proceeds on luminance and distort the contrast.
These distortions are corrected with a gamma correction and contrast
adjustment. Finally, the new enhanced foreground image is segmented
to foreground/background on the basis of ML estimation. The initial
parameters for the ML method are estimated by k-means clustering
algorithm. The segmented image is used to produce a final restored
document image. The techniques are tested on a set of Arabic historical
manuscripts documents from the National Tunisian Library. The performance
of the algorithm is demonstrated on by real color manuscripts distorted
with show-through effects, uneven background color and localized
spot.},
address = {Seoul, Korea},
author = {Boussellaa, Wafa and Zahour, Abderrazak and Alimi, Adel},
booktitle = {SAC '07: Proceedings of the 2007 ACM symposium on Applied computing},
doi = {http://doi.acm.org/10.1145/1244002.1244141},
file = {:D$\backslash$:/Papers/Documents/2007/Boussellaa, Zahour, Alimi - 2007.pdf:pdf},
isbn = {1-59593-480-4},
keywords = { Arabic historical color manuscript image., foreground/background, k-means, light intensity normalisation, maximum likelihood, restoration,Segmentation},
pages = {605--609},
publisher = {ACM},
title = {{A Methodology for the Separation of Foreground/Background in Arabic Historical Manuscripts using Hybrid Methods}},
year = {2007}
}
@article{Tsu1997,
author = {Tsu, Kamihama},
file = {:D$\backslash$:/Papers/Documents/1997/Tsu - 1997.pdf:pdf},
journal = {Test},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {866--869},
title = {{F. Kimura+, N. Kayahara+, Y. Miyake+, M. Shridhar++ + Faculty of Engineering, Mie University 15 15 Kamihama Tsu 5 14, JAPAN}},
year = {1997}
}
@article{Maniezzo1999,
author = {Maniezzo, Vittorio and Carbonaro, Antonella},
file = {:D$\backslash$:/Papers/Documents/1999/Maniezzo, Carbonaro - 1999.pdf:pdf},
keywords = {ant colony optimization,combinatorial optimization},
title = {{Ant Colony Optimitzation: An Overview}},
year = {1999}
}
@inproceedings{Monson2006,
author = {Monson, C.K. and Seppi, K.D.},
booktitle = {Proceedings of the 8th annual conference on Genetic and evolutionary computation},
file = {:D$\backslash$:/Papers/Documents/2006/Monson, Seppi - 2006.pdf:pdf},
isbn = {1595931864},
keywords = {adaptation,optimization,swarm intelligence},
pages = {59--66},
publisher = {ACM},
title = {{Adaptive diversity in PSO}},
url = {http://portal.acm.org/citation.cfm?id=1144006},
year = {2006}
}
@article{Nel2008,
abstract = {Static handwritten scripts originate as images on documents and do not, by definition, contain any dy- namic information. To improve the accuracy of static handwriting recognition systems, many techniques aim to estimate dynamic information from the static scripts. Mostly, the pen trajectories of the scripts are estimated. However, the efficacy of the resulting pen trajectories are rarely evaluated quantitatively. This paper proposes a protocol for the objective evaluation of automatically determined pen trajectories. A hidden Markov model is derived from a ground-truth trajectory. An estimated trajectory is then matched to the derived model. Statistics describing substitution, insertion and deletion errors are then computed from this match. The proposed algorithm is especially useful for performance comparisons between different pen trajectory estimation algorithms. ©},
author = {Nel, Emli-mari and {Du Preez}, JA and Herbst, BM},
doi = {10.1016/j.patcog.2008.05.005},
file = {:D$\backslash$:/Papers/Documents/2008/Nel, Du Preez, Herbst - 2008.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {Automatic assessment,Estimating pen trajectories of static scripts,document analysis,document processing,handwriting analysis,pattern recognition,strok recovery,text processing},
number = {12},
pages = {3773--3785},
publisher = {Elsevier},
title = {{Verification of dynamic curves extracted from static handwritten scripts}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308001726},
volume = {41},
year = {2008}
}
@inproceedings{PDBMozaffari2005,
abstract = {A Statistical method embedded with statistical features is proposed
for Farsi/Arabic handwritten zip code recognition in this paper.
The numeral is first smoothed and the skeleton is obtained. A set
of feature points are then detected and the skeleton is decomposed
into primitives. A primitive code includes the information of each
primitive and a global code is derived from the primitive codes to
describe the topological structure of the skeleton. By using the
average and variance of X and Y changes in each primitive, the Direction
and curvature of the skeleton can be statistically described. 

Since the global codes have different lengths, we applied PCA algorithm
to normalize their lengths. Thanks to statistically description of
the skeleton, we can use the nearest neighbor classifier for recognition.


According to experimental results, classification rate of 94.44\% is
obtained for numerals on the test sets gathered from various people
with different educational background and different ages. Our database
includes 480 samples per digit. We used 280 samples of each digit
for training and the rest (200) for test.},
address = {Seoul, Korea},
author = {Mozaffari, Saeed and Faez, Karim and Ziaratban, Majid},
booktitle = {Eighth International Conference on Document Analysis and Recognition (ICDAR 2005)},
doi = {http://doi.ieeecomputersociety.org/10.1109/ICDAR.2005.221},
file = {:D$\backslash$:/Papers/Documents/2005/Mozaffari, Faez, Ziaratban - 2005.pdf:pdf},
isbn = {0-7695-2420-6},
pages = {237--241},
publisher = {IEEE Computer Society},
title = {{Structural Decomposition and Statistical Description of Farsi/Arabic Handwritten Numeric Characters.}},
year = {2005}
}
@inproceedings{DSMelegy2007,
abstract = {The domain of automatic handwriting recognition has a variety of applications
in real world problems such as cheque processing, office automation
and data entry applications. In this paper an approach for describing
the role of holistic structural features in the recognition of offline
handwritten Arabic literal amounts has been presented. Our proposed
system attempts to recognize words from their overall shape. The
extracted features are presented to several classifiers. The system
is trained and tested using an Arabic handwritten database.},
author = {El-Melegy, M T and Abdelbaset, A A},
booktitle = {Information and Communications Technology, 2007. ICICT 2007. ITI 5th International Conference on},
doi = {10.1109/ITICT.2007.4475631},
file = {:D$\backslash$:/Papers/Documents/2007/El-Melegy, Abdelbaset - 2007.pdf:pdf},
keywords = {Arabic handwritten database;automatic handwriting },
pages = {125--129},
title = {{Global features for offline recognition of handwritten Arabic literal amounts}},
year = {2007}
}
@article{Agarwal1995,
author = {Agarwal, a. and Granowetter, L. and Hussein, K. and Gupta, a. and Wang, P.S.P.},
doi = {10.1109/ICDAR.1995.602011},
file = {:D$\backslash$:/Papers/Documents/1995/Agarwal et al. - 1995.pdf:pdf},
isbn = {0-8186-7128-9},
journal = {Proceedings of 3rd International Conference on Document Analysis and Recognition},
keywords = {all checks,block detection,cessing,check analysis and pro-,heuristics,image processing,optical character recognition,pattern recognition,segmentation,some courtesy amount,the same place on},
pages = {748--751},
publisher = {IEEE Comput. Soc. Press},
title = {{Detection of courtesy amount block on bank checks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=602011},
year = {1995}
}
@inproceedings{Juchmes2004,
author = {Juchmes, Roland and Leclercq, Pierre and Azar, Sleiman},
booktitle = {EG Workshop on Sketch-Based Interfaces and Modeling},
file = {:D$\backslash$:/Papers/Documents/2004/Juchmes, Leclercq, Azar - 2004.pdf:pdf},
pages = {53--61},
title = {{A multi-agent system for the interpretation of architectural sketches}},
url = {http://www.uop.edu.jo/download/research/members/06.pdf},
year = {2004}
}
@article{Tao2007,
author = {Tao, Wenbing and Jin, Hai and Liu, Liman},
doi = {10.1016/j.patrec.2006.11.007},
file = {:D$\backslash$:/Papers/Documents/2007/Tao, Jin, Liu - 2007.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {ant colony optimization,fuzzy entropy,global thresholding,infrared object segmentation,performance evaluation},
month = may,
number = {7},
pages = {788--796},
title = {{Object segmentation using ant colony optimization algorithm and fuzzy entropy☆}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865506002893},
volume = {28},
year = {2007}
}
@article{Salah2002,
author = {a.a. Salah and Alpaydin, E. and Akarun, L.},
doi = {10.1109/34.990146},
file = {:D$\backslash$:/Papers/Documents/2002/Salah, Alpaydin, Akarun - 2002.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = mar,
number = {3},
pages = {420--425},
title = {{A selective attention-based method for visual pattern recognition with application to handwritten digit recognition and face recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=990146},
volume = {24},
year = {2002}
}
@article{Alvarado2006,
address = {New York, New York, USA},
author = {Alvarado, Christine and Davis, Randall},
doi = {10.1145/1185657.1185793},
file = {:D$\backslash$:/Papers/Documents/2006/Alvarado, Davis - 2006.pdf:pdf},
isbn = {1595933646},
journal = {ACM SIGGRAPH 2006 Courses on - SIGGRAPH '06},
pages = {32},
publisher = {ACM Press},
title = {{Dynamically constructed Bayes nets for multi-domain sketch understanding}},
url = {http://portal.acm.org/citation.cfm?doid=1185657.1185793},
year = {2006}
}
@article{Hammond2002a,
author = {Hammond, T. and Hammond, J.},
doi = {10.1109/FIE.2002.1158185},
file = {:D$\backslash$:/Papers/Documents/2002/Hammond, Hammond - 2002.pdf:pdf},
isbn = {0-7803-7444-4},
journal = {32nd Annual Frontiers in Education},
pages = {F3C--5--F3C--10},
publisher = {Ieee},
title = {{Gender-based underrepresentation in computer science and related disciplines}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1158185},
year = {2002}
}
@article{Rodriguez-Serranoa2009,
abstract = {Handwritten word-spotting is traditionally viewed as an image matching task between one or multiple query word-images and a set of candidate word-images in a database. This is a typical instance of the query-by-example paradigm. In this article, we introduce a statistical framework for the word-spotting problem which employs hidden Markov models (HMMs) to model keywords and a Gaussian mixture model (GMM) for score normalization. We explore the use of two types of HMMs for the word modeling part: continuous HMMs (C-HMMs) and semi-continuous HMMs (SC-HMMs), i.e. HMMs with a shared set of Gaussians. We show on a challenging multi-writer corpus that the proposed statistical framework is always superior to a traditional matching system which uses dynamic time warping (DTW) for word- image distance computation. A very important finding is that the SC-HMM is superior when labeled training data is scarce—as low as one sample per keyword—thanks to the prior information which can be incorporated in the shared set of Gaussians. ©},
author = {Rodriguez-Serranoa, J.A. and Perronninb, F.},
doi = {10.1016/j.patcog.2009.02.005},
file = {:D$\backslash$:/Papers/Documents/2009/Rodriguez-Serranoa, Perronninb - 2009.pdf:pdf},
journal = {Pattern Recognition},
number = {1},
pages = {2106--2116},
title = {{Handwritten word-spotting using hidden Markov models and universal vocabularies}},
url = {http://www.comp.leeds.ac.uk/scsjars/pubs/rodriguez\_wordspotting\_HMM.pdf},
volume = {42},
year = {2009}
}
@article{Forbus2004,
author = {Forbus, K.D. and Usher, J. and Chapman, V.},
file = {:D$\backslash$:/Papers/Documents/2004/Forbus, Usher, Chapman - 2004.pdf:pdf},
issn = {0738-4602},
journal = {AI magazine},
number = {3},
pages = {61},
title = {{Qualitative spatial reasoning about sketch maps}},
url = {http://www.aaai.org/ojs/index.php/aimagazine/article/viewArticle/1777},
volume = {25},
year = {2004}
}
@article{MCHotta2009,
abstract = {zzzzzzzzzzzzzzzzzz},
author = {Hotta, Kazuhiro},
file = {:D$\backslash$:/Papers/Documents/2009/Hotta - 2009.pdf:pdf},
journal = {Pattern Recognition},
pages = {619--628},
title = {{Adaptive weighting of local classifiers by particle filters for robust tracking}},
volume = {42},
year = {2009}
}
@misc{Chang2001,
author = {Chang, C.C. and Lin, C.J.},
booktitle = {Computer},
file = {:D$\backslash$:/Papers/Documents/2001/Chang, Lin - 2001.pdf:pdf},
pages = {1--30},
publisher = {Citeseer},
title = {{LIBSVM: a library for support vector machines}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.4532\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
@article{Elms1998,
abstract = {. A method for word recognition based on the use of hidden Markov models (HMMs) is described. An evaluation of its performance is presented using a test set of real printed documents that have been subjected to se- vere photocopy and fax transmission distortions. A com- parison with a commercial OCR package highlights the inherent advantages of a segmentation-free recognition strategy when the word images are severely distorted, as well as the importance of using contextual knowledge. The HMM method makes only one quarter of the num- ber of word errors made by the commercial package when tested on word images taken from faxed pages.},
author = {a.J. Elms and Procter, S. and Illingworth, J.},
doi = {10.1007/s100320050003},
file = {:D$\backslash$:/Papers/Documents/1998/Elms, Procter, Illingworth - 1998.pdf:pdf},
issn = {1433-2833},
journal = {International Journal on Document Analysis and Recognition},
keywords = {Reference From Doctor,hidden markov,ocr,word recognition},
mendeley-tags = {Reference From Doctor},
month = feb,
number = {1},
pages = {18--36},
title = {{The advantage of using an HMM-based approach for faxed word recognition}},
url = {http://www.springerlink.com/openurl.asp?genre=article\&id=doi:10.1007/s100320050003},
volume = {1},
year = {1998}
}
@article{Ball2009,
author = {Ball, Gregory R. and Srihari, Sargur N.},
doi = {10.1109/ICDAR.2009.249},
file = {:D$\backslash$:/Papers/Documents/2009/Ball, Srihari - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {26--30},
publisher = {Ieee},
title = {{Semi-supervised Learning for Handwriting Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277806},
year = {2009}
}
@inproceedings{DSXu2002,
abstract = { This paper describes an off-line system which recognizes unconstrained
handwritten month words extracted from Canadian bank cheques. A segmentation
based grapheme level HMM (hidden Markov model) classifier and two
multilayer perceptron classifiers with different architectures and
different features have been developed in CENPARMI for the recognition
of month words. In this paper, a combination method with an effective
conditional topology is presented, and the most widely used combination
rules including Vote, Sum and Product, are experimented. A new modified
Product rule is also proposed, which has produced the best recognition
rate of 85.36\% when tested on a real-life standard Canadian bank
cheque database.},
author = {Xu, Qizhi and Kim, Jin Ho and Lam, L and Suen, C Y},
booktitle = {Frontiers in Handwriting Recognition, 2002. Proceedings. Eighth International Workshop on},
doi = {10.1109/IWFHR.2002.1030895},
file = {:D$\backslash$:/Papers/Documents/2002/Xu et al. - 2002.pdf:pdf},
keywords = {CENPARMI; Canadian bank cheques; Hidden Markov Mod},
pages = {111--116},
title = {{Recognition of handwritten month words on bank cheques}},
year = {2002}
}
@inproceedings{PDBFu2006,
abstract = {Band ratios have many useful applications in hyperspectral image analysis.
While optimal ratios have been chosen empirically in previous research,
we propose a principled algorithm for the automatic selection of
ratios directly from data. First, a robust method is used to estimate
the Kullback-Leibler divergence (KLD) between different sample distributions
and evaluate the optimality of individual ratio features. Then, the
boosting framework is adopted to select multiple ratio features iteratively.
Multiclass classification is handled by using a pairwise classification
framework. The algorithm can also be applied to the selection of
discriminant bands. Experimental results on both simple material
identification and complex land cover classification demonstrate
the potential of this ratio selection algorithm. 1. Introduction},
address = {Hong Kong, China},
author = {Fu, Zhouyu and Caelli, Terry and Liu, Nianjun and Robles-Kelly, Antonio},
booktitle = {18th International Conference on Pattern Recognition (ICPR 2006)},
doi = {http://doi.ieeecomputersociety.org/10.1109/ICPR.2006.334},
file = {:D$\backslash$:/Papers/Documents/2006/Fu et al. - 2006.pdf:pdf},
isbn = {0-7695-2521-0},
pages = {1059--1062},
publisher = {IEEE Computer Society},
title = {{Boosted Band Ratio Feature Selection for Hyperspectral Image Classification.}},
year = {2006}
}
@article{Gutjahr2000,
abstract = {A general framework for solving combinatorial optimization problems heuristically by the Ant System approach is developed. The framework is based on the concept of a construction graph, a graph assigned to an instance of the optimization problem under consideration, encoding feasible solutions by walks. It is shown that under certain conditions, the solutions generated in each iteration of this Graph–based Ant System converge with a probability that can be made arbitrarily close to one to the optimal solution of the given problem instance.},
author = {Gutjahr, WJ},
file = {:D$\backslash$:/Papers/Documents/2000/Gutjahr - 2000.pdf:pdf},
journal = {Future Generation Computer Systems},
keywords = {ant colony optimization,ant system,combinatorial optimization,heuristic,markov},
number = {9},
pages = {873--888},
title = {{A graph-based ant system and its convergence}},
url = {http://iridia.ulb.ac.be/\~{}mdorigo/ACO/downloads/ants5.pdf},
volume = {16},
year = {2000}
}
@phdthesis{Caduff2002,
author = {Caduff, David},
booktitle = {Biography An Interdisciplinary Quarterly},
file = {:D$\backslash$:/Papers/Documents/2002/Caduff - 2002.pdf:pdf},
publisher = {Citeseer},
title = {{Sketch-based Queries in Mobile GIS-Environments}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.8212\&amp;rep=rep1\&amp;type=pdf},
year = {2002}
}
@inproceedings{Alvarado2004SketchREAD,
author = {Alvarado, Christine and Davis, Randall},
booktitle = {Proceedings of UIST 2004},
file = {:D$\backslash$:/Papers/Documents/2004/Alvarado, Davis - 2004.pdf:pdf},
publisher = {ACM Press},
title = {{SketchREAD: A Multi-Domain Sketch Recognition Engine}},
year = {2004}
}
@article{Khorsheed2003,
abstract = {This paper presents a new method on off-line recognition of handwritten Arabic script. The method does not require segmentation into characters, and is applied to cursive Arabic script, where ligatures, overlaps and style variation pose challenges to the recognition system. The method trains a single hidden Markov model (HMM) with the structural features extracted from the manuscript words. TheHMMis composed of multiple character models where each model represents one letter from the alphabet. The performance of the proposed method is assessed using samples extracted from a historical handwirtten manuscript.},
author = {Khorsheed, M.S.},
doi = {10.1016/S0167-8655(03)00050-3},
file = {:D$\backslash$:/Papers/Documents/2003/Khorsheed - 2003.pdf:pdf},
issn = {0167-8655},
journal = {Pattern Recognition Letters},
keywords = {arabic character recognition,cursive script,handwritten,hmm,off-line recognition,viterbi algorithm},
number = {14},
pages = {2235--2242},
publisher = {Elsevier},
title = {{Recognising handwritten Arabic manuscripts using a single hidden Markov model}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865503000503},
volume = {24},
year = {2003}
}
@misc{PDB11He2001,
abstract = {Size normalization is an important pre-processing technique in character
recognition. Although various effective learning-based methods have
been proposed, the role of the original data in a database is always
ignored. In this paper, we have conducted experiments to investigate
its effects with neural networks and support vector machines and
have found that the performance of handwritten numeric recognition
systems deteriorates dramatically due to low size resolution. For
the MNIST dataset, this study shows that enlarging the size from
20 * 20 to 26 * 26 by bilinear interpolation can improve the performance
significantly. After constructing a smaller database of difficult
original patterns from NIST, we find that normalizing the original
data to a size larger than 20 * 20 in MNIST increases the recognition
rate further.},
author = {He, Chun Lei and Zhang, Ping and Dong, Jianxiong and Suen, Ching Y and Bui, Tien D},
file = {:D$\backslash$:/Papers/Documents/2001/He et al. - 2001.pdf:pdf},
keywords = { MNIST,Arabic Handwriting},
title = {{The Role of Size Normalization on the Recognition Rate of Handwritten Numerals}},
year = {2001}
}
@article{Sousa2010,
abstract = {Currently, there are large collections of drawings from which users can select the desired ones to insert in their documents. However, to locate a particular drawing among thousands is not easy. In our prior work we proposed an approach to index and retrieve vector drawings by content, using topological and geometric information automatically extracted from figures. In this paper, we present a new approach to enrich the topological information by integrating spatial proximity in the topology graph, through the use of weights in adjacency links. Additionally, we developed a web search engine for clip art drawings, where we included the new technique. Experimental evaluation reveals that the use of topological proximity results in better retrieval results than topology alone. However, the increase in precision was not as high as we expected. To understand why, we analyzed sketched queries performed by users in previous experimental sessions and we present here the achieved conclusions.},
author = {Sousa, Pedro and Fonseca, Manuel J.},
doi = {10.1016/j.jvlc.2009.12.001},
file = {:D$\backslash$:/Papers/Documents/2010/Sousa, Fonseca - 2010.pdf:pdf},
issn = {1045926X},
journal = {Journal of Visual Languages \& Computing},
keywords = {sketch-based retrieval,spatial proximity,topology,vector drawing retrieval},
month = apr,
number = {2},
pages = {69--80},
title = {{Sketch-based retrieval of drawings using spatial proximity}},
url = {http://dx.doi.org/10.1016/j.jvlc.2009.12.001},
volume = {21},
year = {2010}
}
@article{Ouyang,
author = {Ouyang, T.Y. and Davis, Randall},
file = {:D$\backslash$:/Papers/Documents/Unknown/Ouyang, Davis - Unknown.pdf:pdf},
journal = {Citeseer},
pages = {1--9},
publisher = {Citeseer},
title = {{Learning from Neighboring Strokes: Combining Appearance and Context for Multi-Domain Sketch Recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.159.2515}
}
@article{Foltz2001Ligature,
author = {Foltz, Mark},
file = {:D$\backslash$:/Papers/Documents/2001/Foltz - 2001.pdf:pdf},
journal = {Proceedings of the MIT Student Oxygen Workshop},
title = {{Ligature, Gesture-Based Configuration of the E21 Intelligent Environment}},
year = {2001}
}
@article{Agar2003,
address = {New York, New York, USA},
author = {Agar, Peter and Novins, Kevin},
doi = {10.1145/604471.604500},
file = {:D$\backslash$:/Papers/Documents/2003/Agar, Novins - 2003.pdf:pdf},
isbn = {1581135785},
journal = {Proceedings of the 1st international conference on Computer graphics and interactive techniques in Austalasia and South East Asia - GRAPHITE '03},
keywords = {corner detection,sketch-based user interfaces},
number = {212},
pages = {147},
publisher = {ACM Press},
title = {{Polygon recognition in sketch-based interfaces with immediate and continuous feedback}},
url = {http://portal.acm.org/citation.cfm?doid=604471.604500},
volume = {1},
year = {2003}
}
@article{ARKherallah2009,
abstract = {One of the most promising methods of interacting with small portable
computing devices, such as personal digital assistants, is the use
of handwriting. In order to make this communication method more natural,
we propose to observe visually the writing process on an ordinary
paper and to automatically recover the pen trajectory from numerical
tablet sequences. On the basis of this work, we developed a handwriting
recognition system based on visual coding and genetic algorithm ��GA��.
The system is applied on Arabic script. In this paper, we will present
the different steps of the handwriting recognition system. We focus
our contribution on the encoding system and the fitness function
conception used as basic steps of the GA. A new approach based on
visual indices similarity is developed to calculate the evaluation
function. We optimize the times cooling of our system to give the
final output (proposed words). Several experimentations are developed
using an Arabic data set words extracted from ��LMCA�� database elaborated
in our laboratory by 24 participants. The results obtained are very
promising and prove that our new method based on hybridization between
visual codes and GA is a powerful method.},
author = {Kherallah, M and Bouri, F and Alimi, A M},
file = {:D$\backslash$:/Papers/Documents/2009/Kherallah, Bouri, Alimi - 2009.pdf:pdf},
journal = {Engineering Applications of Artificial Intelligence},
keywords = { Beta-elliptical representation, Stroke overlapping, Visual encoding,Arabic script,Word recognition},
pages = {153�170},
title = {{On-line Arabic handwriting recognition system based on visual encoding and genetic algorithm}},
volume = {22},
year = {2009}
}
@article{Makhoul1998,
author = {Makhoul, J},
doi = {10.1016/S0031-3203(97)00152-0},
file = {:D$\backslash$:/Papers/Documents/1998/Makhoul - 1998.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = sep,
number = {9},
pages = {1285--1294},
title = {{a Script-Independent Methodology for Optical Character Recognition}},
volume = {31},
year = {1998}
}
@article{Hammond2003Ladder,
address = {Acapulco, Mexico},
author = {Hammond, Tracy and Davis, Randall},
journal = {Proceedings of the 2003 Internaltional Joint Conference on Artificial Intelligence (IJCAI)},
title = {{\{LADDER\}: A Language to Describe Drawing, Display, and Editing in Sketch Recognition}},
year = {2003}
}
@article{Phillips1999,
author = {Phillips, Ihsin T and Chhabra, Atul K and Member, Senior},
file = {:D$\backslash$:/Papers/Documents/1999/Phillips, Chhabra, Member - 1999.pdf:pdf},
journal = {Analysis},
number = {9},
pages = {849--870},
title = {{Empirical performance evaluation of Graphics Recognition Systems}},
volume = {21},
year = {1999}
}
@article{Llad2002,
author = {Llad, Josep and Valveny, Ernest and S, Gemma and Mart, Enric},
file = {:D$\backslash$:/Papers/Documents/2002/Llad et al. - 2002.pdf:pdf},
journal = {Advances in LNCS},
number = {GREC},
pages = {104--128},
title = {{Symbol Recognition : Current advances and perspectives}},
volume = {2390},
year = {2002}
}
@inproceedings{ARPechwitz2002,
abstract = {In this paper we are presenting a new database with handwritten Arabic
town/village names. For each name the ground truth information, e.g.
the sequence of character shapes, some style information, and the
baseline are coded. 411 writers filled forms with about 26400 names
containing more than 210000 characters. The database is described
in detail. It is designed for training and testing recognition systems
for handwritten Arabic words. The IFN/ENIT-database is available
for the purpose of research.},
address = {Hammamet, Tunis},
author = {Pechwitz, M and Maddouri, S Snoussi and M�rgner, V and Ellouze, N and Amiri, H},
booktitle = {i7th Colloque International Francophone sur l'Ecrit et le Document , CIFED 2002, Oct. 21-23, 2002, Hammamet, Tunis, (2002)},
file = {:D$\backslash$:/Papers/Documents/2002/Pechwitz et al. - 2002.pdf:pdf},
keywords = { Arabic OCR, Database, Handwriting, Recognition system,Arabic},
title = {{IFN/ENIT-DATABASE OF HANDWRITTEN ARABIC WORDS}},
year = {2002}
}
@inproceedings{Oltmans2004ETCHASketch,
author = {Oltmans, Michael and Alvarado, Christine and Davis, Randall},
booktitle = {Making Pen-Based Interaction Intelligent and Natural},
file = {:D$\backslash$:/Papers/Documents/2004/Oltmans, Alvarado - 2004.pdf:pdf},
publisher = {AAAI Fall Symposium},
title = {{ETCHA Sketches: Lessons Learned from Collecting Sketch Data}},
year = {2004}
}
@inproceedings{DSMuntean2007,
abstract = {In spite of evolution of electronic techniques, a large number of
applications continue to rely on the use of paper as the dominant
medium. Bank checks are a widely known example. When filled by hand,
the processing of the written information requires either a human
or a special software which has intelligent abilities. This paper
examines the issue of reading the amount of money written on the
checks. Genetic Programming (GP) technique is used for dealing with
this problem. A new type of input representation is proposed: histograms.
Several numerical experiments with GP are performed by using large
datasets taken from the MNIST benchmarking set. Preliminary results
show a good behavior of the method.},
author = {Muntean, O and Oltean, M},
booktitle = {Bio-inspired, Learning, and Intelligent Systems for Security, 2007. BLISS 2007. ECSIS Symposium on},
doi = {10.1109/BLISS.2007.27},
file = {:D$\backslash$:/Papers/Documents/2007/Muntean, Oltean - 2007.pdf:pdf},
keywords = {MNIST benchmarking set;electronic techniques;genet},
pages = {102--105},
title = {{Processing Bank Checks with Genetic Programming and Histograms}},
year = {2007}
}
@article{ARBahlmann2005,
abstract = {Abstract. The selection of valuable features is crucial in pattern
recognition. In this paper we deal with the issue that part of features
originate from directional instead of common linear data. Both for
directional and linear data a theory for a statistical modeling exists.
However, none of these theories gives an integrated solution to problems,
where linear and directional variables are to be combined in a single,
multivariate probability density function. We describe a general
approach for a unified statistical modeling, given the constraint
that variances of the circular variables are small. The method is
practically evaluated in the context of our online handwriting recognition
system frog on hand and the so-called tangent slope angle feature.
Recognition results are compared with two alternative modeling approaches.
The proposed solution gives significant improvements in recognition
accuracy, computational speed and memory requirements},
author = {Bahlmann, Claus},
file = {:D$\backslash$:/Papers/Documents/2005/Bahlmann - 2005.pdf:pdf},
journal = {Pattern Recognition},
pages = {115 � 125},
title = {{Directional features in online handwriting recognition}},
volume = {39},
year = {2005}
}
@inproceedings{Adler2004Building,
address = {Menlo Park, California},
author = {Adler, Aaron and Eisenstein, Jacob and Oltmans, Michael and Guttentag, Lisa and Davis, Randall},
booktitle = {Making Pen-Based Interaction Intelligent and Natural},
file = {:D$\backslash$:/Papers/Documents/2004/Adler et al. - 2004.pdf:pdf},
month = oct,
pages = {1--7},
publisher = {AAAI Press},
title = {{Building the Design Studio of the Future}},
year = {2004}
}
@inproceedings{DSMorita2001,
abstract = {This paper describes an off-line system under development to process
unconstrained handwritten dates on Brazilian bank cheques in an omni-writer
context. We show here some improvements on our previous work on isolated
month word recognition using hidden Markov models (HMM). After preprocessing,
a word image is explicitly segmented into characters or pseudo-characters
and represented by two feature sequences of equal length, which are
combined using HMM. The word models are generated from the concatenation
of appropriate character models. In addition to the small date database,
we also make use of the legal amount database to increase the frequency
of characters in the training and the validation sets. Although this
study deals with a limited lexicon, the many similarities among the
word classes can affect the performance of the recognition. Experiments
show an increase in the average recognition rate from 84\% to 91\%.
Finally, we present our perspectives of future work},
author = {Morita, M and {El Yacoubi}, A and Sabourin, R and Bortolozzi, F and Suen, C Y},
booktitle = {Document Analysis and Recognition, 2001. Proceedings. Sixth International Conference on},
doi = {10.1109/ICDAR.2001.953930},
file = {:D$\backslash$:/Papers/Documents/2001/Morita et al. - 2001.pdf:pdf},
keywords = { ;hidden Markov models;image segmentation;,Brazilian bank cheques;HMM;Handwritten month word },
pages = {972--976},
title = {{Handwritten month word recognition on Brazilian bank cheques}},
year = {2001}
}
@inproceedings{ARAlamri2008,
abstract = {This paper presents the work toward developing a new comprehensive
database for Arabic off-line handwriting recognition. The database
includes: isolated Indian digits, numerical strings, Arabic isolated
letters,i and a collection of 70 Arabic words. Also, the database
includes a free format sample of an Arabic date. A data entry form
was designed to collect written samples from Arabic native speakers.
Our database is advanced in terms of the variety of sets, words and
number of the participants involved. The databases have been divided
into respective training, testing and validation sets which will
be available in the future for the handwriting recognition community.},
address = {Montreal, Canada},
author = {Alamri, Huda and Sadri, Javad and Suen, Ching Y and Nobile, Nicola},
booktitle = {Eleventh International Conference on Frontiers in Handwriting Recognition},
file = {:D$\backslash$:/Papers/Documents/2008/Alamri et al. - 2008.pdf:pdf},
keywords = { Arabic OCR, Farsi handwritten recognition, Handwritten Segmentation,Arabic Handwritten Recognition},
month = aug,
pages = {664--669, Montreal},
title = {{A Novel Comprehensive Database for Arabic Off-Line Handwriting Recognition}},
year = {2008}
}
@article{Fritz2010,
abstract = {UBC;Software Engineering},
address = {New York, New York, USA},
author = {Fritz, Thomas and Murphy, Gail C.},
doi = {10.1145/1806799.1806828},
file = {:D$\backslash$:/Papers/Documents/2010/Fritz, Murphy - 2010.pdf:pdf},
isbn = {9781605587196},
journal = {Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - ICSE '10},
keywords = {human-centric software engineering,information fragments},
pages = {175},
publisher = {ACM Press},
title = {{Using information fragments to answer the questions developers ask}},
url = {http://portal.acm.org/citation.cfm?doid=1806799.1806828},
year = {2010}
}
@inproceedings{Watt2009,
author = {Golubitsky, Oleg and Watt, Stephen M},
booktitle = {10th International Conference on Document Analysis and Recognition},
doi = {10.1109/ICDAR.2009.229},
file = {:D$\backslash$:/Papers/Documents/2009/Golubitsky, Watt - 2009.pdf:pdf},
pages = {1265--1269},
title = {{Online Recognition of Multi-Stroke Symbols with Orthogonal Series}},
year = {2009}
}
@inproceedings{Hammond2008,
abstract = {Sketch recognition techniques have generally fallen into two camps. Gesture-based techniques, such as those used by the Palm Pilot’s Graffiti, can provide high- accuracy, but require the user to learn a particular drawing style in order for shapes to be recognized. Free-sketch recognition allows users to draw shapes as they would naturally, but most current techniques have low accuracies or require significant domain-level tweaking to make them usable. Our goal is to recognize free-hand sketches with high accuracy by developing generalized techniques that work for a variety of domains, including design and education. This is a work-in-progress, but we have made significant advancements toward our over-arching goal.},
author = {Hammond, Tracy and Eoff, B. and Paulson, Brandon and Wolin, Aaron and Dahmen, Katie and Johnston, Joshua and Rajan, Pankaj},
booktitle = {CHI'08 extended abstracts on Human factors in computing systems},
file = {:D$\backslash$:/Papers/Documents/2008/Hammond et al. - 2008.pdf:pdf},
keywords = {LADDER,PaleoSketch,ShortStraw,Sketch recognition,free-sketch,multimodal interaction,pen input,tablet pc},
pages = {3027--3032},
publisher = {ACM},
title = {{Free-sketch recognition: putting the chi in sketching}},
url = {http://portal.acm.org/citation.cfm?id=1358628.1358802},
year = {2008}
}
@inproceedings{DSZhang2002,
abstract = { A segmentation based courtesy amount recognition (CAR) system is
presented in this paper. A two-stage segmentation module has been
proposed, namely the global segmentation stage and the local segmentation
stage. At the global segmentation stage, a courtesy amount is coarsely
segmented into sub-images according to the spatial relationships
of the connected components. These sub-images are then verified by
the recognition module and the rejected sub-images are sequentially
split using contour analysis at the local segmentation stage. Two
neural network classifiers are combined into a recognition module.
The isolated digit classifier divides the input patterns into ten
numeral classes (0-9), while the holistic double zeros classifier
recognizes the cursive and touching double zeros. Experimental results
show that the system reads 66.5\% bank checks correctly at 0\% misreading
rate.},
author = {Zhang, L Q and Suen, C Y},
booktitle = {Frontiers in Handwriting Recognition, 2002. Proceedings. Eighth International Workshop on},
doi = {10.1109/IWFHR.2002.1030926},
file = {:D$\backslash$:/Papers/Documents/2002/Zhang, Suen - 2002.pdf:pdf},
keywords = { ; image classification; image segmentation; neura,CAR system; bank checks; connected components; cur},
pages = {298--302},
title = {{Recognition of courtesy amounts on bank checks based on a segmentation approach}},
year = {2002}
}
@misc{Hammond2002e,
author = {Hammond, Tracy and Davis, Randall},
booktitle = {Symposium A Quarterly Journal In Modern Foreign Literatures},
file = {:D$\backslash$:/Papers/Documents/2002/Hammond, Davis - 2002.pdf:pdf},
number = {September},
pages = {6--7},
title = {{A Domain Description Language for Sketch Recognition}},
year = {2002}
}
@article{Bazzi1999,
abstract = {We present an omnifont, unlimited-vocabulary OCR system for English and Arabic. The system is based on Hidden Markov Models (HMM), an approach that has proven to be very successful in the area of automatic speech recognition. In this paper we focus on two aspects of the OCR system. First, we address the issue of how to perform OCR on omnifont and multi-style data, such as plain and italic, without the need to have a separate model for each style. The amount of training data from each style, which is used to train a single model, becomes an important issue in the face of the conditional independence assumption inherent in the use of HMMs. We demonstrate mathematically and empirically how to allocate training data among the different styles to alleviate this problem. Second, we show how to use a word-based HMM system to perform character recognition with unlimited vocabulary. The method includes the use of a trigram language model on character sequences. Using all these techniques, we have achieved character error rates of 1.1 percent on data from the University of Washington English Document Image Database and 3.3 percent on data from the DARPA Arabic OCR Corpus.},
author = {Bazzi, I. and Schwartz, R. and Makhoul, J.},
doi = {10.1109/34.771314},
file = {:D$\backslash$:/Papers/Documents/1999/Bazzi, Schwartz, Makhoul - 1999.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Arabic OCR,Hidden Markov Models,Omnifont OCR,Optical character recognition,Reference From Doctor,language modeling,segmentation-free recognition.,speech recognition},
mendeley-tags = {Reference From Doctor},
month = jun,
number = {6},
pages = {495--504},
title = {{An omnifont open-vocabulary OCR system for English and Arabic}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=771314},
volume = {21},
year = {1999}
}
@article{Deussen2000,
address = {New York, New York, USA},
author = {Deussen, Oliver and Strothotte, Thomas},
doi = {10.1145/344779.344792},
file = {:D$\backslash$:/Papers/Documents/2000/Deussen, Strothotte - 2000.pdf:pdf},
isbn = {1581132085},
journal = {Proceedings of the 27th annual conference on Computer graphics and interactive techniques - SIGGRAPH '00},
keywords = {biological systems,frame buffer tricks,non-},
pages = {13--18},
publisher = {ACM Press},
title = {{Computer-generated pen-and-ink illustration of trees}},
url = {http://portal.acm.org/citation.cfm?doid=344779.344792},
year = {2000}
}
@conference{ARDaifallah2009,
abstract = {In this paper, we introduce an on-line Arabic handwritten recognition
system based on new stroke segmentation algorithm. The proposed algorithm
uses an over segmentation method that has the advantage of giving
all correct segments at least. It is based on arbitrary segmentation
followed by segmentation enhancement, consecutive joints connection
and finally segmentation point locating. The proposed system gives
an excellent recognition rate up to 97\% and 92\% for words and letter
recognition.},
author = {Daifallah, Khaled and Zarka, Dr. Nizar and Jamous, Hassan},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Daifallah, Zarka, Jamous - 2009.pdf:pdf},
title = {{Recognition-Based Segmentation Algorithm for On-Line Arabic Handwriting}},
year = {2009}
}
@article{Liu2004a,
abstract = {Online handwriting recognition is gaining renewed interest owing to the increase of pen computing applications and new pen input devices. The recognition of Chinese characters is different from western handwriting recognition and poses a special challenge. To provide an overview of the technical status and inspire future research, this paper reviews the advances in online Chinese character recognition (OLCCR), with emphasis on the research works from the 1990s. Compared to the research in the 1980s, the research efforts in the 1990s aimed to further relax the constraints of handwriting, namely, the adherence to standard stroke orders and stroke numbers and the restriction of recognition to isolated characters only. The target of recognition has shifted from regular script to fluent script in order to better meet the requirements of practical applications. The research works are reviewed in terms of pattern representation, character classification, learning/adaptation, and contextual processing. We compare important results and discuss possible directions of future research.},
author = {Liu, Cheng-Lin and Jaeger, Stefan and Nakagawa, Masaki},
doi = {10.1109/TPAMI.2004.1262182},
file = {:D$\backslash$:/Papers/Documents/2004/Liu, Jaeger, Nakagawa - 2004.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automatic Data Processing,China,Computer Graphics,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Natural Language Processing,Numerical Analysis, Computer-Assisted,Pattern Recognition, Automated,Reading,Reproducibility of Results,Review Literature as Topic,Sensitivity and Specificity,Signal Processing, Computer-Assisted,Subtraction Technique,Technology Assessment, Biomedical,User-Computer Interface,Vocabulary, Controlled},
month = feb,
number = {2},
pages = {198--213},
pmid = {15376895},
title = {{Online recognition of Chinese characters: the state-of-the-art.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15376895},
volume = {26},
year = {2004}
}
@article{Schmieder2010,
abstract = {Diagrams are often used to model complex systems: in many cases several different types of diagrams are used to model different aspects of the system. These diagrams, perhaps from multiple stakeholders of different specialties, must be combined to achieve a full abstract representation of the system. Many CAD tools offer multi-diagram integration; however, sketch-based diagramming tools are yet to tackle this difficult integration problem. We extend the diagram sketching tool InkKit to combine software engineering sketches of different types. Our extensions support software design processes by providing a sketch-based approach that allows the iterative creation of multiple outputs interacting with one another from the inter-linked models. We demonstrate that InkKit can generate a functional system consisting of a user interface with processes to submit and retrieve data from a database from sketched user interfaces designs and sketched entity relationship diagrams.},
author = {Schmieder, Paul and Plimmer, Beryl and Vanderdonckt, Jean},
doi = {10.1016/j.jvlc.2009.12.003},
file = {:D$\backslash$:/Papers/Documents/2010/Schmieder, Plimmer, Vanderdonckt - 2010.pdf:pdf},
issn = {1045926X},
journal = {Journal of Visual Languages \& Computing},
keywords = {sketch recognition,sketch tools,software modeling},
month = apr,
number = {2},
pages = {98--108},
title = {{Generating systems from multiple sketched models}},
url = {http://dx.doi.org/10.1016/j.jvlc.2009.12.003},
volume = {21},
year = {2010}
}
@inproceedings{Corey2008,
author = {Corey, Paul and Hammond, Tracy},
booktitle = {Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence, AAAI 2008},
file = {:D$\backslash$:/Papers/Documents/2008/Corey, Hammond - 2008.pdf:pdf},
keywords = {Student Abstracts},
pages = {13--17},
title = {{GLADDER: combining gesture and geometric sketch recognition}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:GLADDER+:+Combining+Gesture+and+Geometric+Sketch+Recognition\#0},
year = {2008}
}
@inproceedings{Zalewski2008,
abstract = {Medicine has benefited widely from the use of computational techniques, which are often employed in the analysis of data generated in medical clinics. Among the computational techniques used in these analyses are those from Knowledge Discovery in Databases (KDD). In order to apply KDD techniques in the analysis of clinical data, it is often necessary to map them into an adequate structured format. This paper presents an extension in a methodology to map medical forms into struc- tured datasets, in which a sub-system for handwritten digit recognition is added to the overall mapping system},
author = {Zalewski, Willian and Lee, H. and Caetano, A. and Lorena, A. and Maletzke, A. and Fagundes, J. and Saddy, C. and Coy, R. and Wu, F.},
booktitle = {Advances in Bioinformatics and Computational Biology},
file = {:D$\backslash$:/Papers/Documents/2008/Zalewski et al. - 2008.pdf:pdf},
keywords = {digit recognition,machine learning,medical forms},
pages = {178--181},
publisher = {Springer},
title = {{Evaluation of Models for the Recognition of Hadwritten Digits in Medical Forms}},
url = {http://www.springerlink.com/index/l8217ww668114618.pdf},
year = {2008}
}
@inproceedings{Augustin,
abstract = {This paper presents a novel research investigation on legal amount recognition of unconstrained cursive handwritten Chinese character in the environment of A2iA CheckReader™ – a commercial bank check recognition system. The following problems and their solutions are described: character set of Chinese legal amounts, preprocessing (slant detection and correction), segmentation, feature extraction, grammar, automatic annotation of Chinese characters before and during training, and neural training and recognition. The system is trained with 47.8 thousand real bank checks, and validated with 12 thousand real bank checks. The recognition rate at the character level is 93.5\%, and the recognition rate at the legal amount level is 60\%. This is the first successful commercial product in this domain},
author = {Augustin, E. and Suen, C.Y. and Baret, O. and Cheriet, M.},
booktitle = {Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.},
doi = {10.1109/ICPR.2004.1334322},
file = {:D$\backslash$:/Papers/Documents/2004/Augustin et al. - 2004.pdf:pdf},
isbn = {0-7695-2128-2},
pages = {610--613},
publisher = {Ieee},
title = {{Recognition of unconstrained legal amounts handwritten on chinese bank checks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1334322},
year = {2004}
}
@article{Awaidah2009a,
author = {Awaidah, Sameh M. and Mahmoud, Sabri a.},
doi = {10.1016/j.sigpro.2008.12.022},
file = {:D$\backslash$:/Papers/Documents/2009/Awaidah, Mahmoud - 2009.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
month = jun,
number = {6},
pages = {1176--1184},
title = {{A multiple feature/resolution scheme to Arabic (Indian) numerals recognition using hidden Markov models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S016516840900005X},
volume = {89},
year = {2009}
}
@inproceedings{Kara2004b,
address = {Utah, USA, September 28},
author = {Kara, L.B. and Gennari, Leslie and Stahovich, T.F.},
booktitle = {Proceedings of ASME international design engineering technical conferences},
file = {:D$\backslash$:/Papers/Documents/2004/Kara, Gennari, Stahovich - 2004.pdf:pdf},
publisher = {Citeseer},
title = {{A sketch-based interface for the design and analysis of simple vibratory mechanical systems}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.10.8223\&amp;rep=rep1\&amp;type=pdf},
year = {2004}
}
@inproceedings{Siriboon2002,
abstract = {Researchers have extensively applied Hidden Markov Model (HMM) to handwritten recognition in English, Chinese, and other languages. Most researchers have been using the left-right topology for handwritten and speech recognition. This research studied the effect of HMM topology on isolated on- line Thai handwritten recognition. The left-right, fully connected and the proposed topologies (left-right-left) were compared. The number of state of a character HMM for each topology was varied from 15 to 35 nodes and the one with the best training observations probability was selected. The feature used was Chain code-like with modification to represent originated quadrant position. The recognition results showed that the proposed topology increases the recognition rate in comparison to the most widely used left-right topology.},
annote = {===========================================
          
Paper Index : Siriboon2002
          
Date:22-11-2010

        
          
Why read paper ?
        
HMM background 

        
          
Paper Overview ?
        
HMM or chain code features with online 
the paper focus on toplogy change of hmm and comparison. 

        
          
What is these paper about ? (Summary)
        
online data are resampled to make point ahve same distance. 
chain code extracted. 
there is tow types of chain code one for upper part of character other for lower partof character. 
training HMM one for each character where trainig HMM using baum welch. 
Different topolgy of hmm is teat ( FC (fully connected), LR (left right), LRL (left - right - left)).  
see fig 3. 

        
          
Result :
        
no discription of data, only tested topology vs. no of states and the parameters of hmm. 
best result was on LRL with best No of states is 95.67\%. 

        

        
          
1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?
        
The simple chain code features. 
          
2. What can we take from this work  ? what do we learn ? What can be incorporated into our own work ?
        

        
Changing the chain code from upper to lower to get more feature and distinguish characters. 

        
          
3. What are the problems of the paper ?
        

        
No data discriptions and analysis number of classes or number of sample per class. 

        
          
4. what is lacking from the work ? why does this work knot be the final  research in this subject ?
        

        
          
5. what about the methods causes this lack ? is there a fundamental reason ?
        

        
          
6. Could incremental Changes Fix this lack ? if so, what changes ? 
        

        

        
          
Is there is any question you had about the paper ? 

        
        

        
          
The final conclusion..........
        
Simple but with no real indication of comparing system with others. 

        
==========================================================================

      },
author = {Siriboon, Kritawan and Jirayusakul, Apirak and Kruatrachue, Boontee},
booktitle = {Proceedings of the First International Symposium on Cyber Worlds (CW’02)},
file = {:D$\backslash$:/Papers/Documents/2002/Siriboon, Jirayusakul, Kruatrachue - 2002.pdf:pdf},
keywords = {Arabic Handwritting recognition,HMM,Read,Summarized,on-line handwriting recognition},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
pages = {0142},
publisher = {Published by the IEEE Computer Society},
title = {{Hmm topology selection for on-line thai handwritten recognition}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/CW.2002.1180872},
year = {2002}
}
@article{Olsen2009,
author = {Olsen, Luke and Samavati, Faramarz and {Costa Sousa}, Mario and Jorge, Joaquim A.},
doi = {10.1016/j.cag.2008.09.013},
file = {:D$\backslash$:/Papers/Documents/2009/Olsen et al. - 2009.pdf:pdf},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {Doctor Samavati,Scholarships Doctors,Survey,To Read,sketch-based modeling},
mendeley-tags = {Scholarships Doctors,Survey,To Read},
month = feb,
number = {1},
pages = {85--103},
title = {{Sketch-based modeling: A survey}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849308001295},
volume = {33},
year = {2009}
}
@article{Gennari2005,
author = {Gennari, L and Kara, Levent Burak and Stahovich, Thomas F and Shimada, K},
doi = {10.1016/j.cag.2005.05.007},
file = {:D$\backslash$:/Papers/Documents/2005/Gennari et al. - 2005(3).pdf:pdf},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {electric circuits,ink density,pen-based computing,sketch parsing,sketch understanding,symbol recognition},
month = aug,
number = {4},
pages = {547--562},
title = {{Combining geometry and domain knowledge to interpret hand-drawn diagrams}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849305000889},
volume = {29},
year = {2005}
}
@inproceedings{Tokuno2006,
abstract = {This paper describes stochastic modeling of pen- coordinate information in HMMs with structured character pattern representation (SCPR) for on-line Japanese handwriting recognition. SCPR allows HMMs for Kanji character patterns to share common subpatterns. Although SCPR-based HMMs have been successfully applied to Kanji character recognition, the pen-coordinate feature has not been modeled since it is unique feature in each character pattern. In this paper, we employ mapping from a common subpattern to each occurrence in Kanji patterns and adaptation of state parameters to each character pattern in generating character HMMs by composing SCPR- based HMMs. Experimental results show that the pen- coordinate feature modeled in the SCPR-based HMMs effects significantly.},
author = {Tokuno, Junko and Yang, Yiping and da Silva, G.P. and Kitadai, Akihito and Nakagawa, Masaki},
booktitle = {Pattern Recognition, 2006. ICPR 2006. 18th International Conference on},
file = {:D$\backslash$:/Papers/Documents/2006/Tokuno et al. - 2006.pdf:pdf},
isbn = {0769525210},
issn = {1051-4651},
pages = {348--351},
publisher = {IEEE},
title = {{Pen-coordinate information modeling by scpr-based hmm for on-line japanese handwriting recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1699537},
volume = {3},
year = {2006}
}
@inproceedings{Sun2003,
abstract = {Sketching is a natural and effective way to capture designer’s brainstorms ideas. This paper presents a sketch-based graphics input system for conceptual design (SketchGIS), which is mainly based on online graphic recognition and dynamic user modeling. Online graphic recognition can discover latent primitive shapes among user-drawn strokes and show the regularized shape on the screen immediately based on spatial-relation graph (SRG) representation and conditioned partial matching by shape preparing, feature recognition, shape filtering and regularization. Dynamic user modeling method is used to recognize and predict sketchy composite shapes before they are completely drawn for user adaptation, which is based on the SVM-based incremental active learning method and the incremental decision tree induction method. Experiments show that the proposed method in this paper can yield good recognition precision, and the prototype system proposed provides fine user interaction effect, especially for UML diagramming},
address = {Xian},
author = {Sun, Zheng-xing and Zhang, B I N and Qiu, Qing-hua and Zhang, Li-sha},
booktitle = {Proceedings of the Second International Conference on Machine Learning and Cybernetics, Xi’an, 2-5 November 2003},
file = {:D$\backslash$:/Papers/Documents/2003/Sun et al. - 2003.pdf:pdf},
keywords = {dynamic user modeling,have focused on the,online sketchy graphic,points,recognition,single or multi-stroke stroke,sketch-based user interface,user adaptation},
number = {November},
pages = {2--5},
title = {{A FREEHAND SKETCHY GRAPHIC INPUT SYSTEM : SKETCHGIS}},
year = {2003}
}
@conference{ARMargner2009,
abstract = {This paper describes the Online Arabic handwriting recognition competition
held at ICDAR 2009. This first competition uses the ADAB-database
with Arabic online handwritten words. This year, 3 groups with 7
systems are participating in the competition. The systems were tested
on known data (sets 1 to 3) and on one test dataset which is unknown
to all participants (set 4). The systems are compared on the most
important characteristic of classification systems, the recognition
rate. Additionally, the relative speed of the different systems were
compared. A short description of the participating groups, their
systems, the experimental setup, and the performed results are presented.},
author = {Abed, Haikal El and Margner, Volker and Kherallah, Monji and Alimi, Adel M},
booktitle = {2009 10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Abed et al. - 2009.pdf:pdf},
title = {{ICDAR 2009 Online Arabic Handwriting Recognition Competition}},
year = {2009}
}
@inproceedings{Ah-Soon2002,
author = {Ah-Soon, C. and Tombre, Karl},
booktitle = {Document Analysis and Recognition, 1997., Proceedings of the Fourth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2002/Ah-Soon, Tombre - 2002.pdf:pdf},
isbn = {0818678984},
pages = {347--351},
publisher = {IEEE},
title = {{Variations on the analysis of architectural drawings}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=619869},
volume = {1},
year = {2002}
}
@article{Pal2009,
author = {Pal, Umapada and Roy, Rami Kumar and Roy, Kaushik and Kimura, Fumitaka},
doi = {10.1109/ICDAR.2009.171},
file = {:D$\backslash$:/Papers/Documents/2009/Pal et al. - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {456--460},
publisher = {Ieee},
title = {{Indian Multi-Script Full Pin-code String Recognition for Postal Automation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277632},
year = {2009}
}
@inproceedings{ARMoussa2008,
abstract = {In this paper, we present multilingual automatic identification of
Arabic and Latin in both handwritten and printed script. The proposed
scheme is based, Firstly, on morphological transform of line text
images, secondly on fractal analysis features of both (i): original
texture of 2-D images, (ii): vertical and horizontal profile projection.
We used two techniques to obtain only 12 features based on fractal
multidimension. The proposed system has been tested for 1000 prototypes
with various typefaces, scriptors styles and sizes. The accuracy
discrimination rate is about of 96.64 \% by using KNN, and 98.72 \%
by using RBF. Experimental results show the importance of the proposed
approach.},
address = {Tampa, Florida, USA},
author = {Moussa, S Ben and Zahour, A and Benabdelhafid, A and Alimi, A M},
booktitle = {19th International Conference on Pattern Recognition (ICPR 2008)},
file = {:D$\backslash$:/Papers/Documents/2008/Moussa et al. - 2008.pdf:pdf},
month = dec,
title = {{Fractal-Based System for Arabic/Latin, Printed/Handwritten Script Identification}},
year = {2008}
}
@article{ARCavalin2009,
abstract = {We present an evaluation of incremental learning algorithms for the
estimation of hidden Markov model (HMM) parameters. The main goal
is to investigate incremental learning algorithms that can provide
as good performances as traditional batch learning techniques, but
incorporating the advantages of incremental learning for designing
complex pattern recognition systems. Experiments on handwritten characters
have shown that a proposed variant of the ensemble training algorithm,
employing ensembles of HMMs, can lead to very promising performances.
Furthermore, the use of a validation dataset demonstrated that it
is possible to reach better performances than the ones presented
by batch learning.},
author = {PauloR.Cavalina and RobertSabourina and ChingY.Suenb and AlceuS.BrittoJr},
file = {:D$\backslash$:/Papers/Documents/2009/PauloR.Cavalina et al. - 2009.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Incremental learning; Hidden Markov models; Ensemb},
month = dec,
number = {12},
pages = {3241--3253},
title = {{Evaluation of incremental learning algorithms for HMM in the recognition of alphanumeric characters}},
volume = {42},
year = {2009}
}
@article{Bhattacharya2005,
author = {Bhattacharya, U. and Chaudhuri, B.B.},
doi = {10.1109/ICDAR.2005.84},
file = {:D$\backslash$:/Papers/Documents/2005/Bhattacharya, Chaudhuri - 2005.pdf:pdf},
isbn = {0-7695-2420-6},
journal = {Eighth International Conference on Document Analysis and Recognition (ICDAR'05)},
pages = {789--793},
publisher = {Ieee},
title = {{Databases for Research on Recognition of Handwritten Characters of Indian Scripts}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1575653},
year = {2005}
}
@article{Zanchettin2006,
author = {Zanchettin, C. and Cavalcanti, G.D.C. and Doria, R.C. and Silva, E.F.a. and Rabelo, J.C.B. and Bezerra, B.L.D.},
doi = {10.1109/IJCNN.2006.1716535},
file = {:D$\backslash$:/Papers/Documents/2006/Zanchettin et al. - 2006.pdf:pdf},
isbn = {0-7803-9490-9},
journal = {The 2006 IEEE International Joint Conference on Neural Network Proceedings},
number = {000185},
pages = {3210--3217},
publisher = {Ieee},
title = {{A neural architecture to identify courtesy amount delimiters}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1716535},
year = {2006}
}
@article{Gader1997,
abstract = {An off-line handwritten word recognition system is described. Images of handwritten words are matched to lexicons of candidate strings. A word image is segmented into primitives. The best match between sequences of unions of primitives and a lexicon string is found using dynamic programming. Neural networks assign match scores between characters and segments. Two particularly unique features are that neural networks assign confidence that pairs of segments are compatible with character confidence assignments and that this confidence is integrated into the dynamic programming. Experimental results are provided on data from the U.S. Postal Service.},
author = {Gader, P D and Mohamed, M and Chiang, J H},
doi = {10.1109/3477.552199},
file = {:D$\backslash$:/Papers/Documents/1997/Gader, Mohamed, Chiang - 1997.pdf:pdf},
issn = {1083-4419},
journal = {IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = jan,
number = {1},
pages = {158--64},
pmid = {18255853},
title = {{Handwritten word recognition with character and inter-character neural networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18255853},
volume = {27},
year = {1997}
}
@article{Fujisawa2008,
abstract = {This paper presents an overview on the last 40-years of technical advances in the field of character and document recognition. Representative developments in each decade are described. Then, key technical developments in the specific area of Kanji recognition in Japan are highlighted. The main part of the paper discusses robustness design principles, which have proven to be effective to solve complex problems in postal address recognition. Included are the hypothesis-driven principle, deferred decision/multiple-hypotheses principle, information integration principle, alternative solution principle, and perturbation principle. Finally, future prospects, the ‘long-tail’ phenomena, and promising new applications are discussed.},
annote = {(Reading order = 4) Mainly industrial view from 60 til 90's. 

        
Application of character is form reading, bank check and postal address reading . Discuss comercial systems in OCR by ibm, hitachi from 60,70,80 and 90's. 
Mentions state of art in 
M. Cheriet, N. Kharma, C.-L. Liu, C. Y. Suen; Character Recognition Systems: A Guide for Students and Practitioners, John Wiley \& Sone, November 2007, ISBN: 978-0-471-41570-
Focus on Kanji characters, the approaches of recognition can be structural or statistical. Mentions also the directional features are effictive.

        
Mentions Character segmentation algorithms and the integration of linguistics information to add knowldge which helps recognition.

        

        
Robustness desing to datl with uncertainity and variablity by 
1)Principles Expected effects
P1 Hypothesis-driven principle When type of a problem is uncertain, set up hypotheses and test them
P2 Deferred decision/multiple hypotheses principle Do not decide; leave decision to next experts carrying over multiple hypotheses
 P3a Process integration Solve a problem by multiple different-field experts as a team
 P3b Information integration principle Combination-based integration Decide as a team of multiple same-field experts
 P3c Corroboration-based integration Utilize other input information; seek more evidence
P4 Alternative solutions principle Solve a problem by multiple alternative approaches
P5 Perturbation principle Modify problem slightly and try again},
author = {Fujisawa, H},
doi = {10.1016/j.patcog.2008.03.015},
file = {:D$\backslash$:/Papers/Documents/2008/Fujisawa - 2008.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Character Recognition,Japanese or Chinese Characters,OCR,Postal Adress Design,Read,Robustness design,Survey},
mendeley-tags = {Read,Survey},
month = aug,
number = {8},
pages = {2435--2446},
title = {{Forty years of research in character and document recognition—an industrial perspective}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308000964},
volume = {41},
year = {2008}
}
@inproceedings{PDB14Hamamura2003,
abstract = {In this paper, a new method of composing a multiclass classifier using
pairwise classifiers is proposed. A �Resemblance Model� is exploited
to calculate a posteriori probability for combining pairwise classifiers.
We proved the validity of this model by using approximation of a
posteriori probability formula. Using this theory, we can obtain
the optimal decision. An experimental result of handwritten numeral
recognition is presented, supporting the effectiveness of our method.},
address = {Edinburgh, Scotland, UK},
author = {Hamamura, Tomoyuki and Mizutani, Hiroyuki and Irie, Bunpei},
booktitle = {7th International Conference on Document Analysis and Recognition (ICDAR 2003)},
doi = {http://csdl.computer.org/comp/proceedings/icdar/2003/1960/02/196020809abs.htm},
file = {:D$\backslash$:/Papers/Documents/2003/Hamamura, Mizutani, Irie - 2003.pdf:pdf},
isbn = {0-7695-1960-1},
pages = {809--813},
publisher = {IEEE Computer Society},
title = {{A Multiclass Classification Method Based on Multiple Pairwise Classifiers.}},
volume = {2-Volume S},
year = {2003}
}
@article{Liu2003,
author = {Liu, C},
doi = {10.1016/S0031-3203(03)00085-2},
file = {:D$\backslash$:/Papers/Documents/2003/Liu - 2003.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {art,discriminative learning,feature extraction,handwritten digit recognition,pattern classi\"{y}cation,support,the state of the},
month = oct,
number = {10},
pages = {2271--2285},
title = {{Handwritten digit recognition: benchmarking of state-of-the-art techniques}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320303000852},
volume = {36},
year = {2003}
}
@inproceedings{Halir,
author = {Halir, Radim},
booktitle = {proceedings of WSCG},
file = {:D$\backslash$:/Papers/Documents/Unknown/Halir - Unknown.pdf:pdf},
publisher = {Citeseer},
title = {{Robust bias-corrected least squares fitting of ellipses}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.20.9451},
volume = {1}
}
@article{Hammond2002Multi,
author = {Hammond, Tracy and Sezgin, Metin and Veselova, Olya and Adler, Aaron and Oltmans, Michael and Alvarado, Christine and Hitchcock, Rebecca},
file = {:D$\backslash$:/Papers/Documents/2002/Hammond et al. - 2002(2).pdf:pdf},
journal = {Proceedings of the 2nd Annual MIT Student Oxygen Workshop},
title = {{Multi-Domain Sketch Recognition}},
year = {2002}
}
@article{Maitra2008,
author = {Maitra, Madhubanti and Chatterjee, Amitava},
doi = {10.1016/j.eswa.2007.01.002},
file = {:D$\backslash$:/Papers/Documents/2008/Maitra, Chatterjee - 2008.pdf:pdf},
issn = {0957-4174},
journal = {Expert Systems with Applications},
keywords = {comprehensive learning,cooperative learning,hcoclpso,image segmentation,multilevel thresholding,pso},
number = {2},
pages = {1341--1350},
publisher = {Elsevier},
title = {{A hybrid cooperative-comprehensive learning based PSO algorithm for image segmentation using multilevel thresholding}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0957417407000127},
volume = {34},
year = {2008}
}
@inproceedings{Sezgin2004Handling,
author = {Sezgin, Tevfik Metin and Davis, Randall},
booktitle = {Making Pen-Based Interaction Intelligent and Natural},
file = {:D$\backslash$:/Papers/Documents/2004/Sezgin, Davis - 2004.pdf:pdf},
publisher = {AAAI Fall Symposium},
title = {{Handling Overtraced Strokes in Hand-Drawn Sketches}},
year = {2004}
}
@inproceedings{Kim2002,
abstract = {This paper presents a new algorithm that is capable of ex- tracting circles from complicated and heavily corrupted im- ages. The algorithm uses a least-squares fitting algorithm for arc segments. The arcs are segmented by using the short straight lines which are extracted by a fast line extraction algorithm. The arc segments are used to yield accurate cir- cle parameters. Tests performed on synthetic and real-world images show that the algorithm quickly and accurately ex- tracts circles from complicated and heavily corrupted im- ages.},
author = {Kim, Euijin and Haseyama, Miki and Kitajima, Hideo},
booktitle = {The 15th International Conference on Vision Interface},
file = {:D$\backslash$:/Papers/Documents/2002/Kim, Haseyama, Kitajima - 2002.pdf:pdf},
number = {1},
title = {{A New Fast and Robust Circle Extraction Algorithm}},
year = {2002}
}
@article{Jacobson2008,
author = {Jacobson, E.R. and Kaster, B.L. and Hammond, Tracy},
file = {:D$\backslash$:/Papers/Documents/2008/Jacobson, Kaster, Hammond - 2008.pdf:pdf},
journal = {srlweb.cs.tamu.edu},
pages = {2--7},
title = {{SOUSA: The Sketch-Based Online User Study Application}},
url = {http://srlweb.cs.tamu.edu/srlng\_media/content/objects/object-1225223315-ff7c436328f7d2c7e67a127ea5017f7a/SOUSApaper.pdf},
volume = {50112},
year = {2008}
}
@article{MCZhang2007,
abstract = {This paper presents a novel cascade ensemble classifier system for
the recognition of handwritten digits. This new system aims at attaining
a very high recognition rate and a very high reliability at the same
time, in other words, achieving an excellent recognition performance
of handwritten digits. The trade-offs among recognition, error, and
rejection rates of the new recognition system are analyzed. Three
solutions are proposed: (i) extracting more discriminative features
to attain a high recognition rate, (ii) using ensemble classifiers
to suppress the error rate and (iii) employing a novel cascade system
to enhance the recognition rate and to reduce the rejection rate.
Based on these strategies, seven sets of discriminative features
and three sets of random hybrid features are extracted and used in
the different layers of the cascade recognition system. The novel
gating networks (GNs) are used to congregate the confidence values
of three parallel artificial neural networks (ANNs) classifiers.
The weights of the GNs are trained by the genetic algorithms (GAs)
to achieve the overall optimal performance. Experiments conducted
on the MNIST handwritten numeral database are shown with encouraging
results: a high reliability of 99.96\% with minimal rejection, or
a 99.59\% correct recognition rate without rejection in the last cascade
layer.},
author = {Zhang, Ping and Bui, Tien D and Suen, ChingY.},
file = {:D$\backslash$:/Papers/Documents/2007/Zhang, Bui, Suen - 2007.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Handwritten digit recognition; Hybrid feature extr},
pages = {3415 � 3429},
title = {{Anovel cascade ensemble classifier system with a high recognition performance on handwritten digits}},
volume = {40},
year = {2007}
}
@inproceedings{Alvarado2005Dynamically,
author = {Alvarado, Christine and Davis, Randall},
booktitle = {Proceedings of IJCAI-05},
file = {:D$\backslash$:/Papers/Documents/2006/Alvarado, Davis - 2006.pdf:pdf},
title = {{Dynamically Constructed Bayes Nets for Multi-Domain Sketch Understanding}},
year = {2005}
}
@inproceedings{Iwata2009,
author = {Iwata, Kazumasa and Kise, Koichi and Nakai, Tomohiro and Iwamura, Masakazu and Uchida, Seiichi and Omachi, Shinichiro},
booktitle = {Document Analysis and Recognition, 2009. ICDAR'09. 10th International Conference on},
doi = {10.1109/ICDAR.2009.192},
file = {:D$\backslash$:/Papers/Documents/2009/Iwata et al. - 2009.pdf:pdf},
issn = {1520-5363},
pages = {1236--1240},
publisher = {IEEE},
title = {{Capturing digital ink as retrieving fragments of document images}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5277653},
year = {2009}
}
@incollection{Foltz2000Supporting,
author = {Foltz, Mark and Davis, Randall},
booktitle = {MIT Artificial Intelligence Laboratory Annual Abstract},
month = sep,
publisher = {MIT AI Lab},
title = {{Supporting Group Brainstorming}},
year = {2000}
}
@article{Vuong2010,
abstract = {The emergence of pen-based mobile devices such as PDAs and tablet PCs provides a new way to input mathematical expressions to computer by using handwriting which is much more natural and efficient for entering mathematics. This paper proposes a web-based handwriting mathematics system, called WebMath, for supporting mathematical problem solving. The proposed WebMath system is based on cli- ent–server architecture. It comprises four major components: a standard web server, handwriting math- ematical expression editor, computation engine and web browser with Ajax-based communicator. The handwriting mathematical expression editor adopts a progressive recognition approach for dynamic rec- ognition of handwritten mathematical expressions. The computation engine supports mathematical functions such as algebraic simplification and factorization, and integration and differentiation. The web browser provides a user-friendly interface for accessing the system using advanced Ajax-based com- munication. In this paper, we describe the different components of the WebMath system and its perfor- mance analysis. },
author = {Vuong, Ba-Quy and He, Yulan and Hui, Siu Cheung},
doi = {10.1016/j.eswa.2009.05.091},
file = {:D$\backslash$:/Papers/Documents/2010/Vuong, He, Hui - 2010.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {progressive handwriting recognition,progressive structural analysis,web-based handwriting mathematics},
month = jan,
number = {1},
pages = {886--893},
publisher = {Elsevier Ltd},
title = {{Towards a web-based progressive handwriting recognition environment for mathematical problem solving}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0957417409005193},
volume = {37},
year = {2010}
}
@inproceedings{PDBLuo2005,
abstract = {We present two optimization algorithms for the design of a cascade
of classifiers, which is becoming a popular choice formany classification
problems. Both algorithms represent each node classifier of a cascade
using a high-level abstraction model and attempt to jointly optimize
the setting of the thresholding parameters of all the node classifiers
within the cascade. We applied both algorithms to optimize the famous
Viola and Jones face detector and one of them in particular greatly
improved the performance. We believe both algorithms can serve as
a useful post-processing process for general cascaded classifier
design},
address = {San Diego, CA, USA},
author = {Luo, Huitao},
booktitle = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2005)},
doi = {http://dx.doi.org/10.1109/CVPR.2005.266},
file = {:D$\backslash$:/Papers/Documents/2005/Luo - 2005.pdf:pdf},
isbn = {0-7695-2372-2},
pages = {480--485},
publisher = {IEEE Computer Society},
title = {{Optimization Design of Cascaded Classifiers.}},
year = {2005}
}
@article{Saleem2009,
author = {Saleem, Shirin and Cao, Huaigu and Subramanian, Krishna and Kamali, Matin and Prasad, Rohit and Natarajan, Prem},
doi = {10.1109/ICDAR.2009.282},
file = {:D$\backslash$:/Papers/Documents/2009/Saleem et al. - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {773--777},
publisher = {Ieee},
title = {{Improvements in BBN's HMM-Based Offline Arabic Handwriting Recognition System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277506},
year = {2009}
}
@article{Hammond2004Automatically,
annote = {Won Best Paper},
author = {Hammond, Tracy},
journal = {Proceedings of the 4th Annual MIT Student Oxygen Workshop},
title = {{Automatically Generating Sketch Interfaces from Shape Descriptions}},
year = {2004}
}
@inproceedings{DSSAMOUD2008,
abstract = {This paper presents an automatic extraction of handwritten Arabic
components of complex documents. Two methods are developed for this
extraction. The first one is based on Mathematical Morphology (MM).
The second one is based on Hough Transform (HT). The developed methods
are evaluated on CENPARMI-Arabic Checks Database, in order to extract
the handwritten components existing in the check: numerical amount,
literal amount and date zone. We present a concept for automatic
evaluation of the results, based on label tools for the different
parts of used documents. We achieve a correct classification rate
of 98\% for numerical amount, 96\% for literal amount, and 98\% for
date, extracted by Hough Transform method.},
author = {SAMOUD, Fadoua BOUAFIF and MADDOURI, Samia SNOUSSI and ABED, Haikal E L and ELLOUZE, Noureddine},
booktitle = {The 11th International Conference on Frontiers in Handwriting Recognition},
file = {:D$\backslash$:/Papers/Documents/2008/SAMOUD et al. - 2008.pdf:pdf},
keywords = { CENPARMIDatabase., Extraction methods, Hough Transform, Mathematical Morphology,Document processing},
title = {{COMPARISON OF TWO HANDWRITTEN ARABIC ZONES EXTRACTION METHODS OF COMPLEX DOCUMENTS}},
year = {2008}
}
@incollection{Oltmans2004Building,
author = {Oltmans, Michael and Davis, Randall},
booktitle = {MIT Computer Science and Artificial Intelligence Laboratory Annual Research Abstract},
file = {:D$\backslash$:/Papers/Documents/2004/Oltmans, Davis - 2004.pdf:pdf},
keywords = {multimodal},
month = feb,
publisher = {MIT CSAIL},
title = {{Building a Training and Test Corpus of Hand Drawn Sketches}},
year = {2004}
}
@inproceedings{FE6Tsymbal2002,
abstract = {This paper shows the importance of the use of class information in
feature extraction for classification and inappropriateness of conventional
PCA to feature extraction for classification. We consider two eigenvector-based
approaches that take into account the class information. The first
approach is parametric and optimizes the ratio of between-class variance
to within-class variance of the transformed data. The second approach
is a nonparametric modification of the first one based on local calculation
of the between-class covariance matrix. We compare the two approaches
with each other, with conventional PCA, and with plain nearest neighbor
classification without feature extraction.},
address = {Pensacola Beach, Florida, USA},
author = {Tsymbal, Alexey and Puuronen, Seppo and Pechenizkiy, Mykola and Baumgarten, Matthias and Patterson, David W},
booktitle = {Proceedings of the Fifteenth International Florida Artificial Intelligence Research Society Conference, May 14-16, 2002, Pensacola Beach, Florida, USA},
editor = {Haller, Susan M and Simmons, Gene},
file = {:D$\backslash$:/Papers/Documents/2002/Tsymbal et al. - 2002.pdf:pdf},
isbn = {1-57735-141-X},
keywords = {Features Extraction},
month = may,
pages = {354--358},
publisher = {AAAI Press},
title = {{Eigenvector-Based Feature Extraction for Classification.}},
year = {2002}
}
@article{Scrivener2002,
author = {Scrivener, S.A.R. and Tseng, W.S.W. and Ball, L.J.},
file = {:D$\backslash$:/Papers/Documents/2002/Scrivener, Tseng, Ball - 2002.pdf:pdf},
journal = {Library},
keywords = {accuracy,design,functional,knowledge,memory,part-by-part,recall,sketching},
pages = {57--64},
publisher = {ACM Press},
title = {{The Impact of Functional Knowledge on Sketching.}},
url = {http://eprints.lancs.ac.uk/11137/},
year = {2002}
}
@article{MCLee1999,
abstract = {This paper presents a recognition system which obtains a recognition
rate higher than 99\% for the printed Korean characters of multifont
and multisize. We recognize a given input by "rst identifying the
character type of the input and then recognizing its constituent
graphemes. In order to improve the performance we incorporated three
new ideas in our system: the expansion of the subimage areas used
by the grapheme classi"ers, an algorithm to accurately segment the
horizontal vowel's subimage areas, and a validation process to evaluate
the result of the type classi"er. Through experiments we con"rmed
that our system performs well in a multi-font and multi-size environment
and that those three ideas actually contributed to improve the performance
signi"cantly},
author = {Lee, Jin-Soo and Kwon, Oh-Jun and Bang, Sung-Yang},
file = {:D$\backslash$:/Papers/Documents/1999/Lee, Kwon, Bang - 1999.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Korean characters; OCR; Neural networks; Multi-fon},
pages = {1935--1945},
title = {{Highly accurate recognition of printed Korean characters through an improved two-stage classication method}},
volume = {32},
year = {1999}
}
@article{Mcfadzean1999,
author = {Mcfadzean, J. and Cross, N.G. and Johnson, J.H.},
doi = {10.1109/IV.1999.781568},
file = {:D$\backslash$:/Papers/Documents/1999/Mcfadzean, Cross, Johnson - 1999.pdf:pdf},
isbn = {0-7695-0210-5},
journal = {1999 IEEE International Conference on Information Visualization (Cat. No. PR00210)},
pages = {258--265},
publisher = {IEEE Comput. Soc},
title = {{An analysis of architectural visual reasoning in conceptual sketching via Computational Sketch Analysis (CSA)}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=781568},
year = {1999}
}
@article{Krishnapuram2004,
author = {Krishnapuram, B. and Bishop, C.M. and Szummer, M.},
doi = {10.1109/IWFHR.2004.46},
file = {:D$\backslash$:/Papers/Documents/2004/Krishnapuram, Bishop, Szummer - 2004.pdf:pdf},
isbn = {0-7695-2187-8},
journal = {Ninth International Workshop on Frontiers in Handwriting Recognition},
pages = {20--25},
publisher = {Ieee},
title = {{Generative Models and Bayesian Model Comparison for Shape Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1363881},
year = {2004}
}
@article{Monson2005,
address = {New York, New York, USA},
author = {Monson, Christopher K. and Seppi, Kevin D.},
doi = {10.1145/1068009.1068039},
file = {:D$\backslash$:/Papers/Documents/2005/Monson, Seppi - 2005.pdf:pdf},
isbn = {1595930108},
journal = {Proceedings of the 2005 conference on Genetic and evolutionary computation - GECCO '05},
keywords = {mathematical models,optimization,swarm intelligence},
pages = {193},
publisher = {ACM Press},
title = {{Bayesian optimization models for particle swarms}},
url = {http://portal.acm.org/citation.cfm?doid=1068009.1068039},
year = {2005}
}
@inproceedings{K.DeMeyer2003,
abstract = {Stochastic Diffusion Search (SDS) is an efficient generic search method, originally developed as a population-based solution to the problem of best-fit pattern matching. In re- cent years, similarities between previously unrelated search methods have been discovered [28] and further unification and hybridisation is expected. In this context this paper seeks to establish links between SDS and Ant Algorithms, (AA). Contrary to the stigmergetic communication used in most AA, SDS uses a one-to-one recruitment system akin to the tandem-running behaviour found in certain species of ants. With reference to SDS it is claimed that efficient global decision making can emerge from interaction and communication in a population of individuals each forming hypotheses on the basis of partial evidence.},
address = {London, UK},
author = {{K . De Meyer}, J M Bishop And S J Nasuto},
booktitle = {Symposium on Evolvability \& Interaction 8-10th},
file = {:D$\backslash$:/Papers/Documents/2003/K . De Meyer - 2003.pdf:pdf},
number = {October},
pages = {1--19},
title = {{STOCHASTIC DIFFUSION : USING RECRUITMENT FOR SEARCH}},
year = {2003}
}
@incollection{ARCheriet2007,
abstract = {From the administrative point of view, cheque processing involves
all tasks a bank officer may perform to process an incoming cheque
for a client. This includes: accessing account numbers, verifying
names and signatures on the cheque, verifying the date of the cheque,
matching the legal amount with the courtesy amount and verifying
the credit of the cheque writer. However, from the technical point
of view, cheque processing could involve capturing the cheque image,
separating the foreground of the cheque from its background, extracting
fields of interest and recognizing each of them. This work employs
theories and methodologies from various fields ranging from Natural
language processing, Optical Character Recognition to Banking. 

The motivation of the work on Cheque processing is not less than the
motivation of the entire research in artificial intelligence, which
aims to program the computer to carry out tedious routine processes,
freeing time and space for humans to perform tasks that require higher
levels of intelligence. A major advantage of such study is that it
can be easily adjusted to serve more than 20 different countries
(all of them use Arabic as their first language). In addition, legal
amounts are widely found in documents other than bank cheques (e.g.
business sell/purchase forms). Therefore, this study will be applicable
to a wide range of applications. Moreover, similar languages (e.g.
Urdu, Farisi) which use the same alphabet can benefit from these
studies.

The remaining sections provide a description of datasets available
for researchers as well as a detailed description of one system that
processes legal amounts and one system dedicated for processing of
courtesy amount},
author = {Cheriet, M and Al-Ohali, Y and Ayat, N E and Suen, C Y},
booktitle = {Digital Document Processing},
doi = {http://dx.doi.org/10.1007/978-1-84628-726-8\_10},
file = {:D$\backslash$:/Papers/Documents/2007/Cheriet et al. - 2007.pdf:pdf},
keywords = { Cheque processing,Arabic Handwriting},
pages = {213--234},
publisher = {Springer London},
series = {Advances in Pattern Recognition},
title = {{Arabic Cheque Processing System: Issues and Future Trends}},
year = {2007}
}
@phdthesis{Alvarado2000a,
author = {Alvarado, C.J.},
booktitle = {Structure},
file = {:D$\backslash$:/Papers/Documents/2000/Alvarado - 2000.pdf:pdf},
publisher = {Citeseer},
title = {{A natural sketching environment: Bringing the computer into early stages of mechanical design}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.62.9709\&amp;rep=rep1\&amp;type=pdf},
year = {2000}
}
@inproceedings{Stutzle1998,
author = {St\"{u}tzle, T},
booktitle = {Parallel Problem Solving from Nature—PPSN V},
file = {:D$\backslash$:/Papers/Documents/1998/St\"{u}tzle - 1998.pdf:pdf},
title = {{Parallelization strategies for ant colony optimization}},
url = {http://www.springerlink.com/index/u705n746l3x58620.pdf},
year = {1998}
}
@article{Mohamed1996,
author = {Mohamed, Magdi and Gader, Paul},
doi = {10.1109/TNB.2008.2005325},
file = {:D$\backslash$:/Papers/Documents/1996/Mohamed, Gader - 1996.pdf:pdf},
issn = {1558-2639},
journal = {IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = oct,
number = {8},
pages = {548--554},
pmid = {20952322},
title = {{Hidden Word Recognition using segmentatino free hidden markov modeling and segmentation - based dynamic programming techniques}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20952322},
volume = {18},
year = {1996}
}
@phdthesis{ThesisSaid1997,
abstract = {Automatic processing of documents with the purpose to scan different
documents, recognize them, extract, and process different data items
obtained from them could be achieved by top-down and bottom-up approaches.
The former processes documents starting from the document class and
ends with the pixel representation of the different items that should
be extracted. The latter, however, processes documents in a reversed
manner. In this thesis, a top-down formal approach for automatic
processing of documents and bank cheques is proposed. This approach
will view a document as a hierarchy of related items: (a) the background
which contains simple or complex scenes that should be eliminated,
and (b) the foreground which contains (i) base lines that must be
removed and (ii) handwritten data, such as the date, the legal amount,
and the courtesy amount, that should be extracted with minimum distortion.
The novelty of this new approach is to eliminate the background,
first, by introducing a new recursive dynamic thresholding technique
that could be used globally or locally on a given cheque image. As
a second step, base lines that intersect the handwritten data are
recognized and removed with the challenge of minimizing the distortion
on the extracted items. Two methods are proposed to tackle this difficulty.
The first method detects the handwritten data that intersects with
the base lines that should be eliminated and uses morphological and
topological processing to identify and fill the gaps resulting from
the elimination of the detected base lines. The second method proposed
a new dynamic morphological processing technique which acts as a
detector and a preserver of the handwritten data that intersect,
with the base lines. The second method highly increased the efficiency
of item extraction by more than 80\% and enhanced the quality of the
extracted items when combined with local processing techniques. In
a step to study the reliability of the proposed top-down automatic
item extraction system, a quantitative analysis technique is investigated
and an experimental study is performed comparing the top-down formal
approach with another newly developed bottom-up approach using the
same training set of 500 real-life bank cheques and two testing sets
of 200 bank cheques obtained from the CENPARMI database. The purpose
of the quantitative performance analysis technique is to subject
the extracted items of the top-down and the bottom-up approaches
to the same item processing system that is able to recognize these
corresponding items and provide quantitative results to indicate
the reliability of both approaches. The experimental results showed
that the reliability of the top-down approach on the training set.
first testing set, and second testing set are 89.20\%, 87.91\%, and
90.10\% respectively while those on the bottom-up approach are 91.35\%,
91.30\%, and 93.10\%, respectively. Finally, in a step towards the
construction of a highly reliable system, a feasibility study has
been conducted by combining both approaches. The result is quite
encouraging and a reliability of 97.09\% has been achieved when these
two systems are combined},
annote = {Thesis Advisor:Suen, Ching Y},
author = {Said, Joseph Nassif},
file = {:D$\backslash$:/Papers/Documents/1997/Said - 1997.pdf:pdf},
school = {Concordia University.},
title = {{Automatic processing of documents and bank cheques}},
year = {1997}
}
@phdthesis{Adler2001,
author = {Adler, A.D. and Davis, R.},
file = {:D$\backslash$:/Papers/Documents/2001/Adler, Davis - 2001.pdf:pdf},
school = {MIT},
title = {{New Frontiers in Sketch Understanding}},
url = {http://mtlweb.mit.edu/researchgroups/MEngTP/Aaron\_Adler\_Proposal.pdf},
year = {2001}
}
@article{Hutton1997,
author = {Hutton, G. and Cripps, M. and Elliman, D.G. and Higgins, C.a.},
doi = {10.1109/ICDAR.1997.620614},
file = {:D$\backslash$:/Papers/Documents/1997/Hutton et al. - 1997.pdf:pdf},
isbn = {0-8186-7898-4},
journal = {Proceedings of the Fourth International Conference on Document Analysis and Recognition},
pages = {771--775},
publisher = {IEEE Comput. Soc},
title = {{A strategy for on-line interpretation of sketched engineering drawings}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=620614},
year = {1997}
}
@inproceedings{Abed2009,
abstract = {Arabic character and text recognition methods for printed or handwritten characters are known since many years. We present in the first part of this paper a state of the art of Arabic text classification techniques and existing recognition systems. In the second part we discuss how evaluation methods and competitions help to support the development of text recognition systems and methods. Based on the results of the last Arabic handwriting recognition competitionwe show a concept to develop efficient recognition systems. On the basis of the actual situation of research future trends are de- scribed in the last part of this paper},
author = {Abed, Haikal El},
booktitle = {Innovations in Information Technology,},
file = {:D$\backslash$:/Papers/Documents/2009/Abed - 2009.pdf:pdf},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {692--696},
title = {{Arabic text recognition systems-state of the art and future trends}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4781781},
year = {2009}
}
@inproceedings{Kara2004a,
author = {Kara, L.B. and Stahovich, T.F.},
booktitle = {Proceedings of the working conference on Advanced visual interfaces},
file = {:D$\backslash$:/Papers/Documents/2004/Kara, Stahovich - 2004.pdf:pdf},
pages = {354--357},
publisher = {ACM},
title = {{Sim-U-Sketch: a sketch-based interface for SimuLink}},
url = {http://portal.acm.org/citation.cfm?id=989923},
year = {2004}
}
@inproceedings{George2006,
author = {George, C. and Wolfer, James},
booktitle = {Proceedings of the 24th IASTED international conference on Artificial intelligence and applications},
file = {:D$\backslash$:/Papers/Documents/2006/George, Wolfer - 2006.pdf:pdf},
isbn = {0889865566},
keywords = {background and other foreground,by processing,computational intelligence,computer,objects,swarm intelligence,vision and manufacturing},
pages = {125--130},
publisher = {Citeseer},
title = {{A swarm intelligence approach to counting stacked symmetric objects}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.84.1962\&amp;rep=rep1\&amp;type=pdf},
year = {2006}
}
@inproceedings{Kara2004d,
author = {Kara, L.B. and Stahovich, T.F.},
booktitle = {Proceedings of the 17th annual ACM symposium on User interface software and technology},
file = {:D$\backslash$:/Papers/Documents/2004/Kara, Stahovich - 2004(2).pdf:pdf},
isbn = {1581139578},
number = {2},
pages = {13--22},
publisher = {ACM},
title = {{Hierarchical parsing and recognition of hand-sketched diagrams}},
url = {http://portal.acm.org/citation.cfm?id=1029632.1029636},
volume = {6},
year = {2004}
}
@inproceedings{DiFiore2002,
author = {{Di Fiore}, F. and {Van Reeth}, F.},
booktitle = {Sketch Understanding: Papers from the 2002 American Association for Artificial Intelligence (AAAI 2002) Spring Symposium},
file = {:D$\backslash$:/Papers/Documents/2002/Di Fiore, Van Reeth - 2002.pdf:pdf},
keywords = {2d animation,character animation,computer as-,form strokes,free,mation,sketching,traditional ani-},
pages = {32--36},
title = {{A multi-level sketching tool for pencil-and-paper animation}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:A+Multi+–+Level+Sketching+Tool+for+“+Pencil+–+and+–+Paper+”+Animation\#0},
year = {2002}
}
@article{Neves2008,
author = {Neves, R.F.P. and Mello, C.a.B. and Silva, M.S. and Bezerra, B.L.D.},
doi = {10.1109/IWSSIP.2008.4604375},
file = {:D$\backslash$:/Papers/Documents/2008/Neves et al. - 2008.pdf:pdf},
isbn = {978-80-227-2856-0},
journal = {2008 15th International Conference on Systems, Signals and Image Processing},
keywords = {2 presents a sample,all of,check and the distribution,check processing,checks,fig,identification code,in spite of the,locations of the,them have to use,these areas in specific,thresholding,tsallis entropy,variety of banks},
month = jun,
pages = {93--96},
publisher = {Ieee},
title = {{A new technique to threshold the courtesy amount of Brazilian bank checks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4604375},
volume = {2},
year = {2008}
}
@article{Koerich2003,
author = {Koerich, Alessandro L.},
doi = {10.1007/s10032-003-0113-0},
file = {:D$\backslash$:/Papers/Documents/2003/Koerich - 2003.pdf:pdf},
journal = {International Journal on Document Analysis and Recognition},
keywords = {Reference From Doctor,handwriting recognition,hidden markov models,large vocabu-,lary,level building algorithm},
mendeley-tags = {Reference From Doctor},
month = oct,
number = {2},
pages = {126--144},
title = {{Lexicon-driven HMM decoding for large vocabulary handwriting recognition with multiple character models}},
volume = {6},
year = {2003}
}
@inproceedings{ARSubramanian2009,
abstract = {Text from Arabic optical handwriting recognition (OHR) systems can
provide key indexing information. In particular, the text is rich
in named entities (NEs) and detection of such entities is critical
for search applications. Traditional approaches for detecting NEs
in optical character recognition (OCR) output look for these NEs
in the single-best recognition results. Due to the inevitable presence
of recognition errors in the single-best output, such approaches
usually result in low recall. Given that a lattice is more likely
to contain the correct answer, we explore NE detection from word
lattices produced by our Arabic handwriting recognition system. Since
the improvement in recall is accompanied by a large number of false
positives, we use confidence scores based on posterior scores to
control precision. We show a 7\% improvement in true detects for the
same false acceptance rate on using lattices instead of 1-best hypothesis
for NE lookup.},
address = {Barcelona, Spain},
author = {Subramanian, Krishna and Prasad, Rohit and Natarajan, Prem},
booktitle = {AND '09: Proceedings of The Third Workshop on Analytics for Noisy Unstructured Text Data},
doi = {http://doi.acm.org/10.1145/1568296.1568308},
file = {:D$\backslash$:/Papers/Documents/2009/Subramanian, Prasad, Natarajan - 2009.pdf:pdf},
isbn = {978-1-60558-496-6},
pages = {63--68},
publisher = {ACM},
title = {{Robust named entity detection using an Arabic offline handwriting recognition system}},
year = {2009}
}
@incollection{Hammond2002SketchUMLAbstract,
author = {Hammond, Tracy and Gajos, Krzystof and Davis, Randall and Shrobe, Howard},
booktitle = {MIT Artificial Intelligence Laboratory Annual Abstract},
file = {:D$\backslash$:/Papers/Documents/2002/Hammond et al. - 2002.pdf:pdf},
keywords = {multimodal},
month = sep,
publisher = {MIT AI Lab},
title = {{Sketch Recognition in Software Design}},
year = {2002}
}
@inproceedings{ARHUSSAIN2000,
abstract = {The goal to produce effective Optical Character

Recognition (OCR) methods has lead to the

development of a number of algorithms. The

purpose of these is to take the hand-written or

printed text and to translate it into a

corresponding digital form. The multitude

requirements and developments are well

represented in the literature ( see for example

Abuhaiba [ 1 J and Suen [2 J ).

The primary objective of this paper is to provide

an insight into a robust system which has been

successfully developed and employed to

recognise Latin and Arabic characters and

whose workings has been described by the

authors in a sister publication [ 3 J .The focus

here is to discuss the main components used in

the multi-stage system, paying particular

attention to the nonnalisation process used for

orientation and size for a given bitmapped

character. The effectiveness of the approach is

demonstrated through its workings for the Arabic

and Latin case, both for characters and numbers.},
author = {HUSSAIN, FIAZ and COWELL, JOHN},
booktitle = {IEEE International Conference on Information Visualization (IV'00)},
file = {:D$\backslash$:/Papers/Documents/2000/HUSSAIN, COWELL - 2000.pdf:pdf},
keywords = { Latin, OCR, confusion matrix., fonts, nonnalisation, pattern recognition,Arabic},
title = {{Character Recognition of Arabic and Latin Scripts}},
year = {2000}
}
@article{CSAIL2009,
abstract = {Diagrams are an essential means of capturing and communi- cating information in many different domains. They are also a valuable part of the early design process, helping us ex- plore ideas and solutions in an informal environment. This paper presents a new approach to sketched symbol recogni- tion that preserves as much of the visual nature of the symbol as possible. Our method is robust to differences in drawing style, computationally efficient, and achieves excellent per- formance for several different domains.},
annote = {index : Ouyang2009
The system uses Visual properities of symbol to detect it. It converts the points into pixel image and hangle it using image based recognition. 
the system uses the input then extract five feature images of the input pixel representation of the strokes drawn.  the features images are based on gradient operators in different directions (0, 45, 90 and 135). the features images are then smothed and downsampled to finalled get 720 features or 5 24by 24 i mages. Image deformation model is created from train samples to compare with test sample at run time using four different classification methods ( pixel (raw) Nearst neighbors, features NN . hausdroff NN , or a SVM). 
A hierarchial clusting is used with NN methods to help get faster results. Ranking and various rotational models is generated to make system rotaional invariant. 
System is test on Digits, HHRec and Electrical symbols the result is 99.2 \%, 98.2 \%96.2\% on datasets respectivily .  a run time performance is also evaluated and SVM seems to get better performance than it },
author = {CSAIL, MIT},
file = {:D$\backslash$:/Papers/Documents/2009/CSAIL - 2009.pdf:pdf},
journal = {rationale.csail.mit.edu},
keywords = {Classifiers,Hierarchical,Image based,Information Interfaces and Presentation: Input dev,Sketch Recognition,Summarized,symbol recognition,vision recognition algorithms},
mendeley-tags = {Summarized},
title = {{Visual Recognition of Sketched Symbols}},
url = {http://rationale.csail.mit.edu/publications/Ouyang2009Symbol.pdf},
year = {2009}
}
@article{Mozaffari2006,
abstract = {This paper presents a new comprehensive database for isolated offline handwritten Farsi/Arabic numbers and characters for use in optical character recognition research. The database is freely available for academic use. So far no such a freely database in Farsi language is available. Grayscale images of 52,380 characters and 17,740 numerals are included. Each image was scanned from Iranian school entrance exam forms during the years 2004-2006 at 300 dpi. The only restriction imposed on the writers is to write each character within a rectangular box. The number of samples in each class of the database is non-uniform corresponding to their real life distributions. Also, for comparison purposes, each dataset has been properly divided into respective training and test sets.},
author = {Mozaffari, Saeed and Faez, Karim and Faradji, Farhad and Ziaratban, Majid and Golzan, S.M.},
file = {:D$\backslash$:/Papers/Documents/2006/Mozaffari et al. - 2006.pdf:pdf},
journal = {Electrical Engineering},
keywords = {arabic,comparative database,farsi,isolated characters or assuming,isolated numbers and characters,it is notable that,most of the above,ocr,offline,that the farsi,work was done on},
title = {{A comprehensive isolated Farsi/Arabic character database for handwritten OCR research}},
url = {http://hal.inria.fr/inria-00112676/},
year = {2006}
}
@article{Elbaati2009,
author = {Elbaati, Abdelkarim and Boubaker, Houcine and Kherallah, Monji and Ennaji, Abdellatif and Abed, Haikal El and Alimi, Adel M.},
doi = {10.1109/ICDAR.2009.262},
file = {:D$\backslash$:/Papers/Documents/2009/Elbaati et al. - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {411--415},
publisher = {Ieee},
title = {{Arabic Handwriting Recognition Using Restored Stroke Chronology}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277647},
year = {2009}
}
@inproceedings{DSDimauro2002,
abstract = { This paper presents a new database for off-line handwriting recognition.
The database, that is particularly devoted to research on bank-check
recognition, up to now includes instances of isolated digits and
characters, basic words of worded amounts, and signatures. Pattern
images are stored using a standard image format, and hence they are
easily usable by several commercial and scientific image processing
packages.},
author = {Dimauro, G and Impedovo, S and Modugno, R and Pirlo, G},
booktitle = {Frontiers in Handwriting Recognition, 2002. Proceedings. Eighth International Workshop on},
doi = {10.1109/IWFHR.2002.1030964},
file = {:D$\backslash$:/Papers/Documents/2002/Dimauro et al. - 2002.pdf:pdf},
keywords = { ; visual databases;,bank-check processing; bank-cheque processing; dat},
pages = {524--528},
title = {{A new database for research on bank-check processing}},
year = {2002}
}
@article{DSKoch2005,
abstract = {In this paper, we propose a method for the automatic extraction of
numerical fields in handwritten documents. The approach exploits
the known syntactic structure of the numerical field to extract,
combined with a set of contextual morphological features to find
the best label for each connected component. Applying a Markov model
based syntactic analyzer on the overall document allows to localize/extract
fields of interest. Reported results on the extraction of zip codes,
phone numbers and customer codes from handwritten incoming mail documents
demonstrate the interest of the proposed approach.},
author = {Koch, G and Heutte, L and Paquet, T},
doi = {DOI: 10.1016/j.patrec.2004.10.006},
file = {:D$\backslash$:/Papers/Documents/2005/Koch, Heutte, Paquet - 2005.pdf:pdf},
issn = {0167-8655},
journal = {Pattern Recognition Letters},
keywords = {Document analysis},
number = {8},
pages = {1118--1127},
title = {{Automatic extraction of numerical sequences in handwritten incoming mail documents}},
url = {http://www.sciencedirect.com/science/article/B6V15-4DTTHDM-5/2/2325ca93a5882505f71e923c7a1d52e9},
volume = {26},
year = {2005}
}
@article{Halavati2007,
abstract = {Persian is a fully cursive handwriting in which each character may take different forms in different parts of the word, characters overlap and there is a wide range of possible styles. These complexities make automatic recognition of Persian a very hard task. This paper presents a novel approach on recognition of such writings systems which is based on the description of input stream by a sequence of fuzzy linguistic terms; representation of character patterns with the same descriptive language; and comparison of inputs with character patterns using a novel elastic pattern matching approach. As there is no general benchmark for recognition of Persian handwriting, the approach has been tested on the set of words in first primary Iranian school books including 1250 words resulting in 78\% correct recognition without dictionary and 96\% with dictionary.},
author = {Halavati, Ramin and Shouraki, Saeed Bagheri},
file = {:D$\backslash$:/Papers/Documents/2007/Halavati, Shouraki - 2007.pdf:pdf},
journal = {International Journal of Pattern Recognition and Artificial Intelligence},
keywords = {elastic pattern matching,fuzzy modeling,online handwriting recognition},
number = {3},
pages = {491--513},
title = {{USING ELASTIC FUZZY PATTERN RECOGNITION}},
volume = {21},
year = {2007}
}
@article{Don2009,
author = {Don, Liam and Ivrissimtzis, Ioannis},
doi = {10.4304/jmm.4.2.80-86},
file = {:D$\backslash$:/Papers/Documents/2009/Don, Ivrissimtzis - 2009.pdf:pdf},
issn = {1796-2048},
journal = {Journal of Multimedia},
month = apr,
number = {2},
pages = {80--86},
title = {{Multi-pen Sketch Recognition in a Learning Environment}},
url = {http://ojs.academypublisher.com/index.php/jmm/article/view/2230},
volume = {4},
year = {2009}
}
@article{Kessentini2010,
abstract = {In this paper, we present a multi-stream approach for off-line handwritten word recognition. The pro- posed approach combines low level feature streams namely, density based features extracted from 2 dif- ferent sliding windows with different widths, and contour based features extracted from upper and lower contours. The multi-stream paradigm provides an interesting framework for the integration of multiple sources of information and is compared to the standard combination strategies namely fusion of repre- sentations and fusion of decisions. We investigate the extension of 2-stream approach to N streams (N =2, ... , 4) and analyze the improvement in the recognition performance. The computational cost of this extension is discussed. Significant experiments have been carried out on two publicly available word databases: IFN/ENIT benchmark database (Arabic script) and IRONOFF database (Latin script). The multi- stream framework improves the recognition performance in both cases. Using 2-stream approach, the best recognition performance is 79.8\%, in the case of the Arabic script, on a 2100-word lexicon consisting of 946 Tunisian town/village names. In the case of the Latin script, the proposed approach achieves a rec- ognition rate of 89.8\% using a lexicon of 196 words},
annote = {===========================================

        Paper Index : Kessentini2010

        Date:22-11-2010

        
          
Why read paper ?
        
Recent arabic hmm. 

        

        Paper Overview ?
        
offline word recognition using 
multistream hmm. with contour and density  features. 
for both arabic and english on IFN and IRONOFF datasets. 

        

        What is these paper about ? (Summary)
        

        
          
1. preprocessing 
        
a) normalization then using slant and slope correction. 
b)  contour smothing to remove small blobs 
c) base line detection. 

        2) feature extraction 
        
a) contour detection 
for upper and lower . For each contour direction density histogram is computed a second fature for every point based on upper and lower point 
 third features set is loccation of contour point. there is generated for each window 15 contour feature 
b) density features
word is divided by windows with h and w. 
a set fo 15 features is computed using 8 and 14 pixel as widths. 

        
the final is 4 streams (upper contour, lower contour, density with 8 pixel width and density with 14 pixel length.). 
The streams  are independent of each other and computed using sliding windows. 
          
Classification:
        
HMM multi stream using more than one features as input. 
introduction and training , testing systems. is explained. 
comparing and triang of streams are explained n detailed . 
HMM recombinatino which is an adaptation of viterbibi search algorithm allow to decompose a single stream hmm inot tow independent component. 
HMM i sused to get most probalbe words from 1 , 2, 3, and 4 streams. 

        
          
result. 
        
Used two dataset one for arabic (IFN /ENIT ) and one for latin (IRON) both offline. 
comparison between different streams combinations. 1-2,3-2, . 
1-4 got best results (79.6\% on IFN and 89.8\% on laten)
propose a system is cbest compred to other icdar 2007 and 2005 systems. 
using 3 streams and 4 streams but with small lexicon (due to complexity) was 98 and 99 \%. 

        

        

        

        
          
1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?
        

        
The use of different streams of features on same hmm to get results. 
Simple contour and density features. 
System proved on both arabic and latin words. 
          
2. What can we take from this work  ? what do we learn ? What can be incorporated into our own work ?
        
Contour , density Features  and some ideas of building hmm topolgy and multiple streams. 

        
          
3. What are the problems of the paper ?
        
The complexitiy of handling hmm data and output probability. 

        
          
4. what is lacking from the work ? why does this work knot be the final  research in this subject ?
        

        
Lacks an optimizied algorithm to handle multiple feature set on same hmm output. 

        
          
5. what about the methods causes this lack ? is there a fundamental reason ?
        

        

        
          
6. Could incremental Changes Fix this lack ? if so, what changes ? 
        

        

        
          
Is there is any question you had about the paper ? 
        

        

        
          
The final conclusion..........
        
Method can be used on multiple features et and may need optimization 
very good analysis of reault and comparision of other results 
simple contour and density feaures but focus on hmm multiple streams

        
==========================================================================

      },
author = {Kessentini, Yousri and Paquet, Thierry and {Ben Hamadou}, AbdelMajid},
doi = {10.1016/j.patrec.2009.08.009},
file = {:D$\backslash$:/Papers/Documents/2010/Kessentini, Paquet, Ben Hamadou - 2010.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Arabic Handwritting recognition,Read,Summarized,hidden markov models,off-line handwriting recognition},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
month = jan,
number = {1},
pages = {60--70},
publisher = {Elsevier B.V.},
title = {{Off-line handwritten word recognition using multi-stream hidden Markov models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865509002232},
volume = {31},
year = {2010}
}
@inproceedings{DSGorski1999,
abstract = {The paper presents new A2iA bank check recognition systems designed
to process handwritten and/or printed checks issued in France, UK
or USA. All the systems have identical architecture and design principles.
However, each of them contains a country-specific part and is trained
with country-specific data. Each system performs location, extraction,
segmentation and recognition of courtesy and legal amounts in a document
image, as well as deciding whether to accept or reject the check.
The recognition rate is 80-90\%. In the production mode, the check
acceptance rate is 60-75\%, with the misread rate corresponding to
that of a human operator (close to 1\%)},
author = {Gorski, N and Anisimov, V and Augustin, E and Baret, O and Price, D and Simon, J.-C.},
booktitle = {Proceedings of the Fifth International Conference on Document Analysis and Recognition, 1999. ICDAR '99.},
doi = {10.1109/ICDAR.1999.791840},
file = {:D$\backslash$:/Papers/Documents/1999/Gorski et al. - 1999.pdf:pdf},
keywords = { ;,A2iA Check Reader;A2iA bank check recognition syst},
month = sep,
pages = {523--526},
title = {{A2iA Check Reader: a family of bank check recognition systems}},
year = {1999}
}
@article{Bouslama1999,
author = {Bouslama, Faouzi},
file = {:D$\backslash$:/Papers/Documents/1999/Bouslama - 1999.pdf:pdf},
journal = {International Journal of pattern recogntion and Artificial Intelligence},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
number = {7},
pages = {1027--1040},
title = {{Structural and fuzzy techniques in the recognition of online Arabic characters}},
url = {http://www.worldscinet.com/abstract?id=pii:S0218001499000574},
volume = {13},
year = {1999}
}
@article{Taele2010,
abstract = {The non-Romanized Mandarin Phonetic Symbols I (MPS1) system is a highly advantageous phonetic system for native English users studying Chinese Mandarin to learn, yet its steep initial learning curve discourages language programs to instead adopt Romanized phonetic systems. Computer-assisted language instruction (CALI) can greatly reduce this learning curve, in order to enable students to sooner benefit from the long-term advantages presented in MPS1 usage during the course of Chinese Mandarin study. Unfortunately, the technologies surrounding existing online handwriting recognition algorithms and CALI applications are insufficient in providing a “dynamic” counterpart to traditional paper-based workbooks employed in the classroom setting. In this paper, we describe our sketch recognition-based LAMPS system for teaching MPS1 by emulating the naturalness and realism of paper-based workbooks, while extending their functionality with human instructor-level critique and assessment at an automated level.},
annote = {Paper index: Taele2010
      using sketch algorithm handling handwritten recongnition of mandarine chinese letters. The paper is foucused on how the system is used for teaching chineese for forigen language. It is an application of sketch recognition.  The paper uses paloesketch system then ladder sysstem as geometeric representation. A symbol template matching is used to match new symbol to geomteric models.  No recognition resutl is presented mostly user feedback on how to draw chineese words},
author = {Taele, Paul and Hammond, Tracy},
doi = {10.1016/j.jvlc.2009.12.004},
file = {:D$\backslash$:/Papers/Documents/2010/Taele, Hammond - 2010.pdf:pdf},
issn = {1045926X},
journal = {Journal of Visual Languages \& Computing},
keywords = {Handwritting recognition,High Level,Ladder,PaleoSketch,Read,application,bopomofo,chinese,sketch recognition},
mendeley-tags = {Read,application},
month = apr,
number = {2},
pages = {109--120},
title = {{LAMPS: A sketch recognition-based teaching tool for Mandarin Phonetic Symbols I}},
url = {http://dx.doi.org/10.1016/j.jvlc.2009.12.004},
volume = {21},
year = {2010}
}
@inproceedings{Adler2003a,
author = {Adler, Aaron},
booktitle = {In Third Annual MIT CSAIL Student Oxygen Workshop},
file = {:D$\backslash$:/Papers/Documents/2003/Adler - 2003(2).pdf:pdf},
publisher = {Citeseer},
title = {{Creating a multimodal design environment using speech and sketching}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.4627\&amp;rep=rep1\&amp;type=pdf},
year = {2003}
}
@article{PDB2Zhao2007,
abstract = {In an object recognition task where an image is represented as a constellation
of image patches, often many patches correspond to the cluttered
background. If such patches are used for object class recognition,
they will adversely affect the recognition rate. In this paper, we
present a statistical method for selecting the image patches which
characterize the target object class and are capable of discriminating
between the positive images containing the target objects and the
complementary negative images. This statistical method select those
images patches from the positive images which, when used individually,
have the power of discriminating between the positive and negative
images in the evaluation data. Another contribution of this paper
is the part-based probabilistic method for object recognition. This
Bayesian approach uses a common reference frame instead of reference
patch to avoid the possible occlusion problem. We also explore different
feature representation using PCA an 2D PCA. The experiment demonstrates
our approach has outperformed most of the other known methods on
a popular benchmark data set while approaching the best known results.},
author = {Zhao, Zhipeng and Vashist, Akshay and Elgammal, Ahmed M and Muchnik, Ilya B and Kulikowski, Casimir A},
doi = {http://dx.doi.org/10.1080/00207160601167045},
file = {:D$\backslash$:/Papers/Documents/2007/Zhao et al. - 2007.pdf:pdf},
journal = {Int. J. Comput. Math.},
keywords = { Class recognition, Feature selection, Object detection, Pattern representation and modeling,Computer vision},
number = {9},
pages = {1285--1297},
title = {{Combinatorial and statistical methods for part selection for object recognition.}},
volume = {84},
year = {2007}
}
@misc{Alvarado2000,
author = {Alvarado, Christine and Davis, Randall},
booktitle = {Mechanical Engineering},
file = {:D$\backslash$:/Papers/Documents/2000/Alvarado, Davis - 2000.pdf:pdf},
title = {{Intelligent Mechanical Engineering Design Enviroment: From sketching to Simulation}},
year = {2000}
}
@incollection{Hammond2004DebuggingAbstract,
author = {Hammond, Tracy and Davis, Randall},
booktitle = {MIT Computer Science and Artificial Intelligence Laboratory Annual Research Abstract},
keywords = {multimodal},
month = sep,
publisher = {MIT CSAIL},
title = {{Debugging Shape Definitions for Use in Sketch Recognition}},
year = {2004}
}
@article{Caetano2000,
author = {Caetano, A. and Goulart, Neri and Fonseca, Manuel and Jorge, Joaquim},
file = {:D$\backslash$:/Papers/Documents/2000/Caetano et al. - 2000.pdf:pdf},
journal = {Computers \& Graphics},
keywords = {calligraphic interfaces,task analysis,usability evaluation,visual pars-},
number = {6},
pages = {835--849},
publisher = {Citeseer},
title = {{Sketching user interfaces with visual patterns}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.79.4409\&amp;rep=rep1\&amp;type=pdf},
volume = {24},
year = {2000}
}
@article{Stefanidis1998,
author = {Stefanidis, Anthony and Agouris, Peggy},
file = {:D$\backslash$:/Papers/Documents/1998/Stefanidis, Agouris - 1998.pdf:pdf},
journal = {INTERNATIONAL ARCHIVES OF PHOTOGRAMMETRY AND REMOTE SENSING},
keywords = {image retrieval,integrated environments,shape queries,spatial information management systems},
pages = {597--604},
publisher = {INTERNATIONAL SOCIETY FOR PHOTOGRAMMETRY \& REMOTE},
title = {{Sketch-based image retrieval in an integrated GIS environment}},
url = {http://www.ifp.uni-stuttgart.de/publications/commIV/stef96neu.pdf},
volume = {32},
year = {1998}
}
@inproceedings{PDBNunes2004,
abstract = {This paper presents an optimized Hill-Climbing algorithm to select
subset of features for handwritten character recognition. The search
is conducted taking into account a random mutation strategy and the
initial relevance of each feature in the recognition process. A first
set of experiments have shown a reduction in the original number
of features used in an MLP-based character recognizer from 132 to
77 features (reduction of 42\%) without a significant loss in terms
of recognition rates, which are 99.1\% for 30,089 digits and 93.0\%
for 11,941 uppercase characters, both handwritten samples from the
NIST SD19 database. Additional experiments have been done by considering
some loss in terms of recognition rate during the feature subset
selection. A byproduct of these experiments is a cascade classifier
based on feature subsets of different sizes, which is used to reduce
the complexity of the classification task by 86.54\% on the digit
recognition experiment. The proposed feature selection method has
shown to be an interesting strategy to implement a wrapper approach
without the need of complex and expensive hardware architectures.},
address = {Lisbon, Portugal},
author = {Nunes, Carlos M and {de Souza Britto Jr.}, Alceu and Kaestner, Celso A A and Sabourin, Robert},
booktitle = {Structural, Syntactic, and Statistical Pattern Recognition, Joint IAPR International Workshops, SSPR 2004 and SPR 2004, 2004 Proceedings},
doi = {http://springerlink.metapress.com/openurl.asp?genre=article\&issn=0302-9743\&volume=3138\&spage=1018},
editor = {Fred, Ana L N and Caelli, Terry and Duin, Robert P W and Campilho, Aur\'{e}lio C and de Ridder, Dick},
file = {:D$\backslash$:/Papers/Documents/2004/Nunes et al. - 2004.pdf:pdf},
isbn = {3-540-22570-6},
month = aug,
pages = {1018--1025},
publisher = {Springer},
title = {{Feature Subset Selection Using an Optimized Hill Climbing Algorithm for Handwritten Character Recognition.}},
year = {2004}
}
@incollection{Sezgin2000EarlyAbstract,
author = {Sezgin, Tevfik Metin and Davis, Randall},
booktitle = {MIT Artificial Intelligence Laboratory Annual Abstract},
publisher = {MIT AI Lab},
title = {{Early Processing in Sketch Understanding}},
year = {2000}
}
@article{ARFrias-Martinez2006,
abstract = {The problem of automatic signature recognition has received little
attention in comparison with the problem of signature verification
despite its potential applications for accessing security-sensitive
facilities and for processing certain legal and historical documents.
This paper presents an efficient off-line human signature recognition
system based on support vector machines (SVM) and compares its performance
with a traditional classification technique, multi-layer perceptrons
(MLP). In both cases we propose two approaches to the problem: (1)
construct each feature vector using a set of global geometric and
moment-based characteristics from each signature and (2) construct
the feature vector using the bitmap of the corresponding signature.
We also present a mechanism to capture the intrapersonal variability
of each user using just one original signature. Our results empirically
show that SVM, which achieves up to 71\% correct recognition rate,
outperforms MLP.},
annote = {Special Section on Innovative Production Machines and Systems (I*PROMS)},
author = {Frias-Martinez, E and Sanchez, A and Velez, J},
doi = {DOI: 10.1016/j.engappai.2005.12.006},
file = {:D$\backslash$:/Papers/Documents/2006/Frias-Martinez, Sanchez, Velez - 2006.pdf:pdf},
issn = {0952-1976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {Multi-layer perceptrons},
number = {6},
pages = {693--704},
title = {{Support vector machines versus multi-layer perceptrons for efficient off-line signature recognition}},
url = {http://www.sciencedirect.com/science/article/B6V2M-4JFGF83-2/2/aece9ce4b6ffffb81b9b6cf4f0861706},
volume = {19},
year = {2006}
}
@conference{ARYin2009,
abstract = {With rejection strategies in a handwriting recognition system, we
are able to improve the reliability and accuracy of the recognized
characters. In this paper, we propose several rejection strategies
with multiple classifiers for handwritten character recognition.
First, the rejection strategy for the single classifier is introduced,
which is composed of three stages: initial scaling, confidence measure
calculation, and rejection performing. Then, we analyze rejection
strategies for multiple classifiers. We divided our rejection strategies
into two categories: (1) for voting combination; and (2) for linear
combination with multiple classifiers. In the voting combination
style, three rejection strategies, OR, AND, and VOTING, are proposed.
And for the linear combination one, rejection strategies for average
and weighted combination are analyzed respectively. We also experiment
and compare our rejection strategies with handwritten digit recognition.},
author = {Yin, Xu-Cheng and Hao, Hong-Wei and Tang, Yun-Feng and Sun, Jun and Naoi, Satoshi},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Yin et al. - 2009.pdf:pdf},
title = {{Rejection Strategies with Multiple Classifiers for Handwritten Character Recognition}},
year = {2009}
}
@article{Xin2007,
author = {Xin, Min and Sharlin, Ehud and Samavati, Faramarz and {Costa Sousa}, Mario and Greenberg, Saul},
file = {:D$\backslash$:/Papers/Documents/2007/Xin et al. - 2007.pdf:pdf},
journal = {Human Factors},
keywords = {Doctor Samavati,Scholarships Doctors,To Read,electronic entertainment,mixed reality,physical interaction,sketch-based interfaces,social interaction,tangible interfaces},
mendeley-tags = {Scholarships Doctors,To Read},
pages = {208--211},
publisher = {Citeseer},
title = {{Purple Crayon–From Sketches to Interactive Environment}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.71.5858\&amp;rep=rep1\&amp;type=pdf},
year = {2007}
}
@inproceedings{adler-iui04,
author = {Adler, Aaron and Davis, Randall},
booktitle = {Proceedings of the 9th International Conference on Intelligent User Interfaces},
file = {:D$\backslash$:/Papers/Documents/2004/Adler, Davis - 2004(2).pdf:pdf},
isbn = {1-58113-815-6},
pages = {214--216},
publisher = {ACM Press},
title = {{Speech and Sketching for Multimodal Design}},
year = {2004}
}
@article{Gunter2005,
abstract = {Unconstrained handwritten text recognition is one of the most difficult problems in the field of pattern recognition. Recently, a number of classifier creation and combination methods, known as ensemble methods, have been proposed in the field of machine learning. They have shown improved recognition performance over single classifiers. In this paper, we examine the influence of the vocabulary size, the number of training samples, and the number of classifiers on the performance of three ensemble methods in the context of cursive handwriting recognition. All experiments were conducted using an off-line handwritten word recognizer based on hidden Markov models (HMMs).},
author = {Gunter, S. and Bunke, Horst},
doi = {10.1016/j.optlaseng.2004.01.004},
file = {:D$\backslash$:/Papers/Documents/2005/Gunter, Bunke - 2005.pdf:pdf},
issn = {0143-8166},
journal = {Optics and Lasers in Engineering},
keywords = {ensemble methods,ensemble size,handwritten text recognition,hidden markov model,hmm,multiple classifier combination,training set size,vocabulary size},
number = {3-5},
pages = {437--454},
publisher = {Elsevier},
title = {{Off-line cursive handwriting recognition using multiple classifier systems–on the influence of vocabulary, ensemble, and training set size}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0143816604001034},
volume = {43},
year = {2005}
}
@article{Juchmes2005,
abstract = {This paper presents an on-line system for capturing and interpreting architectural sketches. The prototype is based on a multi-agent system, which enables real-time management of recognition scenarios. We describe the different types of agents, their characteristics, the basic mechanisms involved in interpreting freehand architectural drawings and the collaboration modes between agents. Finally, we illustrate the general operations of the system by a short example.},
author = {Juchmes, R. and Leclercq, Pierre and Azar, Sleiman},
doi = {10.1016/j.cag.2005.09.008},
file = {:D$\backslash$:/Papers/Documents/2005/Juchmes, Leclercq, Azar - 2005.pdf:pdf},
issn = {0097-8493},
journal = {Computers \& Graphics},
keywords = {computer interaction,computer-aided design,freehand sketches recognition,human,multi-agent system},
number = {6},
pages = {905--915},
publisher = {Elsevier},
title = {{A freehand-sketch environment for architectural design supported by a multi-agent system}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849305001627},
volume = {29},
year = {2005}
}
@inproceedings{DSZhou2001,
abstract = {The proposed feedback-based approach is implemented in two steps.
In the first step, segmentation is done according to the structural
features between the connected components in the legal amounts. In
the second step, a feedback process is introduced to re-segment the
parts that could not be identified in the first step. Then a multiple
neural network classifier is used to verify the re-segmentation result.
The confidence value produced by the classifier is used to determine
the best segmentation points. This approach is tested on a CENPARMI
database and the result indicates that the correct segmentation rate
increased by 13.4\% from the previous approach},
author = {Zhou, Jun and Suen, C Y and Liu, Ke},
booktitle = {Document Analysis and Recognition, 2001. Proceedings. Sixth International Conference on},
doi = {10.1109/ICDAR.2001.953914},
file = {:D$\backslash$:/Papers/Documents/2001/Zhou, Suen, Liu - 2001.pdf:pdf},
keywords = { ;image classification;image segmentation;neural n,CENPARMI database;bank cheques;confidence value;fe},
pages = {887--891},
title = {{A feedback-based approach for segmenting handwritten legal amounts on bank cheques}},
year = {2001}
}
@inproceedings{Pinto-Albuquerque2000,
author = {Pinto-Albuquerque, M. and Fonseca, M.J. and Jorge, J.A.},
booktitle = {IEEE Symposium on Visual Languages},
file = {:D$\backslash$:/Papers/Documents/2000/Pinto-Albuquerque, Fonseca, Jorge - 2000.pdf:pdf},
pages = {225--232},
title = {{Visual languages for sketching documents}},
url = {http://orion.lcg.ufrj.br/cg2/downloads/Interfaces Caligraficas/vl2k.pdf},
year = {2000}
}
@inproceedings{Cates2004New,
address = {Menlo Park, California},
author = {Cates, Sonya and Davis, Randall},
booktitle = {Making Pen-Based Interaction Intelligent and Natural},
file = {:D$\backslash$:/Papers/Documents/2004/Cates, Davis - 2004.pdf:pdf},
month = oct,
pages = {29--34},
publisher = {AAAI Press},
title = {{New Approach to Early Sketch Processing}},
year = {2004}
}
@article{PDB1Zhon2002,
abstract = {Neural network ensemble is a learning paradigm where many neural networks
are jointly used to solve a

problem. In this paper, the relationship between the ensemble and
its component neural networks is analyzed

from the context of both regression and classification, which reveals
that it may be better to ensemble many

instead of all of the neural networks at hand. This result is interesting
because at present, most approaches

ensemble all the available neural networks for prediction. Then, in
order to show that the appropriate neural

networks for composing an ensemble can be effectively selected from
a set of available neural networks, an

approach named GASEN is presented. GASEN trains a number of neural
networks at first. Then it assigns

random weights to those networks and employs genetic algorithm to
evolve the weights so that they can

characterize to some extent the fitness of the neural networks in
constituting an ensemble. Finally it selects

some neural networks based on the evolved weights to make up the ensemble.
A large empirical study shows

that, comparing with some popular ensemble approaches such as Bagging
and Boosting, GASEN can

generate neural network ensembles with far smaller sizes but stronger
generalization ability. Furthermore, in

order to understand the working mechanism of GASEN, the bias-variance
decomposition of the error is

provided in this paper, which shows that the success of GASEN may
lie in that it can significantly reduce the

bias as well as the variance.},
author = {Zhon, Zhi-Hua and Wu, Jianxin and Tang, Wei},
doi = {http://dx.doi.org/10.1016/S0004-3702(02)00190-X},
file = {:D$\backslash$:/Papers/Documents/2002/Zhon, Wu, Tang - 2002.pdf:pdf},
institution = {National Laboratory for Novel Software Technology, Nanjing University, Nanjing 210093, P.R.China},
journal = {Artif. Intell.},
keywords = { Bagging, Bias - Variance Decomposition, Boosting, Genetic Algorithm, Neural Networks,MultiClassifier Systems},
number = {1-2},
pages = {239--263},
title = {{Ensembling Neural Networks: Many Could Be Better Than All.}},
volume = {137},
year = {2002}
}
@phdthesis{Hammond2003,
author = {Hammond, Tracy and Davis, R.},
booktitle = {Proceedings of},
file = {:D$\backslash$:/Papers/Documents/2003/Hammond, Davis - 2003.pdf:pdf},
pages = {1--89},
publisher = {Citeseer},
title = {{A domain description language for sketch recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.6693\&amp;rep=rep1\&amp;type=pdf},
year = {2003}
}
@inproceedings{DSMarisa2002b,
abstract = {This paper presents an HMM-MLP hybrid system to recognize complex
date images written on Brazilian bank cheques. The system first segments
implicitly a date image into sub-fields through the recognition process
based on an HMM-based approach. Afterwards, the three obligatory
date sub-fields are processed by the system (day, month and year).
A neural approach has been adopted to work with strings of digits
and a Markovian strategy to recognize and verify words. We also introduce
the concept of meta-classes of digits, which is used to reduce the
lexicon size of the day and year and improve the precision of their
segmentation and recognition. Experiments show interesting results
on date recognition.},
address = {Niagara-on-the-Lake, CA},
author = {{Morita M Sabourin R.}, Bortolozzi F and C.Y, Suen},
booktitle = {8th International Workshop on Frontiers of Handwriting Recognition (IWFHR'8)},
file = {:D$\backslash$:/Papers/Documents/2002/Morita M Sabourin R., C.Y - 2002.pdf:pdf},
month = aug,
pages = {105--110},
title = {{Segmentation and Recognition of Handwritten Dates}},
year = {2002}
}
@inproceedings{Recognition2001,
abstract = {The purpose of our research is to improve the recog- nition rate of an off-line handwritten character recog- nition system using HMM (Hidden Markov Model), so that we can use the syst,em for practical application. Due to the insufficient recognition rate of 1D HMM character recognition systems and the requirement for a huge number of learning samples to construct 2D HMM character recognition systems, HMM-based character recognition systems have not yet achieved sufficient recognition performance for practical use. In this research, we propose the character recognition method that integrates 4 simply structured 1D HMMs all of which are based on feature extraction using linear filters. The results of our evaluation experiment using the Hand-Printed Character Database (ETLG) showed that the first rank recognition rate of the test samples was 98.5\% and that the cumulative recognition rate of top 3 candidates was 99.3\%. Although our method is relatively easy to implement, it can work even better than 2D HMM method. These results show the pro- posed method is very effective.},
annote = {
        Paper Index : Nishimura2001

        Date:23-Nov-2010

        

        Why read paper ?
        
HMM knowldege base. 

        

        Paper Overview ?
        
HMM but focus on the difference of 1D HMM vs. the 2D HMM. 
the features are build on filter masks. 
offline and test only on seperate latin characters. 

        

        What is these paper about ? (Summary)
        

        
The paper talks about the 1D HMM used to recognize characters int the following steps. 

        Features extraction:
        
feature is a weighted sum of image where 
F(i,j)= sum (sum ( w(i)I(i,j)). (f is features , w is the mask and I is the image pixel  see page 3 eq1  )
Uses 4 different sturctures (filters masks) called sptial Integrated filter). SIF to extract features from the image by sliding the structure throught the image and computing the features.

        
          
Recognition:
        
4 HMM models for each character is generated. The final recognition is computed as sum of 4 hmm probability and the class with Max probablity is the recognizied.  

        
          
The results :
        

        
Latin hand printed characters are used to test (600 sample per class so 18,636  total samples)
comparisons between 2DHMM and 1D HMM methods the best result achieved is 1D HMM SIF 98\% 
it is supposed to be less complex than 2D HMM. 

        

        

        1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?
        

        
Simple formulation of HMM. 

        

        2. What can we take from this work  ? what do we learn ?  What can be incorporated into our own work ?
        

        

        

        3. What are the problems of the paper ?
        

        
The main problem is that it only test isolated characters, Simple features and also it seems that the high number of features for each mask. 

        

        4. what is lacking from the work ? why does this work knot be the final  research in this subject ?
        
good filters, as the filters seems to only capture some of the spatial informaition it may be difficult to capture complex characters. 

        

        

        5. what about the methods causes this lack ? is there a fundamental reason ?
        
The use of image and a masked filter it self. 

        6. Could incremental Changes Fix this lack ? if so, what changes ? 
        
More better features. 

        

        Is there is any question you had about the paper ? 
        

        

        

        The final conclusion..........
        

        
Small paper, that may provide simple HMM method to recognize character but restricted to latin only .

        
============},
author = {Nishimura, H. and Tsutsumi, M.},
booktitle = {Document Analysis and Recognition, 2001. Proceedings. Sixth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2002/Nishimura, Tsutsumi - 2002.pdf:pdf},
isbn = {0769512631},
keywords = {Arabic Handwritting recognition,HMM,Off-line recognition,Read,Summarized},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
pages = {417--421},
publisher = {IEEE},
title = {{Off-line hand-written character recognition using integrated 1D HMMs based on feature extraction filters}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=953824},
year = {2002}
}
@inproceedings{Samet1994a,
author = {Samet, Hanan and Soffer, A.},
booktitle = {In Proceedings of the 12th International Conference on Pattern Recognition, volume II},
file = {:D$\backslash$:/Papers/Documents/1994/Samet, Soffer - 1994.pdf:pdf},
pages = {350--355},
publisher = {Citeseer},
title = {{A legend-driven geographic symbol recognition system}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.30.7993},
volume = {II},
year = {1994}
}
@inproceedings{Alvarado2004,
author = {Alvarado, Christine and Davis, Randall},
booktitle = {Proceedings of the 17th annual ACM symposium on User interface software and technology},
file = {:D$\backslash$:/Papers/Documents/2004/Alvarado, Davis - 2004(3).pdf:pdf},
pages = {23--32},
publisher = {ACM},
title = {{SketchREAD: a multi-domain sketch recognition engine}},
url = {http://portal.acm.org/citation.cfm?id=1029632.1029637},
year = {2004}
}
@inproceedings{Hammond2002,
author = {Hammond, Tracy and Davis, Randall},
booktitle = {AAAI Spring Symposium: Sketch Recognition},
file = {:D$\backslash$:/Papers/Documents/2002/Hammond, Davis - 2002.pdf:pdf},
pages = {59--68},
title = {{Tahuti: A geometrical Sketch Recognition System for UML Class Diagrams}},
year = {2002}
}
@article{FE10Teow2002,
abstract = {We use well-established results in biological vision to construct
a model for handwritten digit recognition. We show

empirically that the features extractedby our model are linearly separable
over a large training set (MNIST). Using only a

linear discriminant system on these features, our model is relatively
simple yet outperforms other models on the same data set.

In particular, the best result is obtainedby applying triowise linear
support vector machines with soft voting on vision-based

features extractedfrom deslantedimages.},
annote = {Other then in review no...},
author = {Teow, Loo-Nin and Loe, Kia Fock},
file = {:D$\backslash$:/Papers/Documents/2002/Teow, Loe - 2002.pdf:pdf},
journal = {Pattern Recognition},
keywords = { Handwritten digits, MNIST},
pages = {2355--2364},
title = {{Robust vision based features and classification schemes for off line handwritten digit recognition}},
volume = {35},
year = {2002}
}
@incollection{ARAbdulKader2008,
abstract = {Abstract. In this paper we present a novel approach for the recognition
of offline Arabic handwritten text motivated by the Arabic letters�
conditional joining rules. A lexicon of Arabic words can be expressed
in terms of a new alphabet of PAWs (Part of Arabic Word). PAWs can
be expressed in terms of letters. The recognition problem is decomposed
into two problems to solve simultaneously. To find the best matching
word for an input image, a Two-Tier Beam search is performed. In
Tier One, the search is constrained by a letter to PAW lexicon. In
Tier Two, the search is constrained by a PAW to word lexicon. The
searches are driven by a PAW recognizer. Experiments conducted on
the standard IFN/ENIT database [6] of handwritten Tunisian town names
show word error rates of about 11\%. This result compares to the results
of the commonly used HMM based approaches.},
author = {AbdulKader, Ahmad},
booktitle = {Arabic and Chinese Handwriting Recognition},
file = {:D$\backslash$:/Papers/Documents/2008/AbdulKader - 2008.pdf:pdf},
keywords = { IFN/INIT, Neural Networks,Arabic Handwriting},
pages = {70--81},
publisher = {Springer-Verlag Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Two-Tier Arabic Offline Handwriting Recognition Based on Conditional Joining Rules}},
volume = {Volume 476},
year = {2008}
}
@article{Shridhar2009,
author = {Shridhar, M and Houle, GF and Kimura, F},
file = {:D$\backslash$:/Papers/Documents/2009/Shridhar, Houle, Kimura - 2009.pdf:pdf},
journal = {ieeexplore.ieee.org},
number = {Figure 1},
pages = {170--173},
title = {{Document Recognition Strategies for Bank Cheques}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5189604},
year = {2009}
}
@inproceedings{DShonggang2005,
abstract = {In this paper, a method based on signal matching to binarize low signal-noise
rate bank check image is proposed. This method can extract information
from the check image interfered with both complex background and
imprinted seal. With the prior knowledge, the image projection function
without noise is the source signal, the projection function of image
binarized by iterative threshold will match the source signal, and
the threshold which projection function matches best is the optimum
threshold. Experimental results showed that significant improvement
in the binarization quality in comparison with other well-established
algorithms},
author = {Honggang, Zhang and Guang, Chen and Gang, Liu and Jun, Guo},
booktitle = {Information, Communications and Signal Processing, 2005 Fifth International Conference on},
doi = {10.1109/ICICS.2005.1689294},
file = {:D$\backslash$:/Papers/Documents/2005/honggang et al. - 2005.pdf:pdf},
keywords = {bank check image binarization;image projection fun},
pages = {1430--1433},
title = {{Bank Check Image Binarization Based on Signal matching}},
year = {2005}
}
@inproceedings{Madhvanath2007b,
author = {Madhvanath, Sriganesh and Vijayasenan, Deepu and Kadiresan, T.M.},
booktitle = {ACM SIGGRAPH 2007 courses},
file = {:D$\backslash$:/Papers/Documents/2007/Madhvanath, Vijayasenan, Kadiresan - 2007.pdf:pdf},
keywords = {api,languages - no,linguistic resources,online handwriting recognition,parts of the world,recognition,shape,such as the indic,the languages in these,toolkit,unfortunately for many of},
pages = {13},
publisher = {ACM},
title = {{Lipitk: A generic toolkit for online handwriting recognition}},
url = {http://portal.acm.org/citation.cfm?id=1281500.1281524},
year = {2007}
}
@inproceedings{ARAbed2007,
abstract = {Preprocessing and feature extraction are very important steps in automatic
cursive handwritten word recognition. Based on an offline recognition
system for Arabic handwritten words which uses a semi-continuous
1-dimensional Hidden Markov Model recognizer, different preprocessing
combined with different feature sets are presented. The dependencies
of the feature sets from preprocessing steps are discussed and their
performances are compared using the IFN/ENIT-database of handwritten
Arabic words. As the lower and upper baseline of each word are part
of the ground truth of the database, the dependency of the feature
set from the accuracy of the estimated baseline is evaluated},
author = {Abed, Haikal El and Margner, Volker},
booktitle = {Proceedings of the Ninth International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2007/Abed, Margner - 2007(2).pdf:pdf},
pages = {974--978},
title = {{Comparison of Different Preprocessing and Feature Extraction Methods for Offline Recognition of Handwritten ArabicWords}},
volume = {2},
year = {2007}
}
@article{Sternby2009a,
abstract = {After a long period of focus on western and East Asian scripts there is now a general trend in the on-line handwriting recognition community to explore recognition of other scripts such as Arabic and various Indic scripts. One difficulty with the Arabic script is the number and position of diacritic marks associated to Arabic characters. This paper explores the application of a template matching scheme to the recog- nition of Arabic script with a novel algorithm for dynamically treating the diacritical marks. Template based systems are robust to conditions with scarce training data and in experiments the proposed system outperformed a reference system based on the promising state-of-the-art network technique of BLSTM. Experiments have been conducted in an environment similar to that of many handheld devices with promising results both in terms of memory consumption and response time.},
author = {Sternby, Jakob and Morwing, Jonas and Andersson, Jonas and Friberg, Christer},
doi = {10.1016/j.patcog.2008.12.017},
file = {:D$\backslash$:/Papers/Documents/2009/Sternby et al. - 2009(2).pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Arabic,Branch-and-bound,Diacritic,Graph,HWR,Modeling,On-line,Template,Trie},
month = dec,
number = {12},
pages = {3278--3286},
publisher = {Elsevier},
title = {{On-line Arabic handwriting recognition with templates}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308005347},
volume = {42},
year = {2009}
}
@inproceedings{Blumenstein,
abstract = {This paper describes a neural network-based technique for cursive character recognition applicable to segmentation-based word recognition systems. The proposed research builds on a novel feature extraction technique that extracts direction information from the structure of character contours. This principal is extended so that the direction information is integrated with a technique for detecting transitions between background and foreground pixels in the character image. The proposed technique is compared with the standard direction feature extraction technique, providing promising results using segmented characters from the CEDAR benchmark database.},
author = {Blumenstein, M. and Liu, X.Y. and Verma, B.},
booktitle = {2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541)},
doi = {10.1109/IJCNN.2004.1381140},
file = {:D$\backslash$:/Papers/Documents/2004/Blumenstein, Liu, Verma - 2004.pdf:pdf},
isbn = {0-7803-8359-1},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {2983--2987},
publisher = {Ieee},
title = {{A modified direction feature for cursive character recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1381140},
year = {2004}
}
@article{Cho2007,
author = {Cho, S.J. and Kim, J.},
file = {:D$\backslash$:/Papers/Documents/2007/Cho, Kim - 2007.pdf:pdf},
journal = {Digital Document Processing},
pages = {121--141},
publisher = {Springer},
title = {{A Bayesian Network Approach for On-line Handwriting Recognition}},
url = {http://www.springerlink.com/index/n12828qg1502873h.pdf},
volume = {1},
year = {2007}
}
@article{Bunke1995,
abstract = {-A method for the off-line recognition of cursive handwriting based on hidden Markov models (HMMs) is described. The features used in the HMMs are based on the arcs of skeleton graphs of the words to be recognized. An algorithm is applied to the skeleton graph of a word that extracts the edges in a particular order. Given the sequence of edges extracted from the skeleton graph, each edge is transformed into a 10-dimensional feature vector. The features represent information about the location of an edge relative to the four reference lines, its curvature and the degree of the nodes incident to the considered edge. The linear model was adopted as basic HMM topology. Each letter of the alphabet is represented by a linear HMM. Given a dictionary of fixed size, an HMM for each dictionary word is built by sequential concatenation of the H M Ms representing the individual letters of the word. Training of the HM Ms is done by means of the Baum-Welch algorithm, while the Viterbi algorithm is used for recognition. An average correct recognition rate of over 98\% on the word level has been achieved in experiments with cooperative writers using two dictionaries of 150 words each.},
author = {Bunke, H},
doi = {10.1016/0031-3203(95)00013-P},
file = {:D$\backslash$:/Papers/Documents/1995/Bunke - 1995.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Cursive script recognition,HMM,Hidden Markov model,Optical character recognition,Skeleton graphs,off-line recognition},
mendeley-tags = {HMM},
month = sep,
number = {9},
pages = {1399--1413},
title = {{Off-line cursive handwriting recognition using hidden markov models}},
volume = {28},
year = {1995}
}
@article{DueTrier1996,
author = {{Due Trier}, $\backslash$vR. and Jain, A.K. and Taxt, T.},
file = {:D$\backslash$:/Papers/Documents/1996/Due Trier, Jain, Taxt - 1996.pdf:pdf},
issn = {0031-3203},
journal = {Pattern recognition},
number = {4},
pages = {641--662},
publisher = {Elsevier},
title = {{Feature extraction methods for character recognition-a survey}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0031320395001182},
volume = {29},
year = {1996}
}
@article{Paulson2008c,
abstract = {Mouse and keyboard interfaces handle traditional text-based queries, and standard search engines provide for effective text-based search. However, everyday documents are filled with not only text, but photos, cartoons, diagrams, and sketches. These images can often be easier to recall than the surrounding text. In an effort to make human computer interaction handle more forms of human-human interaction, sketching has recently become an important means of interacting with computer systems. We propose extending the traditional monomodal model of text-based search to include the capabilities of sketch-based search. Our goal is to create a sketch-based search that can find documents from a single query sketch. We imagine an important use for this technology would be to allow users to search a computerized laboratory notebook for a previously drawn sketch. Because such as sketch will have initially been drawn only a single time, it is important that the search-by-sketch system (1) recognize a wide range of shapes that are not necessarily geometric nor drawn in the same way each time, (2) recognize a query example from only one initial training example, and (3) learn from successful queries to improve accuracy over time. We present here such an algorithm. To test the algorithm, we implemented a proof-of-concept-system: MARQS, a system that uses sketches to query existing media albums. Preliminary results show that the system yielded an average search rank of 1.51, indicating that the correct sketch is presented as either the top or second search result on average.},
annote = {Paper Index : Paulson2008 
paper speaks about using two recognizier : 

        
A single example classifier that uses four global featues. 
A linear classifier than use more training examples (when available from user) to get more accuracy. 

        
The gloabal features is ==> ( bounding box ratio, pixel density, average curvature, number of corners). 

        
The sketch recognizier is used as search reterival. the system achieved a search rank of 1.5 which means that result are on the average in either the first or second. best result. 

        
My comments :
the few number of 

        

      },
author = {Paulson, Brandon and Hammond, Tracy},
doi = {10.1007/s12193-008-0006-0},
file = {:D$\backslash$:/Papers/Documents/2008/Paulson, Hammond - 2008(2).pdf:pdf},
issn = {1783-7677},
journal = {Journal on Multimodal User Interfaces},
keywords = {Feature-based recognition,Read,Search by sketch,Sketch Research,Sketch recognition,Sketch-based interfaces,Summarized,application},
mendeley-tags = {Read,Sketch Research,Summarized,application},
month = may,
number = {1},
pages = {3--11},
publisher = {Springer Berlin / Heidelberg},
title = {{MARQS: retrieving sketches learned from a single example using a dual-classifier}},
url = {http://www.springerlink.com/content/4601854000500828/},
volume = {2},
year = {2008}
}
@article{Okabe2005,
address = {New York, New York, USA},
author = {Okabe, Yuta and Saito, Suguru and Nakajima, Masayuki},
doi = {10.1145/1101389.1101405},
file = {:D$\backslash$:/Papers/Documents/2005/Okabe, Saito, Nakajima - 2005.pdf:pdf},
isbn = {1595932011},
journal = {Proceedings of the 3rd international conference on Computer graphics and interactive techniques in Australasia and South East Asia - GRAPHITE '05},
keywords = {drawing result,drawn in,figure 1,footprint,hmm,learning,mouse,stroke,where all strokes are},
number = {212},
pages = {91},
publisher = {ACM Press},
title = {{Paintbrush rendering of lines using HMMs}},
url = {http://portal.acm.org/citation.cfm?doid=1101389.1101405},
volume = {1},
year = {2005}
}
@article{Hamdani2009,
author = {Hamdani, Mahdi and Abed, Haikal El and Kherallah, Monji and Alimi, Adel M.},
doi = {10.1109/ICDAR.2009.40},
file = {:D$\backslash$:/Papers/Documents/2009/Hamdani et al. - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {201--205},
publisher = {Ieee},
title = {{Combining Multiple HMMs Using On-line and Off-line Features for Off-line Arabic Handwriting Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277731},
year = {2009}
}
@article{Kim2006,
author = {Kim, D. and Choi, H. and Kim, J.},
file = {:D$\backslash$:/Papers/Documents/2006/Kim, Choi, Kim - 2006.pdf:pdf},
journal = {Ubiquitous Computing Systems},
keywords = {3d space handwriting,bayesian network,gnition,ligature model,online handwriting reco-},
pages = {41--56},
publisher = {Springer},
title = {3d space handwriting recognition with ligature model},
url = {http://www.springerlink.com/index/q872002003062745.pdf},
year = {2006}
}
@article{Liu,
author = {Liu, Yin and Wenyin, Liu and Jiang, Changjun},
doi = {10.1109/ICPR.2004.1334129},
file = {:D$\backslash$:/Papers/Documents/Unknown/Liu, Wenyin, Jiang - Unknown.pdf:pdf},
isbn = {0-7695-2128-2},
journal = {Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.},
pages = {371--375},
publisher = {Ieee},
title = {{A structural approach to recognizing incomplete graphic objects}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1334129}
}
@inproceedings{Tokuno2002,
abstract = {This paper describes context-dependent substroke hid- den Markov models (HMMs) for on-line handwritten recog- nition of cursive Kanji and Hiragana characters. As there are more than 6,000 distinctive characters including Kanji and Hiragana in Japanese, modeling each character by an HMM leads to an infeasible character-recognition system requiring huge amount of memory and enormous computa- tion time. In order to tackle this problem, we have proposed the substroke HMM approach where a modeling unit “sub- stroke” that is much smaller than a whole character is em- ployed and each character is modeled as a concatenation of only 25 kinds of substroke HMMs. One of the drawback of this approach is that the recognition accuracy deterio- rates in case of scribbled characters, and characters where the shape of the substrokes varies a lot. In this paper, we show that the context-dependent substroke modeling which depends on how the substroke connects to the adjacent sub- strokes is effective to achieve robust recognition of low qual- ity characters. The Successive State Splitting (SSS) algo- rithm which was mainly developed for speech recognition is employed to construct the context dependent substroke HMMs. Experimental results show that the correct recogni- tion rate improved from88\% to 92\% for cursive Kanji hand- writings and from 90\% to 98\% for Hiragana handwritings.},
author = {Tokuno, Junko and Inami, Nobuhito and Matsuda, Shigeki and Nakai, M. and Shimodaira, H. and Sagayama, S.},
booktitle = {Frontiers in Handwriting Recognition, 2002. Proceedings. Eighth International Workshop on},
file = {:D$\backslash$:/Papers/Documents/2002/Tokuno et al. - 2002.pdf:pdf},
isbn = {0769516920},
pages = {78--83},
publisher = {IEEE},
title = {{Context-dependent substroke model for HMM-based on-line handwriting recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1030888},
year = {2002}
}
@inproceedings{Huang2006a,
author = {Huang, BQ and Du, CJ and Zhang, YB and Kechadi, M-t},
booktitle = {Intelligent Systems Design and Applications, 2006. ISDA'06. Sixth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2006/Huang et al. - 2006.pdf:pdf},
isbn = {0769525288},
pages = {887--891},
publisher = {IEEE},
title = {{A hybrid hmm-svm method for online handwriting symbol recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4021556},
volume = {1},
year = {2006}
}
@inproceedings{Kara2004c,
author = {Kara, L.B. and Stahovich, T.F.},
booktitle = {AAAI Fall Symposium Series 2004: Making Pen-Based Interaction Intelligent and Natural},
file = {:D$\backslash$:/Papers/Documents/2004/Kara, Stahovich - 2004(4).pdf:pdf},
pages = {99--105},
title = {{An image-based trainable symbol recognizer for sketch-based interfaces}},
url = {http://www.aaai.org/Papers/Symposia/Fall/2004/FS-04-06/FS04-06-016.pdf},
year = {2004}
}
@inproceedings{Sezgin2004Scalespace,
author = {Sezgin, Tevfik Metin and Davis, Randall},
booktitle = {Making Pen-Based Interaction Intelligent and Natural},
file = {:D$\backslash$:/Papers/Documents/2004/Sezgin, Davis - 2004.pdf:pdf},
publisher = {AAAI Fall Symposium},
title = {{Scale-space Based Feature Point Detection for Digital Ink}},
year = {2004}
}
@inproceedings{Sezgin2001,
author = {Sezgin, T.M.},
booktitle = {128.232.0.20},
file = {:D$\backslash$:/Papers/Documents/2001/Sezgin - 2001(3).pdf:pdf},
pages = {2001--2002},
publisher = {Technical report, MIT Project Oxygen Student Workshop Abstracts, 2003},
title = {{Generic and HMM based approaches to freehand sketch recognition}},
url = {http://128.232.0.20/\~{}mts33/publications/Sezgin2003Generic.pdf},
year = {2001}
}
@article{ARAdankon2008,
abstract = {The support vector machine (SVM) is a powerful classifier which has
been used successfully in many pattern recognition problems. It has
also been shown to perform well in the handwriting recognition field.
The least squares SVM (LS-SVM), like the SVM, is based on the margin-maximization
principle performing structural risk minimization. However, it is
easier to train than the SVM, as it requires only the solution to
a convex linear problem, and not a quadratic problem as in the SVM.
In this paper, we propose to conduct model selection for the LS-SVM
using an empirical error criterion. Experiments on handwritten character
recognition show the usefulness of this classifier and demonstrate
that model selection improves the generalization performance of the
LS-SVM},
author = {M.Adankon, Mathias and MohamedCheriet},
file = {:D$\backslash$:/Papers/Documents/2008/M.Adankon, MohamedCheriet - 2008.pdf:pdf},
journal = {Pattern Recognition},
month = dec,
number = {12},
pages = {3264--3270},
title = {{Model selection for the LS-SVM Application to handwriting recognition}},
volume = {42},
year = {2008}
}
@article{Sun2005,
author = {Sun, Zhengxing and Zhang, Lisha and Tang, Enyi},
file = {:D$\backslash$:/Papers/Documents/2005/Sun, Zhang, Tang - 2005.pdf:pdf},
journal = {Advances in Natural Computation},
pages = {655--659},
publisher = {Springer},
title = {{An incremental learning method based on SVM for online sketchy shape recognition}},
url = {http://www.springerlink.com/index/dedu3lcnwhutwnat.pdf},
year = {2005}
}
@article{Zhou2002b,
author = {Zhou, M.X.},
doi = {10.1109/INFVIS.2002.1173143},
file = {:D$\backslash$:/Papers/Documents/2002/Zhou - 2002.pdf:pdf},
isbn = {0-7695-1751-X},
journal = {IEEE Symposium on Information Visualization, 2002. INFOVIS 2002.},
pages = {23--30},
publisher = {IEEE Comput. Soc},
title = {{Building a visual database for example-based graphics generation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1173143},
volume = {2002},
year = {2002}
}
@inproceedings{Bishop1989a,
author = {Bishop, JM},
booktitle = {del First IEE Conference on Artifical Neural Networks},
file = {:D$\backslash$:/Papers/Documents/1989/Bishop - 1989.pdf:pdf},
pages = {1--4},
title = {{Stochastic searching networks}},
url = {http://www.doc.gold.ac.uk/\~{}mas02mb/sdp/download/ssn.pdf},
year = {1989}
}
@inproceedings{Foltz2001Query,
author = {Foltz, Mark and Davis, Randall},
booktitle = {Proceedings of Fifth International Conference on Information Visualization (InfoVis 2001)},
file = {:D$\backslash$:/Papers/Documents/2001/Foltz, Davis - 2001.pdf:pdf},
keywords = {perception},
title = {{Query By Attention: Visually Searchable Information Maps}},
year = {2001}
}
@inproceedings{MCRodriguez2002,
abstract = {This paper analyses the application of hierarchical classifiers based
on the k-NN rule to the automatic classification of handwritten characters.
The discriminating capacity of a k-NN classifier increases as the
size of the reference pattern set (RPS) increases. This supposes
aproblem for k-NN classifiers in real applications: the high computational
cost required when the RPS is large. In order to accelerate the process
of calculating the distance to each pattern of the RPS, some authors
propose the use of condensing techniques. These methods try to reduce
the size of the RPS without losing classification power. Our alternative
proposal is based on incremental learning and hierarchical classifiers
with rejection techniques that reduce the computational cost of the
classifier. We have used 133,944 characters (72,105 upper-case characters
and 61,839 lower-case characters) of the NIST Special Data Bases
3 and 7 as experimental data set. The binary image of the character
is transformed to gray image. The best non-hierarchical classifier
achieves a hit rate of 94.92\% (upper-case) and 87,884\% (lower-case).
The hierarchical classifier achieves the same hit ratio, but with
3 times lower computational cost than the cost of the best non-hierarchical
classifier found in our experimentation and 14\% less than Hart's
Algorithm.},
author = {Rodriguez, C and Boto, F and Soraluze, I and P\'{e}rez, A},
booktitle = {ICPR '02: Proceedings of the 16 th International Conference on Pattern Recognition (ICPR'02) Volume 3},
file = {:D$\backslash$:/Papers/Documents/2002/Rodriguez et al. - 2002.pdf:pdf},
isbn = {0-7695-1695-X},
pages = {30098},
title = {{An Incremental and Hierarchical K-NN classifier for Hadwritten characters}},
volume = {3},
year = {2002}
}
@inproceedings{Cates2004,
abstract = {Early processing of sketches is a requirement common to many pen based systems. The task is difficult because of variations between sketches from different users and in different domains, and because of ambiguities that arise within even slightly messy sketches, especially when the input is allowed to be unconstrained. We propose a graphical model based approach to early sketch processing. Small areas of a sketch correspond- ing to features such as corners and straight segments are considered individually, and a likely labeling for such features is found by incorporating some context in or- der to improve on labels computed with only local in- formation. Results from applying this approach to the problem of detecting corners show an improvement},
author = {Cates, Sonya and Davis, Randall},
booktitle = {AAAI Symposium: Making Pen-Based Interaction},
file = {:D$\backslash$:/Papers/Documents/2004/Cates, Davis - 2004.pdf:pdf},
title = {{A new approach to early sketch processing}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:A+New+Approach+to+Early+Sketch+Processing\#0},
year = {2004}
}
@article{Bertolami2008,
author = {Bertolami, R and Bunke, H},
doi = {10.1016/j.patcog.2008.04.003},
file = {:D$\backslash$:/Papers/Documents/2008/Bertolami, Bunke - 2008.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {offline handwritten text line,recognition},
month = nov,
number = {11},
pages = {3452--3460},
title = {{Hidden Markov model-based ensemble methods for offline handwritten text line recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308001349},
volume = {41},
year = {2008}
}
@incollection{Hammond2004LadderAbstract,
author = {Hammond, Tracy and Davis, Randall},
booktitle = {MIT Computer Science and Artificial Intelligence Laboratory Annual Research Abstract},
file = {:D$\backslash$:/Papers/Documents/2004/Hammond, Davis - 2004.pdf:pdf},
keywords = {multimodal},
month = sep,
publisher = {MIT CSAIL},
title = {{LADDER: A Sketch Recognition Language}},
year = {2004}
}
@article{Touj2005,
author = {Touj, Sameh and Amara, Najoua Ben and Amiri, Hamid},
file = {:D$\backslash$:/Papers/Documents/2005/Touj, Amara, Amiri - 2005.pdf:pdf},
journal = {International Arab Journal of Information},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
number = {4},
pages = {318----325},
title = {{Arabic handwritten words recognition based on a planar hidden Markov model}},
url = {http://www.ccis2k.org/iajit/PDF/vol.2,no.4/9-Sameh.pdf},
volume = {2},
year = {2005}
}
@phdthesis{Adler2003,
author = {Adler, Aaron D},
file = {:D$\backslash$:/Papers/Documents/2003/Adler - 2003.pdf:pdf},
pages = {1},
school = {Massachusetts Institute of Technology},
title = {{Segmentation and Alignment of Speech and Sketching in Design Enviroment}},
type = {Master},
year = {2003}
}
@mastersthesis{Sezgin2001Feature,
annote = {Department of EECS, MIT},
author = {Sezgin, Tevfik Metin},
month = may,
title = {{Feature Point Detection and Curve Approximation for Early Processing of Free-Hand Sketches}},
year = {2001}
}
@inproceedings{Pechwitz2003,
abstract = {An offline recognition system for Arabic handwritten words is presented. The recognition system is based on a semi-continuous 1-dimensional HMM. From each binary word image normalization parameterswere estimated. First height, length, and baseline skew are normalized, then fea- tures are collected using a sliding window approach. This paper presents these methods in more detail. Some parame- ters were modified and the consequent effect on the recogni- tion results are discussed. Significant tests were performed using the new IFN/ENIT - database of handwritten Ara- bic words. The comprehensive database consists of 26459 Arabic words (Tunisian town/village names) handwritten by 411 different writers and is free for non-commercial re- search. In the performed tests we achieved maximal recognition rates of about 89\% on a word level.},
author = {Pechwitz, Mario and Maergner, Volker},
booktitle = {Proceedings of the Seventh International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2003/Pechwitz, Maergner - 2003.pdf:pdf},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {0--4},
title = {{HMM Based Approach for Handwritten Arabic Word Recognition Using the IFN / ENIT - Database}},
year = {2003}
}
@inproceedings{ARWang2008,
abstract = {A word segmentation method based on Inductive Learning for non-segmented
language uses only surface information of a character string; it
has an advantage that is entirely not dependent on any specific language.
The method extracts recursively a character string that occur frequently
in text as word candidates, extracts segmentation rule with context
information to deal with segmentation ambiguity. The method classifies
those extracted word candidates to different ranking according to
extraction situation, segments a text into words with extracted word
candidates. Though proofread process erroneous segmentation was corrected,
ranking of word candidates and segmentation rules was renewed. Evaluation
experiments showed availability of the method for Japanese and Chinese
word segmentation.},
author = {Wang, Zhongjian and Araki, Kenji and Tochinai, Koji},
booktitle = {2008 International Symposium on Computational Intelligence and Design},
file = {:D$\backslash$:/Papers/Documents/2008/Wang, Araki, Tochinai - 2008.pdf:pdf},
title = {{Word Segmentation Method Based on Inductive Learning and Segmentation Rule}},
year = {2008}
}
@inproceedings{Daru1991,
author = {Daru, Roel},
booktitle = {Experiences with CAAD in Education and Practice [eCAADe Conference Proceedings] Munich (Germany)},
file = {:D$\backslash$:/Papers/Documents/1991/Daru - 1991.pdf:pdf},
number = {conversion},
pages = {17--19},
title = {{Sketch as Sketch Can-Design Sketching with Imperfect Aids and Sketchpads of the Future}},
url = {http://alexandria.tue.nl/campusonly/Metis229315.pdf},
year = {1991}
}
@incollection{Adler2004Using,
author = {Adler, Aaron and Davis, Randall},
booktitle = {MIT Computer Science and Artificial Intelligence Laboratory Annual Research Abstract},
month = feb,
publisher = {MIT CSAIL},
title = {{Using \{S\}peech and \{S\}ketching in a \{D\}esign \{E\}nvironment}},
year = {2004}
}
@article{Doyens2008,
author = {Doyens, Place},
file = {:D$\backslash$:/Papers/Documents/2008/Doyens - 2008.pdf:pdf},
journal = {Work},
number = {September},
pages = {64--73},
title = {{Cross-Domain Diagram Sketch Recognition Private Bag 92019}},
year = {2008}
}
@inproceedings{Daniel2006,
abstract = {—This paper reports the results of a study of a specific type of concurrency in the Ant Colony System (ACS) algorithm. Studies of Cellular Automata (CA) have shown that the update mechanism used can have a dramatic influence on the dynamics of the CA. ACS is usually implemented with a sequential update mechanism. A new method for controlling the concurrency in a nature-inspired algorithm is introduced. Comprehensive tests on a wide range of problem instances are reported. The study found that concurrency levels had no statistically significant effect on ACS performance. This result is interesting because it contradicts what has been observed in another form of nature-inspired algorithm, namely CAs.},
author = {Daniel, E.R.},
booktitle = {IEEE Congress on Evolutionary Computation},
file = {:D$\backslash$:/Papers/Documents/2006/Daniel - 2006.pdf:pdf},
pages = {6126--6133},
publisher = {Citeseer},
title = {{A Study of Concurrency in the Ant Colony System Algorithm}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.7514},
year = {2006}
}
@incollection{Davis2002Designs,
author = {Davis, Randall and Adler, Aaron and Alvarado, Christine and Hammond, Tracy and Hitchcock, Rebecca and Sezgin, Metin Tevfik and Veselova, Olya},
booktitle = {MIT Artificial Intelligence Laboratory Annual Abstract},
month = sep,
publisher = {MIT AI Lab},
title = {{Designs for the \{F\}uture}},
year = {2002}
}
@inproceedings{ARMargner2006,
abstract = {The great success and high recognition rates of both OCR systems and
recognition systems for handwritten words are unconceivable without
the availability of huge datasets of real world data. This chapter
gives a short survey of datasets used for recognition with special
focus on their application. The main part of this chapter deals with
Arabic handwriting, datasets for recognition systems, and their availability.
A description of different datasets and their usability is given,
and the results of a competition are presented. Finally, a strategy
for the development of Arabic handwriting recognition systems based
on datasets and competitions is presented.},
address = {University of Maryland, College Park, MD},
author = {Margner, Volker and Abed, Haikal El},
booktitle = {SACH06},
file = {:D$\backslash$:/Papers/Documents/2006/Margner, Abed - 2006.pdf:pdf},
pages = {161--169},
title = {{Databases and Competitions: Strategies to Improve Arabic Recognition Systems}},
year = {2006}
}
@article{Shimanuki,
author = {Shimanuki, H. and Kato, J. and Watanabe, T.},
doi = {10.1109/ICPR.2004.1334235},
file = {:D$\backslash$:/Papers/Documents/Unknown/Shimanuki, Kato, Watanabe - Unknown.pdf:pdf},
isbn = {0-7695-2128-2},
journal = {Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.},
pages = {628--631},
publisher = {Ieee},
title = {{Constituting origami models from sketches}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1334235}
}
@phdthesis{Leung2003a,
author = {Leung, Howard Wing Ho},
file = {:D$\backslash$:/Papers/Documents/2003/Leung - 2003.pdf:pdf},
pages = {1--121},
school = {CARNEGIE MELLON UNIVERSITY},
title = {{Representation, feature extraction, matching and relevance feedback for sketch retrieval}},
type = {DOCTOR OF PHILOSOPHY},
year = {2003}
}
@conference{FE11Hamamoto,
abstract = {We study a Gabor filter-based feature extraction method for handwritten
numeral character recognition. The performance of the Gabor filter-based
method is demonstrated on the ETL-1 database. Experimental results
suggest that the Gabor jilter-based method should be considered in
recognition of handwritten numeric characters..},
author = {Hamamoto, Yoshihiko and Uchimura, Shunji and Masamizu, K and Tomita, Shingo},
booktitle = {Procedding of the 1996 International conference on pattern Recognition ICDAR},
doi = {http://computer.org/proceedings/icdar/7128/vol\_2/71280819abs.htm},
file = {:D$\backslash$:/Papers/Documents/1996/Hamamoto et al. - 1996.pdf:pdf},
pages = {819--823},
publisher = {IEEE},
title = {{Recognition of handprinted Chinese characters using Gabor features.}},
year = {1996}
}
@inproceedings{Oh2001,
author = {Oh, B.S. and Kim, Chang-hun},
booktitle = {Proceedings of the 9th Pacific Conference on Computer Graphics and Applications (PG’01},
file = {:D$\backslash$:/Papers/Documents/2001/Oh, Kim - 2001.pdf:pdf},
pages = {0108},
publisher = {Published by the IEEE Computer Society},
title = {{Progressive 3D reconstruction from a sketch drawing}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/PCCGA.2001.962863},
year = {2001}
}
@article{Mello2007,
author = {Mello, C. and Bezerra, B. and Zanchettin, C. and Macario, V.},
doi = {10.1109/ICDAR.2007.4378702},
file = {:D$\backslash$:/Papers/Documents/2007/Mello et al. - 2007.pdf:pdf},
isbn = {0-7695-2822-8},
issn = {1520-5363},
journal = {Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)},
month = sep,
number = {Icdar},
pages = {193--197},
publisher = {Ieee},
title = {{An Efficient Thresholding Algorithm for Brazilian Bank Checks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4378702},
year = {2007}
}
@inproceedings{ARHuang2006,
abstract = {This paper presents a combined approach for online handwriting symbols
recognition. The basic idea of this approach is to employ a set of
left-right HMMs to generate a new feature vector as input, and then
use SNN as a classifier to finally identify unknown symbols. The
new feature vector consists of global features and several pairs
of maximum probabilities with their associated different model labels
for an observation pattern. A recogniser based on this method inherits
the practical and dynamical modeling abilities from HMM, and robust
discriminating ability from SNN for classification tasks. This hybrid
technique also reduces the dimensions of feature vectors significantly,
complexity, and solves size problem when using only SNN. The experimental
results show that this approach outperforms several classifiers reported
in recent research, and can achieve recognition rates of 97.41\%,
91.81\% and 91.63\% for digits and upper/lower case characters respectively
on the UNIPEN database benchmarks.},
address = {P\{\'{o}\}voa de Varzim, Portugal},
author = {Huang, B Q and Kechadi, M.-T.},
booktitle = {ICIAR 2006, LNCS 4142, pp. 897�905, 2006.},
editor = {Campilho, Aur\'{e}lio C and Kamel, Mohamed S},
file = {:D$\backslash$:/Papers/Documents/2006/Huang, Kechadi - 2006(2).pdf:pdf},
month = sep,
pages = {897--905},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{An HMM-SNN Method for Online Handwriting Symbol Recognition}},
volume = {4142},
year = {2006}
}
@article{Paulson2009,
author = {Paulson, Brandon and Hammond, Tracy},
file = {:D$\backslash$:/Papers/Documents/2009/Paulson, Hammond - 2009.pdf:pdf},
journal = {srlweb.cs.tamu.edu},
title = {{Towards a Framework for Truly Natural Low-level Sketch Recognition}},
url = {http://srlweb.cs.tamu.edu/srlng\_media/content/objects/object-1234413449-80f5591a8d1fb9154910b2aafbbc0279/Paulson-IUI09.pdf},
year = {2009}
}
@misc{Fruhwirth2002,
abstract = {Presentation Outline ❖ Introduction and background ❖ Circle fitting ❖ Helix fitting ❖ Conclusion R. Fr¨ uhwirth},
author = {Fruhwirth, R. and Strandlie, A. and Waltenberger, W. and Wroldsen, J.},
file = {:D$\backslash$:/Papers/Documents/2002/Fruhwirth et al. - 2002.pdf:pdf},
keywords = {Presentation},
mendeley-tags = {Presentation},
title = {{A review of fast circle and helix fitting}},
year = {2002}
}
@article{Kim1997,
abstract = {-In this paper, we propose a novel recognition model of on-line cursive Korean characters using the hidden Markov model (HMM) and a level building algorithm. The model is constructed as a form of recognition network with HMMs for graphemes and Korean combination rules. Though the network represents the large character set efficiently and is flexible enough to accommodate variability of input patterns, it has a problem of recognition speed, caused by 11,172 search paths. To solve the problem, we modify a level building algorithm to be adapted directly to the Korean combination rules and apply it to the model. The modified algorithm is an efficient network search procedure, the time complexity of which depends on the number of grapheme HMMs and ligature HMMs, not the number of paths in the extensive recognition network. A test with 20,000 handwritten characters shows a recognition rate of 90.2\% and speed of 0.72 s per character. ©},
author = {Kim, H},
doi = {10.1016/S0031-3203(96)00078-7},
file = {:D$\backslash$:/Papers/Documents/1997/Kim - 1997.pdf:pdf},
journal = {Pattern Recognition},
keywords = {character recognition network,hidden markov model,level building,on-line characcter},
month = mar,
number = {3},
pages = {491--502},
title = {{An HMM-based character recognition network using level building}},
volume = {30},
year = {1997}
}
@inproceedings{Madhvanath2007,
address = {New York, NY, USA},
author = {Madhvanath, Sriganesh and Vijayasenan, Deepu and Kadiresan, Thanigai Murugan},
booktitle = {SIGGRAPH '07: ACM SIGGRAPH 2007 courses},
doi = {http://0-doi.acm.org.lib.aucegypt.edu/10.1145/1281500.1281524},
file = {:D$\backslash$:/Papers/Documents/2007/Madhvanath, Vijayasenan, Kadiresan - 2007.pdf:pdf},
pages = {13},
publisher = {ACM},
title = {{LipiTk: a generic toolkit for online handwriting recognition}},
year = {2007}
}
@inproceedings{Leung2003,
author = {Leung, W.H. and Chen, T.},
booktitle = {Multimedia and Expo, 2003. ICME'03. Proceedings. 2003 International Conference on},
file = {:D$\backslash$:/Papers/Documents/2003/Leung, Chen - 2003.pdf:pdf},
isbn = {0780379659},
pages = {4--7},
publisher = {IEEE},
title = {{Hierarchical matching for retrieval of hand-drawn sketches}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1221545},
volume = {2},
year = {2003}
}
@article{Bazzi1997,
abstract = {We present a set of techniques for omnifont, unlimited-vocabulary OCR, within the context of a system based on Hidden Markov Models (HMM). First, we address the issue of how to perform OCR on omnqont and multi-style data, such as plain and italic, without the need to have a separate model for each style. The amount of training data from each style, which is used to train a single model, becomes an important issue in the face of the conditional independence assumption inherent in the use of HMMs. We demonstrate mathematically and empirically how to allocate training data among the different styles to alleviate this problem. Second, we show how to use a word-based HMM system to perform character recognition with unlimited vocabulary. The method includes the use of a trigram language model on character sequences. Using all these techniques, we have achieved character error rates of 1.1\% on data from the University of Washington English Document Image Database and 3.3\% on data from the DARPA Arabic OCR Corpus.},
author = {Bazzi, I. and LaPre, C. and Makhoul, J. and Raphael, C. and Schwartz, R.},
doi = {10.1109/ICDAR.1997.620630},
file = {:D$\backslash$:/Papers/Documents/1997/Bazzi et al. - 1997.pdf:pdf},
isbn = {0-8186-7898-4},
journal = {Proceedings of the Fourth International Conference on Document Analysis and Recognition},
keywords = {Reference From Doctor,character recognition,hidden markov models,recognition},
mendeley-tags = {Reference From Doctor},
pages = {842--846},
publisher = {IEEE Comput. Soc},
title = {{Omnifont and unlimited-vocabulary OCR for English and Arabic}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=620630},
year = {1997}
}
@inproceedings{Chhabra1998,
author = {Chhabra, A.K. and Phillips, I.T.},
booktitle = {Empirical Evaluation Techniques in Computer Vision, IEEE Comp Press, CA, USA},
file = {:D$\backslash$:/Papers/Documents/1998/Chhabra, Phillips - 1998.pdf:pdf},
pages = {1--17},
publisher = {Citeseer},
title = {{A benchmark for graphics recognition systems}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.4915\&amp;rep=rep1\&amp;type=pdf},
year = {1998}
}
@article{Singh2009,
address = {New York, New York, USA},
author = {Singh, Dayashankar and Dutta, Maitreyee and Singh, Sarvpal H.},
doi = {10.1145/1517303.1517320},
file = {:D$\backslash$:/Papers/Documents/2009/Singh, Dutta, Singh - 2009.pdf:pdf},
isbn = {9781605584768},
journal = {Proceedings of the 2nd Bangalore Annual Compute Conference on 2nd Bangalore Annual Compute Conference - COMPUTE '09},
keywords = {character recognition,extraction techniques,feature,hcr,hindi,mlp,multilayer perceptron,neural networks,pattern recognition,recognition accuracy and training,time},
pages = {1},
publisher = {ACM Press},
title = {{Neural network based handwritten hindi character recognition system}},
url = {http://portal.acm.org/citation.cfm?doid=1517303.1517320},
year = {2009}
}
@article{Goraine1992,
author = {Goraine, H.},
doi = {10.1109/2.144444},
file = {:D$\backslash$:/Papers/Documents/1992/Goraine - 1992.pdf:pdf},
journal = {Computer},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = jul,
number = {7},
pages = {71--74},
title = {{Off-line Arabic character recognition}},
volume = {25},
year = {1992}
}
@article{PDB15Golfarelli1997,
abstract = {Abstract�In this work, we address the problem of performance evaluation
in biometric verification systems. By formulating the optimum Bayesian
decision criterion for a verification system and by assuming the
data distributions to be multinormals, we derive two statistical
expressions for calculating theoretically the false acceptance and
false rejection rates. Generally, the adoption of a Bayesian parametric
model does not allow for obtaining explicit expressions for the calculation
of the system errors. As far as biometric verification systems are
concerned, some hypotheses can be reasonably adopted, thus allowing
simple and affordable expressions to be derived. By using two verification
system prototypes, based on hand shape and human face, respectively,
we show our results are well founded.},
author = {Golfarelli, Matteo and Maio, Dario and Maltoni, Davide},
doi = {http://www.computer.org/tpami/tp1997/i0786abs.htm},
file = {:D$\backslash$:/Papers/Documents/1997/Golfarelli, Maio, Maltoni - 1997.pdf:pdf},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
number = {7},
pages = {786--796},
title = {{On the Error-Reject Trade-Off in Biometric Verification Systems.}},
volume = {19},
year = {1997}
}
@article{MCWang2008,
abstract = {We propose a new hierarchical design method, weighted support vector
(WSV) k-means clustering, to design a binary hierarchical classification
structure. This method automatically selects the classes to be separated
at each node in the hierarchy, and allows visualization of clusters
of highdimensional support vector data; no prior hierarchical designs
address this. At each node in the hierarchy, we use an SVRDM (support
vector representation and discrimination machine) classifier, which
offers generalization and good rejection of unseen false objects
(rejection is not achieved with the standard SVMs). We give the basis
and new insight into why a Gaussian kernel provides good rejection.
Recognition and rejection test results on a real IR (infrared) database
show that our proposed method outperforms the standard one-vs-rest
methods and the use of standard SVM classifiers.},
author = {Yu-Chiang and Wang, Frank and Casasent, David},
file = {:D$\backslash$:/Papers/Documents/2008/Yu-Chiang, Wang, Casasent - 2008.pdf:pdf},
journal = {Neural Networks},
keywords = {Automatic target recognition; Hierarchical classif},
pages = {502�510},
title = {{New support vector-based design method for binary hierarchical classifiers for multi-class classification problems}},
volume = {21},
year = {2008}
}
@inproceedings{Llados2003,
author = {Llados, J. and Sanchez, Gemma},
booktitle = {Image Processing, 2003. ICIP 2003. Proceedings. 2003 International Conference on},
file = {:D$\backslash$:/Papers/Documents/2003/Llados, Sanchez - 2003.pdf:pdf},
isbn = {0780377508},
issn = {1522-4880},
pages = {3--6},
publisher = {IEEE},
title = {{Symbol recognition using graphs}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1246613},
volume = {2},
year = {2003}
}
@inproceedings{Kara2001,
abstract = {We describe an approach that uses causal reasoning and ge- ometric reasoning to construct explanations for the purposes of the geometric features on the parts of a mechanical device. To identify the purpose of a feature, the device is simulated with and without the feature. The simulations are then translated into a “causal-process” representation, which allows qualitatively im- portant differences to be identified. These differences reveal be- haviors that the feature causes to occur and those it prevents from occurring. The focus of this paper is geometric reasoning tech- niques that reveal causal relationships between the caused and prevented behaviors. For example, these techniques can deter- mine if a particular caused behavior is responsible for preventing a particular prevented behavio},
author = {Kara, Levent Burak and Stahovich, Thomas F.},
booktitle = {Proceedings of ASME Design Theory and},
file = {:D$\backslash$:/Papers/Documents/2001/Kara, Stahovich - 2001.pdf:pdf},
pages = {1--8},
title = {{Spatial reasoning about mechanical behaviors}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.2.7975\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
@article{DSSouiciMeslati2004,
abstract = {The challenge of hybrid learning systems is to use the information
provided by one source of information to compensate information missing
from the other source. The neuro�symbolic combination represents
a promising research way. The synergy between the symbolic (theoretical)
and neural (empirical) approaches makes their combination more effective
than each of them used alone. In this article, we describe an Arabic
literal amount recognition system that uses a neuro-symbolic classifier.
For this purpose, we first extract structural features from the words
contained in the amounts vocabulary. Then, we build a symbolic knowledge
base that reflects a classification of words according to their features.
In a third step, we use a translation algorithm (from rules to neural
network) to determine the neural network architecture and to initialize
its connections with specific values rather than random values, as
is the case in classical neural networks. This construction approach
provides the network with theoretical knowledge and reduces the training
stage, which remains necessary because of styles and writing conditions
variability. After this empirical training stage using real examples,
the network acquires a final topology, which allows it to recognize
new handwritten amounts.},
author = {Souici-Meslati, Labiba and Sellami, Mokhtar},
file = {:D$\backslash$:/Papers/Documents/2004/Souici-Meslati, Sellami - 2004.pdf:pdf},
journal = {The Arabian Journal for Science and Engineering},
keywords = { neuro-symbolic integration; literal amounts,Artificial intelligence; pattern recognition; hand},
number = {2B},
pages = {177--194},
title = {{A HYBRID APPROACH FOR ARABIC LITERAL AMOUNTS RECOGNITION}},
volume = {29},
year = {2004}
}
@article{Oltmans2004,
author = {Oltmans, M and Alvarado, C},
file = {:D$\backslash$:/Papers/Documents/2004/Oltmans, Alvarado - 2004.pdf:pdf},
journal = {Making Pen-Based Interaction Intelligent},
title = {{Etcha sketches: Lessons learned from collecting sketch data}},
url = {http://www.aaai.org/Papers/Symposia/Fall/2004/FS-04-06/FS04-06-021.pdf},
year = {2004}
}
@article{Nasri2009,
address = {New York, New York, USA},
author = {Nasri, A. and Karam, W. Bou and Samavati, Faramarz},
doi = {10.1145/1572741.1572751},
file = {:D$\backslash$:/Papers/Documents/2009/Nasri, Karam, Samavati - 2009.pdf:pdf},
isbn = {9781605586021},
journal = {Proceedings of the 6th Eurographics Symposium on Sketch-Based Interfaces and Modeling - SBIM '09},
keywords = {Doc:Samavati,Scholarships Doctors},
mendeley-tags = {Scholarships Doctors},
pages = {53},
publisher = {ACM Press},
title = {{Sketch-based subdivision models}},
url = {http://portal.acm.org/citation.cfm?doid=1572741.1572751},
volume = {1},
year = {2009}
}
@inproceedings{Mihov2005,
author = {Mihov, Stoyan and Schulz, K.U. and Ringlstetter, Christoph and Dojchinova, Veselka and Nakova, Vanja},
booktitle = {German Research},
file = {:D$\backslash$:/Papers/Documents/2005/Mihov et al. - 2005.pdf:pdf},
keywords = {comparative broad range of,contents,contents and formats,corpora,cyrillic documents,evaluation,genres and documents types,ground truth data,meta-data,mixed-alphabet documents,optical character recognition,postcor- w,public corpora,r,rection of ocr results,should be covered,t,the collection of new,which means that a},
publisher = {IEEE Computer Society},
title = {{A Corpus for Comparative Evaluation of OCR Software and Postcorrection Techniques}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICDAR.2005.6},
year = {2005}
}
@article{ARBasu2009,
abstract = {A novel hierarchical approach is presented here for optical character
recognition (OCR) of handwritten Bangla words. Instead of dealing
with isolated characters as found in selected works [T.K. Bhowmik,
U. Bhattacharya, S.K. Parui, Recognition of Bangla handwritten characters
using an MLP classifier based on stroke features, in: Proceedings
of the ICONIP, Kolkata, India, 2004, pp. 814�819; K. Roy, U. Pal,
F. Kimura, Bangla handwritten character recognition, in: Proceedings
of the Second Indian International Conference on Artificial Intelligence
(IICAI), 2005, pp. 431�443; S. Basu, N. Das, R. Sarkar, M. Kundu,
M. Nasipuri, D.K. Basu, Handwritten Bangla alphabet recognition using
an MLP based classifier, in: Proceedings of the Second National Conference
on Computer Processing of Bangla, Dhaka, 2005, pp. 285�291; A.F.R.
Rahman, R. Rahman, M.C. Fairhurst, Recognition of handwritten Bengali
characters: a novel multistage approach, Pattern Recognition 35,
2002, pp. 997�1006; U. Bhattacharya, S.K. Parui, M. Sridhar, F. Kimura,
Twostage recognition of handwritten Bangla alphanumeric characters
using neural classifiers, in: Proceedings of the Second Indian International
Conference on Artificial Intelligence (IICAI), 2005, pp. 1357�1376;
U. Bhattacharya, M. Sridhar, S.K. Parui, On recognition of handwritten
Bangla characters, in: Proceedings of the ICVGIP-06, Lecture Notes
in Computer Science, vol. 4338, 2006, pp. 817�828], the present approach
segments a word image on Matra hierarchy, then recognizes the individual
word segments and finally identifies the constituent characters of
the word image through intelligent combination of recognition decisions
of the associated word segments. Due to possible appearances of consecutive
characters of Bangla words on overlapping character positions, segmentation
of Bangla word images is not easy. For successful OCR of handwritten
Bangla text, not only recognition but also segmentation of word images
are important. In this respect the present hierarchical approach
deals with both segmentation and recognition of handwritten Bangla
word images for a complete solution to handwritten word recognition
problem, an essential area of OCR of handwritten Bangla text. In
dealing with certain category of word segments, created on Matra
hierarchy, a sophisticated recognition technique, viz., two-pass
approach [S. Basu, C. Chaudhury, M. Kundu, M. Nasipuri, D.K. Basu,
A two pass approach to pattern classification, in: N.R. Pal et al.
(Ed.), Lecture Notes in Computer Science, vol. 3316, ICONIP, Kolkata,
2004, pp. 781�786] is employed here. The degree of sophistication
of the classification technique is also rationally tuned depending
on various categories of word segments to be recognized. For example,
the two-pass approach is employed here for recognizing middle zone
character segments, whereas recognition of middle zone modified shapes
of Bangla script is done through simple template matching. Considering
learning and generalization abilities of multi layer perceptrons
(MLPs), MLP based pattern classifiers are used here for most of the
classification related tasks. A powerful feature set is also designed
under this work for recognition of complex character patterns using
three types of topological features, viz., longest-run features,
modified shadow features and octant-centroid features. In a nutshell,
the work deals with a practical problem of OCR of Bangla text involving
recognition as well as segmentation of constituent characters of
handwritten Bangla words.},
author = {{Subhadip Basu Nibaran Das}, Ram Sarkar Mahantapas Kundu Mita Nasipuri? Dipak Kumar Basu},
file = {:D$\backslash$:/Papers/Documents/2009/Subhadip Basu Nibaran Das - 2009.pdf:pdf},
journal = {Pattern Recognition},
pages = {1467--1484},
title = {{A hierarchical approach to recognition of handwritten Bangla characters}},
volume = {42},
year = {2009}
}
@article{MCKussul2005,
abstract = {We have developed a novel neural classifier LImited Receptive Area
(LIRA) for the image recognition. The classifier LIRA contains three
neuron layers: sensor, associative and output layers. The sensor
layer is connected with the associative layer with no modifiable
random connections and the associative layer is connected with the
output layer with trainable connections. The training process converges
sufficiently fast. This classifier does not use floating point and
multiplication operations. The classifier was tested on two image
databases. The first database is the MNIST database. It contains
60,000 handwritten digit images for the classifier training and 10,000
handwritten digit images for the classifier testing. The second database
contains 441 images of the assembly microdevice. The problem under
investigation is to recognize the position of the pin relatively
to the hole. A random procedure was used for partition of the database
to training and testing subsets. There are many results for the MNIST
database in the literature. In the best cases, the error rates are
0.7, 0.63 and 0.42\%. The classifier LIRA gives error rate of 0.61\%
as a mean value of three trials. In task of the pin�hole position
estimation the classifier LIRA also shows sufficiently good results.},
author = {Kussul, Ernst and Baidyk, Tatiana},
file = {:D$\backslash$:/Papers/Documents/2005/Kussul, Baidyk - 2005.pdf:pdf},
journal = {Image and Vision Computing},
pages = {971�981},
title = {{Improved method of handwritten digit recognition tested on MNIST database}},
volume = {22},
year = {2005}
}
@article{Marji2003,
author = {Marji, Majed and Siy, Pepe},
doi = {10.1016/S0031-3203(03)00119-5},
file = {:D$\backslash$:/Papers/Documents/2003/Marji, Siy - 2003.pdf:pdf},
issn = {0031-3203},
journal = {Pattern recognition},
keywords = {corner,curvature,digital curve,dominant points,polygonal approximation,shape representation},
number = {10},
pages = {2239--2251},
publisher = {Elsevier},
title = {{A new algorithm for dominant points detection and polygonization of digital curves}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320303001195},
volume = {36},
year = {2003}
}
@inproceedings{Sezgin2005HMM,
address = {New York, New York},
author = {Sezgin, Tevfik Metin and Davis, Randall},
booktitle = {Proceedings of the International Conference on Intelligent User Interfaces (\{IUI'05\})},
file = {:D$\backslash$:/Papers/Documents/2005/Sezgin, Davis - 2005(3).pdf:pdf},
month = jan,
pages = {www},
publisher = {ACM Press},
title = {{HMM-Based Efficient Sketch Recognition}},
year = {2005}
}
@article{Liu2009,
author = {Liu, Cheng-Lin and Suen, Ching Y.},
doi = {10.1016/j.patcog.2008.10.007},
file = {:D$\backslash$:/Papers/Documents/2009/Liu, Suen - 2009.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {bangla numeral recognition,farsi numeral recognition},
month = dec,
number = {12},
pages = {3287--3295},
title = {{A new benchmark on the recognition of handwritten Bangla and Farsi numeral characters}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308004457},
volume = {42},
year = {2009}
}
@inproceedings{Pinto-Albuquerque2000a,
author = {Pinto-Albuquerque, M. and Fonseca, M.J. and Jorge, J.A.},
booktitle = {IEEE Symposium on Visual Languages},
file = {:D$\backslash$:/Papers/Documents/2000/Pinto-Albuquerque, Fonseca, Jorge - 2000.pdf:pdf},
pages = {225--232},
title = {{Visual languages for sketching documents}},
url = {http://orion.lcg.ufrj.br/cg2/downloads/Interfaces Caligraficas/vl2k.pdf},
year = {2000}
}
@inproceedings{Wolin2007,
annote = {I want to test my note a out the documents of the maast 

      },
author = {Wolin, Aaron and Smith, Devin and Alvarado, Christine},
booktitle = {Proceedings of the 4th Eurographics workshop on Sketch-based interfaces and modeling},
file = {:D$\backslash$:/Papers/Documents/2007/Wolin, Smith, Alvarado - 2007.pdf:pdf},
keywords = {Sketch Research},
mendeley-tags = {Sketch Research},
pages = {67--74},
publisher = {ACM},
title = {{A pen-based tool for efficient labeling of 2d sketches}},
url = {http://portal.acm.org/citation.cfm?id=1384429.1384446},
year = {2007}
}
@inproceedings{ARKavianifar1999,
abstract = {English and Chinese are languages, which have tremendously attracted
interests of character recognition researchers. In contrast, research
in the field of character recognition for Arabic / Persian scripts
face major problems mainly related to the unique characteristics
of these two like being cursive, multiple shapes of one character
in different positions in a word and connectivity of characters on
the baseline. The proposed work consists of three major phases. After
digitizing the text, the original image is transformed into a gray
scale image using a 300-dpi scanner. Different steps of preprocessing
are then applied on the image file. In the next phase, sub-words
of all words are recognized and global features for each word are
extracted. Contour tracing plays a very important role in the phase
of feature extraction.},
author = {Kavianifar, Mandana and Amin, Adnan},
booktitle = {Proceedings of the Fifth International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/1999/Kavianifar, Amin - 1999.pdf:pdf},
title = {{Preprocessing and Structural Feature Extraction for a Multi-Fonts Arabic / Persian OCR}},
year = {1999}
}
@inproceedings{Hammond2002d,
author = {Hammond, Tracy and Davis, R.},
booktitle = {Proceedings of},
file = {:D$\backslash$:/Papers/Documents/2002/Hammond, Davis - 2002.pdf:pdf},
pages = {1--2},
publisher = {Citeseer},
title = {{A domain description language for sketch recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.6693\&amp;rep=rep1\&amp;type=pdf},
year = {2002}
}
@incollection{Foltz2001QueryAbstract,
author = {Foltz, Mark and Davis, Randall},
booktitle = {MIT Artificial Intelligence Laboratory Annual Abstract},
file = {:D$\backslash$:/Papers/Documents/2001/Foltz, Davis - 2001.pdf:pdf},
month = sep,
publisher = {MIT AI Lab},
title = {{Query by Attention: Visually Searchable Information Maps}},
year = {2001}
}
@inproceedings{PDB12Prevost2003,
abstract = {Handwriting recognition is such a complex classification problem that
it is quite usual now to make co-operate several classification methods
at the preprocessing stage or at the classification stage. In this
paper, we present an original two stages recognizer. The first stage
is a model-based classifier that stores an exhaustive set of character
models. The second stage is a discriminative classifier that separates
the most ambiguous pairs of classes. This hybrid architecture is
based on the idea that the correct class almost systematically belongs
to the two more relevant classes found by the first classifier. Experiments
on Unipen database show a 30\% improvement on a 62 classes recognition
problem.},
address = {Edinburgh, Scotland, UK},
author = {Prevost, Lionel and Michel-Sendis, Christian and Moises, Alvaro and Oudot, Lo\"{\i}c and Milgram, Maurice},
booktitle = {7th International Conference on Document Analysis and Recognition (ICDAR 2003)},
doi = {http://csdl.computer.org/comp/proceedings/icdar/2003/1960/01/196010031abs.htm},
file = {:D$\backslash$:/Papers/Documents/2003/Prevost et al. - 2003.pdf:pdf},
isbn = {0-7695-1960-1},
keywords = {Handwritten digits},
pages = {31--},
publisher = {IEEE Computer Society},
title = {{Combining model-based and discriminative classifiers : application to handwritten character recognition.}},
volume = {2},
year = {2003}
}
@article{Hammond2004Shady,
author = {Hammond, Tracy and Davis, Randall},
title = {{No Title}}
}
@article{Lee2007,
author = {Lee, W.S. and Burakkara, L and Stahovich, Thomas F},
doi = {10.1016/j.cag.2007.04.007},
file = {:D$\backslash$:/Papers/Documents/2007/Lee, Burakkara, Stahovich - 2007.pdf:pdf},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {graph isomorphism,graph matching,pattern recognition,pen computing,sketch understanding,symbol recognition},
month = aug,
number = {4},
pages = {554--567},
title = {{An efficient graph-based recognizer for hand-drawn symbols}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849307001008},
volume = {31},
year = {2007}
}
@inproceedings{Thimbleby2004,
author = {Thimbleby, William},
booktitle = {Proceedings of the third Nordic conference on Human-computer interaction},
file = {:D$\backslash$:/Papers/Documents/2004/Thimbleby - 2004.pdf:pdf},
isbn = {1581138571},
pages = {445--448},
publisher = {ACM},
title = {{A novel pen-based calculator and its evaluation}},
url = {http://portal.acm.org/citation.cfm?id=1028014.1028091},
year = {2004}
}
@article{Varley,
author = {Varley, P.a.C. and Martin, R.R.},
doi = {10.1109/GMAP.2000.838235},
file = {:D$\backslash$:/Papers/Documents/Unknown/Varley, Martin - Unknown.pdf:pdf},
isbn = {0-7695-0562-7},
journal = {Proceedings Geometric Modeling and Processing 2000. Theory and Applications},
pages = {13--32},
publisher = {IEEE Comput. Soc},
title = {{A system for constructing boundary representation solid models from a two-dimensional sketch}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=838235}
}
@article{ARLiwicki2008,
abstract = {In this paper we present a multiple classifier system (MCS) for on-line
handwriting recognition. The MCS combines several individual recognition
systems based on hidden Markov models (HMMs) and bidirectional long
short-term memory networks (BLSTM). Beside using two different recognition
architectures (HMM and BLSTM), we use various feature sets based
on on-line and off-line features to obtain diverse recognizers. Furthermore,
we generate a number of different neural network recognizers by changing
the initialization parameters. To combine the word sequences output
by the recognizers, we incrementally align these sequences using
the recognizer output voting error reduction framework (ROVER). For
deriving the final decision, different voting strategies are applied.
The best combination ensemble has a recognition rate of 84.13\%, which
is significantly higher than the 83.64\% achieved if only one recognition
architecture (HMM or BLSTM) is used for the combination, and even
remarkably higher than the 81.26\% achieved by the best individual
classifier. To demonstrate the high performance of the classification
system, the results are compared with two widely used commercial
recognizers from Microsoft and Vision Objects.},
author = {Liwicki, Marcus and HorstBunkeb},
file = {:D$\backslash$:/Papers/Documents/2008/Liwicki, HorstBunkeb - 2008.pdf:pdf},
journal = {Pattern Recognition},
keywords = {On-line handwriting recognition; Off-line handwrit},
month = dec,
number = {12},
pages = {3254--3263},
title = {{Combining diverse on-line and off-line systems for handwritten text line recognition}},
volume = {42},
year = {2008}
}
@inproceedings{PDBPong2006,
abstract = {We describe a method for optimal construction of a detection cascade
comprising 3D models of increasing levelof- detail (LOD). An LOD
3D model hierarchy of the target object is first generated. By analyzing
detection performance of each individual model in the LOD hierarchy,
an optimization framework that allows trade-off between speed and
accuracy is formulated. The formulation allows models to be explicitly
selected for inclusion in the final detection cascade while achieving
optimal running time with respect to a target detection performance.},
author = {Pong, Hon-Keat and Cham, Tat-Jen},
booktitle = {Proceedings of the 18th International Conference on Pattern Recognition (ICPR'06)},
file = {:D$\backslash$:/Papers/Documents/2006/Pong, Cham - 2006.pdf:pdf},
publisher = {IEEE Computer Society},
title = {{Optimal Cascade Construction for Detection using 3D Models}},
year = {2006}
}
@article{Sezgin2001FreeSOW,
author = {Sezgin, Tevfik Metin},
file = {:D$\backslash$:/Papers/Documents/2001/Sezgin - 2001.pdf:pdf},
journal = {Proceedings of the MIT Student Oxygen Workshop},
title = {{Free-Hand Stroke Approximation for Intelligent Sketching Systems}},
year = {2001}
}
@inproceedings{Plimmer2007,
abstract = {Sketch-based tools provide a more human centered design environment than traditional widget-based computer design software. A number of sketch tools exist that support specific design tasks: however wider exploration of computer supported sketching is being hampered by the effort required to build the sketching software. Here we present a sketch tool framework, its implementation and evaluation. The implementation, InkKit, provides context free design spaces and a powerful, trainable and extensible modeless writing/drawing recognition engine. It reduces the development effort for a specific diagram type from thousands of lines of code to a few hundred. We evaluated our toolkit by asking fourth year computer science students to use InkKit to develop a diagram specific recognizer.},
author = {Plimmer, Beryl and Freeman, Isaac},
booktitle = {Proceedings of the 21st British CHI Group Annual Conference on HCI 2007: People and Computers XXI: HCI... but not as we know it-Volume 1},
editor = {{Linden J. Ball, M. Angela Sasse, Corina Sas, Thomas C. Ormerod, Alan Dix, Peter Bagnall}, And Tom McEwan},
file = {:D$\backslash$:/Papers/Documents/2007/Plimmer, Freeman - 2007.pdf:pdf},
keywords = {hand-drawn diagrams,pen,sketch recognition,sketch tools},
pages = {205--213},
publisher = {British Computer Society},
title = {{A toolkit approach to sketched diagram recognition}},
url = {http://portal.acm.org/citation.cfm?id=1531323},
year = {2007}
}
@article{Slimane2009,
author = {Slimane, Fouad and Ingold, Rolf and Kanoun, Slim and Alimi, Adel M. and Hennebert, Jean},
doi = {10.1109/ICDAR.2009.155},
file = {:D$\backslash$:/Papers/Documents/2009/Slimane et al. - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {946--950},
publisher = {Ieee},
title = {{A New Arabic Printed Text Image Database and Evaluation Protocols}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277558},
year = {2009}
}
@inproceedings{Zhang2009a,
abstract = {—The purpose of this paper is to improve recognition rate of off-line handwritten character recognition system.We apply the statistical characteristics of the percentage of pixels and structural characteristics of boundary chain code of character projection, after train based on HMM to obtain corresponding parameters, then integrate different classifiers through the Bagging algorithm in Voting method. Experimental results indicate that this approach can further improve the performance.},
author = {Zhang, Yan and Yao, Xiaodong and Chang, Ching},
booktitle = {Computational Intelligence and Software Engineering, 2009. CiSE 2009. International Conference on},
file = {:D$\backslash$:/Papers/Documents/2009/Zhang, Yao, Chang - 2009.pdf:pdf},
keywords = {- handwriten recognition,Handwritten Character Recognition Using HMM Model ,bagging,hmm model},
pages = {1--4},
publisher = {IEEE},
title = {{Handwritten Character Recognition Using HMM Model Based on Bagging Method}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5366197},
year = {2009}
}
@article{DSElnagar2003,
abstract = {A new approach to separating single touching handwritten digit strings
is presented. The image of the connected numerals is normalized,
preprocessed and then thinned before feature points are detected.
Potential segmentation points are determined based on decision line
that is estimated from the deepest/highest valley/hill in the image.
The partitioning path is determined precisely and then the numerals
are separated before restoration is applied. Experimental results
on the NIST Database 19, CEDAR CD-ROM and our own collection of images
show that our algorithm can get a successful recognition rate of
96\%, which compares favorably with those reported in the literature.},
author = {Elnagar, Ashraf and Alhajj, Reda},
doi = {DOI: 10.1016/S0031-3203(02)00097-3},
file = {:D$\backslash$:/Papers/Documents/2003/Elnagar, Alhajj - 2003.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {Character segmentation},
number = {3},
pages = {625--634},
title = {{Segmentation of connected handwritten numeral strings}},
url = {http://www.sciencedirect.com/science/article/B6V14-4771RWD-3/2/7cbc7f3ab0340029eb6aaaff3e9693b8},
volume = {36},
year = {2003}
}
@article{Eisenstein2006,
address = {Morristown, NJ, USA},
author = {Eisenstein, Jacob and Davis, Randall},
doi = {10.3115/1614049.1614059},
file = {:D$\backslash$:/Papers/Documents/2006/Eisenstein, Davis - 2006.pdf:pdf},
journal = {Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers on XX - NAACL '06},
pages = {37--40},
publisher = {Association for Computational Linguistics},
title = {{Gesture improves coreference resolution}},
url = {http://portal.acm.org/citation.cfm?doid=1614049.1614059},
year = {2006}
}
@inproceedings{Zeleznik2006,
abstract = {We present Fluid Inking, a generally applicable approach to aug- menting the fluid medium of free-form inking with gestural com- mands. Our approach is characterized by four design criteria, in- cluding: 1) pen-based hardware impartiality: all interactions can be performed with a button-free stylus, the minimal input hardware requirement for inking, and the least common denominator device for pen-based systems ranging from PDAs to whiteboards; 2) per- formability: gestures use short sequences of simple and familiar inking interactions that require minimal targeting; 3) extensibility: gestures are a regular pattern of optional shortcuts for commands in an arbitrarily scalable menu system; and 4) discoverability: gesture shortcuts (analogous to modifier keys) are displayed in the interac- tive menu and are suggested with dynamic feedback during inking. This paper presents the Fluid Inking techniques in the unified con- text of a prototype notetaking application and emphasizes howpost- fix terminal punctuation and prefix flicks can disambiguate gestures from regular inking. We also discuss how user feedback influenced the Fluid Inking design.},
author = {Zeleznik, Robert and Miller, T.},
booktitle = {Proceedings of Graphics Interface 2006},
file = {:D$\backslash$:/Papers/Documents/2006/Zeleznik, Miller - 2006.pdf:pdf},
isbn = {1568813082},
keywords = {button-free,gestures,inking,terminal punctuation},
pages = {155--162},
publisher = {Canadian Information Processing Society},
title = {{Fluid inking: augmenting the medium of free-form inking with gestures}},
url = {http://portal.acm.org/citation.cfm?id=1143079.1143105},
year = {2006}
}
@inproceedings{ARMello2008,
abstract = {In this paper, we describe an approach for the problem of segmenting
overlapping characters. We are working with digit segmentation for
bank check processing. Our method is based on the idea of a hypothetical
ball traversing the number. The inertia of the movement segments
the overlapping digits. Rules are defined for this movement. Our
initial proposal achieved very good results with O(n2) complexity.},
address = {Sao Paulo, Brazil},
annote = {Last edited 2 march 2010},
author = {A.B.Mello, Carlos and Roe, Edward and B.Lacerda, Everton},
booktitle = {DocEng '08: Proceeding of the eighth ACM symposium on Document engineering},
doi = {http://doi.acm.org/10.1145/1410140.1410199},
file = {:D$\backslash$:/Papers/Documents/2008/A.B.Mello, Roe, B.Lacerda - 2008.pdf:pdf},
isbn = {978-1-60558-081-4},
keywords = { overlapping digits., segmentation,Document processing},
pages = {271--274},
publisher = {ACM},
title = {{Segmentation of Overlapping Cursive Handwritten Digits}},
year = {2008}
}
@article{Liu2004b,
author = {Liu, X.Y. and Blumenstein, M.},
doi = {10.1109/IWFHR.2004.40},
file = {:D$\backslash$:/Papers/Documents/2004/Liu, Blumenstein - 2004.pdf:pdf},
isbn = {0-7695-2187-8},
journal = {Ninth International Workshop on Frontiers in Handwriting Recognition},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {353--358},
publisher = {Ieee},
title = {{Experimental Analysis of the Modified Direction Feature for Cursive Character Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1363936},
year = {2004}
}
@inbook{Maniezzo1991,
author = {Maniezzo, Vittorio and Gambardella, Luca Maria and Luigi, Fabio De},
booktitle = {Optimization},
file = {:D$\backslash$:/Papers/Documents/1991/Maniezzo, Gambardella, Luigi - 1991.pdf:pdf},
pages = {1--21},
title = {{Ant Colony Optimization}},
year = {1991}
}
@article{Costagliola2010,
author = {Costagliola, Gennaro and Hammond, Tracy and Plimmer, Beryl},
doi = {10.1016/j.jvlc.2010.01.003},
file = {:D$\backslash$:/Papers/Documents/2010/Costagliola, Hammond, Plimmer - 2010.pdf:pdf},
issn = {1045926X},
journal = {Journal of Visual Languages \& Computing},
month = apr,
number = {2},
pages = {67--68},
title = {{JVLC special issue on sketch computation}},
url = {http://dx.doi.org/10.1016/j.jvlc.2010.01.003},
volume = {21},
year = {2010}
}
@article{Imran2010,
abstract = {Urdu script-based languages’ character recognition has some technical issues not existing in other lan- guages and makes these languages more complicated. Segmentation-based character recognition approach for handwritten Urdu, both Nasta’liq and Nasakh script-based languages, incorporates number of overhead and very less accurate as compared to segmentation free. This paper presents a segmenta- tion-free approach for recognition of online Urdu handwritten script using hybrid classifier, HMM and fuzzy logic. Trained data set consisting of HMMs for each stroke is further classified into 62 sub-patterns based on the primary stroke shape at the beginning and end using fuzzy rule. Fuzzy linguistic variables based on language structure are used to model features and provide suitable result for large variation in handwritten strokes. Twenty-six time variant structural and statistical features are extracted for the base strokes. The fuzzy classification into sub-patterns increases the efficiency and decreases the computa- tional complexity due to reduction in data set size. The hybrid HMM–fuzzy technique is efficient for large and complex data set. It provided 87.6\% and 74.1\% for Nasta’liq and Nasakh, respectively, on 1800 ligatures. },
author = {Imran, Muhammad and Anwar, Fareeha and Husain, S A and Belaid, Abdel and Sher, Muhammad and Cedex, Nancy},
doi = {10.1016/j.knosys.2010.06.007},
file = {:D$\backslash$:/Papers/Documents/2010/Imran et al. - 2010.pdf:pdf},
issn = {0950-7051},
journal = {Knowledge-Based Systems},
keywords = {Fuzzy logic,HMM,Hybrid model,Online handwriting character recognition,Segmentation free},
number = {8},
pages = {914--923},
publisher = {Elsevier B.V.},
title = {{Knowledge-Based Systems HMM and fuzzy logic : A hybrid approach for online Urdu script-based languages ’ character recognition}},
url = {http://dx.doi.org/10.1016/j.knosys.2010.06.007},
volume = {23},
year = {2010}
}
@article{MCCao95,
abstract = {Multiple experts system is shown to be a promising strategy for handwritten
recognition. This paper presents a multiple experts system using
neural networks. In the proposed system, the authors have developed:
(11 an incremental clustering neural network algorithm with merging
and canceling process, (2) a modified directional histogram feature
extraction method, and (3) a subclass method with learning rejection
neuron strategy. Our experimental results on a large set of data
show the efficiency and robustness of the proposed system.},
author = {{JUN CAOt}, M AHMADI and SHRIDHAR, M},
journal = {Pattern Recoynition},
number = {2},
pages = {153 160,},
title = {{RECOGNITION OF HANDWRITTEN NUMERALS WITH MULTIPLE FEATURE AND MULTISTAGE CLASSIFIER}},
volume = {28},
year = {1995}
}
@inproceedings{Kundu2002,
abstract = {We describe an MD-HMM (model discriminant HMM) based HWR system (called NEHMM - non- ergodic HMM) whose system parameters are derived from the parameters of the VDHMM (variable dura- tion HMM) system described an [I]. The new HMM achieves better experimental results by more eficient utilization of variable duration information. However, more often the problem is ‘reliable computation’ of du- ration probabilities given limited databases. In the sec- ond phase of the paper, a scheme (VSLHMM - variable sequence length HMM) has been presented to avoid the computation of duration probabilities altogether with- out sacrificing the performance gain of the VDHMM system.},
author = {Kundu, A. and He, Y. and Chen, M.Y.},
booktitle = {Image Processing, 1997. Proceedings., International Conference on},
file = {:D$\backslash$:/Papers/Documents/2002/Kundu, He, Chen - 2002.pdf:pdf},
isbn = {0818681837},
pages = {304--307},
publisher = {IEEE},
title = {{Efficient utilization of variable duration information in HMM based HWR systems}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=632099},
volume = {3},
year = {2002}
}
@inproceedings{DSShah2008,
abstract = {In this paper, we present the creation of the first comprehensive
database for research and development on handwritten recognition
of Dari language. This new handwritten database consists of many
aspects of Dari scripts such as: handwritten isolated characters,
isolated digits, numeral strings of various lengths, many words/terms,
dates, and some special symbols. For each handwritten image in this
database, very useful ground truth information is provided to facilitate
successful recognition experiments on the images. The data has been
archived into two different formats - Gray level and Binary. The
contents of the database are frequently used in several kinds of
documents such as scientific and business documents. The overall
structure of the database has been designed in such a way to make
it convenient for conducting recognition experiments on the handwritten
Dari scripts.},
address = {Montreal, Canada},
author = {Shah, M I and Sadri, J and Suen, C Y and Nobile, N},
booktitle = {Eleventh International Conference on Frontiers in Handwriting Recognition},
file = {:D$\backslash$:/Papers/Documents/2008/Shah et al. - 2008.pdf:pdf},
keywords = { (OCR), Dari Handwritten Database, Dari Handwritten Recognition, Farsi and Arabic Hand-written Recognition., Handwritten Recognition,Optical},
month = aug,
pages = {635--640},
title = {{A New Multipurpose Comprehensive Database for Handwritten Dari Recognition}},
year = {2008}
}
@conference{ARLopresti2006,
abstract = {Two methods, Symbolic Indirect Correlation (SIC) and Style Constrained
Classification (SCC), are proposed for recognizing handwritten Arabic
and Chinese words and phrases. SIC reassembles variablelength segments
of an unknown query that match similar segments of labeled reference
words. Recognition is based on the correspondence between the order
of the feature vectors and of the lexical transcript in both the
query and the references. SIC implicitly incorporates language context
in the form of letter n-grams. SCC is based on the notion that the
style (distortion or noise) of a character is a good predictor of
the distortions arising in other characters, even of a different
class, from the same source. It is adaptive in the sense that, with
a long-enough field, its accuracy converges to that of a style-specific
classifier trained on the writer of the unknown query. Neither SIC
nor SCC requires the query words to appear among the references.},
author = {Lopresti, Daniel and Nagy, George and Seth, Sharad and Zhang, Xiaoli},
booktitle = {SACH06},
file = {:D$\backslash$:/Papers/Documents/2006/Lopresti et al. - 2006.pdf:pdf},
pages = {xx--yy},
title = {{Multi-character Field Recognition for Arabic and Chinese Handwriting}},
year = {2006}
}
@inproceedings{Samet1994,
author = {Samet, Hanan and Soffer, A.},
booktitle = {In Proceedings of the 12th International Conference on Pattern Recognition, volume II},
file = {:D$\backslash$:/Papers/Documents/1994/Samet, Soffer - 1994(2).pdf:pdf},
number = {Figure 1},
pages = {350--355},
publisher = {Citeseer},
title = {{A legend-driven geographic symbol recognition system}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.30.7993},
year = {1994}
}
@inproceedings{Sezgin2006,
author = {Sezgin, T.M. and Stahovich, Thomas and Davis, Randall},
booktitle = {ACM SIGGRAPH 2006 Courses},
file = {:D$\backslash$:/Papers/Documents/2006/Sezgin, Stahovich, Davis - 2006.pdf:pdf},
keywords = {freehand sketching,multiple sources of,natural interaction},
pages = {22},
publisher = {ACM},
title = {{Sketch based interfaces: Early processing for sketch understanding}},
url = {http://portal.acm.org/citation.cfm?id=1185783},
year = {2006}
}
@inproceedings{Lim2003,
author = {Lim, Chor-kheng},
booktitle = {In Proc. 6th Asian Design International Conference},
file = {:D$\backslash$:/Papers/Documents/2003/Lim - 2003.pdf:pdf},
publisher = {Citeseer},
title = {{An insight into the freedom of using a pen: Pen-based system and pen-and-paper}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.131.759},
year = {2003}
}
@article{Davis2002Sketch,
address = {Stanford, California},
author = {Davis, Randall},
file = {:D$\backslash$:/Papers/Documents/2002/Davis - 2002(2).pdf:pdf},
journal = {Sketch Understanding, Papers from the 2002 AAAI Spring Symposium},
month = mar,
pages = {24--31},
publisher = {AAAI Press},
title = {{Sketch Understanding in Design: Overview of Work at the \{MIT\} \{AI\} Lab}},
year = {2002}
}
@misc{Bishop,
author = {Bishop, J M and Torr, P},
booktitle = {Engineering},
file = {:D$\backslash$:/Papers/Documents/Unknown/Bishop, Torr - Unknown.pdf:pdf},
title = {{The Stochastic Search Network}}
}
@inproceedings{ARICDAR2005,
abstract = {This paper describes the Arabic handwriting recognition competition for ICDAR 2005. With the presentation of the IFN/ENIT-database in the year 2002 a database with handwritten Arabic town names was made available for free to non commercial research groups. Till now more than 30 groups are working with this data worldwide. By announcing a competition of Arabic handwriting recognition systems based on the IFN/ENIT-database, we hope to contribute to the development of Arabic handwriting recognition systems. The use of the same database by different research groups allows the comparison of different systems. We compare the systems on the most important characteristic: recognition rate, but also features like word length, writing style, and character connectivity will be discussed.},
author = {Margner, V and Pechwitz, M and Abed, H El},
booktitle = {Proceedings of the 2005 Eight International Conference on Document Analysis and Recognition (ICDAR�05)},
file = {:D$\backslash$:/Papers/Documents/2005/Margner, Pechwitz, Abed - 2005.pdf:pdf},
title = {{ICDAR 2005 Arabic Handwriting Recognition Competition}},
year = {2005}
}
@article{DSFarah2005,
abstract = {Given the number and variety of methods used for handwriting recognition,
it has been shown that there is no single method that can be called
the best. In recent years, the combination of different classifiers
and the use of contextual information have become major areas of
interest in improving recognition results. This paper addresses a
case study on the combination of multiple classifiers and the integration
of syntactic level information for the recognition of handwritten
Arabic literal amounts. To the best of our knowledge, this is the
first time either of these methods has been applied to Arabic word
recognition. Using three individual classifiers with high level global
features, we performed word recognition experiments. A parallel combination
method was tested for all possible configuration cases of the three
chosen classifiers. A syntactic analyzer makes a final decision on
the candidate words generated by the best configuration scheme. The
effectiveness of contextual knowledge integration in our application
is confirmed by the obtained results.},
author = {Farah, Nadir and Souici, Labiba and Sellami, Mokhtar},
file = {:D$\backslash$:/Papers/Documents/2005/Farah, Souici, Sellami - 2005.pdf:pdf},
journal = {Journal of Computer Science and Technology},
keywords = { Arabic literal amounts, contextual knowledge, multiclassifier systems,handwriting recognition},
month = may,
number = {3},
pages = {402--410},
title = {{Arabic Word Recognition by Classifiers and Context}},
volume = {20},
year = {2005}
}
@article{Khosravi2007,
author = {Khosravi, H and Kabir, E},
doi = {10.1016/j.patrec.2006.12.022},
file = {:D$\backslash$:/Papers/Documents/2007/Khosravi, Kabir - 2007.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {arabic,dataset,digit variety,farsi digits,handwriting,persian},
month = jul,
number = {10},
pages = {1133--1141},
title = {{Introducing a very large dataset of handwritten Farsi digits and a study on their varieties}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865507000037},
volume = {28},
year = {2007}
}
@article{Sezgin2005,
address = {New York, New York, USA},
author = {Sezgin, Tevfik Metin and Davis, Randall},
doi = {10.1145/1040830.1040899},
file = {:D$\backslash$:/Papers/Documents/2005/Sezgin, Davis - 2005(2).pdf:pdf},
isbn = {1581138946},
journal = {Proceedings of the 10th international conference on Intelligent user interfaces - IUI '05},
keywords = {and as,are drawn,enabling input technolo-,gies,important source of,in which the strokes,intelligent user interfaces,interpretation of user input,sketch recognition,stroke ordering is an,we describe below,we know the order},
pages = {281},
publisher = {ACM Press},
title = {{HMM-based efficient sketch recognition}},
url = {http://portal.acm.org/citation.cfm?doid=1040830.1040899},
year = {2005}
}
@article{Amin1998,
abstract = {Machine simulation of human reading has been the subject of intensive research for almost three decades.A large number of research papers and reports have already been published on Latin, Chinese and Japanese characters.However,littlework has been conductedonthe automaticrecognition of Arabic characters because of the complexity of printed and handwritten text, and this problem is still an open research field. The main objective of this paper is to present the state of Arabic character recognition research throughout the last two decades.1998 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved},
author = {Amin, a},
doi = {10.1016/S0031-3203(97)00084-8},
file = {:D$\backslash$:/Papers/Documents/1998/Amin - 1998.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Arabic characters,Feature extraction,Handwriting recognition,Hidden Markov Models,Neural Network classifiers,Off-line recognition,Optical character recognition,Segmentation},
month = mar,
number = {5},
pages = {517--530},
title = {{Off-line Arabic character recognition the state of the art}},
volume = {31},
year = {1998}
}
@article{Eid2007,
address = {New York, New York, USA},
author = {Eid, Mohamad a. and Mansour, Mohamed and {El Saddik}, Abdulmotaleb H. and Iglesias, Rosa},
doi = {10.1145/1290144.1290161},
file = {:D$\backslash$:/Papers/Documents/2007/Eid et al. - 2007.pdf:pdf},
isbn = {9781595937834},
journal = {Proceedings of the international workshop on Educational multimedia and multimedia education - Emme '07},
pages = {103},
publisher = {ACM Press},
title = {{A haptic multimedia handwriting learning system}},
url = {http://portal.acm.org/citation.cfm?doid=1290144.1290161},
year = {2007}
}
@article{Costagliola2004,
author = {Costagliola, G. and Deufemia, V. and Polese, G. and Risi, M.},
doi = {10.1109/VLHCC.2004.3},
file = {:D$\backslash$:/Papers/Documents/2004/Costagliola et al. - 2004.pdf:pdf},
isbn = {0-7803-8696-5},
journal = {2004 IEEE Symposium on Visual Languages - Human Centric Computing},
pages = {19--26},
publisher = {Ieee},
title = {{A Parsing Technique for Sketch Recognition Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1372292},
year = {2004}
}
@article{Ouyang2009,
author = {Ouyang, Jie and Patel, Nilesh and Sethi, Ishwar},
doi = {10.1016/j.patcog.2009.01.033},
file = {:D$\backslash$:/Papers/Documents/2009/Ouyang, Patel, Sethi - 2009.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {distributed data mining},
month = sep,
number = {9},
pages = {1786--1794},
title = {{Induction of multiclass multifeature split decision trees from distributed data}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320309000661},
volume = {42},
year = {2009}
}
@inproceedings{Saloum2001,
abstract = {Z suggest in this paper a method to recognition the Arabic hand-written text. First I explain a one step method for line thinning and introduce the concept of undetermined color in order to reduce the neighborhoods which increase the program speed, then Z spoke about the kind of different critical points which help us in distinguishing a letter from another. Then I gave a suitable method for building the text model on witch the process of recognition will take place.},
author = {Saloum, SS},
booktitle = {Int. Conf Comput. Syst. Appli},
file = {:D$\backslash$:/Papers/Documents/2001/Saloum - 2001.pdf:pdf},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {106--109},
title = {{Arabic hand-written text recognition}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/AICCSA.2001.933959},
year = {2001}
}
@article{Zadrozny2002,
abstract = {This paper presents a method for obtaining class membership probability esti- mates for multiclass classification problems by coupling the probability estimates produced by binary classifiers. This is an extension for arbitrary code matrices of a method due to Hastie and Tibshirani for pairwise coupling of probability estimates. Experimental results with Boosted Naive Bayes show that our method produces calibrated class membership probability estimates, while having similar classification accuracy as loss-based decoding, a method for obtaining the most likely class that does not generate probability estimates},
author = {Zadrozny, Bianca and Elkan, C.},
file = {:D$\backslash$:/Papers/Documents/2002/Zadrozny, Elkan - 2002.pdf:pdf},
journal = {Advances in neural information processing systems},
pages = {1041--1048},
publisher = {Citeseer},
title = {{Reducing multiclass to binary by coupling probability estimates}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.8948\&amp;rep=rep1\&amp;type=pdf},
volume = {2},
year = {2002}
}
@inproceedings{Su2007,
abstract = {A novel recognition strategy is proposed for the transcription of Chinese handwritten documents. The recognizer adapts continuous density Hidden Markov Model (HMM) as the recognition engine. It incorporates character segmentation and recognition in one step avoiding character segmentation phase. Textline is extracted and converted to observation sequence by sliding windows first. Then Baum-Welch algorithm is used to train character HMMs. Finally, best character string in maximizing a posteriori criterion is found out through Viterbi algorithm as output. Experiments are conducted on a writer-dependent Chinese handwriting database with a 1,695 lexicon. The results show that our baseline recognizer outperforms much one popular commercial handwritten character recognition product and the strategy presented in this paper is a promising research direction.},
author = {Su, T.H. and Zhang, T.W. and Qiu, Z.W.},
booktitle = {Machine Learning and Cybernetics, 2007 International Conference on},
file = {:D$\backslash$:/Papers/Documents/2007/Su, Zhang, Qiu - 2007.pdf:pdf},
keywords = {character recognition,chinese characters,handwriting recognition,hidden markov models,optical,sliding},
number = {August},
pages = {3412--3417},
publisher = {IEEE},
title = {{HMM-based system for transcribing Chinese handwriting}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4370738},
volume = {6},
year = {2007}
}
@article{Yan2003,
author = {Yan, Luo},
doi = {10.1109/ICDAR.2003.1227657},
file = {:D$\backslash$:/Papers/Documents/2003/Yan - 2003.pdf:pdf},
isbn = {0-7695-1960-1},
journal = {Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.},
pages = {190--194},
publisher = {IEEE Comput. Soc},
title = {{Engineering drawings recognition using a case-based approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1227657},
year = {2003}
}
@inproceedings{PDB10Bhattacharya2003,
abstract = {This paper proposes a simple voting scheme for off-line recognition
of handprinted numerals. One of the main features of the proposed
scheme is that this is not script dependent. Another interesting
feature is that it is sufficiently fast for real-life applications.
In contrast to the usual practices, here we studied the efficiency
of a majority voting approach when all the classifiers involved are
multilayer perceptron (MLP) of different sizes and respective features
are based on wavelet transforms at different resolution levels. The
rationale for this approach is to explore how one can improve the
recognition performance without adding much to the requirements for
computational time and resources. For simplicity and efficiency,
in the present work, we considered only three coarse-to-fine resolution
levels of wavelet representation. We primarily simulated the proposed
technique on a database of off-line handprinted Bangla (a major Indian
script) numerals. We achieved 97.16\% correct recognition rate on
a test set of 5000 Bangla numerals. In this simulation we used two
other disjoint sets (one for training and the other for validation
purpose) of sizes 6000 and 1000 respectively. We have also tested
our approach on MNIST database for handwritten English digits. The
result is comparable with state-of-the-art technologies.},
address = {Edinburgh, Scotland, UK},
author = {Bhattacharya, Ujjwal and Chaudhuri, B B},
booktitle = {7th International Conference on Document Analysis and Recognition (ICDAR 2003)},
doi = {http://csdl.computer.org/comp/proceedings/icdar/2003/1960/01/196010016abs.htm},
file = {:D$\backslash$:/Papers/Documents/2003/Bhattacharya, Chaudhuri - 2003.pdf:pdf},
isbn = {0-7695-1960-1},
keywords = { Arabic Handwriting, MNIST,MultiClassifier Systems},
month = aug,
pages = {16--20},
publisher = {IEEE Computer Society},
title = {{A Majority Voting Scheme for Multiresolution Recognition of Handprinted Numerals.}},
volume = {2},
year = {2003}
}
@incollection{Sezgin2005ModelingCSW,
author = {Sezgin, Tevfik Metin and Davis, Randall},
booktitle = {CSW '05 Gloucester, MA},
title = {{Modeling Sketching as a Dynamic Process}},
year = {2005}
}
@inproceedings{Zhu2009,
abstract = {Editing a sketch should be one of the essential features provided by sketch recognition systems to allow people to modify what they have drawn, without having to delete and redraw shapes. This paper introduces a control point based editing approach we call RingEdit. RingEdit differs from other sketch editors in that the user actually draws their own control points on the sketch, rather than relying on control points generated by the recognition system. It provides modes that allow moving, rotating, scaling, and bending on both the shape level and stroke level. RingEdit shows great editing capabilities},
address = {Sanibel Island, Florida, USA},
author = {Zhu, Yuxiang and Johnston, Joshua and Hammond, Tracy},
booktitle = {IUI 2009 , Workshop on Sketch Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Zhu, Johnston, Hammond - 2009.pdf:pdf},
keywords = {Sketch recognition,control points,sketch editing},
pages = {1},
title = {{RingEdit: A Control Point Based Editing Approach in Sketch Recognition Systems}},
url = {http://srl.csdl.tamu.edu/workshops/2009/iui/finalPapers/Zhu.pdf},
year = {2009}
}
@article{PDBSRIKANTAN1996,
author = {SRIKANTAN, GEETHA and LAM, STEPHEN W and SRIHARI, SARGUR N},
file = {:D$\backslash$:/Papers/Documents/1996/SRIKANTAN, LAM, SRIHARI - 1996.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Read},
mendeley-tags = {Read},
number = {7},
pages = {1147--1160},
title = {{GRADIENT-BASED CONTOUR ENCODING FOR CHARACTER RECOGNITION}},
volume = {29},
year = {1996}
}
@article{Al-Ohali2003,
author = {Al-Ohali, Y. and Cheriet, Mohamed and Suen, Ching},
file = {:D$\backslash$:/Papers/Documents/2003/Al-Ohali, Cheriet, Suen - 2003.pdf:pdf},
journal = {Pattern Recognition},
keywords = {arabic ocr,cheque processing,database of indian digits,databases of arabic handwriting,image processing},
number = {1},
pages = {111--122},
publisher = {Citeseer},
title = {{Databases for recognition of handwritten Arabic cheques}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.2091\&amp;rep=rep1\&amp;type=pdf},
volume = {36},
year = {2003}
}
@inproceedings{Srihari2006,
author = {Srihari, S.N. and Ball, G.R. and Srinivasan, Harish},
booktitle = {Proceedings of the 2006 conference on Arabic and Chinese handwriting recognition},
file = {:D$\backslash$:/Papers/Documents/2006/Srihari, Ball, Srinivasan - 2006.pdf:pdf},
pages = {57--69},
publisher = {Springer-Verlag},
title = {{Versatile search of scanned Arabic handwriting}},
url = {http://portal.acm.org/citation.cfm?id=1792262.1792266},
year = {2006}
}
@article{Yu2003,
address = {New York, New York, USA},
author = {Yu, Bo and Cai, Shijie},
doi = {10.1145/604471.604499},
file = {:D$\backslash$:/Papers/Documents/2003/Yu, Cai - 2003.pdf:pdf},
isbn = {1581135785},
journal = {Proceedings of the 1st international conference on Computer graphics and interactive techniques in Austalasia and South East Asia - GRAPHITE '03},
keywords = {1,a new sketching interface,arvo and novins described,different from traditional ways,graphics recognition,hci,in,multimodal interface,of recognizing sketches,sketch recognition,their},
pages = {141},
publisher = {ACM Press},
title = {{A domain-independent system for sketch recognition}},
url = {http://portal.acm.org/citation.cfm?doid=604471.604499},
year = {2003}
}
@phdthesis{Foltz2003DrJones,
author = {Foltz, Mark},
file = {:D$\backslash$:/Papers/Documents/2003/Foltz - 2003.pdf:pdf},
month = aug,
school = {Massachusetts Institute of Technology},
title = {{Dr. Jones: A software Design Explorer's Crystal Ball}},
year = {2003}
}
@article{Hammond2008b,
author = {Hammond, Tracy and Davis, Randall},
file = {:D$\backslash$:/Papers/Documents/2008/Hammond, Davis - 2008.pdf:pdf},
journal = {Artificial Intelligence},
number = {September},
pages = {2--3},
publisher = {Citeseer},
title = {{Debugging Shape Definitions for use in Sketch Recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.128.662\&amp;rep=rep1\&amp;type=pdf},
year = {2008}
}
@article{Kasturi1997,
author = {Kasturi, R. and Luo, H.},
file = {:D$\backslash$:/Papers/Documents/1997/Kasturi, Luo - 1997.pdf:pdf},
isbn = {0780377508},
issn = {1522-4880},
journal = {Advances in Document Image Analysis},
pages = {99--110},
publisher = {Springer},
title = {{Research advances in graphics recognition: An update}},
url = {http://www.springerlink.com/index/cj7426054675u26m.pdf},
volume = {2},
year = {1997}
}
@conference{ARDC2009,
abstract = {A new method for recognition of isolated handwritten English digits
is presented here. This method is based on Support Vector Machines
(SVMs). Mean and standard deviation of each digit is considered as
the features. Using these features, multiple SVM classifiers are
trained to separate different classes of digits. Support vector machine
are based on the concept of decision planes that defines the decision
boundaries. The decision plane is one that separates between the
set of digits having different class membership. The approach works
in four steps 1) Preprocessing 2) Feature extraction 3) Classification
4) detection. A database of 100 different representation of each
digit is constructed for the training database. The digits are first
manually segmented into 5 classes to minimize the time required to
obtain the hyperplane. Then the input is again check against the
two classes by 2-class SVM classifier. Experiments show that the
proposed features can provide a very good recognition result using
Support Vector Machines at a recognition rate 97\%, compared with
91.25\% obtained by MLP neural network classifier using the same features
and test set.},
author = {C, Shubhangi D and Hiremath, P S},
booktitle = {International Conference on Advances in Computing, Communication and Control (ICAC3�09)},
file = {:D$\backslash$:/Papers/Documents/2009/C, Hiremath - 2009.pdf:pdf},
keywords = { English handwritten digits, structural features,Multi-class SVM classifier},
title = {{Multi-Class SVM Classifier for English Handwritten Digit Recognition using Manual Class Segmentation}},
year = {2009}
}
@article{Wang2009,
author = {Wang, Yanjie and Liu, Xiabi and Jia, Yunde},
doi = {10.1109/ICDAR.2009.25},
file = {:D$\backslash$:/Papers/Documents/2009/Wang, Liu, Jia - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {421--425},
publisher = {Ieee},
title = {{Statistical Modeling and Learning for Recognition-Based Handwritten Numeral String Segmentation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277643},
year = {2009}
}
@inproceedings{Said1999,
abstract = {The p ap er intr duc o es a metho d of nding the neigh b orho d of the optimal numb o er of hidden neur ons for 70 an err or b ackpr op agation neur al network with a sin gle hidden layer It is b ase d on a study of the curva tur e of the err or function during the tr aining phase 60 of the network The metho d assur es c onver genc e and byp asses lo al minimas Exp c erimental r esults show the 50 uniqueness of the metho ds solution r gar e dless of the initial values of the networks p ar ameters Two neur al 40 networks wer e built one for r c gnizing unc e o onstr aine d handwritten English numer als and the other for A a r bic numer als R c gnition r e o esults and c omp arison with 30 other metho ds ar e also pr esente d 20},
author = {Said, F.N. and Yacoub, A. and Suen, C.Y.},
booktitle = {Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318)},
doi = {10.1109/ICDAR.1999.791768},
file = {:D$\backslash$:/Papers/Documents/1999/Said, Yacoub, Suen - 1999.pdf:pdf},
isbn = {0-7695-0318-7},
keywords = {Reference From Doctor,character recognition,english and},
mendeley-tags = {Reference From Doctor},
pages = {237--240},
publisher = {Ieee},
title = {{Recognition of English and Arabic numerals using a dynamic number of hidden neurons}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=791768},
year = {1999}
}
@inproceedings{Paulson2008b,
author = {Paulson, Brandon and Wolin, Aaron and Johnston, Joshua and Hammond, Tracy},
booktitle = {EUROGRAPHICS Workshop on Sketch-Based Interfaces and Modeling},
file = {:D$\backslash$:/Papers/Documents/2008/Paulson et al. - 2008.pdf:pdf},
title = {{SOUSA: Sketch-based online user study applet}},
url = {http://srlweb.cs.tamu.edu/srlng\_media/content/objects/object-1233782946-9a475f350ea72659f00fb886bbf37ec1/Paulson\_SBIM08.pdf},
year = {2008}
}
@inproceedings{PDB19Madeed2004,
abstract = {In this paper we present a new database for off-line Arabic handwriting
recognition, together with associated preprocessing procedures. We
have developed a new database for the collection, storage and retrieval
of Arabic handwritten text (AHDB). This is an advance both in terms
of the size of the database as well as the number of different writers
involved. We further designed an innovative, simple yet powerful,
in place tagging procedure for our database. It enables us to easily
extract the bitmaps of words. We also constructed a preprocessing
class, which contains some useful preprocessing operations. In this
paper the most popular words in Arabic writing were identified for
the first time, using an associated program.},
author = {Al-M\'{a}adeed, Somaya and Elliman, Dave and Higgins, Colin},
booktitle = {Int. Arab J. Inf. Technol.},
doi = {http://www.iajit.org/ABSTRACTS-1.htm\#06},
file = {:D$\backslash$:/Papers/Documents/2004/Al-M\'{a}adeed, Elliman, Higgins - 2004.pdf:pdf},
number = {1},
title = {{A Data Base for Arabic Handwritten Text Recognition Research.}},
volume = {1},
year = {2004}
}
@incollection{Alvarado2000Intelligent,
author = {Alvarado, Christine and Davis, Randall},
booktitle = {MIT Artificial Intelligence Laboratory Annual Abstract},
month = sep,
publisher = {MIT AI Lab},
title = {{Intelligent Mechanical Engineering Design Environment: From sketching to simulation}},
year = {2000}
}
@incollection{DSCheriet2008,
abstract = {Automatic recognition of Arabic handwritten text presents a problem
worth solving; it has increasingly more interest, especially in recent
years. In this paper, we address the most frequently encountered
problems when dealing with Arabic handwriting recognition, and we
briefly present some lessons learned from several serious attempts.
We show why morphological analysis of Arabic handwriting could improve
the accuracy of Arabic handwriting recognition. In general, Arabic
Natural Language Processing could provide some error handling techniques
that could be used effectively to improve the overall accuracy during
post-processing. We give a summary of techniques concerning Arabic
handwriting recognition research. We conclude with a case study about
the recognition of Tunisian city names, and place emphasis on visual-based
strategies for Arabic Handwriting Recognition (AHR).},
author = {Cheriet, Mohamed},
booktitle = {Arabic and Chinese Handwriting Recognition},
file = {:D$\backslash$:/Papers/Documents/2008/Cheriet - 2008.pdf:pdf},
pages = {1--21},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Visual Recognition of Arabic Handwriting: Challenges and New Directions}},
volume = {4768},
year = {2008}
}
@article{Stahovich1998,
author = {Stahovich, T},
doi = {10.1016/S0004-3702(98)00058-7},
file = {:D$\backslash$:/Papers/Documents/1998/Stahovich - 1998.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {design generalization,mechanical design,qualitative geometric reasoning,sketch understanding},
month = sep,
number = {1-2},
pages = {211--264},
title = {{Generating multiple new designs from a sketch}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370298000587},
volume = {104},
year = {1998}
}
@article{Sivagaminathan2007,
author = {Sivagaminathan, R.K. and Ramakrishnan, Sreeram},
doi = {10.1016/j.eswa.2006.04.010},
file = {:D$\backslash$:/Papers/Documents/2007/Sivagaminathan, Ramakrishnan - 2007.pdf:pdf},
issn = {0957-4174},
journal = {Expert Systems with Applications},
keywords = {ant colony optimization,feature subset selection,neural networks},
number = {1},
pages = {49--60},
publisher = {Elsevier},
title = {{A hybrid approach for feature subset selection using neural networks and ant colony optimization}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0957417406001187},
volume = {33},
year = {2007}
}
@inproceedings{Forbus2001,
abstract = {Many Qualitative Reasoning Group Northwestern University 1890 Maple Avenue Evanston, IL 60201 USA +1 847 491 7699 usher@northwestern.edu concepts and situations are best explained by sketching. This paper describes our work on sKEA, the sketching Knowledge Entry Associate, a system designed for knowledge capture via sketching. We discuss the key ideas of sKEA: blob semantics for glyphs to sidestep recognition for visual symbols, qualitative spatial reasoning to provide richer visual and conceptual understanding of what is being communicated, arrows to express domain relationships, layers to express within-sketch segmentation (including a meta-layer to express subsketch relationships themselves via sketching), and analogical comparison to explore similarities and differences between sketched concepts. Experiences with sKEA to date and future plans are also discussed.},
address = {San Franciso, California, USA},
author = {Forbus, Kenneth D and Usher, Jeffrey},
booktitle = {IUT 2002, January, 13-15, San Franciso},
editor = {ACM},
file = {:D$\backslash$:/Papers/Documents/2001/Forbus, Usher - 2001.pdf:pdf},
keywords = {a large knowledge base,and cml,annotations is drawn from,files in kif,meld,skea can produce flat,the cases,the knowledge base,they produce can in,turn be added to},
pages = {71--77},
title = {{Sketching for Knowledge Capture : A progress report}},
year = {2001}
}
@article{Ishida2010,
abstract = {We propose a novel sequence alignment algorithm for recognizing handwriting gestures by a camera. In the proposed method, an input image sequence is aligned to the reference sequences by phase- synchronization of analytic signals which are transformed from original feature values. A cumulative distance is calculated simultaneously with the alignment process, and then used for the classification. A major benefit of this method is that over-fitting to sequences of incorrect categories is restricted. The proposed method exhibited higher recognition accuracy in handwriting gesture recognition, compared with the conventional dynamic time warping method which explores optimal alignment results for all categories.},
author = {Ishida, Hiroyuki and Takahashi, Tomokazu and Ide, Ichiro and Murase, Hiroshi},
doi = {10.1016/j.patcog.2010.02.021},
file = {:D$\backslash$:/Papers/Documents/2010/Ishida et al. - 2010.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Analytic signal,Classification method,Gesture recognition,Sequence alignment},
month = aug,
number = {8},
pages = {2799--2806},
publisher = {Elsevier},
title = {{A Hilbert warping method for handwriting gesture recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320310001007},
volume = {43},
year = {2010}
}
@inproceedings{Citrin1996,
abstract = {We present a system supporting pen-based input and diagram recognition that employs a personal digital assistant (PDA) as an intelligent input device for the system. Functionality is distributed between the PDA and the main computer, with the PDA performing low-level shape recognition and editing functions, and the back-end computer performing high-level recognition functions, including recognition of spatial relations between picture elements. This organization provides a number of advantages over conventional pen-based systems employing simple digitizing tablets. It provides the opportunity to use hardware specially designed for shape recognition and editing in a general diagram recognition system, it allows for improved performance through parallel processing, and it allows diagram entry to be performed remotely through use of the PDA front end in the field, with recognized shapes subsequently downloaded to the main diagram recognizer. We discuss the overall organization of the system, as well as the individual pieces and the communication between them, and describe two ongoing projects employing this architecture.},
author = {Citrin, Wayne},
booktitle = {Proceedings of the workshop on Advanced},
file = {:D$\backslash$:/Papers/Documents/1996/Citrin - 1996.pdf:pdf},
keywords = {diagram recognition,graphical editors,pen-based interfaces},
pages = {132--140},
title = {{Distributed architectures for pen-based input and diagram recognition}},
url = {http://portal.acm.org/citation.cfm?id=948470},
year = {1996}
}
@inproceedings{ARSabri2006,
abstract = {Arabic character recognition algorithm using Modified Fourier Spectrum
(MFS) is presented. The MFS descriptors are estimated by applying
the Fast Fourier Transform (FFT) to the Arabic character primary
part contour. Ten descriptors are estimated from the Fourier spectrum
of the character primary part contour by subtracting the imaginary
part from the real part (and not from the amplitude of the Fourier
spectrum as is usually the case). These descriptors are then used
in the training and testing of Arabic characters. The computation
of the MFS descriptors requires less computation time than the computation
of the Fourier descriptors. Experimental results have shown that
the MFS features are suitable for Arabic character recognition. Average
recognition rate of 95.9\% was achieved for the model classes. The
analysis of the errors indicates that this recognition rate can be
improved by using the �hole� feature of a character and use cleaning
corrupted data.},
address = {London, UK},
author = {Mahmoud, Sabri A and Mahmoud, Ashraf S},
booktitle = {2006 International Conference on Geometric Modeling and Imaging (GMAI 2006)},
doi = {http://doi.ieeecomputersociety.org/10.1109/GMAI.2006.8},
file = {:D$\backslash$:/Papers/Documents/2006/Mahmoud, Mahmoud - 2006.pdf:pdf},
isbn = {0-7695-2604-7},
pages = {155--159},
publisher = {IEEE Computer Society},
title = {{Arabic Character Recognition using Modified Fourier Spectrum (MFS).}},
year = {2006}
}
@article{Natarajan2009,
author = {Natarajan, Prem and Subramanian, Krishna and Bhardwaj, Anurag and Prasad, Rohit},
doi = {10.1109/ICDAR.2009.278},
file = {:D$\backslash$:/Papers/Documents/2009/Natarajan et al. - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {971--975},
publisher = {Ieee},
title = {{Stochastic Segment Modeling for Offline Handwriting Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277556},
year = {2009}
}
@article{Hamid2001,
abstract = {The segmentation and recognition of Arabic handwritten text has been an area of great interest in the past few years. However, a small number of research papers and reports have been published in this area due to the dificult problems associated with Arabic handwritten text processing. In this work a technique is presented that segments handwritten Arabic text. A conventional algorithm is used for the initial segmentation of the text into connected blocks of characters. The algorithm then generates pre- segmentation points for these blocks. A neural network is subsequently used to verify the accuracy of these segmentation points. Two major problems were encountered: The segmentation phase proved to be successful in vertical segmentation of connected blocks of characters. However, it couldn’t segment characters that were overlapping horizontally. Second, segmentation of handwritten Arabic text depends largely on contextual information, and not only on topographic features extracted from these characters.},
author = {Hamid, a. and Haraty, R.},
doi = {10.1109/AICCSA.2001.933960},
file = {:D$\backslash$:/Papers/Documents/2001/Hamid, Haraty - 2001.pdf:pdf},
isbn = {0-7695-1165-1},
journal = {Proceedings ACS/IEEE International Conference on Computer Systems and Applications},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {110--113},
publisher = {IEEE Comput. Soc},
title = {{A neuro-heuristic approach for segmenting handwritten Arabic text}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=933960},
year = {2001}
}
@article{Seung2000,
author = {Seung, H.S. and Lee, D.D.},
file = {:D$\backslash$:/Papers/Documents/2000/Seung, Lee - 2000.pdf:pdf},
issn = {0036-8075},
journal = {Science(Washington)},
number = {5500},
pages = {2268--9},
publisher = {American Association for the Advancement of Science, 1333 H St, NW, 8 th Floor, Washington, DC, 20005, USA},
title = {{The manifold ways of perception}},
url = {http://www.iipl.fudan.edu.cn/\~{}zhangjp/literatures/Principal Curves/The Manifold Ways of Perception.doc},
volume = {290},
year = {2000}
}
@article{DSZhou2002,
abstract = {This paper investigates verification schemes and their applications
to the recognition of both isolated and touching handwritten numerals.
Definitions and functionality analyses of the verifiers are given.
The measurement of precision rate is used to assess the system reliability
in a class-specific manner. Verification-enhanced systems are proposed
with extensive experiments conducted on both isolated and touching
numerals. Two databases for touching numerals are built/organized
to serve as standard data sets. Experimental results indicate a substantial
improvement in system precision rates by the verification scheme,
which proves the effectiveness of the proposed systems and justifies
the important role of verifiers in OCR systems.},
author = {Zhou, Jie and Krzyzak, Adam and Suen, Ching Y},
doi = {DOI: 10.1016/S0031-3203(01)00109-1},
file = {:D$\backslash$:/Papers/Documents/2002/Zhou, Krzyzak, Suen - 2002.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {Handwritten numerals recognition},
number = {5},
pages = {1179--1189},
title = {{Verification--a method of enhancing the recognizers of isolated and touching handwritten numerals}},
url = {http://www.sciencedirect.com/science/article/B6V14-454609Y-K/2/1325f84ab8bc2015a1ff4639d7f3ccda},
volume = {35},
year = {2002}
}
@article{Cheriet2009,
author = {Cheriet, Mohamed and Bunke, Horst and Hu, Jianying and Kimura, Fumitaka and Suen, Ching Y.},
doi = {10.1016/j.patcog.2009.03.013},
file = {:D$\backslash$:/Papers/Documents/2009/Cheriet et al. - 2009.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
month = dec,
number = {12},
pages = {3129--3130},
publisher = {Elsevier},
title = {{New Frontiers in Handwriting Recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320309000971},
volume = {42},
year = {2009}
}
@article{Abed2007,
author = {Abed, Haikal El},
file = {:D$\backslash$:/Papers/Documents/2007/Abed - 2007.pdf:pdf},
journal = {Analysis},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {2--6},
title = {{ICDAR 2007 - Arabic Handwriting Recognition Competition}},
year = {2007}
}
@article{Bailey1999,
address = {New York, New York, USA},
author = {Bailey, Brian},
doi = {10.1145/319878.319943},
file = {:D$\backslash$:/Papers/Documents/1999/Bailey - 1999.pdf:pdf},
isbn = {1581132395},
journal = {Proceedings of the seventh ACM international conference on Multimedia (Part 2) - MULTIMEDIA '99},
pages = {205--206},
publisher = {ACM Press},
title = {{Interactive sketching of multimedia storyboards}},
url = {http://portal.acm.org/citation.cfm?doid=319878.319943},
year = {1999}
}
@incollection{Hammond2004TestingAbstract,
author = {Hammond, Tracy and Davis, Randall},
booktitle = {MIT Computer Science and Artificial Intelligence Laboratory Annual Research Abstract},
file = {:D$\backslash$:/Papers/Documents/2004/Hammond, Davis - 2004(2).pdf:pdf},
keywords = {multimodal},
month = sep,
publisher = {MIT CSAIL},
title = {{Testing Shape Descriptions by Automatically Translating them for Use in Sketch Recognition}},
year = {2004}
}
@article{Kosmala,
author = {Kosmala, Andreas and Rigoll, Gerhard},
file = {:D$\backslash$:/Papers/Documents/Unknown/Kosmala, Rigoll - Unknown.pdf:pdf},
journal = {Signal Processing},
pages = {1--3},
title = {{On-Line Handwritten Formula Recognition Using Statistical Methods}}
}
@inproceedings{DSGuillevic1994,
abstract = {We describe the cursive script recognition module of a cheque processing
system currently under development at the Centre for Pattern Recognition
and Machine Intelligence (CENPARMI). Common systems perform recognition
either on a character by character basis, or on a word level. The
present study investigates the recognition at a higher level of abstraction,
at the sentence level. Our computational theory is based on a psychological
model of the reading process of a fast reader. In this paper, we
discuss the processing of the legal amount written on cheques. The
preprocessing and feature extraction modules as well as the word
classifier are presented. Preliminary results are not only promising,
but they also support our computational theory},
author = {Guillevic, Didier and Suen, Ching Y},
booktitle = {In International Workshop on Frontiers of Handwriting Recognition},
file = {:D$\backslash$:/Papers/Documents/1994/Guillevic, Suen - 1994.pdf:pdf},
pages = {216--223},
title = {{Cursive Script Recognition: A Sentence Level Recognition Scheme}},
year = {1994}
}
@article{Intrator1999,
author = {Intrator, Nathan and Steinherz, Tal and Rivlin, Ehud},
doi = {10.1007/s100320050040},
file = {:D$\backslash$:/Papers/Documents/1999/Intrator, Steinherz, Rivlin - 1999.pdf:pdf},
issn = {1433-2833},
journal = {International Journal on Document Analysis and Recognition},
keywords = {Reference From Doctor,cursive,handwritten,offline,recognition,segmentation,survey,word},
mendeley-tags = {Reference From Doctor},
month = dec,
number = {2-3},
pages = {90--110},
title = {{Offline cursive script word recognition ? a survey}},
url = {http://www.springerlink.com/Index/10.1007/s100320050040},
volume = {2},
year = {1999}
}
@article{Adler2004,
author = {Adler, Aaron and Eisenstein, Jacob and Oltmans, Michael and Guttentag, Lisa and Davis, Randall},
file = {:D$\backslash$:/Papers/Documents/2004/Adler et al. - 2004.pdf:pdf},
journal = {Making Pen-Based Interaction Intelligent and Natural},
pages = {1--7},
title = {{Building the design studio of the future}},
url = {http://www.aaai.org/Papers/Symposia/Fall/2004/FS-04-06/FS04-06-001.pdf},
year = {2004}
}
@article{Kara2005,
author = {Kara, L and Stahovich, T},
doi = {10.1016/j.cag.2005.05.004},
file = {:D$\backslash$:/Papers/Documents/2005/Kara, Stahovich - 2005.pdf:pdf},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {hausdorff distance,pattern recognition,pen computing,polar transform,sketch understanding,symbol recognition,tanimoto coefficient,yule coefficient},
month = aug,
number = {4},
pages = {501--517},
title = {{An image-based, trainable symbol recognizer for hand-drawn sketches}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849305000853},
volume = {29},
year = {2005}
}
@article{Yu2003a,
address = {New York, New York, USA},
author = {Yu, Bo},
doi = {10.1145/604045.604077},
file = {:D$\backslash$:/Papers/Documents/2003/Yu - 2003.pdf:pdf},
isbn = {1581135866},
journal = {Proceedings of the 8th international conference on Intelligent user interfaces - IUI '03},
keywords = {hci,mean shift,multimodal interface,sketch recognition},
pages = {204},
publisher = {ACM Press},
title = {{Recognition of freehand sketches using mean shift}},
url = {http://portal.acm.org/citation.cfm?doid=604045.604077},
year = {2003}
}
@article{Saund1994,
address = {New York, New York, USA},
author = {Saund, Eric and Moran, Thomas P.},
doi = {10.1145/192426.192494},
file = {:D$\backslash$:/Papers/Documents/1994/Saund, Moran - 1994.pdf:pdf},
isbn = {0897916573},
journal = {Proceedings of the 7th annual ACM symposium on User interface software and technology - UIST '94},
pages = {175--184},
publisher = {ACM Press},
title = {{A perceptually-supported sketch editor}},
url = {http://portal.acm.org/citation.cfm?doid=192426.192494},
year = {1994}
}
@conference{ARBenjelil2009,
abstract = {Arabic and Latin script identification in printed and handwritten
nature present several difficulties because the Arabic (printed or
handwritten) and the handwritten Latin scripts are cursive scripts
of nature. To avoid all possible confusions which can be generated,
we propose in this paper an accurate and suitable designed system
for script identification at word level which is based on steerable
pyramid transform. The features extracted from pyramid sub bands
serve to classify the scripts on only one script among the scripts
to identify. The encouraging and promising results obtained are presented
in this research paper.},
author = {Benjelil, Mohamed and Kanoun, Slim and Mullot, R�my and Alimi, Adel M},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Benjelil et al. - 2009.pdf:pdf},
title = {{Arabic and Latin script identification in printed and handwritten types Based on Steerable Pyramid Features}},
year = {2009}
}
@article{ARZiaratban2008,
abstract = {In this study, a structural method described with

statistical features is proposed for isolated Farsi/Arabic

handwritten character recognition. All the character�s dots

are first removed, and the character�s body is thinned. A

set of feature points are then extracted and the skeleton is

decomposed into segments named primitives. Novel

statistical features are extracted from each segment. Three

basic characteristics behind the extracted features can

accurately describe the direction and curvatures of each

primitive. Since the numbers of primitives for characters

are not the same, three algorithms are applied to equalize

the lengths of features. Also another method is used for

reducing the recognition time based on the size of the

feature vectors.

Experimental results show the prominence of the

proposed features. The best recognition rate is obtained by

using the PCA algorithm for equalizing the feature vectors

that is 1.34\% more than wavelet features. Our dataset

includes 19118 samples. We used 11471 samples for

training and the rest (7647) for test.},
author = {Ziaratban, Majid and Faez, Karim and Allahveiradi, Farshid},
file = {:D$\backslash$:/Papers/Documents/2008/Ziaratban, Faez, Allahveiradi - 2008.pdf:pdf},
keywords = { Statistical description, hybrid feature extraction.,Farsi handwritten},
title = {{Novel Statistical Description for the Structure of Isolated Farsi/Arabic Handwritten Characters}},
year = {2008}
}
@article{LaViolaJr2004,
author = {{LaViola Jr}, J.J. and Zeleznik, R.C.},
file = {:D$\backslash$:/Papers/Documents/2004/LaViola Jr, Zeleznik - 2004.pdf:pdf},
issn = {0730-0301},
journal = {ACM Transactions on Graphics (TOG)},
number = {3},
pages = {432--440},
publisher = {ACM},
title = {{MathPad 2: a system for the creation and exploration of mathematical sketches}},
url = {http://portal.acm.org/citation.cfm?id=1015741},
volume = {23},
year = {2004}
}
@article{ARCheriet2009b,
abstract = {CFHR 2008 Panel Discussion},
author = {Cheriet, Mohamed and MounimElYacoubi and Fujisawa, Hiromichi and Lopresti, Daniel and Lorette, Guy},
file = {:D$\backslash$:/Papers/Documents/2008/Cheriet et al. - 2008.pdf:pdf},
journal = {Pattern Recognition},
number = {12},
pages = {3131--3135},
title = {{Handwriting recognition research:Twenty years of achievement...and beyond}},
volume = {42},
year = {2008}
}
@article{Pusch2007,
author = {Pusch, R. and Samavati, Faramarz and Nasri, A. and Wyvill, B.},
file = {:D$\backslash$:/Papers/Documents/2007/Pusch et al. - 2007.pdf:pdf},
journal = {The Visual Computer},
keywords = {Background knowledge,Doctor Samavati,Scholarships Doctors,To Read},
mendeley-tags = {Background knowledge,Scholarships Doctors,To Read},
number = {9-11},
pages = {955--962},
title = {{Improving the Sketch based Interface Forming Curves from Many Small Strokes}},
volume = {23},
year = {2007}
}
@article{Hammond2008a,
author = {Hammond, Tracy and Gajos, Krzysztof and Davis, Randall and Shrobe, Howard},
file = {:D$\backslash$:/Papers/Documents/2008/Hammond et al. - 2008(2).pdf:pdf},
journal = {Symposium A Quarterly Journal In Modern Foreign Literatures},
pages = {379--381},
publisher = {Citeseer},
title = {{Sketch Recognition in Software Design}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.123.7525\&amp;rep=rep1\&amp;type=pdf},
year = {2008}
}
@article{Kara2004,
address = {New York, New York, USA},
author = {Kara, Levent Burak and Stahovich, Thomas F},
doi = {10.1145/1029632.1029636},
file = {:D$\backslash$:/Papers/Documents/2004/Kara, Stahovich - 2004(3).pdf:pdf},
isbn = {1581139578},
journal = {Proceedings of the 17th annual ACM symposium on User interface software and technology - UIST '04},
pages = {13},
publisher = {ACM Press},
title = {{Hierarchical parsing and recognition of hand-sketched diagrams}},
url = {http://portal.acm.org/citation.cfm?doid=1029632.1029636},
year = {2004}
}
@article{Park1996,
abstract = {There are many uncertainties in handwritten character recognition. Stochastic modeling is a flexible and general method for modeling such problems and entails the use of probabilistic models to deal with uncertain or incomplete information. This paper presents an efficient scheme for off-line recognition of large-set handwritten characters in the framework of stochastic models, the first-order hidden Markov models (HMMs). To facilitate the processing of unconnected patterns and patterns with isolated noises, four types of feature vectors based on the regional projection contour transformation (RPCT) are employed. The recognition system consists of two phases. For each character, in the training phase, multiple HMMs corresponding to different feature types of RPCT are built. In the classification phase, the results of individual classifiers to produce the final recognition result for an input character are integrated, where each individual HMM classifier produces one score that is the probability of generating the test observation sequence for each character model. In this paper, several methods for integrating the results of different classifiers are considered so that a better result could be obtained. In order to verify the effectiveness of the proposed scheme, the most frequently used 520 types of Hangul characters in Korea have been considered in the experiments. Experimental results indicate that the proposed scheme is very promising for the recognition of large-set handwritten characters with numerous variations},
author = {Park, H},
doi = {10.1016/0031-3203(95)00081-X},
file = {:D$\backslash$:/Papers/Documents/1996/Park - 1996.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Regional projection contour transformation,hidden markov model,large set handwritten character recognition,multiple classifier combination},
month = feb,
number = {2},
pages = {231--244},
title = {{Off-line recognition of large-set handwritten characters with multiple hidden Markov models}},
volume = {29},
year = {1996}
}
@conference{ARKESSENTINI2009,
abstract = {Generally, handwritten word recognition systems use script specific
methodologies. In this paper, we present a unified approach for multi-lingual
recognition of alphabetic scripts. The proposed system operates independently
of the nature of the script using the multi-stream paradigm. The
experiments have been carried out on a multi-script database composed
of Arabic and Latin handwritten words from the IFN/ENIT and the IRONOFF
public databases and show interesting recognition performances with
only 1.5\% of script confusion and an overall word recognition rate
of 84.5\% using a multi-script lexicon of 1142 words.},
author = {KESSENTIN, Yousri and PAQUET, Thierry and HAMADOU, AbdelMajid B E N},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/KESSENTIN, PAQUET, HAMADOU - 2009.pdf:pdf},
title = {{A Multi-Lingual Recognition System for Arabic and Latin Handwriting}},
year = {2009}
}
@article{DSHussein1999,
abstract = {A knowledge-based segmentation algorithm to enhance recognition of
courtesy amounts on bank checks is proposed in this paper. This algorithm
uses multiple contextual cues to enhance segmentation and recognition.
The system described extracts context from the handwritten numerals
and uses a syntax parser based on a deterministic finite automaton
to provide adequate feedback to enhance recognition. Further feedback
is provided by a simple legal amount decoder that determines word
count and recognizes several key words (e.g. thousand and hundred).
This provides an additional semantic constraint on the dollar section.
The segmentation analysis module presented is capable of handling
a number of commonly used styles for courtesy amount representation.
Both handwritten and machine written courtesy and legal amounts were
utilized to test the efficacy of the preprocessor for the check recognition
system described in this paper. The substitution error was reduced
by 30-40\% depending on the input check mix.},
annote = {Last edited 2 march 2010},
author = {Hussein, Karim M and Agarwal, Arun and Gupta, Amar and Wang, Patrick S P},
doi = {DOI: 10.1016/S0031-3203(98)00073-9},
file = {:D$\backslash$:/Papers/Documents/1999/Hussein et al. - 1999.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {Automata},
number = {2},
pages = {305--316},
title = {{A knowledge-based segmentation algorithm for enhanced recognition of handwritten courtesy amounts}},
url = {http://www.sciencedirect.com/science/article/B6V14-3W83VC2-1B/2/dd26998d2d5e3249216f915288abeb37},
volume = {32},
year = {1999}
}
@article{Turquin2007,
author = {Turquin, E. and Wither, J. and Boissieux, L. and Cani, M.P. and Hughes, J.F.},
file = {:D$\backslash$:/Papers/Documents/2007/Turquin et al. - 2007.pdf:pdf},
issn = {0272-1716},
journal = {IEEE Computer graphics and applications},
number = {February},
pages = {72--81},
publisher = {IEEE Computer Society},
title = {{A sketch-based interface for clothing virtual characters}},
url = {http://doi.ieeecomputersociety.org/10.1109/10.1109/MCG.2007.1},
year = {2007}
}
@article{Zhang2005,
author = {Zhang, P and Bui, TD and Suen, CY},
file = {:D$\backslash$:/Papers/Documents/2005/Zhang, Bui, Suen - 2005.pdf:pdf},
journal = {Analysis},
keywords = {hybrid feature extraction,random feature},
publisher = {IEEE Computer Society},
title = {{Hybrid feature extraction and feature selection for improving recognition accuracy of handwritten numerals}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICDAR.2005.129},
year = {2005}
}
@article{Ahn2001,
abstract = {The least-squares fitting minimizes the squares sum of error-of-fit in predefined measures. By the geometric fitting, the error distances are defined with the orthogonal, or shortest, distances from the given points to the geometric feature to be fitted. For the geometric fitting of circle/sphere/ellipse/hyperbola/parabola, simple and robust nonparametric algorithms are proposed. These are based on the coordinate description of the corresponding point on the geometric feature for the given point, where the connecting line of the two points is the shortest path from the given point to the geometric feature to be fitted.},
author = {Ahn, Sung Joon and Rauh, Wolfgang and Warnecke, Hans-J\"{u}rgen},
doi = {10.1016/S0031-3203(00)00152-7},
file = {:D$\backslash$:/Papers/Documents/2001/Ahn, Rauh, Warnecke - 2001.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {circle fitting,conic fitting,gauss–newton iteration,nonlinear least squares,orthogonal contacting condition,orthogonal distance fitting,singular value decomposition,sphere fitting},
month = dec,
number = {12},
pages = {2283--2303},
title = {{Least-squares orthogonal distances fitting of circle, sphere, ellipse, hyperbola, and parabola}},
url = {http://dx.doi.org/10.1016/S0031-3203(00)00152-7},
volume = {34},
year = {2001}
}
@inproceedings{Paulson2008a,
author = {Paulson, Brandon and Rajan, Pankaj and Davalos, Pedro and Gutierrez-Osuna, R. and Hammond, Tracy},
booktitle = {Workshop on Sketch Tools for Diagramming (VL/HCC’08)},
file = {:D$\backslash$:/Papers/Documents/2008/Paulson et al. - 2008(2).pdf:pdf},
pages = {57--63},
title = {{What!?! no Rubine features?: using geometric-based features to produce normalized confidence values for sketch recognition}},
url = {http://srl.csdl.tamu.edu/courses/SR2008/papers/others/PaulsonVL-HCC08.pdf},
year = {2008}
}
@inproceedings{Eisenstein2003Natural,
address = {New York, New York},
author = {Eisenstein, Jacob and Davis, Randall},
booktitle = {Supplementary Proceedings of the ACM Symposium on User Interface Software and Techology (\{UIST'03\})},
file = {:D$\backslash$:/Papers/Documents/2003/Eisenstein, Davis - 2003.pdf:pdf},
month = nov,
pages = {69--70},
publisher = {ACM Press},
title = {{Natural Gesture in Descriptive Monologues}},
year = {2003}
}
@misc{RobertM.Brown1985,
author = {{Robert M. Brown}},
file = {:D$\backslash$:/Papers/Documents/1985/Robert M. Brown - 1985.pdf:pdf},
pages = {19},
title = {{Handprinted symbol recognition system}},
year = {1985}
}
@inproceedings{ARElAbed2007,
abstract = {Databases enclosing a huge amount of images of handwritten words together
with detailed ground truth information are the most important precondition
for the development of handwritten word recognition systems. The
IFN/ENIT-database of handwritten Tunisian town names is used by many
research groups working on recognition systems. This paper gives
at first a short overview about the most important features of the
IFN/ENIT-database. In the second part an example of using the data
for developing baseline estimation methods is given. In the third
part a recognition system is described and some results are show},
author = {Abed, Haikal El and Margner, Volker},
booktitle = {9th International Symposium on Signal Processing and Its Applications, ISSPA 2007,},
file = {:D$\backslash$:/Papers/Documents/2007/Abed, Margner - 2007.pdf:pdf},
title = {{The IFN/ENIT-database - a tool to develop Arabic handwriting recognition systems}},
year = {2007}
}
@inproceedings{Britto2003,
abstract = {In this paper we combine complementary features based on foreground and background information in an HMM-based classifier to recognize handwritten digits. A zoning scheme based on column and row models provides a way of dividing the digit into zones without making the features size variant. This strategy allows us to avoid the digit normalization, while it provides a way of having information from specific zones of the digit. Recognition rates around 98\% have been achieved using 60,000 digit samples of the NIST SD19 database.},
annote = {===========================================
Paper Index : Jr2003
Date:23-11-2010

        
Why read paper ?
HMM background. 

        
Paper Overview ?
the hmm on digits with nist database with 98\%

        
What is these paper about ? (Summary)

        
Feature extraction:
for each column and row extract both forground and background set of features.  
1) circular transiton basedn on R and center of gravity of trantion (from black to white)of each column
2) realative postion of each transition.
3) wether transition outer or inner. 
4) vertical projection and deravitive between it ato adjacent column (34 features of ff). 
back ground concavity . 
info each fatures get number of background pixel that are labeled using specific conacvity configuration. 
hmm models used 2 for each digits one for row other for colmn 20 model are used (see fig 5) 
the use fo row and column hmm make recognition based on zones. 
Result 
NIST digits with 60,000 and 10,000  test
Experiements vs. state no. and vs. no of codebook size with 256 codebook size si best with 12 min of state 95.26 95.5\%
combinig column and row 98\% 

        

        
1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?

        
2. What can we take from this work  ? what do we learn ? What can be incorporated into our own work ?

        
3. What are the problems of the paper ?

        
4. what is lacking from the work ? why does this work knot be the final  research in this subject ?

        
5. what about the methods causes this lack ? is there a fundamental reason ?

        
6. Could incremental Changes Fix this lack ? if so, what changes ? 

        

        
Is there is any question you had about the paper ? 

        

        
The final conclusion..........

        
==========================================================================

      },
author = {{Britto Jr}, A.S. and Sabourin, R. and Bortolozzi, F. and Suen, C.Y.},
booktitle = {12th International Conference on Image Analysis and Processing, 2003.Proceedings.},
doi = {10.1109/ICIAP.2003.1234127},
file = {:D$\backslash$:/Papers/Documents/2003/Britto Jr et al. - 2003.pdf:pdf},
isbn = {0-7695-1948-2},
keywords = {Arabic Handwritting recognition,Read,Reference From Doctor,Summarized},
mendeley-tags = {Arabic Handwritting recognition,Read,Reference From Doctor,Summarized},
pages = {670--675},
publisher = {IEEE Computer Society},
title = {{Complementary Features Combined in an HMM-Based System to Recognize Handwritten Digits}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICIAP.2003.1234127},
year = {2003}
}
@article{Chiu1998,
address = {New York, New York, USA},
author = {Chiu, Patrick and Wilcox, Lynn},
doi = {10.1145/288392.288605},
file = {:D$\backslash$:/Papers/Documents/1998/Chiu, Wilcox - 1998.pdf:pdf},
isbn = {1581130341},
journal = {Proceedings of the 11th annual ACM symposium on User interface software and technology - UIST '98},
keywords = {audio,clustering,emergent structure,freeform,grouping,implicit structure,informal systems,ink,interaction,marking,multimedia,note-taking},
pages = {195--202},
publisher = {ACM Press},
title = {{A dynamic grouping technique for ink and audio notes}},
url = {http://portal.acm.org/citation.cfm?doid=288392.288605},
year = {1998}
}
@incollection{Foltz2002DrJones,
author = {Foltz, Mark},
booktitle = {MIT Artificial Intelligence Laboratory Annual Abstract},
month = sep,
publisher = {MIT AI Lab},
title = {{Dr. Jones: A Software Design Explorer's Crystal Ball}},
year = {2002}
}
@article{Newman2003,
author = {Newman, Mark and Lin, James and Hong, Jason and Landay, James},
doi = {10.1207/S15327051HCI1803\_3},
file = {:D$\backslash$:/Papers/Documents/2003/Newman et al. - 2003.pdf:pdf},
issn = {0737-0024},
journal = {Human-Computer Interaction},
month = sep,
number = {3},
pages = {259--324},
title = {{DENIM: An Informal Web Site Design Tool Inspired by Observations of Practice}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1207/S15327051HCI1803\_3\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {18},
year = {2003}
}
@article{Gunter2004,
abstract = {In off-line handwriting recognition, classifiers based on hidden Markov models (HMMs) have become very popular.However, while there exist well-established training algorithms which optimize the transition and output probabilities of a given HMM architecture, the architecture itself, and in particular the number of states, must be chosen “by hand”. Also the number of training iterations and the output distributions need to be defined by the system designer. In this paper we examine several optimization strategies for an HMM classifier that works with continuous feature values. The proposed optimization strategies are evaluated in the context of a handwritten word recognition task},
author = {Gunter, Simon and Bunke, Horst},
doi = {10.1016/j.patcog.2004.04.006},
file = {:D$\backslash$:/Papers/Documents/2004/Gunter, Bunke - 2004.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {gaussian mixture,handwritten word recognition,hidden markov model,hmm,state number optimization,training strategy},
number = {10},
pages = {2069--2079},
publisher = {Elsevier},
title = {{HMM-based handwritten word recognition: on the optimization of the number of states, training iterations and Gaussian components}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320304001633},
volume = {37},
year = {2004}
}
@article{LOU2008,
author = {LOU, Z. and YANG, J.Y.U. and JIN, Z.},
file = {:D$\backslash$:/Papers/Documents/2008/LOU, YANG, JIN - 2008.pdf:pdf},
journal = {ieeexplore.ieee.org},
keywords = {bank cheque processing,chinese handwritten character,legal amount,pattern recognition},
pages = {30--31},
title = {{RECOGNITION AND CHECKOUT OF LEGAL AMOUNTS ON CHINESE BANK CHEQUES}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4635811},
year = {2008}
}
@article{Osorio2006,
address = {New York, New York, USA},
author = {Osorio, Fernando C. Col\'{o}n and Klopman, Zachi},
doi = {10.1145/1141277.1141356},
file = {:D$\backslash$:/Papers/Documents/2006/Osorio, Klopman - 2006.pdf:pdf},
isbn = {1595931082},
journal = {Proceedings of the 2006 ACM symposium on Applied computing - SAC '06},
keywords = {1,emergent behavior,internet worms,introduction and previous work,malware,swarm in-,swarm worms,telligence},
pages = {323},
publisher = {ACM Press},
title = {{An initial analysis and presentation of malware exhibiting swarm-like behavior}},
url = {http://portal.acm.org/citation.cfm?doid=1141277.1141356},
year = {2006}
}
@article{ARAssaleh2009,
abstract = {This paperproposesanonlinevideo-based approachtohandwrittenArabicalphabetr
cognition. Various temporalandspatialfeature extractiontechniquesareintroduced.
the motion nformation of the handmovementisprojectedontotwostaticaccumulateddifferenceimagesac
ordingto the motion directionality. the temporalanalysisisfollowed
bytwo-dimensionaldiscret cosine transform andZonalcodingorRadon transformation
andlowpassfiltering. the resulting feature vectors are time-independent
thus canbeclassifiedbyasimpleclassificationtechn quesuchasK Nearest
Neighbor(KNN). the solution is further enhanced by introducing the
notionof uperclasses where similar classesaregrouped toge the rfor
the purposeof multiresolutionalcl ssification. Experimental resultsindicateanimpressive
99\% recognitionrateonuser-dependantmode. o validate the proposed
technique,we haveconductedaseriesof experimentsusingHidde Markov
models (HMM),whichis the classicalwayofclassifyingdatawithtemporaldependenc
es. Experimental resultsrevealedthat the proposedfeatureextractionschemecombinedwiths
mple KNN yields superiorresults tothoseobtainedby the classicalHMM-basedscheme},
author = {{Khaled Assaleha}, c and Shanablehb, Tamer and Hajja, Husam},
file = {:D$\backslash$:/Papers/Documents/2009/Khaled Assaleha, Shanablehb, Hajja - 2009.pdf:pdf},
journal = {Journal of theFranklin Institute},
pages = {175�189},
title = {{Recognition of handwritten Arabicalphabet via hand motion tracking}},
volume = {346},
year = {2009}
}
@inproceedings{Wolin2008,
abstract = {In this paper we introduce ShortStraw, a simple and highly accurate polyline corner finder. ShortStraw uses a bottom-up approach to find corners by: (1) resampling the points of the stroke, (2) calculating the “straw” distance between the endpoints of a window around each resampled point, and (3) taking the points with the minimum straw distance to be corners. Using an all-or-nothing accuracy measure, ShortStraw achieves an accuracy more than twice that of the current best benchmark},
author = {Wolin, Aaron and Eoff, B. and Hammond, Tracy},
booktitle = {EUROGRAPHICS 5th Annual Workshop on Sketch-Based Interfaces and Modeling},
file = {:D$\backslash$:/Papers/Documents/2008/Wolin, Eoff, Hammond - 2008.pdf:pdf},
keywords = {Edge and Feature Detection},
pages = {33--40},
title = {{Shortstraw: A simple and effective corner finder for polylines}},
url = {http://www.eecs.ucf.edu/courses/cap6938/fall2008/penui/handouts/asgn2.pdf},
year = {2008}
}
@phdthesis{Sezgin2001a,
abstract = {Freehand sketching is both a natural and crucial part of design, yet is unsupported by current design automation software. We are working to combine the flexibility and ease of use of paper and pencil with the processing power of a computer to produce a design environment that feels as natural as paper, yet is considerably smarter. One of the most basic steps in accomplishing this is converting the original digitized pen strokes in the sketch into the intended geometric objects using feature point detection and approximation. We demonstrate how multiple sources of information can be combined for feature detection in strokes and apply this technique using two approaches to signal processing, one using simple average based thresholding and a second using scale space.},
author = {Sezgin, Tevfik Metin},
booktitle = {Integration The Vlsi Journal},
file = {:D$\backslash$:/Papers/Documents/2001/Sezgin - 2001.pdf:pdf},
pages = {1----},
title = {{Feature Point Detection and Curve Approximation for Early Processing of Free-Hand Sketches}},
year = {2001}
}
@inproceedings{PDBChen2005,
abstract = {Real-time object detection is essential for many computer vision applications.
Many rapid detection algorithms are based on using cascades of tests.
But existing design criteria for cascades either ignore the time
complexity of the tests or make over-simplified assumptions about
them. This paper gives a criterion for designing a time-efficient
cascade that explicitly takes into account the time complexity of
tests (as evaluated by computer run time) including the time for
pre-processing. We design a greedy algorithm to minimize this criterion
(noting that the full problem is NP-complete). Finally, we illustrate
our method on the task of text detection in city scenes. This gives
a text detection algorithm that runs at 0.025 seconds per 320�240
image, which is equivalent to 40 frames per second. This is a speed
up factor of 2.5 compared to our previous text detector. It gives
a realtime system which can be used for applications to help the
blind and visually impaired.},
author = {Chen, Xiangrong and Yuille, Alan L},
booktitle = {Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR�05)},
file = {:D$\backslash$:/Papers/Documents/2005/Chen, Yuille - 2005.pdf:pdf},
title = {{A Time-Efficient Cascade for Real-Time Object Detection: With applications for the visually impaired}},
year = {2005}
}
@incollection{Sezgin2001ScalespaceAbstract,
author = {Sezgin, Tevfik Metin and Davis, Randall},
booktitle = {MIT Artificial Intelligence Laboratory Annual Abstract},
file = {:D$\backslash$:/Papers/Documents/2001/Sezgin, Davis - 2001.pdf:pdf},
publisher = {MIT AI Lab},
title = {{Scale-space Based Feature Point Detection for Noisy Digital Curves}},
year = {2001}
}
@inproceedings{DSGu2006,
abstract = { In this paper, a novel fusion recognition algorithm of courtesy and
legal amounts in handwritten Chinese bank checks is presented. Unlike
the other fusion methods based on the independent recognition results
of courtesy and legal amount, this proposed fusion algorithm begins
with the segmentation of legal amount with the guide of recognition
candidates of courtesy amount. And then we fuse the recognition candidates
of courtesy and legal amounts. The system is validated with 1053
real bank checks. When the substitution is 0.43\%, the recognition
rate at the amount level can reach 66.10\%},
author = {Gu, Jun-xia and Ding, Xiao-qing},
booktitle = {8th International Conference on Signal Processing, 2006},
doi = {10.1109/ICOSP.2006.345773},
file = {:D$\backslash$:/Papers/Documents/2006/Gu, Ding - 2006.pdf:pdf},
keywords = { ;image segmentation;law administration;,Chinese handwritten bank checks;fusion recognition},
title = {{Fusion Recognition of Courtesy and Legal Amounts on Chinese Handwritten Bank Checks}},
volume = {3},
year = {2006}
}
@article{Valveny2003,
author = {Valveny, E and Mart$\backslash$'$\backslash$i, E.},
doi = {10.1016/S0167-8655(03)00144-2},
file = {:D$\backslash$:/Papers/Documents/2003/Valveny, Mart'i - 2003.pdf:pdf},
issn = {0167-8655},
journal = {Pattern Recognition Letters},
keywords = {deformable models,document analysis,em algorithm,graphics recognition,symbol recognition},
number = {15},
pages = {2857--2867},
publisher = {Elsevier},
title = {{A model for image generation and symbol recognition through the deformation of lineal shapes}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865503001442},
volume = {24},
year = {2003}
}
@article{Mozaffari2009,
author = {Mozaffari, Saeed and Soltanizadeh, Hadi},
doi = {10.1109/ICDAR.2009.283},
file = {:D$\backslash$:/Papers/Documents/2009/Mozaffari, Soltanizadeh - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
keywords = {2009,arabic languages,duplication of efforts,evaluation,farsi,isolated digits and characters,large database,ocr benchmarking,performance,the aim of icdar},
month = jul,
pages = {1413--1417},
publisher = {Ieee},
title = {{ICDAR 2009 Handwritten Farsi/Arabic Character Recognition Competition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277795},
year = {2009}
}
@incollection{Alvarado2001Framework,
author = {Alvarado, Christine and Sezgin, Metin and Scott, Dana and Hammond, Tracy and Kasheff, Zardosht and Oltmans, Michael and Davis, Randall},
booktitle = {MIT Artificial Intelligence Laboratory Annual Abstract},
file = {:D$\backslash$:/Papers/Documents/2002/Alvarado, Oltmans, Davis - 2002.pdf:pdf},
month = sep,
publisher = {MIT AI Lab},
title = {{A Framework for Multi-Domain Sketch Recognition}},
year = {2001}
}
@article{Lipson1998,
author = {Lipson, Hod},
file = {:D$\backslash$:/Papers/Documents/1998/Lipson - 1998.pdf:pdf},
journal = {Laboratory for Computer Graphics and CAD, Israel Institute of Technology},
publisher = {Citeseer},
title = {{Computer aided 3D sketching for conceptual design}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.118.2577\&amp;rep=rep1\&amp;type=pdf},
year = {1998}
}
@article{Masuyama2002,
author = {Masuyama, Takeshi and Nakagawa, H.},
file = {:D$\backslash$:/Papers/Documents/2002/Masuyama, Nakagawa - 2002.pdf:pdf},
journal = {Expert Systems},
pages = {2--6},
publisher = {IEEE COmputer Society},
title = {{Applying cascaded feature selection to SVM text categorization}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/DEXA.2002.1045905},
year = {2002}
}
@inproceedings{DSSaabni2009,
abstract = {The difficulties in segmenting cursive words into individual characters
have shifted the focus of handwriting recognition research from segmentation-based
approaches to segmentation-free (holistic) methods. However, maintaining
and training large number of prototypes (models) that represent the
words in the dictionary make the training process extremely expensive
and difficult in computing resources. In this paper we present an
efficient system that automatically generates prototypes for each
word in a given dictionary using multiple appearance of each letter
shape. Multiple appearance allows for many permutation of shapes
for each word and thus complicates searching for the right prototype.
To simplify the training, reduce the maintained prototypes, and avoid
over fitting, we used dimensionality reduction followed by clustering
techniques to reduce the size of these sets without affecting their
ability to represent the wide variations of the handwriting styles.
A set of generated fonts are created by professional writers imitating
all handwriting styles for each character in each position. These
fonts are used to generate all shapes for writing each word-part
in a comprehensive dictionary. Principal component analysis and k-means
clustering techniques are performed to select the minimal number
of shapes representing the wide variations of handwriting styles
for a word-part. Experimental results using an online recognition
system proves the credibility of this process compared to manually
generated databases.},
author = {Saabni, R and El-Sana, J},
booktitle = {10th International Conference on Document Analysis and Recognition, 2009. ICDAR '09.},
doi = {10.1109/ICDAR.2009.258},
file = {:D$\backslash$:/Papers/Documents/2009/Saabni, El-Sana - 2009.pdf:pdf},
issn = {1520-5363},
keywords = {Kohonen SOM;comprehensive database generation;curs},
month = jul,
pages = {1231--1235},
title = {{Efficient Generation of Comprehensive Database for Online Arabic Script Recognition}},
year = {2009}
}
@article{Lank2001,
author = {Lank, E. and Thorley, J. and Chen, S. and Blostein, D.},
doi = {10.1109/ICDAR.2001.953813},
file = {:D$\backslash$:/Papers/Documents/2001/Lank et al. - 2001.pdf:pdf},
isbn = {0-7695-1263-1},
journal = {Proceedings of Sixth International Conference on Document Analysis and Recognition},
pages = {356--360},
publisher = {IEEE Comput. Soc},
title = {{On-line recognition of UML diagrams}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=953813},
year = {2001}
}
@inproceedings{PDBYuan2005,
abstract = {Nearest neighbor search is commonly employed in face recognition but
it does not scale well to large dataset sizes. A strategy to combine
rejection classifiers into a cascade for face identification is proposed
in this paper. A rejection classifier for a pair of classes is defined
to reject at least one of the classes with high confidence. These
rejection classifiers are able to share discriminants in feature
space and at the same time have high confidence in the rejection
decision. In the face identification problem, it is possible that
a pair of known individual faces are very dissimilar. It is very
unlikely that both of them are close to an unknown face in the feature
space. Hence, only one of them needs to be considered. Using a cascade
structure of rejection classifiers, the scope of nearest neighbor
search can be reduced significantly. Experiments on Face Recognition
Grand Challenge (FRGC) version 1 data demonstrate that the proposed
method achieves significant speed up and an accuracy comparable with
the brute force Nearest Neighbor method. In addition, a graph cut
based clustering technique is employed to demonstrate that the pairwise
separability of these rejection classifiers is capable of semantic
grouping},
author = {Yuan, Quan and Thangali, Ashwin and Sclaroff, Stan},
booktitle = {Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR�05)},
file = {:D$\backslash$:/Papers/Documents/2005/Yuan, Thangali, Sclaroff - 2005.pdf:pdf},
title = {{Face Identification by a Cascade of Rejection Classifiers}},
year = {2005}
}
@article{Nishimura2003,
abstract = {Recognition of variously deformed character patterns is a salient subject for off-line hand-printed character recognition. Sufficient recognition performance for practical use has not been achieved despite reports of many recognition techniques. Our research examines effective recognition techniques for deformed characters, extending conventional recognition techniques using an on-line character writing information containing writing pressure data. This study extends conventional recognition techniques using on-line character writing information containing writing pressure information. A recognition system using simple pattern matching and HMM was made for evaluation experiments using Common Hand- printed English character patterns from the ETL6 database to determine effectiveness of the proposed extending recognition method. Character recognition performance is increased in both expansion recognition methods using on-line writing information.},
author = {Nishimura, Hiromitsu and Timikawa, Takehiko},
file = {:D$\backslash$:/Papers/Documents/2003/Nishimura, Timikawa - 2003.pdf:pdf},
journal = {Document Analysis and Recognition},
pages = {168},
title = {{Off-line Character Recognition using On-line Character Writing Information}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICDAR.2003.1227653},
volume = {1},
year = {2003}
}
@article{Feng2009,
author = {Feng, Guihuan and Viard-Gaudin, Christian and Sun, Zhengxing},
file = {:D$\backslash$:/Papers/Documents/2009/Feng, Viard-Gaudin, Sun - 2009.pdf:pdf},
keywords = {Dynamic programming,Electric circuit diagram,On-line sketch recognition},
title = {{On-line hand-drawn electric circuit diagram recognition using 2D dynamic programming}},
url = {http://hal.archives-ouvertes.fr/hal-00419076/en/},
year = {2009}
}
@article{Pratt1987,
author = {Pratt, Vaughan},
file = {:D$\backslash$:/Papers/Documents/1987/Pratt - 1987.pdf:pdf},
journal = {Computer Graphics},
number = {4},
pages = {145--152},
title = {{Direct Least Square Fitting of Algebraic Surfaces}},
volume = {21},
year = {1987}
}
@inproceedings{ARXiu2006,
abstract = {Abstract. The research on offline handwritten Arabic character recognition
has received more and more attention in recent years, because of
the increasing needs of Arabic document digitization. The variation
in Arabic handwriting brings great difficulty in character segmentation
and recognition, eg., the subparts (diacritics) of the Arabic character
may shift away from the main part. In this paper, a new probabilistic
segmentation model is proposed. First, a contourbased over-segmentation
method is conducted, cutting the word image into graphemes. The graphemes
are sorted into 3 queues, which are character main parts, sub-parts
(diacritics) above or below main parts respectively. The confidence
for each character is calculated by the probabilistic model, taking
into account both of the recognizer output and the geometric confidence
besides with logical constraint. Then, the global optimization is
conducted to find optimal cutting path, taking weighted average of
character confidences as objective function. Experiments on handwritten
Arabic documents with various writing styles show the proposed method
is effective},
address = {Nelson, New Zealand},
author = {Xiu, Pingping and Peng, Liangrui and Ding, Xiaoqing and Wang, Hua},
booktitle = {Document Analysis Systems VII, 7th International Workshop},
editor = {Bunke, Horst and Spitz, A Lawrence},
file = {:D$\backslash$:/Papers/Documents/2006/Xiu et al. - 2006.pdf:pdf},
isbn = {3-540-32140-3},
month = feb,
pages = {402--412},
publisher = {Springer},
title = {{Offline Handwritten Arabic Character Segmentation with Probabilistic Model.}},
year = {2006}
}
@inproceedings{Al-Hajj2007,
abstract = {In this paper we present a two-stage system for the off-line recognition of cursive Arabic handwritten words. The proposed method is analytic without segmentation, and is able to cope with handwriting inclination and with shifted positions of diacritical marks. First, the recognition stage relies on 3 classifiers based on hidden Markov modelling (HMM). The second stage depends on the combination of these classifiers. The feature vectors used for recognition are related to pixel density distribution and to local pixel configurations. These vectors are extracted on word binary images by using a sliding window approach with different angles. We have experimented different combination schemes. The neural network-based combined system yields best performance on the IFN- ENIT benchmark data base of handwritten names of Tunisian villages/towns.},
author = {Al-Hajj, R. and Mokbel, Chafic and Likforman-Sulem, L.},
booktitle = {Document Analysis and Recognition, 2007. ICDAR 2007. Ninth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2007/Al-Hajj, Mokbel, Likforman-Sulem - 2007.pdf:pdf},
issn = {1520-5363},
pages = {959--963},
publisher = {IEEE},
title = {{Combination of hmm-based classifiers for the recognition of arabic handwritten words}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4377057},
volume = {2},
year = {2007}
}
@misc{Kuzunuki1987,
author = {Kuzunuki, S. and Shojima, H. and Yokoyama, T. and Fukunaga, Y. and Hirasawa, K.},
booktitle = {US Patent},
file = {:D$\backslash$:/Papers/Documents/1987/Kuzunuki et al. - 1987.pdf:pdf},
month = jul,
publisher = {Google Patents},
title = {{Method for designating a recognition mode in a hand-written character/graphic recognizer}},
url = {http://www.google.com/patents?hl=en\&amp;lr=\&amp;vid=USPAT4680804\&amp;id=q\_4vAAAAEBAJ\&amp;oi=fnd\&amp;dq=Method+for+designating+a+recognition+mode+in+a+hand-written+character/graphic+recognizer\&amp;printsec=abstract},
year = {1987}
}
@conference{ARSaabni2009,
abstract = {The difficulties in segmenting cursive words into individual characters
have shifted the focus of handwriting recognition research from segmentation-based
approaches to segmentation-free (holistic) methods. However, maintaining
and training large number of prototypes (models) that represent the
words in the dictionary make the training process extremely expensive
and difficult in computing resources. In this paper we present an
efficient system that automatically generates prototypes for each
word in a given dictionary using multiple appearance of each letter
shape. Multiple appearance allows for many permutation of shapes
for each word and thus complicates searching for the right prototype.
To simplify the training, reduce the maintained prototypes, and avoid
over fitting, we used dimensionality reduction followed by clustering
techniques to reduce the size of these sets without affecting their
ability to represent the wide variations of the handwriting styles.
A set of generated fonts are created by professional writers imitating
all handwriting styles for each character in each position. These
Fonts are used to generate all shapes for writing each word-part
in a comprehensive dictionary. Principal component analysis and k-means
clustering techniques are performed to select the minimal number
of shapes representing the wide variations of handwriting styles
for a word-part. Experimental results using an online recognition
system proves the credibility of this process compared to manually
generated databases.},
author = {Saabni, Raid and El-sana, Jihad},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Saabni, El-sana - 2009(3).pdf:pdf},
title = {{Efficient Generation of Comprehensive Database for Online Arabic Script Recognition}},
year = {2009}
}
@article{ARJou2009,
abstract = {Previous handwritten numeral recognition algorithms applied structural
classification to extract geometric primitives that characterize
each image, and then utilized artificial intelligence methods, like
neural network or fuzzy memberships, to classify the images. We propose
a handwritten numeral recognition methodology based on simplified
structural classification, by using a much smaller set of primitive
types, and fuzzy memberships. More specifically, based on three kinds
of feature points, we first extract five kinds of primitive segments
for each image. A fuzzy membership function is then used to estimate
the likelihood of these primitives being close to the two vertical
boundaries of the image. Finally, a tree-like classifier based on
the extracted feature points, primitives and fuzzy memberships is
applied to classify the numerals. With our system, handwritten numerals
in NIST Special Database 19 are recognized with correct rate between
87.33\% and 88.72\%.},
author = {Jou, Chichang and Lee, Hung-Chang},
file = {:D$\backslash$:/Papers/Documents/2009/Jou, Lee - 2009.pdf:pdf},
journal = {Expert Systems with Applications},
keywords = { Feature extraction, Fuzzy memberships, Structural classification,Handwritten numeral recognition},
month = nov,
number = {9},
pages = {11858--11863},
title = {{Handwritten numeral recognition based on simplified structural classification and fuzzy memberships}},
volume = {36},
year = {2009}
}
@article{Liu2003a,
author = {Liu, Ray and Wong, Lisa and Grundy, John},
file = {:D$\backslash$:/Papers/Documents/2003/Liu, Wong, Grundy - 2003.pdf:pdf},
journal = {Software Engineering Research and Practice},
keywords = {8,amulet,cad tools,human-computer interaction,large screen displays,mechanism for rapid icon,pen-based user input,provides a single-stoke input,s,specification,user interfaces,using rubine},
pages = {739--744},
publisher = {Citeseer},
title = {{Experiences Developing an E-whiteboard-based Circuit Designer}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.3.8427\&amp;rep=rep1\&amp;type=pdf},
year = {2003}
}
@incollection{ARAli2008,
abstract = {In this module, Learning Vector Quantization LVQ neural network is
first time introduced as a classifier for Arabic handwritten character.
Classification has been performed in two different strategies, in
first strategy, we use one classifier for all 53 Arabic Character
Basic Shapes CBSs in training and testing phases, in second strategy
we use three classifiers for three subsets of 53 Arabic CBSs, the
three subsets of Arabic CBSs are; ascending CBSs, descending CBSs
and embedded CBSs. Three training algorithms; OLVQ1, LVQ2 and LVQ3
were examined and OLVQ1 found as the best learning algorithm.},
author = {Ali, Mohamed A},
booktitle = {ICISP},
file = {:D$\backslash$:/Papers/Documents/2008/Ali - 2008.pdf:pdf},
keywords = { Classification, Neural Network,Arabic handwritten recognition},
pages = {463 � 470,},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Arabic Handwritten Characters Classification Using Learning Vector Quantization Algorithm}},
year = {2008}
}
@article{Rattarangsi1992,
author = {Rattarangsi, A and Chin, RT},
file = {:D$\backslash$:/Papers/Documents/1992/Rattarangsi, Chin - 1992.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {4},
pages = {430--450},
title = {{Scale-based detection of corners of planar curves}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=126805},
volume = {14},
year = {1992}
}
@article{Sinha2003,
address = {New York, New York, USA},
author = {Sinha, Anoop K. and Landay, James a.},
doi = {10.1145/958432.958457},
file = {:D$\backslash$:/Papers/Documents/2003/Sinha, Landay - 2003.pdf:pdf},
isbn = {1581136218},
journal = {Proceedings of the 5th international conference on Multimodal interfaces - ICMI '03},
pages = {117},
publisher = {ACM Press},
title = {{Capturing user tests in a multimodal, multidevice informal prototyping tool}},
url = {http://portal.acm.org/citation.cfm?doid=958432.958457},
year = {2003}
}
@inproceedings{PDB3Zhu2003,
abstract = {Active and semi-supervised learning are important techniques when
labeled data are scarce. We combine the two under a Gaussian random
field model. Labeled and unlabeled data are represented as vertices
in a weighted graph, with edge weights encoding the similarity between
instances. The semi-supervised learning problem is then formulated
in terms of a Gaussian random field on this graph, the mean of which
is characterized in terms of harmonic functions. Active learning
is performed on top of the semisupervised learning scheme by greedily
selecting queries from the unlabeled data to minimize the estimated
expected classification error (risk); in the case of Gaussian fields
the risk is efficiently computed using matrix methods. We present
experimental results on synthetic data, handwritten digit recognition,
and text classification tasks. The active learning scheme requires
a much smaller number of queries to achieve high accuracy compared
with random query selection.},
address = {Washington, DC, USA},
author = {Zhu, Xiaojin and Ghahramani, Zoubin and Lafferty, John D},
booktitle = {Machine Learning, Proceedings of the Twentieth International Conference (ICML 2003)},
editor = {Fawcett, Tom and Mishra, Nina},
file = {:D$\backslash$:/Papers/Documents/2003/Zhu, Ghahramani, Lafferty - 2003.pdf:pdf},
isbn = {1-57735-189-4},
month = aug,
pages = {912--919},
publisher = {AAAI Press},
title = {{Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions.}},
year = {2003}
}
@article{FE2Gader1996,
abstract = {Abstract-An automatic feature generation method for handwritten digit
recognition is described. Two different evaluation measures, orthogonality
and information, are used to guide the search for features. The features
are used in a backpropagation trained neural network. Classification
rates compare favorably with results published in a survey of high-performance
handwritten digit recognition systems. This classifier is combined
with several other high performance classifiers. Recognition rates
of around 98\% are obtained using two classifiers on a test set with
1,000 digits per class.},
annote = {My notes are},
author = {Gader, Paul D and Khabou, Mohamed Ali},
file = {:D$\backslash$:/Papers/Documents/1996/Gader, Khabou - 1996.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = { Handwritten digits,Features Extraction},
month = dec,
number = {12},
pages = {1256--1261},
title = {{Automatic Feature Generation for Handwritten Digit Recognition}},
volume = {18},
year = {1996}
}
@article{Susca2006,
author = {Susca, Sara and Martinez, Sonia and Bullo, Francesco},
doi = {10.1109/CDC.2006.376736},
file = {:D$\backslash$:/Papers/Documents/2006/Susca, Martinez, Bullo - 2006.pdf:pdf},
isbn = {1-4244-0171-2},
journal = {Proceedings of the 45th IEEE Conference on Decision and Control},
pages = {6512--6517},
publisher = {Ieee},
title = {{Distributed algorithms for polygonal approximation of convex contours}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4177918},
year = {2006}
}
@article{Gadat2007,
author = {Gadat, S. and Younes, Laurent},
file = {:D$\backslash$:/Papers/Documents/2007/Gadat, Younes - 2007.pdf:pdf},
journal = {The Journal of Machine Learning Research},
keywords = {clas-,feature selection,pattern recognition,robbins-monro application,sification algorithm,stochastic learning algorithms},
pages = {547},
publisher = {MIT Press},
title = {{A stochastic algorithm for feature selection in pattern recognition}},
url = {http://portal.acm.org/citation.cfm?id=1248659.1248678},
volume = {8},
year = {2007}
}
@article{Ahuja2001,
author = {Ahuja, N.},
doi = {10.1109/CVPR.2001.991029},
file = {:D$\backslash$:/Papers/Documents/2001/Ahuja - 2001.pdf:pdf},
isbn = {0-7695-1272-0},
journal = {Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001},
number = {C},
pages = {II--677--II--683},
publisher = {IEEE Comput. Soc},
title = {{A representation of image structure and its application to object selection using freehand sketches}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=991029},
volume = {00},
year = {2001}
}
@inproceedings{Vajda2005,
abstract = {In this paper, an improvement of a 2D stochastic model based handwritten entity recognition system is described. To model the handwriting considered as being a two di- mensional signal, a context based, segmentation-free Hid- den Markov Model (HMM) recognition system was used. The baseline approach combines a Markov Random Field (MRF) and a HMM so-called Non-Symmetric Half Plane HiddenMarkovModel (NSHP-HMM). To improve the results performed by this baseline system operating just on low-level pixel information an extension of the NSHP-HMM is proposed. The mechanism allows to extend the observations of the NSHP-HMM by implanting structural information in the system. At present, the accu- racy of the system on the SRTP1 French postal check data- base is 87.52\%while for the handwritten Bangla city names is 86.80\%. The gain using this structural information for the SRTP dataset is 1.57\%.},
author = {Vajda, S. and Belayd, A.},
booktitle = {Eighth International Conference on Document Analysis and Recognition (ICDAR'05)},
doi = {10.1109/ICDAR.2005.222},
file = {:D$\backslash$:/Papers/Documents/2005/Vajda, Belayd - 2005.pdf:pdf},
isbn = {0-7695-2420-6},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {1126--1130},
publisher = {Ieee},
title = {{Structural Information Implant in a Context Based Segmentation-Free HMM Handwritten Word Recognition System for Latin and Bangla Script}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1575719},
year = {2005}
}
@article{Fonseca2004,
address = {New York, New York, USA},
author = {Fonseca, Manuel and Barroso, Bruno and Ribeiro, Pedro and Jorge, Joaquim},
doi = {10.1145/989863.989943},
file = {:D$\backslash$:/Papers/Documents/2004/Fonseca et al. - 2004.pdf:pdf},
isbn = {1581138679},
journal = {Proceedings of the working conference on Advanced visual interfaces - AVI '04},
keywords = {drawing simplification,sketch and content-based retrieval},
pages = {429},
publisher = {ACM Press},
title = {{Sketch-based retrieval of ClipArt drawings}},
url = {http://portal.acm.org/citation.cfm?doid=989863.989943},
year = {2004}
}
@article{Lin2002,
address = {New York, New York, USA},
author = {Lin, James and Thomsen, Michael and Landay, James a.},
doi = {10.1145/503376.503431},
file = {:D$\backslash$:/Papers/Documents/2002/Lin, Thomsen, Landay - 2002.pdf:pdf},
isbn = {1581134533},
journal = {Proceedings of the SIGCHI conference on Human factors in computing systems Changing our world, changing ourselves - CHI '02},
keywords = {denim,user interface design,visual language,web design},
number = {4},
pages = {307},
publisher = {ACM Press},
title = {{A visual language for sketching large and complex interactive designs}},
url = {http://portal.acm.org/citation.cfm?doid=503376.503431},
year = {2002}
}
@inproceedings{Nakai2002,
abstract = {A new method isproposedfor on-line handwriting recog- nition of Kanji characters. The method employs substroke HMMs as minimum units to constitute Japanese Kanji char- acters and utilizes the direction of pen motion. The main motivation is to fully utilize the continuous speech recogni- tion algorithm by relating sentence speech to Kanji charac- te6 phonemes to substrokes, and grammar to Kanji struc- ture. The proposed system consists input feature analysis, substroke HMMs, a character structure dictionary and a de- coder. The present approach has the following advantages over the conventional methods that employ whole charac- ter HMMs. I) Much smaller memory reqiiirenient for dic- tionary and models. 2) Fast recognition by employing e@- cient substroke network search. 3) CapabiliQ of recogniz- ing characters not included in the training data if defined as a sequence of substrokes in the dictionaiy. 4) Capability of recognizing characters written by various diperetit stroke orders with multiple definitions per one character in the dic- tionary. 5) Easiness in HMM adaptation to the user with a few sample character data.},
annote = {===========================================

        Paper Index : Nakai2001

        Date:22-11-2010

        

        Why read paper ?
        

        
Build knowldge on Character recognition by HMM.

        

        Paper Overview ?
        
uses Sub stroke online system. 
HMM per sub stroke. a combination of hmm create character. 
A lot of character as for kanji japanese characters. 

        

        
          
What is these paper about ? (Summary)
        
pen direction and velocity of location pen up is used. 
direction of sub strok and substrokes are extracted. 
There is HMM model for each direction. 
Recognition is used to hmm viterbi algorith to detect sequence of sub stroke that is possible to create a chracter. 
Kanji chracter are defined as in hierarchial manar whera a character can be a set of substrokes or [2 different other characters. ]

        Results:
        
1 , 016 different characters are used to test . 
Test done on japanees dataset. 
Experiement of using substrok 95.34 
 vs. character hmm 95.95. 
 the writer vs. independent hmm. analysis 

        

        1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?
        
The large number of character the system can recognize. 

        2. What can we take from this work  ? what do we learn ? What can be incorporated into our own work ?
        
 The HMM can be part of character not all character.  The features are very simple as they use the directional (curvature of ) online strokes. 

        

        3. What are the problems of the paper ?
        
the decode system that build characters form recognizied substrokes hmm is complex and speciific for languages. 

        

        

        4. what is lacking from the work ? why does this work knot be the final  research in this subject ?
        

        
A full test on various dataset and various languages. also testing different writing styles and sizes. 
          

          
5. what about the methods causes this lack ? is there a fundamental reason ?
        

        
          
6. Could incremental Changes Fix this lack ? if so, what changes ? 

        
        

        

        Is there is any question you had about the paper ? 
        
the decode system is not presented in details. 

        
          
The final conclusion..........
        

        
May have some ideas but I think hard to use on arabic languages. 

        
==========================================================================

      },
author = {Nakai, Mitsuru and Akira, Naoto and Shimodaira, Hiroshi and Sagayama, Shigeki},
booktitle = {Document Analysis and Recognition, 2001. Proceedings. Sixth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2002/Nakai et al. - 2002.pdf:pdf},
isbn = {0769512631},
keywords = {Arabic Handwritting recognition,HMM,Japanese or Chinese Characters,Online handwriting character recognition,Read,Summarized},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
pages = {491--495},
publisher = {IEEE},
title = {{Substroke approach to HMM-based on-line Kanji handwriting recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=953838},
year = {2002}
}
@article{Almuhtaseb2008,
abstract = {This paper describes a technique for automatic recognition of off-line printed Arabic text using Hidden Markov Models. In this work different sizes of overlapping and non- overlapping hierarchical windows are used to generate 16 features from each vertical sliding strip. Eight different Arabic fonts were used for testing (viz. Arial, Tahoma, Akhbar, Thuluth, Naskh, Simplified Arabic, Andalus, and Traditional Arabic). It was experimentally proven that different fonts have their highest recognition rates at different numbers of states (5 or 7) and codebook sizes (128 or 256). Arabic text is cursive, and each charactermay have up to four different shapes based on its location in a word. This research work considered each shape as a different class, resulting in a total of 126 classes (compared to 28 Arabic letters). The achieved average recognition rates were between 98.08\% and 99.89\% for the eight experimental fonts. The main contributions of this work are the novel hierarchical sliding window technique using only 16 features for each sliding window, considering each shape of Arabic characters as a separate class, bypassing the need for segmenting Arabic text, and its applicability to other languages.},
author = {Almuhtaseb, H and Mahmoud, S and Qahwaji, R},
doi = {10.1016/j.sigpro.2008.06.013},
file = {:D$\backslash$:/Papers/Documents/2008/Almuhtaseb, Mahmoud, Qahwaji - 2008.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Reference From Doctor,arabic text recognition,hidden markov models},
mendeley-tags = {Reference From Doctor},
month = dec,
number = {12},
pages = {2902--2912},
title = {{Recognition of off-line printed Arabic text using Hidden Markov Models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165168408001928},
volume = {88},
year = {2008}
}
@article{Rajan2009,
author = {Rajan, Pankaj and Hammond, Tracy},
file = {:D$\backslash$:/Papers/Documents/2009/Rajan, Hammond - 2009.pdf:pdf},
journal = {srl.csdl.tamu.edu},
keywords = {image,scanning,sketch,sketch recognition},
pages = {4--6},
title = {{Applying Online Sketch Recognition Algorithms to a Scanned-In Sketch}},
url = {http://srl.csdl.tamu.edu/workshops/2009/iui/finalPapers/Rajan.pdf},
year = {2009}
}
@phdthesis{MCZing2006,
abstract = {In this thesis, many efforts were devoted to the recognition and verification
of handwritten numeral recognitions. In pursuit of the highest recognition
accuracy and the lowest misrecognition rate, we introduce a hybrid
feature extraction strategy and a multimodal nonparametric analysis
for feature dimensionality reduction (in order to obtain a faster
and more stable classifier training procedure for verification).
The design of a cascade ensemble classifier recognition system with
rejection strategies is also introduced. From a practical perspective,
the various recognizers and verifiers were designed and implemented
using novel hybrid feature extraction algorithms and a newly designed
ensemble cascade classifier system. The designed OCR engines were
applied to handwritten numeral recognition. A summary of thesis contributions
and discussions on future direction is also addressed.},
author = {Zhang, Ping},
school = {Concordia University},
title = {{Reliable Recognition of Handwritten Digits Using A Cascade Ensemble Classifier System and Hybrid Features}},
year = {2006}
}
@mastersthesis{Veselova2003Perceptually,
address = {Cambridge, MA},
author = {Veselova, Olya},
school = {Massachusetts Institute of Technology},
title = {{Perceptually Based Learning of Shape Descriptions}},
year = {2003}
}
@inproceedings{Igarashi1996,
author = {Igarashi, T and Matsuoka, S},
booktitle = {Proceeding of 6th Australin Conference On Comptuer Human Interaction},
file = {:D$\backslash$:/Papers/Documents/1996/Igarashi, Matsuoka - 1996.pdf:pdf},
keywords = {cai,extended pie menu,interactive beautification,perceptual layout,straint},
pages = {314--315},
title = {{GiGA: A pen Based constraint Drawing system}},
year = {1996}
}
@article{Gutjahr2002,
author = {Gutjahr, W.J.},
file = {:D$\backslash$:/Papers/Documents/2002/Gutjahr - 2002.pdf:pdf},
issn = {0020-0190},
journal = {Information Processing Letters},
number = {3},
pages = {145--153},
publisher = {Elsevier Science},
title = {{ACO algorithms with guaranteed convergence to the optimal solution}},
url = {http://cat.inist.fr/?aModele=afficheN\&amp;cpsidt=13526653},
volume = {82},
year = {2002}
}
@article{Awaidah2009,
abstract = {This paper describes a technique for the recognition of optical off-line handwritten Arabic (Indian) numerals using hidden Markov models (HMM). Features that measure the image characteristics at local, intermediate, and large scales were applied. Gradient, structural, and concavity features at the sub-regions level are extracted and used as the features for the Arabic (Indian) numeral. Several experiments were conducted for estimating the suitable number of image divisions, and the best combination of features using theHMMclassifier. A number of experiments were conducted to estimate the best number of states and codebook sizes in terms of the highest recognition rate possible. In this work, we did not follow the general trend of using the sliding window technique with HMM. Instead, a multi-resolution feature extraction approach was implemented on the whole digit. A database of 44 writers, with 48 samples per digit resulting in a database of 21120 sampleswas used. The achieved average recognition rate is 99\%. The classification errors were analysed and attributed to bad data, different writing styles of some digits, errors between digit pairs, and genuine errors. The presented technique, which is writer independent, proved to be effective in the automatic recognition of Arabic (Indian) numerals.},
annote = {Comments:
Use different segment size ( segment is part of digit). 
Extract from each segment GSC features(gradient, structural, concativity))
uses HMM in recognition
99.1\% result achieved. 

        
Details:
The features were chosen because they are somewhat orthogonal and are at different scales to each other. Collectively,these features are known as the gradient, structural, and concavity (GSC)feature set

        
[ Interesting Dividing digit images into segmetns ... ] The first step in the GSC feature extraction algorithm is to divide the imageinto nXm grids with equal number of foreground pixels for each of n rows,and equal number of foreground pixels for each of m columns. A digit sample is segmented into n horizontal segments with approximately equal number of black(foreground)pixels in each segment. The system then segments the digit into m vertical slices with approximately equal number of black (foreground) pixels. the intersection of horizontal and verticalsegmentation lines define (n*m) non-overlapping segments that are used to extract the features in each segment. the segment sizes and x- and y-coordinates are different for each different sample based on the sample black(foreground)pixels’ distribution.

        
Three set of features is computed for each segment ( Gradiaent features (sobel operator), Structual Featrues ( densisty features , stroke features, ...), Concativity shape features). Table 1 in page 1180 shows the details of each feature. 

        
Different HMM model for each digit and but on same number of states for all digits. USing HKT

        
Test on The database consists of 21120 samples.

        
Several expeirments based on segment size and features vector size (Recognition rate between 98\% to 99\%)},
author = {Awaidah, Sameh M. and Mahmoud, Sabri A.},
doi = {10.1016/j.sigpro.2008.12.022},
file = {:D$\backslash$:/Papers/Documents/2009/Awaidah, Mahmoud - 2009(2).pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Arabic optical handwritten,Arabic(Indian) numerals,HMM,Handwritting recognition,Hidden Markov model,Independent writer digit recognition,OCR,Read,Summarized,Writer independent,feature extraction,numeral recognition},
mendeley-tags = {Read,Summarized},
month = jun,
number = {6},
pages = {1176--1184},
title = {{A multiple feature/resolution scheme to Arabic (Indian) numerals recognition using hidden Markov models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S016516840900005X},
volume = {89},
year = {2009}
}
@article{Vinciarelli2002a,
abstract = {This paper presents a surveyon o-line Cursive Word Recognition. The approaches to the problem are described in detail. Each step of the process leading from raw data to the nal result is analyzed. This survey is divided into two parts, the rst one dealing with the general aspects of Cursive Word Recognition, the second one focusing on the applications presented in the literature. ? 2002 Pattern Recognition Society. Published},
author = {Vinciarelli, Alessandro},
file = {:D$\backslash$:/Papers/Documents/2002/Vinciarelli - 2002.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {handwriting recognition,o -line cursive word,recognition,survey},
number = {7},
pages = {1433--1446},
publisher = {Elsevier},
title = {{A survey on off-line cursive word recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320301001297},
volume = {35},
year = {2002}
}
@inproceedings{Methods2009,
author = {Methods, Post-processing and Sundaram, Suresh and Ramakrishnan, A G},
booktitle = {10th International Conference on Document Analysis and Recognition},
doi = {10.1109/ICDAR.2009.65},
file = {:D$\backslash$:/Papers/Documents/2009/Methods, Sundaram, Ramakrishnan - 2009.pdf:pdf},
pages = {1216--1220},
title = {{An Improved Online Tamil Character Recognition Engine using Post Processing Methods}},
year = {2009}
}
@inproceedings{Oliveira2007,
author = {Oliveira, Luciano and Peixoto, Paulo and Nunes, Urbano},
booktitle = {IEEE ICRA 2007 Workshop on” Planning, perception and navegation for intelligent vehicles”, Rome},
file = {:D$\backslash$:/Papers/Documents/2007/Oliveira, Peixoto, Nunes - 2007.pdf:pdf},
publisher = {Citeseer},
title = {{A Hierarchical Fuzzy integration of local and global feature-based classifiers to recognize objects in autonomous vehicles}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.118.883\&amp;rep=rep1\&amp;type=pdf},
year = {2007}
}
@article{Boubaker2009,
author = {Boubaker, Houcine and Kherallah, Monji and Alimi, Adel M.},
doi = {10.1109/ICDAR.2009.265},
file = {:D$\backslash$:/Papers/Documents/2009/Boubaker, Kherallah, Alimi - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {778--782},
publisher = {Ieee},
title = {{New Algorithm of Straight or Curved Baseline Detection for Short Arabic Handwritten Writing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277507},
year = {2009}
}
@article{Hassin2004,
abstract = {The Arabic Language has a very rich vocabulary. More than 200 million people speak this language as their native speaking, and over 1 billion people use it in several religion-related activities. In this paper a new technique is presented for recognizing printed Arabic characters. After a word is segmented, each character/word is entirely transformed into a feature vector. The features of printed Arabic characters include strokes and bays in various directions, endpoints, intersection points, loops, dots and zigzags. The word skeleton is decomposed into a number of links in orthographic order, and then it is transferred into a sequence of symbols using vector quan- tization. Single hidden Markov model has been used for recognizing the printed Arabic characters. Experimental results show that the high recognition rate depends on the number of states in each sample.},
author = {Hassin, Abbas H. and Tang, Xiang-Long and Liu, Jia-Feng and Zhao, Wei},
doi = {10.1007/BF02944755},
file = {:D$\backslash$:/Papers/Documents/2004/Hassin et al. - 2004.pdf:pdf},
issn = {1000-9000},
journal = {Journal of Computer Science and Technology},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = jul,
number = {4},
pages = {538--543},
title = {{Printed Arabic character recognition using HMM}},
url = {http://www.springerlink.com/index/10.1007/BF02944755},
volume = {19},
year = {2004}
}
@incollection{Hammond2002NaturalAbstract,
author = {Hammond, Tracy and Oshiro, Kalani and Davis, Randall},
booktitle = {MIT Artificial Intelligence Laboratory Annual Abstract},
keywords = {multimodal},
month = sep,
publisher = {MIT AI Lab},
title = {{Natural Editing and Recognition of UML Class Diagrams}},
year = {2001}
}
@article{Phillips1998,
author = {Phillips, I. and Liang, Jisheng and Chhabra, A. and Haralick, Robert},
file = {:D$\backslash$:/Papers/Documents/1998/Phillips et al. - 1998.pdf:pdf},
journal = {Graphics Recognition Algorithms and Systems},
pages = {372--389},
publisher = {Springer},
title = {{A performance evaluation protocol for graphics recognition systems}},
url = {http://www.springerlink.com/index/7556688118u3171l.pdf},
volume = {1389},
year = {1998}
}
@inproceedings{ARCowell2001,
abstract = {A successful approach to the recognition of Latin characters is to
extract fiatures from that character such as the number of strokes,
stroke intersections and holes, and to use ad-hoc tests to diflerentiate
between characters which have similar features. The first stage in
this process ib to produce thinned 1 pixel thick representations
of the characters to simplifi feature extraction. This approach works
well with printed Latin characters which are of high quality. With
poor quality characters, however, the thinning process itself is
not, straighrfonvard and can introduce errors which clre manfested
in the later stages of the recognition process. The recognition of
poor quality Arabic characters is a particular problem since the
chara(5tet-s are calligraphic with printed characters having widely
varying stroke thicknesses to simulate the drawing of the character
with a calligraphy pen or brush. This paper describes the problems
encountered when thinning large poor quality Arabic characters prior
to the extraction of their features and submission to a syntactic
recognition system.},
author = {Cowell, Dr John and Hussain, Dr Fiaz},
booktitle = {Proceedings of the Fifth International Conference on Information Visualisation},
file = {:D$\backslash$:/Papers/Documents/2001/Cowell, Hussain - 2001.pdf:pdf},
keywords = { OCR, Urdu, characters, optical, thinning,Arabic},
pages = {181},
title = {{Thinning Arabic Characters for Feature Extraction}},
year = {2001}
}
@article{ElAbed2010,
author = {{El Abed}, Haikal},
doi = {10.1007/s10032-010-0117-5},
file = {:D$\backslash$:/Papers/Documents/2010/El Abed - 2010.pdf:pdf},
journal = {International Journal on Document Analysis and Recognition (IJDAR)},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = apr,
number = {4},
pages = {724},
title = {{ICDAR 2009-Arabic handwriting recognition competition}},
volume = {19},
year = {2010}
}
@article{Palacios2003,
author = {Palacios, R. and Gupta, a.},
doi = {10.1109/NNSP.2003.1318060},
file = {:D$\backslash$:/Papers/Documents/2003/Palacios, Gupta - 2003.pdf:pdf},
isbn = {0-7803-8177-7},
journal = {2003 IEEE XIII Workshop on Neural Networks for Signal Processing (IEEE Cat. No.03TH8718)},
keywords = {- optical character recognition,check processing,document imaging,neural networks,unconstrained handwritten numerals},
pages = {607--616},
publisher = {Ieee},
title = {{Training neural networks for reading handwritten amounts on checks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1318060},
year = {2003}
}
@article{Bertolami2006,
author = {Bertolami, R and Zimmermann, M and Bunke, H},
doi = {10.1016/j.patrec.2006.06.002},
file = {:D$\backslash$:/Papers/Documents/2006/Bertolami, Zimmermann, Bunke - 2006.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {handwritten text recognition,rejection strategies,statistical language model},
month = dec,
number = {16},
pages = {2005--2012},
title = {{Rejection strategies for offline handwritten text line recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865506001632},
volume = {27},
year = {2006}
}
@article{Sezgin2001Sketchbased,
author = {Sezgin, Tevfik Metin and Stahovich, Thomas and Davis, Randall},
file = {:D$\backslash$:/Papers/Documents/2001/Sezgin, Stahovich, Davis - 2001.pdf:pdf},
journal = {Workshop on Perceptive User Interfaces, Orlando FL},
title = {{Sketch Based Interfaces: Early Processing for Sketch Understanding}},
year = {2001}
}
@inproceedings{Alimoglu96,
author = {Alimoglu, Fevzi and Alpaydin, Ethem},
booktitle = {Proceedings of the Fifth Turkish Artificial Intelligence and Artificial Neural Networks Symposium (TAINN 96},
title = {{Methods of Combining Multiple Classifiers Based on Different Representations for Pen-based Handwritten Digit Recognition}},
year = {1996}
}
@article{ARLiu2008b,
abstract = {Pattern classification methods based on learning-from-examples have
been widely applied to character recognition from the 1990s and have
brought forth significant improvements of recognition accuracies.
This kind of methods include statistical methods, artificial neural
networks, support vector machines, multiple classifier combination,
etc. In this chapter, we briefly review the learning-based classification
methods that have been successfully applied to character recognition,
with a special section devoted to the classification of large category
set. We then discuss the characteristics of these methods, and discuss
the remaining problems in character recognition that can be potentially
solved by machine learning methods.},
author = {Liu, Cheng-Lin and Fujisawa, Hiromichi},
file = {:D$\backslash$:/Papers/Documents/2008/Liu, Fujisawa - 2008.pdf:pdf},
journal = {Studies in Computational Intelligence (SCI)},
pages = {139�161},
title = {{Classification and Learning Methods for Character Recognition: Advances and Remaining Problems}},
volume = {90},
year = {2008}
}
@inproceedings{Li2005,
author = {Li, Junfeng and Zhang, X. and Ao, X. and Dai, G.},
booktitle = {Proceedings of the 10th international conference on Intelligent user interfaces},
file = {:D$\backslash$:/Papers/Documents/2005/Li et al. - 2005.pdf:pdf},
pages = {150},
publisher = {ACM},
title = {{Sketch recognition with continuous feedback based on incremental intention extraction}},
url = {http://portal.acm.org/citation.cfm?id=1040866},
year = {2005}
}
@article{Haddawy2007,
abstract = {OBJECTIVE: Sketching is ubiquitous in medicine. Physicians commonly use sketches as part of their note taking in patient records and to help convey diagnoses and treatments to patients. Medical students frequently use sketches to help them think through clinical problems in individual and group problem solving. Applications ranging from automated patient records to medical education software could benefit greatly from the richer and more natural interfaces that would be enabled by the ability to understand sketches. In this paper we take the first steps toward developing a system that can understand anatomical sketches. METHODS: Understanding an anatomical sketch requires the ability to recognize what anatomical structure has been sketched and from what view (e.g. parietal view of the brain), as well as to identify the anatomical parts and their locations in the sketch (e.g. parts of the brain), even if they have not been explicitly drawn. We present novel algorithms for sketch recognition and for part identification. We evaluate the accuracy of the recognition algorithm on sketches obtained from medical students. We evaluate the part identification algorithm by comparing its results to the judgment of an experienced physician. RESULTS: The sketch recognition algorithm achieves a recognition accuracy of 75.5\%, far above the baseline random classification accuracy of 6.7\%. Comparison of the results of the part identification algorithm with the judgment of an experienced physician shows close agreement in terms of location, orientation, size, and shape of the identified parts. CONCLUSIONS: The performance of our prototype in terms of accuracy and running time provides strong evidence that development of robust sketch understanding systems for medical domains is an attainable goal. Further work needs to be done to extend the approach to sketches containing multiple and partial anatomical structures, as well as to be able to interpret sketch annotations.},
author = {Haddawy, Peter and Dailey, Matthew N and Kaewruen, Ploen and Sarakhette, Natapope and Hai, Le Hong},
doi = {10.1016/j.artmed.2006.07.010},
file = {:D$\backslash$:/Papers/Documents/2007/Haddawy et al. - 2007.pdf:pdf},
issn = {0933-3657},
journal = {Artificial intelligence in medicine},
keywords = {Algorithms,Anatomy,Anatomy: methods,Computer Simulation,Humans,Language,Paintings,Reproducibility of Results,Speech,User-Computer Interface},
month = feb,
number = {2},
pages = {165--77},
pmid = {17010580},
title = {{Anatomical sketch understanding: recognizing explicit and implicit structure.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17010580},
volume = {39},
year = {2007}
}
@inproceedings{Alvarado2001Preserving,
author = {Alvarado, Christine and Davis, Randall},
booktitle = {Human Computer Interaction International Proceedings},
title = {{Preserving the Freedom of Sketching to Create a Natural Computer-Based Sketch Tool}},
year = {2001}
}
@inproceedings{DSMadasu2005,
abstract = { This paper describes a novel method for automatically segmenting
and recognizing the various information fields present on a bank
cheque. The uniqueness of our approach lies in the fact that it doesn
\#146;t necessitate any prior information and requires minimum human
intervention. The extraction of segmented fields is accomplished
by means of a connectivity based approach. For the recognition part,
we have proposed four innovative features, namely; entropy, energy,
aspect ratio and average fuzzy membership values. Though no particular
feature is pertinent in itself but a combination of these is used
for differentiating between the fields. Finally, a fuzzy neural network
is trained to identify the desired fields. The system performance
is quite promising on a large dataset of real and synthetic cheque
images.},
author = {Madasu, V K and Lovell, B C},
booktitle = {Proceedings 2005 of Digital Image Computing: Techniques and Applications, 2005. DICTA '05.},
doi = {10.1109/DICTA.2005.18},
file = {:D$\backslash$:/Papers/Documents/2005/Madasu, Lovell - 2005.pdf:pdf},
pages = {33},
title = {{Automatic Segmentation and Recognition of Bank Cheque Fields}},
year = {2005}
}
@inproceedings{MCSu2007,
abstract = {In the literature of psychophysics and neurophysiology, many studies
have shown that both global and local features are crucial for face
representation and recognition. This paper proposes a novel face
recognition method which combines both global and local discriminative
features. In this method, global features are extracted from whole
face images by Fourier transform and local features are extracted
from some spatially partitioned image patches by Gabor wavelet transform.
After this, multiple classifiers are obtained by applying Fisher
Discriminant Analysis on global Fourier features and local patches
of Gabor features. All these classifiers are combined to form a hierarchical
ensemble by sum rule. We evaluated the proposed method using Face
Recognition Grand Challenge (FRGC) experimental protocols and database
known as the largest data sets available. Experimental results on
FRGC version 2.0 data set have shown that the proposed method achieves
a verification rate of 86\%, while the best reported was 76\%.},
address = {Rio de Janeiro,},
author = {Su, Yu and Shan, Shiguang and Chen, Xilin and Gao, Wen},
booktitle = {IEEE 11th International Conference on Computer Vision, 2007. ICCV 2007},
file = {:D$\backslash$:/Papers/Documents/2007/Su et al. - 2007.pdf:pdf},
keywords = { Classifiers Ensemble,Features Extraction},
pages = {1--8},
publisher = {IEEE},
title = {{Hierarchical Ensemble of Global and Local Classifiers for Face Recognition}},
year = {2007}
}
@inproceedings{Eisenstein2004Salience,
address = {East Stroudsburg, Pennsylvania},
author = {Eisenstein, Jacob and Christoudias, C Mario},
booktitle = {Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics},
month = may,
pages = {25--32},
publisher = {ACL Press},
title = {{A Salience-Based Approach to Gesture-Speech Alignment}},
year = {2004}
}
@article{DSBezerra2008,
abstract = {An approach is proposed for detecting and eliminating invasion in
courtesy amount fields. This is a important step toward automatizing
the bank check process. In a real database, 18\% of handwritten courtesy
amount fields exhibited invasions in the legal amount and signature
fields. Experimental results have shown that the proposed approach
is robust and efficient for improving the automatic recognition of
real Brazilian bank checks},
author = {Bezerra, Byron L D and Cavalcanti, George D C and Zanchettin, Cleber and Rabelo, Juliano C B},
file = {:D$\backslash$:/Papers/Documents/2008/Bezerra et al. - 2008.pdf:pdf},
keywords = { Automatic Check Processing., Courtesy Amount Recognition,Contour Invasion Detection},
title = {{Detecting and treating invasion in the courtesy amount field on bank checks}},
year = {2008}
}
@inproceedings{DSOliveira2002,
abstract = {This paper discusses the use of genetic algorithm for feature selection
for handwriting recognition. Its novelty lies in the use of a multi-objective
genetic algorithms where sensitivity analysis and neural network
are employed to allow the use of a representative database to evaluate
fitness and the use of a validation database to identify the subsets
of selected features that provide a good generalization. Comprehensive
experiments on the NIST database confirm the effectiveness of the
proposed strategy.},
address = {Quebec City},
author = {Oliveira, L S and Sabourin, R and Bortolozzi, F and Suen, C Y},
booktitle = {Proc. Int. Conf. on Pattern Recognition},
file = {:D$\backslash$:/Papers/Documents/2002/Oliveira et al. - 2002(2).pdf:pdf},
month = aug,
pages = {568--571},
title = {{Feature selection using multi-objective genetic algorithms for handwritten digit recognition}},
volume = {1},
year = {2002}
}
@article{Toygar2004,
author = {Toygar, Onsen and {Adnan Acan}},
doi = {10.1016/j.patrec.2004.05.005},
file = {:D$\backslash$:/Papers/Documents/2004/Toygar, Adnan Acan - 2004.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {appearance-based statistical methods,classifier combination,local feature-based face,multiple classifier systems},
month = sep,
number = {12},
pages = {1421--1430},
title = {{Multiple classifier implementation of a divide-and-conquer approach using appearance-based statistical methods for face recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865504001114},
volume = {25},
year = {2004}
}
@article{MCShieh2007,
abstract = {Various form features affect consumer preference regarding product
design. It is, therefore, important that designers identify these
critical form features to aid them in developing appealing products.
However, the problems inherent in choosing product form features
have not yet been intensively investigated. In this paper, an approach
based on multiclass support vector machine recursive feature elimination
(SVM-RFE) is proposed to streamline the selection of optimum product
form features. First, a one-versus-one (OVO) multiclass fuzzy support
vector machines (multiclass fuzzy SVM) model using a Gaussian kernel
was constructed based on product samples from mobile phones. Second,
an optimal training model parameter set was determined using two-step
cross-validation. Finally, a multiclass SVM-RFE process was applied
to select critical form features by either using overall ranking
or class-specific ranking. The weight distribution of each iterative
step can be used to analyze the relative importance of each of the
form features. The results of our experiment show that the multiclass
SVM-RFE process is not only very useful for identifying critical
form features with minimum generalization errors but also can be
used to select the smallest feature subset for building a prediction
model with a given discrimination capability.},
author = {Shieh, Meng-Dar and Yang, Chih-Chieh},
file = {:D$\backslash$:/Papers/Documents/2007/Shieh, Yang - 2007.pdf:pdf},
journal = {Expert Systems with Applications},
pages = {531�541},
title = {{Multiclass SVM-RFE for product form feature selection}},
volume = {35},
year = {2007}
}
@article{Choi2010,
abstract = {Current feature-basedgesture recognitionsystemsusehuman- chosen features to perform recognition. Effective features for classification can also be automatically learned and chosen by the computer. In other recognition domains, such as face recognition, manifold learning methods have been found to be good nonlinear feature extractors. Few manifold learning algorithms, however, have been applied to gesture recognition. Current manifold learning techniques focus only on spatial information, makingthemundesirable for use inthedomainof gesture recognitionwhere stroke timing data can provide helpful insight into the recognition of hand- drawn symbols. In this paper, we develop a new algorithmformulti-stroke gesture recognition, which integrates timing data into a manifold learning algorithm based on a kernel Isomap. Experimental results show it to per- form better than traditional human-chosen feature-based systems.},
author = {Choi, Heeyoul and Paulson, Brandon and Hammond, Tracy},
file = {:D$\backslash$:/Papers/Documents/2010/Choi, Paulson, Hammond - 2010.pdf:pdf},
journal = {Structural, Syntactic, and Statistical Pattern Recognition},
keywords = {kernel isomap,manifold learning,sketch recognition},
pages = {247--256},
publisher = {Springer},
title = {{Gesture recognition based on manifold learning}},
url = {http://www.springerlink.com/index/g227252492821568.pdf},
year = {2010}
}
@article{Pal2004,
abstract = {Intensive research has been done on optical character recognition (OCR) and a large number of articles have been published on this topic during the last few decades. Many commercial OCR systems are now available in the market. But most of these systems work for Roman, Chinese, Japanese andArabic characters. There are no sucient number of work on Indian language character recognition although there are 12 major scripts in India. In this paper, we present a review of the OCR work done on Indian language scripts. The review is organizedinto 5 sections. Sections 1 and2 cover introduction andproperties on Indian scripts. In Section 3, we discuss dierent methodologies in OCR development as well as research work done on Indian scripts recognition. In Section 4, we discuss the scope of future work and further steps needed for Indian script OCR development. In Section 5 we conclude the paper.},
author = {Pal, U and Chaudhuri, BB},
doi = {10.1016/j.patcog.2004.02.003},
file = {:D$\backslash$:/Papers/Documents/2004/Pal, Chaudhuri - 2004.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {indian script,indian script ocr,ocr survey,optical character recognition},
number = {9},
pages = {1887--1899},
publisher = {Elsevier},
title = {{Indian script character recognition: a survey}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S003132030400055X},
volume = {37},
year = {2004}
}
@article{Plamondon2000,
author = {Plamondon, R. and Srihari, S.N.},
doi = {10.1109/34.824821},
file = {:D$\backslash$:/Papers/Documents/2000/Plamondon, Srihari - 2000.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
number = {1},
pages = {63--84},
title = {{Online and off-line handwriting recognition: a comprehensive survey}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=824821},
volume = {22},
year = {2000}
}
@inproceedings{MCLecun1998b,
abstract = {A long and detailed paper on convolutional nets, graph transformer
networks, and discriminative training methods for sequence labeling.
We show how to build systems that integrate segmentation, feature
extraction, classification, contextual post-processing, and language
modeling into one single learning machine trained end-to-end. Applications
to handwriting recognition and face detection are described.},
author = {LeCun, Y and Bottou, L and Bengio, Y and Haffner, P},
booktitle = {Proceedings of the IEEE},
file = {:D$\backslash$:/Papers/Documents/1998/LeCun et al. - 1998.pdf:pdf},
month = nov,
number = {11},
pages = {2278--2324},
title = {{Gradient Based Learning Applied to Document Recognition}},
volume = {86},
year = {1998}
}
@article{Smith2000,
author = {Smith, Arthur C},
file = {:D$\backslash$:/Papers/Documents/2000/Smith - 2000.pdf:pdf},
title = {{Understanding Naturally Conveyed Explanations of Device Behavior by Michael Oltmans}},
year = {2000}
}
@article{Kara2003,
author = {Kara, Levent Burak and Stahovich, Thomas F.},
doi = {10.1017/S0890060402165036},
file = {:D$\backslash$:/Papers/Documents/2003/Kara, Stahovich - 2003(2).pdf:pdf},
issn = {0890-0604},
journal = {Ai Edam},
keywords = {causal reasoning,computing purpose,configuration space,design rationale construction,geometric reasoning,simulation,spatial reasoning},
month = jun,
number = {05},
pages = {363--384},
title = {{Causal reasoning using geometric analysis}},
url = {http://www.journals.cambridge.org/abstract\_S0890060402165036},
volume = {16},
year = {2003}
}
@inproceedings{Alvarado2002,
author = {Alvarado, Christine and Oltmans, Michael and Davis, Randall},
booktitle = {AAAI Spring Symposium on Sketch Understanding},
file = {:D$\backslash$:/Papers/Documents/2002/Alvarado, Oltmans, Davis - 2002.pdf:pdf},
pages = {1--8},
title = {{A framework for multi-domain sketch recognition}},
url = {http://www.aaai.org/Papers/Symposia/Spring/2002/SS-02-08/SS02-08-001.pdf},
year = {2002}
}
@article{Liwicki2009a,
abstract = {In this paper, we describe feature selection experiments for online handwriting recog- nition. We investigated a set of 25 online and pseudo-offline features to find out which features are important and which features may be redundant. To analyze the saliency of the features, we applied a sequential forward and a sequential backward search on the feature set. A hidden Markov model and a neural network based recognizer have been used as recognition engines. In our experiments, we obtained interesting results. Using a set of only five features, we achieved a performance similar to that of the reference system that uses all 25 features. The five selected features have a low correlation and have been the top choices during the first iterations of the forward search with both recognizers. Furthermore, for both recognizers, subsets have been identified that outper- form the reference system with statistical significance. In order to assess the results more rigorously, we have compared our recognizer with the widely used commercial recognizer from Microsoft.},
author = {Liwicki, Marcus and Bunke, Horst},
file = {:D$\backslash$:/Papers/Documents/2009/Liwicki, Bunke - 2009.pdf:pdf},
journal = {International Journal of Pattern Recognition and Artificial Intelligence},
keywords = {bidirectional long,cursive handwritten text recognition,feature selection,hidden markov model,hmm,search,sequential backward search,sequential forward,short-term memory network},
number = {5},
pages = {907--923},
title = {{BASED HANDWRITING RECOGNITION}},
volume = {23},
year = {2009}
}
@article{Stahovich2001,
author = {Stahovich, Thomas F. and Kara, Levent Burak},
doi = {10.1017/S0890060401152042},
file = {:D$\backslash$:/Papers/Documents/2001/Stahovich, Kara - 2001.pdf:pdf},
issn = {08900604},
journal = {Ai Edam},
keywords = {causal reasoning,causal representation,computing purpose,design rationale construction},
month = apr,
number = {2},
pages = {189--201},
title = {{A representation for comparing simulations and computing the purpose of geometric features}},
url = {http://www.journals.cambridge.org/abstract\_S0890060401152042},
volume = {15},
year = {2001}
}
@inproceedings{Harty1992,
author = {Harty, K. and Cheriton, D.R.},
booktitle = {Proceedings of the fifth international conference on Architectural support for programming languages and operating systems},
file = {:D$\backslash$:/Papers/Documents/1992/Harty, Cheriton - 1992.pdf:pdf},
isbn = {0897915348},
pages = {187--197},
publisher = {ACM},
title = {{Application-controlled physical memory using external page-cache management}},
url = {http://portal.acm.org/citation.cfm?id=143511},
year = {1992}
}
@inproceedings{ARHachour2006,
abstract = {In this paper Fuzzy Logic (FL) and Expert System (ES) theories are
studied with regard to their contribution to solving the problem
of OCR (Optical Chara cter Recognition). These theories have improved
the learning and adaptation capacities related to varying shapes
where information is qualitative, inaccurate or incomplete. The use
of these technologies FL and ES proves interesting, efficient, and
necessary to recognize all Arabic character. This combination is
very useful to improve the powerful of Hybrid Intelligent Systems
HIS in the field of OCR. The primary goal of this combination (FL,
ES) is to classify and to recognize all presented unknown shapes.
These theories must achieve these tasks: to classify characters,
and to make ones way of intelligent recognition by ES-FL system capturing
the behaviour of a human expert knowledge. The training has used
280 descended pictures of the database of ACR (Arabic Character Recognition).
The Results gotten of ACR databases are promising.},
address = {London},
author = {Hachour, O},
booktitle = {2006 3rd International IEEE Conference on Intelligent Systems},
doi = {10.1109/IS.2006.348415},
file = {:D$\backslash$:/Papers/Documents/2006/Hachour - 2006.pdf:pdf},
pages = {189--191},
title = {{The Combination of Fuzzy Logic and Expert System for Arabic Character Recognition}},
year = {2006}
}
@inproceedings{DSLecce2000,
author = {Lecce, V Di and Dimauro, G and Guerriero, A and Impedovo, S and Pirlo, G and Salzo, A},
booktitle = {In Proceedings of International Workshop on Frontiers in Handwriting Recognition},
file = {:D$\backslash$:/Papers/Documents/2000/Lecce et al. - 2000.pdf:pdf},
pages = {199--208},
title = {{A New Hybrid Approach For Legal Amount Recognition}},
year = {2000}
}
@article{Plimmer2003,
address = {New York, New York, USA},
author = {Plimmer, Beryl and Apperley, Mark},
doi = {10.1145/765891.766126},
file = {:D$\backslash$:/Papers/Documents/2003/Plimmer, Apperley - 2003.pdf:pdf},
isbn = {1581136374},
journal = {CHI '03 extended abstracts on Human factors in computing systems - CHI '03},
keywords = {novice programmers,sketching,tool evaluation},
pages = {1018},
publisher = {ACM Press},
title = {{Evaluating a sketch environment for novice programmers}},
url = {http://portal.acm.org/citation.cfm?doid=765891.766126},
year = {2003}
}
@article{PDB5Yu2004,
abstract = {Feature selection is applied to reduce the number of features in many
applications where data has hundreds or thousands of features. Existing
feature selection methods mainly focus on finding relevant features.
In this paper, we show that feature relevance alone is insufficient
for efficient feature selection of high-dimensional data. We define
feature redundancy and propose to perform explicit redundancy analysis
in feature selection. A new framework is introduced that decouples
relevance analysis and redundancy analysis. We develop a correlation-based
method for relevance and redundancy analysis, and conduct an empirical
study of its efficiency and effectiveness comparing with representative
methods.},
author = {Yu, Lei and Liu, Huan},
doi = {http://www.jmlr.org/papers/volume5/yu04a/yu04a.pdf},
file = {:D$\backslash$:/Papers/Documents/2004/Yu, Liu - 2004.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {Feature selection},
pages = {1205--1224},
title = {{Efficient Feature Selection via Analysis of Relevance and Redundancy.}},
volume = {5},
year = {2004}
}
@phdthesis{Tim1998,
author = {Pastva, Tim},
file = {:D$\backslash$:/Papers/Documents/1998/Pastva - 1998.pdf:pdf},
pages = {1----},
school = {Naval Postgraduate School, Monterey, California},
title = {bezier curve fitting},
type = {Master},
year = {1998}
}
@article{Liu2004,
author = {Liu, C.L. and Nakashima, Kazuki and Sako, Hiroshi and Fujisawa, Hiromichi},
doi = {10.1016/S0031-3203(03)00224-3},
file = {:D$\backslash$:/Papers/Documents/2004/Liu et al. - 2004.pdf:pdf},
journal = {Pattern Recognition},
keywords = {aspect ratio mapping,direction feature,gradient feature,handwritten digit recognition,ncfe,normalization},
number = {2},
pages = {265--279},
publisher = {Elsevier},
title = {{Handwritten digit recognition: investigation of normalization and feature extraction techniques}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320303002243},
volume = {37},
year = {2004}
}
@inbook{Bishop1989,
author = {Bishop, JM},
booktitle = {Order A Journal On The Theory Of Ordered Sets And Its Applications},
file = {:D$\backslash$:/Papers/Documents/1989/Bishop - 1989(2).PDF:PDF},
title = {{Problems of stimulus equivalence.}},
year = {1989}
}
@article{Rosin1993,
abstract = {The characteristics of two normalisations for the general conic equation are investigated for use in least squares fitting: either setting F = 1 or A + C = 1. The normalisations vary in three main areas: curvature bias, singularities, transformational invariance. It is shown that setting F = 1 is the more appropriate for ellipse fitting since it is less heavily curvature biased. Setting A + C = 1 produces more eccentric conics, resulting either in over-elongated ellipses or hyperbolae. Although the F = 1 normalisation is less well suited than the A + C = 1 normalisation with respect to singularities and transformational invariance both these problems are solved by normalising the data, shifting it so that it is centred on the origin before shifting fitting, and then re-expressing the fit in the original frame of reference.},
author = {Rosin, Paul L.},
doi = {10.1016/0167-8655(93)90062-I},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {curvature bias,ellipse,least squares fitting,normalisation,singularity,transformational invariance},
month = oct,
number = {10},
pages = {799--808},
title = {{A note on the least squares fitting of ellipses}},
url = {http://dx.doi.org/10.1016/0167-8655(93)90062-I},
volume = {14},
year = {1993}
}
@inproceedings{PDBZhu2006,
abstract = {We integrate the cascade-of-rejectors approach with the Histograms
of Oriented Gradients (HoG) features to achieve a fast and accurate
human detection system. The features used in our system are HoGs
of variable-size blocks that capture salient features of humans automatically.
Using AdaBoost for feature selection, we identify the appropriate
set of blocks, from a large set of possible blocks. In our system,
we use the integral image representation and a rejection cascade
which significantly speed up the computation. For a 320 � 280 image,
the system can process 5 to 30 frames per second depending on the
density in which we scan the image, while maintaining an accuracy
level similar to existing methods.},
address = {New York, NY, USA},
author = {Zhu, Qiang and Yeh, Mei-Chen and Cheng, Kwang-Ting and Avidan, Shai},
booktitle = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2006)},
doi = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2006.119},
file = {:D$\backslash$:/Papers/Documents/2006/Zhu et al. - 2006.pdf:pdf},
isbn = {0-7695-2597-0},
pages = {1491--1498},
publisher = {IEEE Computer Society},
title = {{Fast Human Detection Using a Cascade of Histograms of Oriented Gradients.}},
year = {2006}
}
@inproceedings{Fiorentino2003,
author = {Fiorentino, Michele and Monno, Giuseppe and Renzulli, Pietro Alexander and Uva, Antonio E and Politecnico, D Dis},
booktitle = {Design Studies, GRAPHICON},
file = {:D$\backslash$:/Papers/Documents/2003/Fiorentino et al. - 2003.pdf:pdf},
keywords = {3d tracking,and constitutes an environment,curve segmentation,direct drawing and positioning,expressing ideas and concepts,for,geometric modelling,s intention,sketching,spline approximation,understanding the user,vr-virtual reality},
pages = {188----191},
title = {{3D Sketch Stroke Segmentation and Fitting in Virtual Reality}},
year = {2003}
}
@inproceedings{Singh,
author = {Singh, S. and Hewitt, M.},
booktitle = {Proceedings 15th International Conference on Pattern Recognition. ICPR-2000},
doi = {10.1109/ICPR.2000.906138},
file = {:D$\backslash$:/Papers/Documents/2000/Singh, Hewitt - 2000.pdf:pdf},
isbn = {0-7695-0750-6},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
number = {Figure 1},
pages = {569--572},
publisher = {IEEE Comput. Soc},
title = {{Cursive digit and character recognition in CEDAR database}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=906138},
year = {2000}
}
@article{VanderLugt2002,
address = {New York, New York, USA},
author = {van der Lugt, Remko},
doi = {10.1145/581710.581723},
file = {:D$\backslash$:/Papers/Documents/2002/van der Lugt - 2002.pdf:pdf},
isbn = {1581134657},
journal = {Proceedings of the fourth conference on Creativity \& cognition - C\&C '02},
keywords = {creative problem solving,design,external memory,idea generation,linkography,sketching,techniques},
pages = {72--79},
publisher = {ACM Press},
title = {{Functions of sketching in design idea generation meetings}},
url = {http://portal.acm.org/citation.cfm?doid=581710.581723},
year = {2002}
}
@article{Arica2002,
abstract = {A new analytic scheme, which uses a sequence of image segmentation and recognition algorithms, is proposed for the off-line cursive handwriting recognition problem. First, some global parameters, such as slant angle, baselines, stroke width and height, are estimated. Second, a segmentation method finds character segmentation paths by combining gray-scale and binary information. Third, a hidden Markov model (HMM) is employed for shape recognition to label and rank the character candidates. For this purpose, a string of codes is extracted from each segment to represent the character candidates. The estimation of feature space parameters is embedded in the HMM training stage together with the estimation of the HMM model parameters. Finally, information from a lexicon and from the HMM ranks is combined in a graph optimization problem for word-level recognition. This method corrects most of the errors produced by the segmentation and HMM ranking stages by maximizing an information measure in an efficient graph search algorithm. The experiments indicate higher recognition rates compared to the available methods reported in the literature},
author = {Arica, Nafiz and Yarman-Vural, F.T.},
file = {:D$\backslash$:/Papers/Documents/2002/Arica, Yarman-Vural - 2002.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Lexicon lookup,cursive handwritten text recognition,graph,handwritten word recognition,hidden markov model,optical character recognition,preprocessing,search,segmentation},
number = {6},
pages = {801--813},
publisher = {Published by the IEEE Computer Society},
title = {{Optical character recognition for cursive handwriting}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/TPAMI.2002.1008386},
volume = {24},
year = {2002}
}
@phdthesis{Foltz1998,
abstract = {Currently, computer users are “lost in hyperspace:” they have difficulty knowing where they are and locating the information they desire. To remedy this, information should be situated in an information space that enables people to explore knowledge in the same way they navigate in the physical environment. This thesis will enumerate a set of principles to guide information space design, enabling designers to create effective information spaces. The design principles fall into three categories: communication principles, which inform the spatial organization of information; wayfinding principles, which structure the space to allow successful navigation; and computational principles, which use the computational nature of digital media to enhance the information space. Two information spaces designed using these principles are presented and analyzed.},
author = {Foltz, MA},
booktitle = {Electrical Engineering},
file = {:D$\backslash$:/Papers/Documents/1998/Foltz - 1998.pdf:pdf},
pages = {1--130},
publisher = {Citeseer},
school = {Massachusetts Institute of Technology},
title = {{Designing navigable information spaces}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.21.6582\&amp;rep=rep1\&amp;type=pdf},
year = {1998}
}
@article{Sezgin2007,
author = {Sezgin, Tevfik Metin and Davis, Randall},
file = {:D$\backslash$:/Papers/Documents/2007/Sezgin, Davis - 2007.pdf:pdf},
journal = {Ieee Computer Graphics And Applications},
number = {February},
pages = {28--37},
title = {{Interpretation Using Multiscale Models of Temporal}},
year = {2007}
}
@article{Tjan2006,
author = {Tjan, B.S. and Nandy, A.S.},
file = {:D$\backslash$:/Papers/Documents/2006/Tjan, Nandy - 2006.pdf:pdf},
journal = {Journal of vision},
keywords = {classification image,invariance,nonlinearity,reverse correlation,spatial uncertainty},
number = {4},
pages = {387--413},
publisher = {Association for Research in Vision and Ophthalmology},
title = {{Classification images with uncertainty}},
url = {http://www.journalofvision.org/content/6/4/8.full},
volume = {6},
year = {2006}
}
@article{DSKapp2007,
abstract = {The study of handwritten words is tied to the development of recognition
methods to be used in real-world applications involving handwritten
words, such as bank checks, postal envelopes, and handwritten texts,
among others. In this work, the focus is handwritten words in the
context of Brazilian bank checks, specifically the months of the
year, and no restrictions are placed on the types or styles of writing
or the number of writers. A global feature set and two architectures
of artificial neural networks (ANN) are evaluated for classification
of the words. The objectives are to evaluate the performance of conventional
and class-modular multiple-layer perceptron (MLP) architectures,
to develop a rejection mechanism based on multiple thresholds, and
to analyze the behavior of the feature set proposed in the two architectures.
The experimental results demonstrate the superiority of the class-modular
architecture over the conventional MLP architecture. A rejection
mechanism with multiple thresholds demonstrates favorable performance
in both architectures. The feature set analysis shows the importance
of the structural primitives such as concavities and convexities,
and perceptual primitives such as ascenders and descenders. The experimental
results reveal a recognition rate of 81.75\% without the rejection
mechanism, and a reliability rate 91.52\% with a rejection rate of
25.33\%.},
author = {Kappa, Marcelo N and {de A. Freitasb}, Cinthia O and Sabourina, Robert},
file = {:D$\backslash$:/Papers/Documents/2007/Kappa, de A. Freitasb, Sabourina - 2007.pdf:pdf},
journal = {Image and Vision Computing},
keywords = {Neural networks; Rejection; Feature selection; Han},
month = jan,
number = {1},
pages = {40--49},
title = {{Methodology for the design of NN-based month-word recognizers written on Brazilian bank checks}},
volume = {25},
year = {2007}
}
@article{Johnston2009,
author = {Johnston, Joshua and Hammond, Tracy},
file = {:D$\backslash$:/Papers/Documents/2009/Johnston, Hammond - 2009.pdf:pdf},
journal = {srlweb.cs.tamu.edu},
number = {v},
pages = {8--11},
title = {{Assigning Confidence Values to Geometric Constraints}},
url = {http://srlweb.cs.tamu.edu/srlng\_media/content/objects/object-1234540737-122e41c674e7b079cefa8ef3aad1286f/Assigning Confidence.pdf},
year = {2009}
}
@article{Ip2001,
author = {Ip, H.H.S. and a.K.Y. Cheng and Wong, W.Y.F.},
doi = {10.1109/CGI.2001.934658},
file = {:D$\backslash$:/Papers/Documents/2001/Ip, Cheng, Wong - 2001.pdf:pdf},
isbn = {0-7695-1007-8},
journal = {Proceedings. Computer Graphics International 2001},
keywords = {-based browsing or searching,data,image retrieval,in this paper,invariant,more importantly,of visual,robust,shape-based retrieval technique for,the,we present an affine,which is efficient and},
pages = {55--61},
publisher = {IEEE Comput. Soc},
title = {{Affine-invariant sketch-based retrieval of images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=934658},
year = {2001}
}
@inproceedings{PDBBritto2004,
abstract = {In this paper we combine complementary features based on foreground
and background information in an HMM-based classifier to recognize
handwritten isolated characters and numeral strings. A zoning scheme
based on column and row models provides a way of dividing the character
into zones without making the features size variant. This strategy
allows us to avoid the character normalization, while it provides
a way of having information from specific zones of the character.
The experimental results on 10 digit classes, 52 character classes
and 6 classes of numeral strings of different lengths have shown
that the proposed features are highly discrimminant.},
author = {{Britto Jr.}, Alceu de S and Sabourin, Robert and Bortolozzi, Flavio and Suen, Ching Y},
booktitle = {IWFHR '04: Proceedings of the Ninth International Workshop on Frontiers in Handwriting Recognition},
doi = {http://dx.doi.org/10.1109/IWFHR.2004.43},
file = {:D$\backslash$:/Papers/Documents/2004/Britto Jr. et al. - 2004.pdf:pdf},
isbn = {0-7695-2187-8},
pages = {371--376},
title = {{Foreground and Background Information in an HMM-Based Method for Recognition of Isolated Characters and Numeral Strings}},
year = {2004}
}
@inproceedings{Cronin2006,
author = {Cronin, Alex and Fitzgerald, J.A. and Kechadi, Tahar},
booktitle = {Tools with Artificial Intelligence, 2006. ICTAI'06. 18th IEEE International Conference on},
file = {:D$\backslash$:/Papers/Documents/2006/Cronin, Fitzgerald, Kechadi - 2006.pdf:pdf},
isbn = {0769527280},
issn = {1082-3409},
keywords = {handwriting recognition},
pages = {693--700},
publisher = {IEEE},
title = {{A Hybrid Recogniser for Handwritten Symbols Based on Fuzzy Logic and Self-Organizing Maps}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4031961},
year = {2006}
}
@inproceedings{Alvarado2001Resolving,
author = {Alvarado, Christine and Davis, Randall},
booktitle = {Proceedings. of IJCAI-2001},
month = aug,
title = {{Resolving Ambiguities to Create a Natural Sketch Based Interface}},
year = {2001}
}
@article{Haddawy2007a,
abstract = {OBJECTIVE: Sketching is ubiquitous in medicine. Physicians commonly use sketches as part of their note taking in patient records and to help convey diagnoses and treatments to patients. Medical students frequently use sketches to help them think through clinical problems in individual and group problem solving. Applications ranging from automated patient records to medical education software could benefit greatly from the richer and more natural interfaces that would be enabled by the ability to understand sketches. In this paper we take the first steps toward developing a system that can understand anatomical sketches. METHODS: Understanding an anatomical sketch requires the ability to recognize what anatomical structure has been sketched and from what view (e.g. parietal view of the brain), as well as to identify the anatomical parts and their locations in the sketch (e.g. parts of the brain), even if they have not been explicitly drawn. We present novel algorithms for sketch recognition and for part identification. We evaluate the accuracy of the recognition algorithm on sketches obtained from medical students. We evaluate the part identification algorithm by comparing its results to the judgment of an experienced physician. RESULTS: The sketch recognition algorithm achieves a recognition accuracy of 75.5\%, far above the baseline random classification accuracy of 6.7\%. Comparison of the results of the part identification algorithm with the judgment of an experienced physician shows close agreement in terms of location, orientation, size, and shape of the identified parts. CONCLUSIONS: The performance of our prototype in terms of accuracy and running time provides strong evidence that development of robust sketch understanding systems for medical domains is an attainable goal. Further work needs to be done to extend the approach to sketches containing multiple and partial anatomical structures, as well as to be able to interpret sketch annotations.},
author = {Haddawy, Peter and Dailey, Matthew N and Kaewruen, Ploen and Sarakhette, Natapope and Hai, Le Hong},
doi = {10.1016/j.artmed.2006.07.010},
file = {:D$\backslash$:/Papers/Documents/2007/Haddawy et al. - 2007(2).pdf:pdf},
issn = {0933-3657},
journal = {Artificial intelligence in medicine},
keywords = {Algorithms,Anatomy,Anatomy: methods,Computer Simulation,Humans,Language,Paintings,Reproducibility of Results,Speech,User-Computer Interface},
month = feb,
number = {2},
pages = {165--77},
pmid = {17010580},
title = {{Anatomical sketch understanding: recognizing explicit and implicit structure.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17010580},
volume = {39},
year = {2007}
}
@incollection{DSRomero2007,
abstract = {Bernoulli mixture models have been recently proposed as simple yet
powerful probabilistic models for binary images in which each image
pattern is modelled by a different Bernoulli prototype (component).
A possible limitation of these models, however, is that usual geometric
transformations of image patterns are not explicitly modelled and,
therefore, each natural transformation of an image pattern has to
be independently modelled using a different, rigid prototype. In
this work, we propose a simple technique to make these rigid prototypes
more flexible by explicit modelling of invariances to translation,
scaling and rotation. Results are reported on a task of handwritten
Indian digits recognition.},
author = {Romero, Ver�nica and Gim�nez, Adri� and Juan, Alfons},
booktitle = {Pattern Recognition and Image Analysis},
doi = {10.1007/978-3-540-72847-4\_69},
file = {:D$\backslash$:/Papers/Documents/2007/Romero, Gim�nez, Juan - 2007.pdf:pdf},
pages = {539--546},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Explicit Modelling of Invariances in Bernoulli Mixtures for Binary Images}},
volume = {4477},
year = {2007}
}
@article{ARSu2009,
abstract = {Great challenges are faced in the off-line recognition of realistic Chinese handwriting. This paper presents a segmentation-free strategy based on Hidden Markov Model (HMM) to handle this problem, where character segmentation stage is avoided prior to recognition. Handwritten textlines are first converted to observation sequence by sliding windows. Then embedded Baum�Welch algorithm is adopted to train character HMMs. Finally, best character string maximizing the a posteriori is located through Viterbi algorithm. Experiments are conducted on the HIT-MW database written by more than 780 writers. The results show the feasibility of such systems and reveal apparent complementary capacities between the segmentation-free systems and the segmentation-based ones.},
author = {Su, Tong-Hua and Zhang, Tian-Wen and Guan, De-Jun and Huang, Hu-Jie},
file = {:D$\backslash$:/Papers/Documents/2009/Su et al. - 2009.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Chinese handwriting recognition,Classifier combination,Hidden Markov Model,Optical,Segmentation-free strategy,Sliding window},
pages = {167--182},
title = {{Off-line recognition of realistic Chinese handwriting using segmentation-free strategy}},
volume = {42},
year = {2009}
}
@inproceedings{Eisenstein2004Visual,
address = {New York, New York},
author = {Eisenstein, Jacob and Davis, Randall},
booktitle = {International Conference on Multimodal Interfaces (\{ICMI'04\})},
month = oct,
pages = {113--120},
publisher = {ACM Press},
title = {{Visual and Linguistic Information in Gesture Classification}},
year = {2004}
}
@article{Vuong2008647,
abstract = {
Structural analysis in handwritten mathematical expressions focuses on interpreting the recognized symbols using geometrical information such as relative sizes and positions of the symbols. Most existing approaches rely on hand-crafted grammar rules to identify semantic relationships among the recognized mathematical symbols. They could easily fail when writing errors occurred. Moreover, they assume the availability of the whole mathematical expression before being able to analyze the semantic information of the expression. To tackle these problems, we propose a progressive structural analysis (PSA) approach for dynamic recognition of handwritten mathematical expressions. The proposed PSA approach is able to provide analysis result immediately after each written input symbol. This has an advantage that users are able to detect any recognition errors immediately and correct only the mis-recognized symbols rather than the whole expression. Experiments conducted on 57 most commonly used mathematical expressions have shown that the PSA approach is able to achieve very good performance results.},
author = {Vuong, Ba-Quy and Hui, Siu-Cheung and He, Yulan},
doi = {DOI: 10.1016/j.patrec.2007.11.017},
file = {:D$\backslash$:/Papers/Documents/2008/Vuong, Hui, He - 2008.pdf:pdf},
issn = {0167-8655},
journal = {Pattern Recognition Letters},
keywords = {Grouping determination},
number = {5},
pages = {647--655},
title = {{Progressive structural analysis for dynamic recognition of on-line handwritten mathematical expressions}},
url = {http://www.sciencedirect.com/science/article/B6V15-4RC2RV6-3/2/1370388e1650065ef95dd4ea94c12604},
volume = {29},
year = {2008}
}
@article{MCHung2004,
abstract = {Detection of recognition errors is important in many areas, suchas
improving recognition performance, saving manual effort for proof-reading
and post-editing, and assigning appropriate weights for retrieval
in constructing digital libraries.We propose a novel application
of multiple classifiers for the detection of recognition errors.
A need for multiple classifiers emerges when a single classifier
cannot improve recognition-error detection performance compared with
the current detection scheme using a simple threshold mechanism.
Although the single classifier does not improve recognition error
performance, it serves as a baseline for comparison and the related
study of useful features for error detection suggests three distinct
cases where improvement is needed. For eachcase, the multiple classifier
approachassigns a classifier to detect the presence or absence of
errors and additional features are considered for each case. Our
results show that the recall rate (70�80\%) of recognition errors,
the precision rate (80�90\%) of recognition error detection and the
saving in manual effort (75\%) were better than the corresponding
performance using a single classifier or a simple threshold detection
scheme},
author = {Hunga, K.-Y. and Luka, R W P and D.S.Yeunga and Chung, K F L and Ua, W Sh},
file = {:D$\backslash$:/Papers/Documents/2004/Hunga et al. - 2004.pdf:pdf},
journal = {Pattern Recognition},
pages = {723--738},
title = {{A multiple classifier approach to detect Chinese character recognition errors}},
volume = {38},
year = {2004}
}
@inproceedings{Xiang2010,
abstract = {-Great challenges are faced in the offline recognition of cursive Arabic handwriting. This paper presents a segmentation-free system based on Hidden Markov Model (HMM) to handle this problem, where character segmentation stage is avoided prior to recognition. The system first extracts a set of robust features on binary handwritten images by sliding windows. Then the proposed system builds character HMM models and learns word HMM models using embedded training. Finally, best word maximizing the a posteriori is located through Viterbi Algorithm. Experiments that have been implemented on the benchmark IFNIENIT database show the average recognition rate of this system is 84.09\%.},
author = {Xiang, Dong and Yan, Huahua and Chen, Xianqiao and Cheng, Yanfen},
booktitle = {Computer Science and Information Technology (ICCSIT), 2010 3rd IEEE International Conference on},
file = {:D$\backslash$:/Papers/Documents/2010/Xiang et al. - 2010.pdf:pdf},
keywords = {- pauern recognition,arabic,even in the case,hidden,markov model,offline handwritten,segmentation and recognition,the concatenation of compound,thus,where,words are modeled as},
pages = {526--529},
publisher = {IEEE},
title = {{Offline Arabic handwriting recognition system based on HMM}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5564429},
volume = {1},
year = {2010}
}
@misc{PDB16Pudil1992,
abstract = {The idea on constructing a multi stage pattern clasification system
with reject option is presented and conditions in terms of upper
bounds of the cost of higher stage measurements for a multi stage
classifier to give lower decision risk than a single classifier are
derived.},
author = {Pudil, P and Novoicova, J and Blaha, S and Kittler, J},
file = {:D$\backslash$:/Papers/Documents/1992/Pudil et al. - 1992.pdf:pdf},
title = {{Multistage Pattern Recognition with Rejct Option}},
year = {1992}
}
@article{Benouareth2008,
abstract = {In this paper, we describe an off-line unconstrained handwritten Arabic word recognition system based on segmentation-free approach and semi-continuous hidden Markov models (SCHMMs) with explicit state duration. Character durations play a significant part in the recognition of cursive handwriting. The duration information is still mostly disregarded in HMM-based automatic cursive handwriting rec- ognizers due to the fact that HMMs are deficient in modeling character durations properly. We will show experimentally that explicit state duration modeling in the SCHMM framework can significantly improve the discriminating capacity of the SCHMMs to deal with very difficult pattern recognition tasks such as unconstrained handwritten Arabic recognition. In order to carry out the letter and word model training and recognition more efficiently, we propose a new version of the Viterbi algorithm taking into account explicit state duration modeling. Three distributions (Gamma, Gauss and Poisson) for the explicit state duration modeling have been used and a comparison between them has been reported. To perform word recognition, the described system uses an original sliding window approach based on vertical projection histogram analysis of the word and extracts a new pertinent set of statistical and structural features from the word image. Several experi- ments have been performed using the IFN/ENIT benchmark database and the best recognition perfor- mances achieved by our system outperform those reported recently on the same database.},
author = {Benouareth, a and Ennaji, A and Sellami, M},
doi = {10.1016/j.patrec.2008.05.008},
file = {:D$\backslash$:/Papers/Documents/2008/Benouareth, Ennaji, Sellami - 2008.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Reference From Doctor,off-line handwritten arabic word},
mendeley-tags = {Reference From Doctor},
month = sep,
number = {12},
pages = {1742--1752},
title = {{Semi-continuous HMMs with explicit state duration for unconstrained Arabic word modeling and recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865508001670},
volume = {29},
year = {2008}
}
@article{Aler2002,
author = {Aler, R},
doi = {10.1016/S0004-3702(02)00246-1},
file = {:D$\backslash$:/Papers/Documents/2002/Aler - 2002.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {citrve fitting,ocnetic i,rogramming},
month = oct,
number = {1-2},
pages = {29--56},
title = {{Using genetic programming to learn and improve control knowledge}},
volume = {141},
year = {2002}
}
@inproceedings{Rigoll2002,
author = {Rigoll, G and Kosmala, A and Rattland, J. and Neukirchen, Ch},
booktitle = {Pattern Recognition, 1996., Proceedings of the 13th International Conference on},
file = {:D$\backslash$:/Papers/Documents/2002/Rigoll et al. - 2002.pdf:pdf},
pages = {205--209},
publisher = {IEEE},
title = {{A comparison between continuous and discrete density hidden Markov models for cursive handwriting recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=546818},
volume = {2},
year = {2002}
}
@phdthesis{Oltmans2007,
author = {Oltmans, Michael},
file = {:D$\backslash$:/Papers/Documents/2007/Oltmans - 2007.pdf:pdf},
number = {2000},
pages = {1--100},
school = {MIT},
title = {{Envisioning Sketch Recognition: A local Feature Based approach to recognizing Informal Sketches}},
type = {Doctor of philosopy},
year = {2007}
}
@inproceedings{ARGolubitsky2008,
abstract = {The process of recognizing individual handwritten characters is one
of classifying curves. Typically, handwriting recognition systems�
even �online� systems�require entire characters be completed before
recognition is attempted. This paper presents another approach for
real-time recognition: certain characteristics of a curve can be
computed as the curve is being written, and these characteristics
are used to classify the character in constant time when the pen
is lifted. We adapt an earlier approach of representing curves in
a functional basis and reduce real-time stroke modelling to the Hausdorff
moment problem.},
address = {Ontario, Canada},
author = {Golubitsky, Oleg and Watt, Stephen M},
booktitle = {CASCON '08 : Proceedings of the 2008 conference of the center for advanced studies on collaborative research},
file = {:D$\backslash$:/Papers/Documents/2008/Golubitsky, Watt - 2008.pdf:pdf},
pages = {72--80},
title = {{Online Stroke Modeling for Handwriting Recognition}},
year = {2008}
}
@article{DSXu1992,
abstract = {Possible solutions to the problem of combining classifiers can be
divided into three categories according to the levels of information
available from the various classifiers. Four approaches based on
different methodologies are proposed for solving this problem. One
is suitable for combining individual classifiers such as Bayesian,
k -nearest-neighbor, and various distance classifiers. The other
three could be used for combining any kind of individual classifiers.
On applying these methods to combine several classifiers for recognizing
totally unconstrained handwritten numerals, the experimental results
show that the performance of individual classifiers can be improved
significantly. For example, on the US zipcode database, 98.9\% recognition
with 0.90\% substitution and 0.2\% rejection can be obtained, as well
as high reliability with 95\% recognition, 0\% substitution, and 5\%
rejection},
author = {Xu, L and Krzyzak, A and Suen, C Y},
doi = {10.1109/21.155943},
file = {:D$\backslash$:/Papers/Documents/1992/Xu, Krzyzak, Suen - 1992.pdf:pdf},
issn = {0018-9472},
journal = {IEEE Transactions on Systems, Man and Cybernetics},
keywords = {Bayesian classifiers;US zipcode database;distance },
number = {3},
pages = {418--435},
title = {{Methods of combining multiple classifiers and their applications to handwriting recognition}},
volume = {22},
year = {1992}
}
@booklet{PDB9SVM1998,
abstract = {This is different article in IEEE Magazine



My first exposure to Support Vector Machines came this spring when
I heard Sue

Dumais present impressive results on text categorization using this
analysis technique.

This issue�s collection of essays should help familiarize our readers
with this interesting

new racehorse in the Machine Learning stable. Bernhard Sch?lkopf,
in an introductory

overview, points out that a particular advantage of SVMs over other
learning

algorithms is that it can be analyzed theoretically using concepts
from computational

learning theory, and at the same time can achieve good performance
when applied to

real problems. Examples of these real-world applications are provided
by Sue Dumais,

who describes the aforementioned text-categorization problem, yielding
the best results

to date on the Reuters collection, and Edgar Osuna, who presents strong
results

on application to face detection. Our fourth author, John Platt, gives
us a practical

guide and a new technique for implementing the algorithm efficiently.

�Marti Hearst},
author = {Hearst, Marti A},
file = {:D$\backslash$:/Papers/Documents/1998/Hearst - 1998.pdf:pdf},
howpublished = {IEEE INTELLIGENT SYSTEMS},
keywords = {SVM},
month = jul,
title = {{Trends and controversies, Support vector machines}},
year = {1998}
}
@article{Mozaffari2008,
abstract = {Unlikemanyother languages, 18 out of 32 Farsi characters have dots appearing in groups of one, two or three.Someof these letters share common primary shapes, differing only in the number of dots and whether the dots are above or below the primary shape. In this paper, a new concept of using dots in a cursively handwritten Farsi/Arabic word is introduced for lexicon reduction and a fast method for extracting dots is presented. The technique involves extraction and representation of number and position of dots from off-line handwritten words to eliminate unlikely candidates. Experimental results on a set of 12,000 handwritten word images yield a lexicon reduction of 93\% with accu- racy of 85\%. The proposed lexicon reduction algorithm achieves the speedup factor of 2 as well as 13\% improvement in recognition rate. },
author = {Mozaffari, S and Faez, K and Margner, V and Elabed, H},
doi = {10.1016/j.patrec.2007.11.009},
file = {:D$\backslash$:/Papers/Documents/2008/Mozaffari et al. - 2008.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Reference From Doctor,arabic handwritten word recognition,discrete hidden markov model,dot extraction,lexicon reduction,off-line farsi,string matching},
mendeley-tags = {Reference From Doctor},
month = apr,
number = {6},
pages = {724--734},
title = {{Lexicon reduction using dots for off-line Farsi/Arabic handwritten word recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865507003741},
volume = {29},
year = {2008}
}
@inproceedings{Paulson2007,
annote = {the low level recognizier 

      },
author = {Paulson, Brandon and Hammond, Tracy},
booktitle = {ACM Symposium on User Interface Software and Technology (UIST2007)},
file = {:D$\backslash$:/Papers/Documents/2007/Paulson, Hammond - 2007.pdf:pdf},
keywords = {Sketch Research},
mendeley-tags = {Sketch Research},
title = {{A system for recognizing and beautifying low-level sketch shapes using ndde and dcr}},
url = {http://srlweb.cse.tamu.edu/srlng\_media/content/objects/object-1233786278-00f9a30e3da32718b248782400c4e5ed/Paulson\_Hammond\_LowLevel\_UIST.pdf},
year = {2007}
}
@article{Morita2003a,
author = {Morita, M. and Sabourin, R. and Bortolozzi, F. and Suen, C.Y.},
doi = {10.1109/ICDAR.2003.1227712},
file = {:D$\backslash$:/Papers/Documents/2003/Morita et al. - 2003.pdf:pdf},
isbn = {0-7695-1960-1},
journal = {Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.},
number = {Icdar},
pages = {482--486},
publisher = {IEEE Comput. Soc},
title = {{A recognition and verification strategy for handwritten word recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1227712},
year = {2003}
}
@electronic{ARBouchain2006,
abstract = {Pattern recognition is one of the traditional uses of neural networks.
When trained with gradient-based learning methods, these networks
can learn the classification of input data by example. An introduction
to classifiers and gradient-based learning is given. It is shown
how several perceptrons can be combined and trained gradient-based.
Furthermore, an overview of convolutional neural networks, as well
as a real-world example, are discussed.},
author = {Bouchain, David},
file = {:D$\backslash$:/Papers/Documents/2006/Bouchain - 2006.pdf:pdf},
howpublished = {Seminar Statistical Learning Theory},
institution = {University of Ulm, Germany},
keywords = { Neural Networks,Character Recognition},
title = {{Character Recognition Using Convolutional Neural Networks}},
year = {2006}
}
@misc{Marji2005,
author = {Marji, M},
booktitle = {Evaluation},
file = {:D$\backslash$:/Papers/Documents/2005/Marji - 2005.pdf:pdf},
number = {March},
pages = {2--7},
title = {{Lecture 24: Evaluation of Algorithms}},
year = {2005}
}
@article{Gennari2005a,
author = {Gennari, L and Kara, L and Stahovich, T and Shimada, K},
doi = {10.1016/j.cag.2005.05.007},
file = {:D$\backslash$:/Papers/Documents/2005/Gennari et al. - 2005.pdf:pdf},
issn = {00978493},
journal = {Computers \& Graphics},
month = aug,
number = {4},
pages = {547--562},
title = {{Combining geometry and domain knowledge to interpret hand-drawn diagrams}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849305000889},
volume = {29},
year = {2005}
}
@article{Gao2004,
abstract = {In sign language recognition (SLR), the major challenges now are developing methods that solve signer-independent continuous sign problems. In this paper, SOFM/HMM is first presented for modeling signer-independent isolated signs. The proposed method uses the self-organizing feature maps (SOFM) as different signers’ feature extractor for continuous hidden Markov models (HMM) so as to transform input signs into significant and low-dimensional representations that can be well modeled by the emission probabilities of HMM. Based on these isolated sign models, a SOFM/SRN/HMM model is then proposed for signer-independent continuous SLR. This model applies the improved simple recurrent network (SRN) to segment continuous sign language in terms of transformed SOFM representations, and the outputs of SRN are taken as the HMM states in which the latticeViterbi algorithm is employed to search the best matched word sequence. Experimental results demonstrate that the proposed system has better performance compared with conventional HMM system and obtains a word recognition rate of 82.9\% over a 5113-sign vocabulary and an accuracy of 86.3\% for signer-independent continuous SLR.  2004 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
author = {Gao, Wen and Fang, Gaolin and Zhao, Debin and Chen, Yiqiang},
doi = {10.1016/j.patcog.2004.04.008},
file = {:D$\backslash$:/Papers/Documents/2004/Gao et al. - 2004.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {chinese sign language,hidden markov model,self-organizing feature map,sign language recognition,simple recurrent network},
number = {12},
pages = {2389--2402},
publisher = {Elsevier},
title = {{A Chinese sign language recognition system based on SOFM/SRN/HMM}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320304001657},
volume = {37},
year = {2004}
}
@conference{PBPan2009,
abstract = {A new isolated handwritten Farsi numeral recognition algorithm is
proposed in this paper, which exploits the sparse and over-complete
structure from the handwritten Farsi numeral data. In this research,
the sparse structure is represented as an over-complete dictionary,
which is learned by the K-SVD algorithm. These atoms in this dictionary
are adopted to initialize the first layer of the Convolutional Neural
Network (CNN), the latter is then trained to do the classification
task. Data distortion techniques are also applied to promote the
generalization capability of the trained classifier. Experiments
have shown that good results have been achieved in CENPARMI handwritten
Farsi numeral database.},
author = {Pan, W M and Bui, T D and Suen, C Y},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Pan, Bui, Suen - 2009.pdf:pdf},
title = {{Isolated Handwritten Farsi numerals Recognition Using Sparse And Over-Complete Representations}},
year = {2009}
}
@article{ARPal2008,
abstract = {Indian pin code is a six-digit string. Because of the writing style
of different individuals some of the digits in a pin code string
may touch with its neighboring digits. Accurate segmentation of such
touching components into individual digits is a difficult task. To
avoid such segmentation, here we consider a pin code string as word
and the pin code recognition problem is treated as lexicon free word
recognition. In the proposed method, at first, binarization of the
input document is done. Next, water reservoir concept is applied
to pre-segment a pin code string into possible primitive components
(individual digits or its parts). Presegmented components of the
pin code are then merged into possible digits to get the best pin
code. In order to merge these primitive components into digits and
to find optimum segmentation, dynamic programming (DP) is applied
using total likelihood of digits as the objective function. To compute
the likelihood of a digit, modified quadratic discriminant function
(MQDF) is used. The features used in the MQDF are based on the directional
information of the components. Our system on handwritten Bangla pin
code shows 99.08\% reliability when rejection and error rates are
19.28\% and 0.74\%, respectively.},
author = {Pal, Umapada and Roy, Kaushik and Kimura, Fumitaka},
file = {:D$\backslash$:/Papers/Documents/2008/Pal, Roy, Kimura - 2008.pdf:pdf},
keywords = { Bangla script, Indian postal automation., Pin code recognition,Handwritten digit recognition},
title = {{Bangla Handwritten Pin Code String Recognition for Indian Postal}},
year = {2008}
}
@inproceedings{Gorgevik2004,
abstract = {This paper proposes an efficient three-stage classifier for handwritten digit recognition based on NN (Neural Network) and SVM (Support Vector Machine) classifiers. The classification is performed by 2 NNs and one SVM. The first NN is designed to provide a low misclassifica- tion rate using a strong rejection criterion. It is applied on a small set of easy to extract features. Rejected pat- terns are forwarded to the second NN that uses addi- tional, more complex features, and utilizes a well- balanced rejection criterion. Finally, rejected patterns from the second NN are forwarded to an optimized SVM that considers only the “top k” classes as ranked by the NN. This way a very fast SVM classification is obtained without sacrificing the classifier accuracy. The obtained recognition rate is among the best on the MNIST database and the classification time is much better compared to the single SVM applied on the same feature set.},
author = {Gorgevik, Dejan and Cakmakov, D.},
booktitle = {Pattern Recognition},
file = {:D$\backslash$:/Papers/Documents/2004/Gorgevik, Cakmakov - 2004.pdf:pdf},
pages = {507--510},
title = {{An efficient three-stage classifier for handwritten digit recognition}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICPR.2004.1333822},
volume = {4},
year = {2004}
}
@article{Hammond2002Tahuti,
address = {Stanford, California},
author = {Hammond, Tracy and Davis, Randall},
file = {:D$\backslash$:/Papers/Documents/2006/Hammond, Davis - 2006.pdf:pdf},
journal = {AAAI Spring Symposium on Sketch Understanding},
month = mar,
pages = {59--68},
publisher = {AAAI Press},
title = {{Tahuti: A Geometrical Sketch Recognition System for UML Class Diagrams}},
year = {2002}
}
@article{Hu2000,
abstract = {n this paper we describe a Hidden Markov Model (HMM) based writer independent handwriting recognition system. A combination of signal normalization preprocessing and the use of invariant features makes the system robust with respect to variability among di!erent writers as well as di!erent writing environments and ink collection mechanisms. A combination of point oriented and stroke oriented features yields improved accuracy. Language modeling constrains the hypothesis space to manageable levels in most cases. In addition a two-pass N-best approach is taken for large vocabularies. We report experimental results for both character and word recognition on several UNIPEN datasets, which are standard datasets of English text collected from around the world.},
author = {Hu, Jianying and Lim, Sok Gek and Brown, Michael K.},
doi = {10.1016/S0031-3203(99)00043-6},
file = {:D$\backslash$:/Papers/Documents/2000/Hu, Lim, Brown - 2000.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Reference From Doctor,handwriting recognition,hidden markov models,invariant features,n-best decoding,segmental features,unipen},
mendeley-tags = {Reference From Doctor},
month = jan,
number = {1},
pages = {133--147},
title = {{Writer independent on-line handwriting recognition using an HMM approach}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320399000436},
volume = {33},
year = {2000}
}
@article{Brieler2010,
abstract = {Many of today's recognition approaches for hand-drawn sketches are feature-based, which is conceptually similar to the recognition of hand-written text. While very suitable for the latter (and more tasks, e.g., for entering gestures as commands), such approaches do not easily allow for clustering and segmentation of strokes, which is crucial to their recognition. This results in applications which do not feel natural but impose artificial restrictions on the user regarding how sketches and single components (shapes) are to be drawn. This paper proposes a concept and architecture for a generic geometry-based recognizer. It is designed for the mentioned issue of clustering and segmentation. All strokes are fed into independent preprocessors called transformers that process and abstract the strokes. The result of the transformers is stored in models. Each model is responsible for a certain type of primitive, e.g., a line or an arc. The advantage of models is that different interpretations of a stroke exist in parallel, and there is no need to rate or sort these interpretations. The recognition of a component in the drawing is then decomposed into the recognition of its primitives that can be directly queried for in the models. Finally, the identified primitives are assembled to the complete component. This process is directed by an automatically computed search plan, which exhibits shape characteristics in order to ensure an efficient recognition. In several case studies the applicability and generality of the proposed approach is shown, as very different types of components can be recognized. Furthermore, the proposed approach is part of a complete system for sketch understanding. This system not only recognizes single components, but can also understand sketched diagrams as a whole, and can resolve ambiguities by syntactical and semantical analysis. A user study was conducted to obtain recognition rates and runtime data of our recognizer.},
author = {Brieler, Florian and Minas, Mark},
doi = {10.1016/j.jvlc.2009.12.002},
file = {:D$\backslash$:/Papers/Documents/2010/Brieler, Minas - 2010.pdf:pdf},
issn = {1045926X},
journal = {Journal of Visual Languages \& Computing},
keywords = {geometry-based recognition,sketch recognition,sketching},
month = apr,
number = {2},
pages = {81--97},
title = {{A model-based recognition engine for sketched diagrams}},
url = {http://dx.doi.org/10.1016/j.jvlc.2009.12.002},
volume = {21},
year = {2010}
}
@misc{Hammond2002b,
author = {Hammond, Tracy Anne and Oshiro, Kalani and Davis, Randall},
file = {:D$\backslash$:/Papers/Documents/2002/Hammond, Oshiro, Davis - 2002.pdf:pdf},
pages = {1},
title = {{Natural Editing and Recognition of UML class diagrams.}},
year = {2002}
}
@article{PDB8AlOmari2004,
abstract = {This paper presents a system for the recognition of the handwritten
Indian numerals one to nine (1�9) using a probabilistic neural network
(PNN) approach. The process involved extracting a feature vector
to represent the handwritten digit based on the center of gravity
and a set of vectors to the boundary points of the digit object.
The feature vector is scale-, translation-, and rotation-invariant.
The extracted feature vector is fed to a PNN, which in turn classifies
it as one of the nine digits. A set of experiments were conducted
to test the performance of the system under different angles between
the vectors from the centroid to the boundary of the digit object.
A 308 angle results in a 99.72\% recognition rate with a short feature
vector of 12 entries. This study is meant to be a seed toward building
a recognition system for Arabic language characters.},
author = {Al-Omari, Faruq A and Al-Jarrah, Omar M},
doi = {http://dx.doi.org/10.1016/j.aei.2004.02.001},
file = {:D$\backslash$:/Papers/Documents/2004/Al-Omari, Al-Jarrah - 2004.pdf:pdf},
journal = {Advanced Engineering Informatics},
keywords = { Handwritten digits, Neural Networks, Pattern Recognition, Probabilistic},
number = {1},
pages = {9--16},
title = {{Handwritten Indian numerals recognition system using probabilistic neural networks.}},
volume = {18},
year = {2004}
}
@article{Vinciarelli2004,
abstract = {This paper presents a system for the offline recognition of large vocabulary unconstrained handwritten texts. The only assumption made about the data is that it is written in English. This allows the application of Statistical Language Models in order to improve the performance of our system. Several experiments have been performed using both single and multiple writer data. Lexica of variable size (from 10,000 to 50,000 words) have been used. The use of language models is shown to improve the accuracy of the system (when the lexicon contains 50,000 words, the error rate is reduced by approximately 50 percent for single writer data and by approximately 25 percent for multiple writer data). Our approach is described in detail and compared with other methods presented in the literature to deal with the same problem. An experimental setup to correctly deal with unconstrained text recognition is proposed.},
author = {Vinciarelli, Alessandro and Bengio, Samy and Bunke, Horst},
doi = {10.1109/TPAMI.2004.14},
file = {:D$\backslash$:/Papers/Documents/2004/Vinciarelli, Bengio, Bunke - 2004.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automatic Data Processing,Automatic Data Processing: methods,Biometry,Biometry: methods,Computer Graphics,Documentation,Handwriting,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Markov Chains,Models, Statistical,Numerical Analysis, Computer-Assisted,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reference From Doctor,Reproducibility of Results,Sensitivity and Specificity,Signal Processing, Computer-Assisted,Subtraction Technique,User-Computer Interface},
mendeley-tags = {Reference From Doctor},
month = jun,
number = {6},
pages = {709--20},
pmid = {18579932},
title = {{Offline recognition of unconstrained handwritten texts using HMMs and statistical language models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18579932},
volume = {26},
year = {2004}
}
@article{Lank2003,
author = {Lank, E.H.},
doi = {10.1109/ICDAR.2003.1227656},
file = {:D$\backslash$:/Papers/Documents/2003/Lank - 2003.pdf:pdf},
isbn = {0-7695-1960-1},
journal = {Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.},
pages = {185--189},
publisher = {IEEE Comput. Soc},
title = {{A retargetable framework for interactive diagram recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1227656},
year = {2003}
}
@article{Oltmans2006,
address = {New York, New York, USA},
author = {Oltmans, Michael and Davis, Randall},
doi = {10.1145/1185657.1185784},
file = {:D$\backslash$:/Papers/Documents/2006/Oltmans, Davis - 2006.pdf:pdf},
isbn = {1595933646},
journal = {ACM SIGGRAPH 2006 Courses on - SIGGRAPH '06},
pages = {23},
publisher = {ACM Press},
title = {{Naturally conveyed explanations of device behavior}},
url = {http://portal.acm.org/citation.cfm?doid=1185657.1185784},
year = {2006}
}
@inproceedings{Namboodiri2004,
author = {Namboodiri, Anoop M. and Jain, Anil.K.},
booktitle = {Proceedings of the 17th International Conference on Pattern Recognition (ICPR’04)},
file = {:D$\backslash$:/Papers/Documents/2004/Namboodiri, Jain - 2004.pdf:pdf},
pages = {1--10},
title = {{Retrieval of online hand drawn sketches}},
year = {2004}
}
@inproceedings{Zhao2003,
abstract = {In this paper, a Cascade Connection Hidden Markov Model (CCHMM) method for on-line English word recognition is propawd. This model, which allows state transition, skip and duration, extends the way of HMM pattern description of handwriting English words. According to the statistic probabilities, the behavior of handwriting CUN\~{} may he depicted’more precisely. The Viterhi algorithm for the cascade connection model may be applied after the whole sample series of a word is input. Compared with the method of creating models for each word in lexicon, this method gives a faster recognition speed. Experiments show that CCHMM approach could obtain 89.26\% recognition rate for the first candidate, while the combination. of character and ligature HMM method’s first candidate is 82.34\%},
author = {Zhao, W. and Liu, J.F. and Tang, X.L.},
booktitle = {Machine Learning and Cybernetics, 2002. Proceedings. 2002 International Conference on},
file = {:D$\backslash$:/Papers/Documents/2003/Zhao, Liu, Tang - 2003.pdf:pdf},
isbn = {0780375084},
keywords = {cascade connection hidden,handwritten word recognition,inter-model state transition probability,markov model},
number = {November},
pages = {1758--1761},
publisher = {IEEE},
title = {{Online handwritten English word recognition based on cascade connection of character HMMs}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1175338},
volume = {4},
year = {2003}
}
@inproceedings{Alimoglu1996,
author = {Alimoglu, Fevzi and Alpaydin, E.},
booktitle = {Proceedings of the Fifth Turkish Artificial Intelligence and Artificial Neural Networks Symposium (TAINN 96},
file = {:D$\backslash$:/Papers/Documents/1996/Alimoglu, Alpaydin - 1996:},
publisher = {Citeseer},
title = {{Methods of Combining Multiple Classifiers Based on Different Representations for Pen-based Handwritten Digit Recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.6383},
year = {1996}
}
@inproceedings{Hong2002,
author = {Hong, Jason and Landay, James and Long, A.C. and Mankoff, Jennifer},
booktitle = {Sketch Understanding, Papers from the 2002 AAAI Spring Symposium},
file = {:D$\backslash$:/Papers/Documents/2002/Hong et al. - 2002.pdf:pdf},
pages = {73--77},
title = {{Sketch recognizers from the end-user’s, the designer’s, and the programmer’s perspective}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Sketch+Recognizers+from+the+End-User+’+s+,+the+Designer+’+s+,+and+the+Programmer+’+s+Perspective\#0},
year = {2002}
}
@article{DSPalacios2008,
abstract = {In the US and many other countries, bank previous termchecksnext term
are preprinted with the account number and the previous termchecknext
term number in special ink and format; as such, these two numeric
fields can be easily read and processed using automated techniques.
However, the amount fields on a filled-in previous termchecknext
term is usually read by human eyes, and involves significant time
and cost, especially when one considers that over 50 billion previous
termchecksnext term are processed per annum in the US alone. The
system described in this paper uses the scanned image of a bank previous
termchecknext term to �read� the previous termcheck.next term It
includes three main modules that allow for fully automated bank previous
termchecknext term processing.

These three modules are described in the paper; they focus sequentially
on: the detection of strings within the image; the segmentation and
previous termrecognitionnext term of string in a feedback loop; and
the post-processing issues that help to ensure higher accuracy of
previous termrecognition.next term The major benefit of the integrated
system is the ability to address the complex problem of reading handwritten
bank previous termchecksnext term by implementing efficient algorithms
for each processing step. All modules have been implemented and subsequently
tested for reading the value of the previous termchecknext term using
different image databases. Due to the particular requirements of
this application, the system can be tuned to yield low levels of
incorrect readings; this, in turn, leads to higher levels of rejection
than the levels encountered in other handwritten previous termrecognitionnext
term applications. A �rejected� previous termchecknext term can be
read subsequently by human eyes or other more advanced automated
approaches. However, a previous termchecknext term �read� incorrectly
is more difficult to deal with, in terms of costs and time involved
to rectify the mistake. As such, our architecture can be geared towards
producing the most suitable balance between inaccurate readings and
rejection level, in accordance with user preferences. The experimental
results presented in the paper do not focus on the best possible
results for a particular database of previous termchecks;next term
instead, they show the benefits attained independently by each of
the modules proposed.},
author = {Palaciosa, Rafael and Guptab, Amar},
file = {:D$\backslash$:/Papers/Documents/2008/Palaciosa, Guptab - 2008.pdf:pdf},
journal = {Image and Vision Computing},
keywords = {Handwritten previous termchecksnext term; Reading },
month = oct,
number = {10},
pages = {1297--1313},
title = {{A system for processing handwritten bank checks automatically}},
volume = {26},
year = {2008}
}
@article{Camastra2001,
author = {Camastra, F},
doi = {10.1016/S0167-8655(01)00008-3},
file = {:D$\backslash$:/Papers/Documents/2001/Camastra - 2001.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Reference From Doctor,cross-validation,cursive character recognition,feature extraction,learning vector quantization},
mendeley-tags = {Reference From Doctor},
month = may,
number = {6-7},
pages = {625--629},
title = {{Cursive character recognition by learning vector quantization}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865501000083},
volume = {22},
year = {2001}
}
@article{MCKharma2001,
abstract = {This paper describes an application of a novel mapping, one that is
intended for use in on-line hand-written character recognition. This
mapping produces the same output pattern regardless of the orientation,
position, and size of the input pattern. The mapping has the advantage
of being simple. This makes it computationally ecient and fast,
which in turn makes it appropriate for on-line implementations. To
demonstrate the usefulness of this mapping, a recognition system
utilizing it has been developed for hand-written Arabic characters.
The performance of this system is shown to be comparable to that
of the existing on-line Arabic character recognition systems.},
author = {Kharma, Nawwaf N and Ward, Rabab K},
file = {:D$\backslash$:/Papers/Documents/2001/Kharma, Ward - 2001.pdf:pdf},
journal = {Pattern Recognition},
pages = {2115--2120},
title = {{A novel invariant mapping applied to hand-written arabic character recognition}},
volume = {34},
year = {2001}
}
@article{Oliveira2002,
author = {Oliveira, L.S. and Sabourin, R. and Bortolozzi, F. and Suen, C.Y.},
file = {:D$\backslash$:/Papers/Documents/2002/Oliveira et al. - 2002.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {11},
pages = {1438--1454},
publisher = {Citeseer},
title = {{Automatic recognition of handwritten numerical strings: A recognition and verification strategy}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.4.4101\&amp;rep=rep1\&amp;type=pdf},
volume = {24},
year = {2002}
}
@inproceedings{Naya2004,
author = {Naya, Ferran and Contero, Manuel and Aleixos, Nuria and Jorge, Joaquim},
booktitle = {Computational Science and Its Applications–ICCSA 2004},
file = {:D$\backslash$:/Papers/Documents/2004/Naya et al. - 2004.pdf:pdf},
pages = {613--621},
publisher = {Springer},
title = {{Parametric Freehand Sketches}},
url = {http://www.springerlink.com/index/77FB2A4X8840P5E3.pdf},
year = {2004}
}
@inproceedings{Mozaffari2004,
author = {Mozaffari, Saeed and Faez, K. and Kanan, HR},
booktitle = {Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004},
file = {:D$\backslash$:/Papers/Documents/2004/Mozaffari, Faez, Kanan - 2004.pdf:pdf},
title = {{Feature comparison between fractal codes and wavelet transform in handwritten alphanumeric recognition using SVM classifier}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1334199},
volume = {2},
year = {2004}
}
@article{Gross1994,
address = {New York, New York, USA},
author = {Gross, Mark D.},
doi = {10.1145/192309.192330},
file = {:D$\backslash$:/Papers/Documents/1994/Gross - 1994(2).pdf:pdf},
isbn = {0897917332},
journal = {Proceedings of the workshop on Advanced visual interfaces - AVI '94},
pages = {88--94},
publisher = {ACM Press},
title = {{Recognizing and interpreting diagrams in design}},
url = {http://portal.acm.org/citation.cfm?doid=192309.192330},
year = {1994}
}
@article{Solimanpour2006,
abstract = {This paper describes an important step towards the standardization of the research on Optical Character Recognition (OCR) in Farsi language. It describes formations of novel and standard handwritten databases including isolated digits, letters, numerical strings, Legal amounts (used for cheques), and dates. Despite conventional research and an Internet search, no publicly accessible Farsi database was found. Hence, it was decided that it would be a worthwhile academic effort to create several Farsi databases that could stand on their own merit functioning as useful tools for OCR researchers. Also, in order to show the potential uses of our new databases we also conducted some experiments on the recognition of handwritten isolated Farsi digits},
author = {Solimanpour, Farshid and Sadri, J. and Suen, C.Y.},
file = {:D$\backslash$:/Papers/Documents/2006/Solimanpour, Sadri, Suen - 2006.pdf:pdf},
journal = {Pattern Recognition},
keywords = {arabic handwritten databases,farsi,farsi handwritten databases,farsi ocr,handwritten recognition,indian digits database,standard databases in order,to improve research on},
title = {{Standard databases for recognition of handwritten digits, numerical strings, legal amounts, letters and dates in Farsi language}},
url = {http://hal.inria.fr/inria-00103983/},
year = {2006}
}
@article{Sezgin2002GeneratingSOW,
author = {Sezgin, Tevfik Metin},
file = {:D$\backslash$:/Papers/Documents/2002/Sezgin - 2002(2).pdf:pdf},
journal = {Proceedings of the MIT Student Oxygen Workshop},
title = {{Generating Domain Specific Sketch Recognizers From Object Descriptions}},
year = {2002}
}
@article{Tang2004,
author = {Tang, X. and Wang, X.},
doi = {10.1109/TCSVT.2003.818353},
file = {:D$\backslash$:/Papers/Documents/2004/Tang, Wang - 2004.pdf:pdf},
issn = {1051-8215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
month = jan,
number = {1},
pages = {50--57},
title = {{Face Sketch Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1262031},
volume = {14},
year = {2004}
}
@article{ARFarooq2009,
abstract = {We propose a method for increasing word recognition accuracies by
correcting the output of a handwriting recognition system. We treat
the handwriting recognizer as a black box, such that there is no
access to its internals. This enables us to keep our algorithm general
and independent of any particular system. We use a novel method for
correcting the output based on a �phrase-based� system in contrast
to traditional source-channel models. We report the accuracies of
two in-house handwritten word recognizers before and after the correction.
We achieve highly encouraging results for a large synthetically generated
dataset. We also report results for a commercially available OCR
on real data.},
author = {Farooq, Faisal and Jose, Damien and Govindaraju, Venu},
doi = {http://dx.doi.org/10.1016/j.patcog.2008.12.014},
file = {:D$\backslash$:/Papers/Documents/2009/Farooq, Jose, Govindaraju - 2009.pdf:pdf},
journal = {Pattern Recognition},
keywords = { Error correction, Handwriting recognition, Noisy channel, Viterbi decoding,Post-processing},
number = {12},
pages = {3271--3277},
title = {{Phrase-based correction model for improving handwriting recognition accuracies}},
volume = {42},
year = {2009}
}
@mastersthesis{Alvarado2000Natural,
author = {Alvarado, Christine},
school = {MIT},
title = {{A Natural Sketching Environmant: Bringing the Computer into Early Stages of Mechanical Design}},
year = {2000}
}
@article{Blostein2002,
author = {Blostein, D. and Cordy, J. and Zanibbi, R.},
doi = {10.1109/ICPR.2002.1047810},
file = {:D$\backslash$:/Papers/Documents/2002/Blostein, Cordy, Zanibbi - 2002.pdf:pdf},
isbn = {0-7695-1695-X},
journal = {Object recognition supported by user interaction for service robots},
pages = {123--126},
publisher = {IEEE Comput. Soc},
title = {{Applying compiler techniques to diagram recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1047810},
year = {2002}
}
@article{Huang2008,
abstract = {In this paper a hidden Markov model (HMM)-based binarization algorithm is presented. This algorithm performs well for images with nonuniform background. To test the usefullness of the proposed technique some images of composite documents of printed characters were used. These characters were extracted through the proposed binarization algorithms and used in a commercial OCR. A comparative study of various binarization techniques is also presented},
author = {Huang, Songtao and Ahmadi, Majid and Sid-Ahmed, MA},
doi = {10.1016/j.patcog.2008.03.004},
file = {:D$\backslash$:/Papers/Documents/2008/Huang, Ahmadi, Sid-Ahmed - 2008.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {binarization,hmm,ocr,stroke,thresholding},
number = {9},
pages = {2890--2900},
publisher = {Elsevier},
title = {{A hidden Markov model-based character extraction method}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308000885},
volume = {41},
year = {2008}
}
@article{FE5Yang2002,
abstract = {In this paper, we combine two kinds of features together by virtue
of complex vectors and then use the developed generalized K�L transform
(or expansion) for feature extraction. The experiments on NUST603
handwritten Chinese character database and CENPARMI handwritten digit
database indicate that the proposed method can improve the recognition
rate significantly.},
author = {Yang, Jian and yu Yang, Jing},
file = {:D$\backslash$:/Papers/Documents/2002/Yang, yu Yang - 2002.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Features Extraction},
pages = {295--297},
title = {{Generalized K�L transform based combined feature extraction}},
volume = {35},
year = {2002}
}
@article{Veselova2006,
address = {New York, New York, USA},
author = {Veselova, Olya and Davis, Randall},
doi = {10.1145/1185657.1185789},
file = {:D$\backslash$:/Papers/Documents/2006/Veselova, Davis - 2006.pdf:pdf},
isbn = {1595933646},
journal = {ACM SIGGRAPH 2006 Courses on - SIGGRAPH '06},
pages = {28},
publisher = {ACM Press},
title = {{Perceptually based learning of shape descriptions for sketch recognition}},
url = {http://portal.acm.org/citation.cfm?doid=1185657.1185789},
year = {2006}
}
@inproceedings{DSSantos2002,
abstract = { The most common goal of automatic bank cheque treatment systems is
the recognition of handwritten information. However, in order to
do this, it is necessary to use a reliable and efficient process
able to identify and to extract the information, which can then be
submitted to a further recognition phase. We present a process for
identifying and distinguishing between handwritten information and
machine printed text based on a set of local features. This process
is based on the characterization of textual elements via properties
derived from their content and their shape. The main advantage of
this process compared with other similar approaches is that no a
priori information of the treated document is used, thus making it
more generic and effective.},
author = {{Eduardo Bastos Dos Santos}, J and Dubuisson, B and Bortolozzi, F},
booktitle = {Computer Graphics and Image Processing, 2002. Proceedings. XV Brazilian Symposium on},
doi = {10.1109/SIBGRA.2002.1167144},
file = {:D$\backslash$:/Papers/Documents/2002/Eduardo Bastos Dos Santos, Dubuisson, Bortolozzi - 2002.pdf:pdf},
issn = {1530-1834},
keywords = { ;, ;image segmentation;machine printed text;text rec, ;image segmentation;optical,automatic bank cheque treatment systems;bank chequ},
pages = {203--209},
title = {{Characterizing and distinguishing text in bank cheque images}},
year = {2002}
}
@article{Freund1999,
author = {Freund, Yoav and Schapire, R. and Abe, N.},
file = {:D$\backslash$:/Papers/Documents/1999/Freund, Schapire, Abe - 1999.pdf:pdf},
issn = {0912-8085},
journal = {JOURNAL-JAPANESE SOCIETY FOR ARTIFICIAL INTELLIGENCE},
number = {5},
pages = {771--780},
publisher = {Citeseer},
title = {{A short introduction to boosting}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.93.5148\&amp;rep=rep1\&amp;type=pdf},
volume = {14},
year = {1999}
}
@article{Mahmoud2009,
abstract = {This paper describes a technique for automatic recognition of off-line handwritten Arabic (Indian) numerals using Support Vector Machines (SVM) and Hidden Markov Models (HMM). Local, intermediate, and large scale features are used. SVM parameters, producing the highest recognition rates, are experimentally found by using an exhaustive search algorithm. In addition, SVM classifier results are compared to those of the HMM classifier. The present research uses a database of 44 writers with 48 samples of each digit totaling 21120 samples. The SVM and HMM classifiers were trained with 75\% of the data and tested with the remaining data. Other divisions of data for training and testing were performed and resulted in comparable performance. The achieved average recognition rates were 99.83\% and 99.00\% using, respectively, the SVM and HMM classifiers. SVM recognition rates proved to be better for all digits. Comparison at the writer’s level (Writers 34 to 44) showed that SVM results outperformed HMM results for all tested writers. The classification errors of the SVM classifier were analyzed. The presented technique, using the powerful set of features and the SVM classifier, proved to be effective in the recognition of independent writer Arabic (Indian) numerals and was shown to be superior to the HMM classifier.},
annote = {==========================================

        Paper Index : Mahmoud2009

        Date:23-11-2010 

        
          
Why read paper ?
        

        
Svm and hmm with digit comparision. 

        

        Paper Overview ?
        
it is arabic digits offlin system uses different types of features (gradient, concavity and density ) then use either SVM and HMM classifiers. 

        
          
What is these paper about ? (Summary)
        

        
First 

        preprocessing:
        
The image is binirized using threshold algorithm, 
Segment division:
the binarized image is divided into segments of 3X3 or nXm grid. 
The size of each segment is not equal, nxn grid is generted with equal number of pixle in each column or row (see figure 3). 
The image is divided that In each n row the number of black pixels  are the same. (same is done for column)

        

        Features extraction:
        
Features is computed for each segment as following:
a) gradinet features
Sobel operator is used to get the directional grandient of the direction. Then direction is divided into 12 regions (degree). the histogram of each region is computed for each segment based on the calculated gradient direction. 
b) structural features 
A set of 12  rules that capture the mini strokes features are computed. ( each rule check the neighbourhood of each pixel and there shapes). 
(see table 1. )
c) concavity features
 consist of segment desnity of black segments ,  maximum vertical and horizontal strokes 
and  concavity featuers 

        Classification and recognition:
        
Two classifier were experiement SVM and HMM
the SVM RBF model was used to recognize the characters 
as for  HMM , model for each digit is used with viterbi algorithm to get max likely segment (digit).  As the system use no sliding windows ,  and the features are computed on the whole image, the features set is split into 10 observation sequence. and presented to the HMM in sequence. 

        

        Result:
        
Dataset of 44 writers with 10 digits and 48 sample per user. so 21,000  nearly samples. 
SVM (99.83\%) result better than HMM (99.0\%)
 A comparison with different features vectors are used and the best result with using all features (GSC)..  
different result based on number of states in HMM and SVM paramters.  
Seperate dcigits analysis to wrong digits. 

        

        1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?
        

        
Using previouly simple image based features with HMM by spliting the feature vectors and using one HMM per digit. 
also a good comparision betweeen HMM and RBF SVM. 

        
          
2. What can we take from this work  ? what do we learn ?  What can be incorporated into our own work ?
        
 We can use the image based features used on character recognition with HMM. ( same feature used in SVM). 
The division of grid based on number of pixel captures the location of interest (gives a good division than equal distance grid). 

        
          
3. What are the problems of the paper ?
        

        
Maybe the division of digits ( is it better than equal distance or is it better based on number of pixels ) it need more investigation. 

        

        4. what is lacking from the work ? why does this work knot be the final  research in this subject ?
        

        
It is good paper nearly lacking nothing.  It may need some testing on other dataset and other languages and application on chracters not digits. 

        

        5. what about the methods causes this lack ? is there a fundamental reason ?
        

        

        6. Could incremental Changes Fix this lack ? if so, what changes ? 
        

        

        

        Is there is any question you had about the paper ? 
        

        

        
          
The final conclusion..........
        

        
Good paper with good analysis of error and final result of 99.83\%  on arabic digits. 
Also the basic idea of spliting feature vector to present it to HMM, and the use of same feature for both SVM and HMM. 
==========================================================================

      },
author = {Mahmoud, S.A. and Awaida, S.M.},
file = {:D$\backslash$:/Papers/Documents/2009/Mahmoud, Awaida - 2009.pdf:pdf},
journal = {Arabian Journal for Science and Engineering},
keywords = {Arabic (Indian) automatic numeral recognition,Arabic Handwritting recognition,HMM,Intelligent Character Recognition (ICR),Read,Reference From Doctor,SVM,Summarized,feature extraction,handwritten digit recognition,normalization},
mendeley-tags = {Arabic Handwritting recognition,Read,Reference From Doctor,Summarized},
number = {2B},
pages = {430},
title = {{RECOGNITION OF OFF-LINE HANDWRITTEN ARABIC (INDIAN) NUMERALS USING MULTI-SCALE FEATURES AND SUPPORT VECTOR MACHINES VS. HIDDEN MARKOV MODELS}},
url = {http://ajse.kfupm.edu.sa/articles/342B\_P.11.pdf},
volume = {34},
year = {2009}
}
@article{Lee2006,
author = {Lee, W.S. and Kara, L.B. and Stahovich, T.F.},
file = {:D$\backslash$:/Papers/Documents/2006/Lee, Kara, Stahovich - 2006.pdf:pdf},
journal = {Sketch-Based Interfaces and Modeling 2006},
pages = {11},
publisher = {Eurographics},
title = {{An efficient graph-based symbol recognizer}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=bcCCXXjSBkMC\&amp;oi=fnd\&amp;pg=PA11\&amp;dq=An+efficient+graph-based+symbol+recognizer\&amp;ots=63eJ488cr3\&amp;sig=Dea1uAazYAxzAMuVgRRM102cDgk},
year = {2006}
}
@article{MCSingh2005,
abstract = {In this paper we propose a �bank of classifiers� approach to image
region labelling and evaluate dynamic classifier selection and classifier
combination approaches against a baseline approach that works with
a single best classifier chosen using a validation set. In this analysis,image
segmentation,feature extraction, and classification are treated as
three separate steps of analysis. The classifiers used are each trained
with a different texture feature representation of training images.
The paper proposes a new knowledge-based predictive approach based
on estimating the Mahalanobis distance between test sample feature
values and the corresponding probability distribution function from
training data that selectively triggers classifiers. This approach
is shown to perform better than probability-based classifier combination
(all classifiers are triggered but their decisions are fused with
combination rules),and single classifier, respectively,based on classification
rates and confusion matrices. The experiments are performed on the
natural scene analysis application.},
author = {Singh, Sameer and Singh, Maneesha},
file = {:D$\backslash$:/Papers/Documents/2005/Singh, Singh - 2005.pdf:pdf},
journal = {Signal Processing: Image Communication},
keywords = {Scene analysis; Texture analysis; Image segmentati},
pages = {219�231},
title = {{A dynamic classifier selection and combination approach to image region labelling}},
volume = {20},
year = {2005}
}
@article{Wshah2009,
author = {Wshah, Safwan and Shi, Zhixin and Govindaraju, Venu},
doi = {10.1109/ICDAR.2009.152},
file = {:D$\backslash$:/Papers/Documents/2009/Wshah, Shi, Govindaraju - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {793--797},
publisher = {Ieee},
title = {{Segmentation of Arabic Handwriting Based on both Contour and Skeleton Segmentation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277512},
year = {2009}
}
@misc{Alvarado2001,
author = {Alvarado, Christine J and Sezgin, Tevfik Metin and Scott, Dana and Hammond, Tracy Anne and Kasheff, Zardosht and Oltmans, Michael and Davis, Randall},
file = {:D$\backslash$:/Papers/Documents/2001/Alvarado et al. - 2001.pdf:pdf},
pages = {1},
title = {{A frame work for multi domain sketch recognition}},
year = {2001}
}
@article{Anderson2002,
address = {New York, New York, USA},
author = {Anderson, Michael and Armen, Chris},
doi = {10.1145/569005.569014},
file = {:D$\backslash$:/Papers/Documents/2002/Anderson, Armen - 2002.pdf:pdf},
isbn = {1581135556},
journal = {Proceedings of the 2nd international symposium on Smart graphics - SMARTGRAPH '02},
pages = {55--62},
publisher = {ACM Press},
title = {{DiaSketches}},
url = {http://portal.acm.org/citation.cfm?doid=569005.569014},
year = {2002}
}
@article{Rodriguez-Serrano2010,
abstract = {In this paper we propose a novel approach for writer adaptation in a handwritten word-spotting task. The method exploits the fact that the semi-continuous hidden Markov model separates the word model parameters into (i) a codebook of shapes and (ii) a set of word-specific parameters. Our main contribution is to employ this property to derive writer-specific word models by statistically adapting an initial universal codebook to each document. This process is unsupervised and does not even require the appearance of the keyword(s) in the searched document. Experimental results show an increase in performance when this adaptation technique is applied. To the best of our knowledge, this is the first work dealing with adaptation for word-spotting. The preliminary version of this paper obtained an IBM Best Student Paper Award at the 19th International Conference on Pattern Recognition.},
author = {Rodr\'{\i}guez-Serrano, Jos\'{e} a. and Perronnin, Florent and S\'{a}nchez, Gemma and Llad\'{o}s, Josep},
doi = {10.1016/j.patrec.2010.01.007},
file = {:D$\backslash$:/Papers/Documents/2010/Rodr\'{\i}guez-Serrano et al. - 2010.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
month = jun,
number = {8},
pages = {742--749},
publisher = {Elsevier B.V.},
title = {{Unsupervised writer adaptation of whole-word HMMs with application to word-spotting}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865510000097},
volume = {31},
year = {2010}
}
@inproceedings{Alamri2008,
abstract = {This paper presents the work toward developing a new comprehensive database for Arabic off-line handwriting recognition. The database includes: isolated Indian digits, numerical strings, Arabic isolated letters,i and a collection of 70 Arabic words. Also, the database includes a free format sample of an Arabic date. A data entry form was designed to collect written samples from Arabic native speakers. Our database is advanced in terms of the variety of sets, words and number of the participants involved. The databases have been divided into respective training, testing and validation sets which will be available in the future for the handwriting recognition community},
author = {Alamri, Huda and Sadri, Javad and {Ching Y Suen} and Nobile, Nicola},
booktitle = {Proc. of the 11 th Int. Conference on Frontiers in Handwriting Recognition (ICFHR 2008)},
file = {:D$\backslash$:/Papers/Documents/2008/Alamri et al. - 2008(2).pdf:pdf},
keywords = {arabic,arabic handwritten recognition,farsi handwritten,handwritten segmentation,ocr},
pages = {664----669},
title = {{A Novel Comprehensive Database for Arabic Off-Line Handwriting Recognition}},
year = {2008}
}
@phdthesis{ThZhang2006,
author = {Zhang, Ping},
booktitle = {Focus},
file = {:D$\backslash$:/Papers/Documents/2006/Zhang - 2006.pdf:pdf},
number = {April},
pages = {1--164},
school = {Concordia University},
title = {{Reliable Recognition of Handwritten Digits Using A Cascade Ensemble Classifier System and Hybrid Features}},
type = {PhD},
year = {2006}
}
@inproceedings{Reynolds1987,
author = {Reynolds, CW},
booktitle = {Proceedings of the 14th annual conference on},
file = {:D$\backslash$:/Papers/Documents/1987/Reynolds - 1987.pdf:pdf},
title = {{Flocks, herds and schools: A distributed behavioral model}},
url = {http://portal.acm.org/citation.cfm?id=37402.37406},
year = {1987}
}
@article{MCGutta1997,
abstract = {We address the problem of surveillance and contents-based image retrieval
(CBIR) for large image databases consisting of face images. The corresponding
face recognition tasks considered herein include (i) surveying a
gallery of images for the presence of specific probes, (ii) CBIR,
and (iii) CBIR subject to correct ID ("match") displaying specific
facial landmarks such as wearing glasses. We developed robust matching
("classification") and retrieval schemes based on hybrid classifiers
and showed their feasibility using the FERET database. The hybrid
classifier architecture consists of an ensemble of connectionist
networks--radial basis functions (RBF)--and inductive decision trees
(DT). The specific characteristics of our hybrid architecture include
(a) query by consensus as provided by ensembles of networks for coping
with the inherent variability of the image formation and data acquisition
process, (b) categorical classifications using decision trees, (c)
flexible and adaptive thresholds as opposed to ad hoc and hard thresholds,
and (d) interpretability of the way classification and retrieval
are eventually achieved. Experimental results, proving the feasibility
of our approach, yield (i) 96\% accuracy, using cross validation,
for surveillance on a database consisting of 904 images corresponding
to 350 subjects (of whom 102 are duplicates), (ii) 97\% accuracy for
CBIR tasks, such as "find all subjects wearing glasses", on a database
of 1084 images (including noisy versions) of 350 subjects (of whom
102 are duplicates), and (iii) 93\% accuracy, using cross validation,
for CBIR subject to correct ID match tasks, such as "find Joe Smith
with/without glasses", on a database of 200 images..},
author = {GUTTA, SRINIVAS and WECHSLER, HARRY},
file = {:D$\backslash$:/Papers/Documents/1997/GUTTA, WECHSLER - 1997.pdf:pdf},
journal = {Pattern Recognition},
number = {4},
pages = {539--553},
title = {{FACE RECOGNITION USING HYBRID CLASSIFIERS}},
volume = {30},
year = {1997}
}
@article{Schambach2009,
author = {Schambach, Marc-Peter},
doi = {10.1109/ICDAR.2009.217},
file = {:D$\backslash$:/Papers/Documents/2009/Schambach - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {1146--1150},
publisher = {Ieee},
title = {{Recurrent HMMs and Cursive Handwriting Recognition Graphs}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277586},
year = {2009}
}
@inproceedings{Paulson2008,
abstract = {Sketching is a natural form of human communication and has become an increasingly popular tool for interacting with user interfaces. In order to facilitate the integration of sketching into traditional user interfaces, we must first develop accurate ways of recognizing users’ intentions while providing feedback to catch recognition problems early in the sketching process. One approach to sketch recognition has been to recognize low-level primitives and then hierarchically construct higher-level shapes based on geometric constraints defined by the user; however, current low-level recognizers only handle a few number of primitive shapes. We propose a new low-level recognition and beautification system that can recognize eight primitive shapes, as well as combinations of these primitives, with recognition rates at 98.56\%. Our system also automatically generates beautified versions of these shapes to provide feedback early in the sketching process. In addition to looking at geometric perception, much of our recognition success can be attributed to two new features, along with a new ranking algorithm, which have proven to be significant in distinguishing polylines from curved segments.},
author = {Paulson, Brandon and Hammond, Tracy},
booktitle = {Proceedings of the 13th international conference on Intelligent user interfaces},
file = {:D$\backslash$:/Papers/Documents/2008/Paulson, Hammond - 2008.pdf:pdf},
keywords = {Implemented,Important,Read,Sketch recognition,low-level processing,pen-based interfaces,shape beautification},
mendeley-tags = {Implemented,Important,Read},
pages = {1--10},
publisher = {ACM},
title = {{Paleosketch: Accurate primitive sketch recognition and beautification}},
url = {http://portal.acm.org/citation.cfm?id=1378775},
year = {2008}
}
@article{Omran2005,
abstract = {A color image quantization algorithm based on Particle Swarm Optimization (PSO) is developed in this paper. PSO is a population-based optimization algorithm modeled after the simulation of social behavior of bird flocks and follows similar steps as evolutionary algorithms to find near-optimal solutions. The proposed algorithm randomly initializes each particle in the swarm to contain K centroids (i.e. color triplets). The K-means clustering algorithm is then applied to each particle at a user-specified probability to refine the chosen centroids. Each pixel is then assigned to the cluster with the closest centroid. The PSO is then applied to refine the centroids obtained from the K-means algorithm. The proposed algorithm is then applied to commonly used images. It is shown from the conducted experiments that the proposed algorithm generally results in a significant improvement of image quality compared to other well-known approaches. The influence of different values of the algorithm control parameters is studied. Furthermore, the performance of different versions of PSO is also investigated.},
author = {Omran, M.G. and Engelbrecht, A.P. and Salman, A.},
file = {:D$\backslash$:/Papers/Documents/2005/Omran, Engelbrecht, Salman - 2005(2).pdf:pdf},
journal = {Informatica},
keywords = {Sketch Research,algorithm based on particle,color image quantization,february 6,is developed in this,k-means clustering algorithm,particle swarm optimization,post-clustering,pre-clustering quantization approaches,pso,quantization approaches,received,swarm optimization},
mendeley-tags = {Sketch Research},
pages = {261--269},
publisher = {Citeseer},
title = {{A color image quantization algorithm based on particle swarm optimization}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.143.5581\&amp;rep=rep1\&amp;type=pdf},
volume = {29},
year = {2005}
}
@article{Hammond2002Gender,
address = {Boston, MA},
author = {Hammond, Tracy and Hammond, Jan},
journal = {Proceedings of the 32nd ASEE/IEEE Frontiers in Education Conference},
title = {{Gender-Based Underrepresentation in Computer Science and Related Disciplines}},
year = {2002}
}
@inproceedings{ARSturgill2008,
abstract = {Pre-processing for raster image based document segmentation begins
with image thresholding, which is a binarization proces separating
foreground from background. In this paper, we compare an existing
(Otsu), modified existing (Kittler-Illingworth) and simple peak-based
thresholding approach on a set of 982 documents for which existing
ground truth (full text) is available. We use the output of an open
source OCR engine which incorporates an adaptive/dynamic thresholder
that can be bypassed by one of the three global thresholds we tested.
This allowed comparison of these three approaches in the aggregate.
We then used an independently generated dictionary as a means of
characterizing thresholder efficacy. Such an approach, if successful,
will provide the means for selecting an optimal thresholder in the
absence of a large set of ground truthed documents. Our preliminary
findings here indicate that this approach may provide a reliable
means for thresholder comparison and eventually preclude the need
for time-intensive human ground truthing.},
address = {Sao Paulo, Brazil},
author = {Sturgill, Margaret and Simske, Steven J},
booktitle = {DocEng '08: Proceeding of the eighth ACM symposium on Document engineering},
doi = {http://doi.acm.org/10.1145/1410140.1410197},
file = {:D$\backslash$:/Papers/Documents/2008/Sturgill, Simske - 2008.pdf:pdf},
isbn = {978-1-60558-081-4},
keywords = { Accuracy, Kittler-Illingworth, Meta-Algorithms., OCR, Otsu, Testing,Threshold},
pages = {263--266},
publisher = {ACM},
title = {{An Optical Character Recognition Approach to Qualifying Thresholding Algorithms}},
year = {2008}
}
@article{Hammond2001NaturalSOW,
author = {Hammond, Tracy},
file = {:D$\backslash$:/Papers/Documents/2001/Hammond - 2001(2).pdf:pdf},
journal = {Proceedings of the MIT Student Oxygen Workshop},
title = {{Natural Sketch Recognition in UML Class Diagrams}},
year = {2001}
}
@article{MCLecun1998a,
abstract = {Multilayer Neural Networks trained with the backpropa- gation algorithm
constitute the best example of a successful Gradient-Based Learning
technique.Given an appropriate network architecture, Gradient-Based
Learning algorithms can be used to synthesize a complex decision
surface that can classify high-dimensional patterns such as handwritten
char- acters, with minimal preprocessing.This paper reviews var-
ious methods applied to handwritten character recognition and compares
them on a standard handwritten digit recog- nition task.Convolutional
Neural Networks, that are specif- ically designed to deal with the
variability of shapes, are shown to outperform all other techniques.Real-life
document recognition systems are composed of multiple modules including
eld extraction, segmenta- tion, recognition, and language modeling.A
new learning paradigm, called Graph Transformer Networks (GTN), al-
lows such multi-module systems to be trained globally using Gradient-Based
methods so as to minimize an overall per- formance measure.Two systems
for on-line handwriting recognition are de- scribed.Experiments demonstrate
the advantage of global training, and the exibility of Graph Transformer
Networks.A Graph Transformer Network for reading bank check is also
described.It uses Convolutional Neural Network char- acter recognizers
combined with global training techniques to provides record accuracy
on business and personal checks.It is deployed commercially and reads
several million checks per day},
author = {LeCun, Yann and Bottou, Leon and Bengio, Yoshua and Haffner, Patrick},
file = {:D$\backslash$:/Papers/Documents/1998/LeCun et al. - 1998(2).pdf:pdf},
journal = {PROC OF THE IEEE},
keywords = { Convolutional Neural Networks , Document Recognition , Finite State Transducers, GradientBased Learning, OCR,Graph Transformer Networks,Machine Learning,Neural Networks},
month = nov,
pages = {1--10},
title = {{GradientBased Learning Applied to Document Recognition}},
volume = {8},
year = {1998}
}
@incollection{Oltmans1999Multimodal,
author = {Oltmans, Michael and Davis, Randall},
booktitle = {MIT Artificial Intelligence Laboratory Annual Abstract},
keywords = {multimodal},
month = sep,
publisher = {MIT AI Lab},
title = {{Behavior Annotated Designs: A multimodal approach to design rational capture and intelligent design environments}},
year = {1999}
}
@misc{Calhoun2003,
author = {Calhoun, C.L. and Stahovich, Thomas F},
booktitle = {US Patent App. 10/350,952},
file = {:D$\backslash$:/Papers/Documents/2003/Calhoun, Stahovich - 2003.pdf:pdf},
month = jan,
publisher = {Google Patents},
title = {{Recognizing multi-stroke symbols}},
url = {http://www.google.com/patents?hl=en\&amp;lr=\&amp;vid=USPATAPP10350952\&amp;id=9-CIAAAAEBAJ\&amp;oi=fnd\&amp;dq=Recognizing+multi-stroke+symbols\&amp;printsec=abstract},
year = {2003}
}
@inproceedings{Yusoff2000,
author = {Yusoff, Y and Christmas, W and Kittler, J},
booktitle = {Proc. British Machine Vision Conference},
file = {:D$\backslash$:/Papers/Documents/2000/Yusoff, Christmas, Kittler - 2000.pdf:pdf},
keywords = {shot cut detection,video databases},
pages = {362--371},
publisher = {Citeseer},
title = {{Video shot cut detection using adaptive thresholding}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.102.7173\&amp;rep=rep1\&amp;type=pdf},
year = {2000}
}
@inproceedings{DSTang2004c,
abstract = {This paper presents the spiral recognition methodology with its application
in unconstrained handwritten Chinese legal amount recognition in
a practical environment of a CheckReader trade;. This paper first
describes the failed application of neural network - hidden Markov
model hybrid recognizer on Chinese bank check legal amount recognition,
and explains the reasons for the failure: the neural network - hidden
Markov model hybrid recognizer cannot handle the complexity in the
training for Chinese legal amounts. Then a spiral recognition methodology
is presented. This methodology enables the system to increase its
recognition power (both the recognition rate and the number of recognized
characters) during the training iterations. Some experiments were
done to show that the spiral recognition methodology has a high performance
in the recognition of unconstrained handwritten Chinese legal amounts.
The recognition rate at the character level is 93.5\%, and the recognition
rate at the legal amount level is 60\%. Combined with the recognition
of courtesy amount, the overall error rate is less than 1\%.},
author = {Tang, Hanshen and Augustin, E and Suen, C Y and Baret, O and Cheriet, M},
booktitle = {Ninth International Workshop on Frontiers in Handwriting Recognition, 2004. IWFHR-9 2004.},
doi = {10.1109/IWFHR.2004.96},
file = {:D$\backslash$:/Papers/Documents/2004/Tang et al. - 2004.pdf:pdf},
issn = {1550-5235},
keywords = { ; hidden Markov models; natural languages; neural,Chinese bank checks recognition; handwritten Chine},
pages = {263--268},
title = {{Spiral recognition methodology and its application for recognition of Chinese bank checks}},
year = {2004}
}
@phdthesis{ThesisAlOhali2002,
abstract = {This thesis presents a study to process Arabic handwritten cheques. It includes the development of a unique set of databases that constitute a solid base for research in this domain. The databases are unique in terms of their source, domain and tags validation process. First, they are originated from real-world bank cheques, which, to the best of our knowledge, has never been reached in a university setting. Second, it constitutes the only databases in the domain of Arabic handwritten cheques so far. To the best of our knowledge, there is no database that provides training and testing samples for Arabic cheques. Third, it involved a unique tagging validation process that takes advantage of the embedded redundancy in the format of the cheque to verify the tagging process. A grammar to validate Arabic legal amounts and translate them to numerical values is also included. This work includes an efficient method to derive one-dimensional feature sequence that preserves the dynamics of the original two-dimensional images. This is very important to accommodate small variations while modeling two-dimensional signals. The thesis provides a detailed description of an improved graph representation of sub-word images, a more efficient method to extract dynamic information from two-dimensional images and a clear positioning of the applicability of other curve-ordering criteria, e.g. vision rules. In addition, this thesis includes a significant improvement in the discrimination power of HMM which allows the differentiation between short sub-words and longer ones that share significant initial observation sequences. It also allows the HMM to properly classify incomplete observation sequences. The improvement is achieved by introducing a new parameter to the HMM called the termination probability. Included in this work are tests that prove the applicability and efficiency of the above contributions. At the time of this dissertation, our survey indicates that this work is the only research in the literature which handles images of handwritten sub-words extracted from Arabic cheques. The results of this study show a 94.36\% sub-word recognition rate on the top 10 choices. Error analysis indicates some errors caused by the pre-processing (48\%), feature extraction (28\%) and classification (24\%) modules},
annote = {Thesis Advisor:Suen, Ching Y},
author = {Al-ohali, Yousef},
file = {:D$\backslash$:/Papers/Documents/2002/Al-ohali - 2002.pdf:pdf},
school = {Concordia University.},
title = {{Handwritten word recognition : application to Arabic cheque processing}},
year = {2002}
}
@article{Abello2001,
author = {Abello, J. and Finocchi, I. and Korn, J.},
doi = {10.1109/INFVIS.2001.963282},
file = {:D$\backslash$:/Papers/Documents/2001/Abello, Finocchi, Korn - 2001.pdf:pdf},
isbn = {0-7695-7342-5},
journal = {IEEE Symposium on Information Visualization, 2001. INFOVIS 2001.},
keywords = {graphs,hierarchies,massive data sets,visualization},
number = {Figure 3},
pages = {67--70},
publisher = {Ieee},
title = {{Graph sketches}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=963282},
volume = {2001},
year = {2001}
}
@conference{PBAlaei2009,
abstract = {In this paper, we propose two types of feature sets based on modified
chain-code direction frequencies in the contour pixels of input image
and modified transition features (horizontally and vertically). A
multi-level support vector machine (SVM) is proposed as classifier
to recognize Persian isolated digits. In first level, we combine
similar shaped numerals into a single group and as result; we obtain
7 classes instead of 10 classes. We compute 196-dimension chain-code
direction frequencies as features to discriminate 7 classes. In the
second level, classes containing more than one numeral because of
high resemblance in their shapes are considered. We use modified
transition features (horizontally and vertically) for discriminating
between two overlapping classes (0 and 1). To separate another overlapping
group containing three numerals 2, 3 and 4 we first eliminate common
parts of these digits (tail) and then compute chain code features.
We employ SVM classifier for the classification and evaluate our
scheme on 80,000 handwritten samples of Persian numerals [10]. Using
60,000 samples for training, we tested our scheme on other 20,000
samples and obtained 99.02\% accuracy.},
author = {Alaei, Alireza and Nagabhushan, P and Pal, Umapada},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Alaei, Nagabhushan, Pal - 2009.pdf:pdf},
keywords = { Chain Code, Handwritten, SVM.,Persian Numeral Recognition},
title = {{Fine Classification of Unconstrained Handwritten Persian/Arabic Numerals by Removing Confusion amongst Similar Classes}},
year = {2009}
}
@inproceedings{Li2003,
abstract = {The inherent ambiguity of sketch-based user interfaces makes the intention extraction process quite different from traditional user interfaces. It is a critical problem of how precise computers can efficiently understand and naturally tolerate ambiguous sketch-based interactions. This paper proposes incremental sketch understanding. Based on the cognitive attributes of humans, a software framework is designed for incremental sketch understanding that is demonstrated by a note structuralizing application},
author = {Li, Yang},
booktitle = {Symposium A Quarterly Journal In Modern Foreign Literatures},
file = {:D$\backslash$:/Papers/Documents/2003/Li - 2003.pdf:pdf},
number = {October},
pages = {1--10},
title = {{Incremental Sketch Understanding for Intention Extraction in Sketch-based User Interfaces Incremental Sketch Understanding for Intention Extraction in Sketch-based User}},
year = {2003}
}
@article{Arica2002a,
abstract = {Character recognition (CR) has been extensively studied in the last half century and progressed to a level sufficient to produce tech- nology driven applications. Now, the rapidly growing computational power enables the implementation of the presentCRmethodologies and creates an increasing demand on many emerging application domains, which require more advanced methodologies. This material serves as a guide and update for readers working in the CR area. First, the historical evolution of CR systems is presented. Then, the available CR techniques with their superiorities and weaknesses are reviewed. Finally, the current status of CR is discussed, and directions for future research are suggested. Special attention is given to the off-line hand- writing recognition since this area requires more research to reach the ul- timate goal of machine simulation of human reading},
author = {Arica, Nafiz and Yarman-Vural, F.T.},
file = {:D$\backslash$:/Papers/Documents/2002/Arica, Yarman-Vural - 2002.pdf:pdf},
issn = {1094-6977},
journal = {Systems, Man, and Cybernetics, Part C: Applications and Reviews, IEEE Transactions on},
keywords = {Character recognition (CR),feature extraction,off-line handwriting recognition,segmentation,training and recognition},
number = {2},
pages = {216--233},
publisher = {IEEE},
title = {{An overview of character recognition focused on off-line handwriting}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=941845\&amp;amp;isnumber=20390},
volume = {31},
year = {2002}
}
@article{Skubic2003,
author = {Skubic, M. and Bailey, C. and Chronis, G.},
doi = {10.1109/ICSMC.2003.1243932},
file = {:D$\backslash$:/Papers/Documents/2003/Skubic, Bailey, Chronis - 2003.pdf:pdf},
isbn = {0-7803-7952-7},
journal = {SMC'03 Conference Proceedings. 2003 IEEE International Conference on Systems, Man and Cybernetics. Conference Theme - System Security and Assurance (Cat. No.03CH37483)},
keywords = {human-robot interaction,route map,sketch},
pages = {919--924},
publisher = {Ieee},
title = {{A sketch interface for mobile robots}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1243932},
year = {2003}
}
@inproceedings{DSCheriet2007,
abstract = {Automatic recognition of Arabic handwritten text is a problem worth
solving; it gained more and more interest in recent years, for various
reasons. In this paper we address the most frequently encountered
problems when dealing with Arabic handwriting recognition and we
briefly present lessons learnt from several serious attempts that
have been undertaken in this regard. We give a summary of techniques
concerning Arabic handwriting recognition research. We will end by
a case study, recognition of Tunisian city names, emphasizing on
visual-based strategies for Arabic handwriting recognition (AHR).},
author = {Cheriet, M},
booktitle = {Signal Processing and Its Applications, 2007. ISSPA 2007. 9th International Symposium on},
file = {:D$\backslash$:/Papers/Documents/2007/Cheriet - 2007.pdf:pdf},
keywords = { Arabic handwritten text recognition , Tunisian city name recognition , automatic recognition , visual-based strategies,Arabic handwriting recognition },
title = {{Strategies for visual arabic handwriting recognition: Issues and case study}},
year = {2007}
}
@incollection{ARAbdelRaouf2008,
abstract = {Electronic Document Management (EDM) technology is being widely adopted
as it makes for the efficient routing and retrieval of documents.
Optical Character Recognition (OCR) is an important front end for
such technology. Excellent OCR now exists for Latin based languages,
but there are few systems that read Arabic, which limits the penetration
of EDM into Arabicspeaking countries. In developing an OCR system
for Arabic it is necessary to create a database of Arabic words.
Such a database has many uses as well as in training and testing
a recognition system. This paper provides a comprehensive study and
analysis of Arabic words and explains how such a database was constructed.
Unlike earlier studies, this paper describes a database developed
using a large number of collected Arabic words (6 million). It also
considers connected segments or Pieces of Arabic Words (PAWs) as
well as Naked Pieces of Arabic Word (NPAWs); PAWS without diacritic
Background information concerning the Arabic language is also presented.},
author = {AbdelRaouf, Ashraf and Higgins, Colin A and Khalil, Mahmoud},
booktitle = {Image Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2008/AbdelRaouf, Higgins, Khalil - 2008.pdf:pdf},
keywords = { Arabic Characters, Database,Character Recognition},
pages = {567--578},
publisher = {Springer-Verlag Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Database for Arabic Printed Character Recognition}},
url = {http://www.springerlink.com/content/p567835u6l07k418/},
volume = {5112},
year = {2008}
}
@article{Camastra2007,
abstract = {This paper presents a cursive character recognizer, a crucial module in any cursive word recognition system based on a segmentation and recognition approach. The character classification is achieved by using support vector machines (SVMs) and a neural gas. The neural gas is used to verify whether lower and upper case version of a certain letter can be joined in a single class or not. Once this is done for every letter, the character recognition is performed by SVMs. A database of 57 293 characters was used to train and test the cursive character recognizer. SVMs compare notably better, in terms of recognition rates, with popular neural classifiers, such as learning vector quantization and multi-layer-perceptron. SVM recognition rate is among the highest presented in the literature for cursive character recognition},
author = {Camastra, F},
doi = {10.1016/j.patcog.2007.03.014},
file = {:D$\backslash$:/Papers/Documents/2007/Camastra - 2007.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Reference From Doctor,crossvalidation,cursive character recognition,learning vector quantization,multi-layer-perceptron,neural gas,support vector machines},
mendeley-tags = {Reference From Doctor},
month = dec,
number = {12},
pages = {3721--3727},
title = {{A SVM-based cursive character recognizer}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320307001409},
volume = {40},
year = {2007}
}
@inproceedings{Hernandez-D\'\iaz2006,
author = {Hern\'{a}ndez-D$\backslash$'$\backslash$iaz, A.G. and Santana-Quintero, L.V. and {Coello Coello}, C. and Caballero, Rafael and Molina, J.},
booktitle = {Proceedings of the 8th annual conference on Genetic and evolutionary computation},
file = {:D$\backslash$:/Papers/Documents/2006/Hern\'{a}ndez-D'iaz et al. - 2006.pdf:pdf},
isbn = {1595931864},
keywords = {differential evolution,hybrid algorithms,multi-objective optimization,rough,sets theory},
pages = {675--682},
publisher = {ACM},
title = {{A new proposal for multi-objective optimization using differential evolution and rough sets theory}},
url = {http://portal.acm.org/citation.cfm?id=1143997.1144117},
year = {2006}
}
@article{Chan2000,
author = {Chan, K.F. and Yeung, D.Y.},
file = {:D$\backslash$:/Papers/Documents/2000/Chan, Yeung - 2000(2).pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {de,document processing,mathematical expression recognition,nite clause grammar,structural analysis},
number = {3},
pages = {375--384},
publisher = {Elsevier},
title = {{An efficient syntactic approach to structural analysis of on-line handwritten mathematical expressions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320399000679},
volume = {33},
year = {2000}
}
@article{Sezgin2003GenericSOW,
author = {Sezgin, Tevfik Metin},
journal = {Proceedings of the MIT Student Oxygen Workshop},
title = {{Generic and HMM based approaches to freehand sketch recognition}},
year = {2003}
}
@inproceedings{DSMarisa2002,
abstract = {This paper presents an HMM-MLP hybrid system to process complex date
images written on Brazilian bank cheques. The system first segments
implicitly a date image into sub-fields through the recognition process
based on anHMMapproach. Afterwards, a recognition and verification
strategy is proposed to recognize the three obligatory date sub-fields
(day, month and year) using different classifiers. Markovian and
neural approaches have been adopted to recognize and verify words
and strings of digits respectively. We also introduce the concept
of meta-classes of digits, which is used to reduce the lexicon size
of the day and year and improve the precision of their segmentation
and recognition. Experiments show interesting results on date recognition.},
address = {Honolulu, USA},
author = {M, Morita and L.S., Oliveira and R., Sabourin and F., Bortolozzi and C.Y., Suen},
booktitle = {International Joint Conference on Neural Networks (IJCNN 2002)},
file = {:D$\backslash$:/Papers/Documents/2002/M et al. - 2002.pdf:pdf},
month = may,
pages = {867--872},
publisher = {IEEE Computer Society Press},
title = {{An HMM-MLP Hybrid System to Recognize Handwritten Dates}},
year = {2002}
}
@inproceedings{Field2009,
author = {Field, Martin and Gordon, Sam and Peterson, Eric and Robinson, Raquel and Stahovich, T. and Alvarado, Christine},
booktitle = {Proceedings of the 6th Eurographics Symposium on Sketch-Based Interfaces and Modeling},
file = {:D$\backslash$:/Papers/Documents/2009/Field et al. - 2009.pdf:pdf},
pages = {109--116},
publisher = {ACM},
title = {{The effect of task on classification accuracy: using gesture recognition techniques in free-sketch recognition}},
url = {http://portal.acm.org/citation.cfm?id=1572741.1572761},
year = {2009}
}
@article{Wendling2004,
author = {Wendling, Laurent and Tabbone, Salvatore},
file = {:D$\backslash$:/Papers/Documents/2004/Wendling, Tabbone - 2004.pdf:pdf},
issn = {0162-8828},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
number = {7},
pages = {935--941},
publisher = {IEEE},
title = {{A new way to detect arrows in line drawings}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1300563},
volume = {26},
year = {2004}
}
@inproceedings{Cherlin2005,
author = {Cherlin, J.J. and Samavati, F. and Sousa, M.C. and Jorge, J.A.},
booktitle = {Proceedings of the 21st spring conference on Computer graphics},
file = {:D$\backslash$:/Papers/Documents/2005/Cherlin et al. - 2005.pdf:pdf},
keywords = {1999,bending,dease et al,depiction,figure 1,free-form surfaces,goldstein 1999,guptill 1977,method,modeling,or distortion,progressive shape,sketch-based interfaces,skirt,traditional hand-drawn techniques for},
pages = {145},
publisher = {ACM},
title = {{Sketch-based modeling with few strokes}},
url = {http://portal.acm.org/citation.cfm?id=1090145},
year = {2005}
}
@article{Alvarado2002Framework,
address = {Stanford, California},
author = {Alvarado, Christine and Oltmans, Michael and Davis, Randall},
file = {:D$\backslash$:/Papers/Documents/2002/Alvarado, Oltmans, Davis - 2002.pdf:pdf},
journal = {AAAI Spring Symposium on Sketch Understanding},
month = mar,
pages = {1--8},
publisher = {AAAI Press},
title = {{A Framework for Multi-Domain Sketch Recognition}},
year = {2002}
}
@article{Beldjehem2009,
abstract = {We propose a novel cognitively motivated unifying framework for Arabic handwriting recognition that takes into account the nature of the human reading process of Arabic handwriting. This Modular Granular Architecture tackles the problem by observing Arabic handwriting from both perceptual and linguistic points of view and hence analyzes the underlying input signal from different granularity levels. It is based on three levels of abstraction: a low granularity level that uses perceptual features called global visual indices, a medium granularity level that is the conventional recognition stage and a high granularity level that consists on morphological analysis dedicated to segmentation/recognition. The original idea is the effective use of Arabic word’s morphology in the recognition not only in post-processing. This architecture carries well around the Arabic word’s morphology, as typically in Arabic, the Arabic word’s morphology is by excellence the logical structure (even semantic) of a given Arabic word, whereas the visual data constitute the physical geometric (topological) structure of a given word. We need to integrate both of them for an effective cooperative recognition of Arabic Handwriting. This framework subsumes the lexicon-driven approaches; in that it can recognize a word that does not exist within the lexicon.},
author = {Beldjehem, Mokhtar},
file = {:D$\backslash$:/Papers/Documents/2009/Beldjehem - 2009.pdf:pdf},
journal = {Computational Intelligence},
keywords = {and soft computing,approximate fault tol-,cooperative,fuzzy,granular arab handwriting recognition,morphological analysis,morphological-guided recognition},
number = {5},
pages = {512--513},
title = {{A Granular Framework for Recognition of Arabic Handwriting}},
volume = {13},
year = {2009}
}
@article{Veselova2004Perceptually,
address = {San Jose, CA},
author = {Veselova, Olya and Davis, Randall},
journal = {Proceedings of the Nineteenth National Conference on Artificial Intelligence (AAAI-04)},
title = {{Perceptually Based Learning of Shape Descriptions}},
year = {2004}
}
@article{Haboubi2009,
author = {Haboubi, Sofiene and Maddouri, Samia and Ellouze, Noureddine and El-Abed, Hailkal},
doi = {10.1109/ICDAR.2009.281},
file = {:D$\backslash$:/Papers/Documents/2009/Haboubi et al. - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {691--697},
publisher = {Ieee},
title = {{Invariant Primitives for Handwritten Arabic Script: A Contrastive Study of Four Feature Sets}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277482},
year = {2009}
}
@inproceedings{Al-Hajj2007,
abstract = {In this paper we present a two-stage system for the off-line recognition of cursive Arabic handwritten words. The proposed method is analytic without segmentation, and is able to cope with handwriting inclination and with shifted positions of diacritical marks. First, the recognition stage relies on 3 classifiers based on hidden Markov modelling (HMM). The second stage depends on the combination of these classifiers. The feature vectors used for recognition are related to pixel density distribution and to local pixel configurations. These vectors are extracted on word binary images by using a sliding window approach with different angles. We have experimented different combination schemes. The neural network-based combined system yields best performance on the IFN- ENIT benchmark data base of handwritten names of Tunisian villages/towns.},
author = {Al-Hajj, R. and Mokbel, Chafic and Likforman-Sulem, L.},
booktitle = {Document Analysis and Recognition, 2007. ICDAR 2007. Ninth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2007/Al-Hajj, Mokbel, Likforman-Sulem - 2007.pdf:pdf},
issn = {1520-5363},
pages = {959--963},
publisher = {IEEE},
title = {{Combination of hmm-based classifiers for the recognition of arabic handwritten words}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4377057},
volume = {2},
year = {2007}
}
@inproceedings{Zhang2009,
abstract = {In this paper, we present an online handwritten recognition method for Chemical Symbols, a widely used symbol in education and academic interactions. This method is based on Hidden Markov Models (HMMs), which are increasingly being used to model characters. We built an HMM for each symbol and used 11-dimensional local features which are suitable for online handwritten recognition, and obtained top-1 accuracy of 89.5\% and top-3 accuracy of 98.7\% on a dataset containing 5,670 train samples and 2,016 test samples. These initial results are promising and warrant further research in this direction},
author = {Zhang, Yang and Shi, Guangshun and Yang, Jufeng},
booktitle = {10th International Conference on Document Analysis and Recognition},
doi = {10.1109/ICDAR.2009.99},
file = {:D$\backslash$:/Papers/Documents/2009/Zhang, Shi, Yang - 2009.pdf:pdf},
pages = {1255--1259},
title = {{HMM-based Online Recognition of Handwritten Chemical Symbols}},
year = {2009}
}
@article{Arica2002a,
abstract = {Character recognition (CR) has been extensively studied in the last half century and progressed to a level sufficient to produce tech- nology driven applications. Now, the rapidly growing computational power enables the implementation of the presentCRmethodologies and creates an increasing demand on many emerging application domains, which require more advanced methodologies. This material serves as a guide and update for readers working in the CR area. First, the historical evolution of CR systems is presented. Then, the available CR techniques with their superiorities and weaknesses are reviewed. Finally, the current status of CR is discussed, and directions for future research are suggested. Special attention is given to the off-line hand- writing recognition since this area requires more research to reach the ul- timate goal of machine simulation of human reading},
author = {Arica, Nafiz and Yarman-Vural, F.T.},
file = {:D$\backslash$:/Papers/Documents/2002/Arica, Yarman-Vural - 2002.pdf:pdf},
issn = {1094-6977},
journal = {Systems, Man, and Cybernetics, Part C: Applications and Reviews, IEEE Transactions on},
keywords = {Character recognition (CR),feature extraction,off-line handwriting recognition,segmentation,training and recognition},
number = {2},
pages = {216--233},
publisher = {IEEE},
title = {{An overview of character recognition focused on off-line handwriting}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=941845\&amp;amp;isnumber=20390},
volume = {31},
year = {2002}
}
@inproceedings{Han2007,
abstract = {This paper presents a systematic multi-path HMM topology design algorithm to better model online handwriting of East Asian characters. This data-driven algorithm solves three key problems in HMM topology design. First, HMM path number determination is formalized as a clustering problem using Subsequence Direction Histogram Vector (SDHV) as feature of both writing order and style. Second, Curvature Scale Space-based (CSS-based) substroke segmentation is used to calculate the optimal state number and initial state parameters. Third, Self-rotation restricted corner state and imaginary stroke state are designed to determine state connectivity and Gaussian mixture number in order to achieve better state alignment. Experiments on large character sets demonstrate both a significant relative error reduction rate and high recognition accuracy using the proposed algorithm.},
author = {Han, Shi and Chang, Ming and Zou, Yu and Chen, Xinjian and Zhang, Dongmei},
booktitle = {Document Analysis and Recognition, 2007. ICDAR 2007. Ninth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2007/Han et al. - 2007.pdf:pdf},
issn = {1520-5363},
pages = {604--608},
publisher = {IEEE},
title = {{Systematic Multi-Path HMM Topology Design for Online Handwriting Recognition of East Asian Characters}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4376986},
volume = {2},
year = {2007}
}
@article{Vinciarelli2002a,
abstract = {This paper presents a surveyon o-line Cursive Word Recognition. The approaches to the problem are described in detail. Each step of the process leading from raw data to the nal result is analyzed. This survey is divided into two parts, the rst one dealing with the general aspects of Cursive Word Recognition, the second one focusing on the applications presented in the literature. ? 2002 Pattern Recognition Society. Published},
author = {Vinciarelli, Alessandro},
file = {:D$\backslash$:/Papers/Documents/2002/Vinciarelli - 2002.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {handwriting recognition,o -line cursive word,recognition,survey},
number = {7},
pages = {1433--1446},
publisher = {Elsevier},
title = {{A survey on off-line cursive word recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320301001297},
volume = {35},
year = {2002}
}
@inproceedings{Zhao2003,
abstract = {In this paper, a Cascade Connection Hidden Markov Model (CCHMM) method for on-line English word recognition is propawd. This model, which allows state transition, skip and duration, extends the way of HMM pattern description of handwriting English words. According to the statistic probabilities, the behavior of handwriting CUN\~{} may he depicted’more precisely. The Viterhi algorithm for the cascade connection model may be applied after the whole sample series of a word is input. Compared with the method of creating models for each word in lexicon, this method gives a faster recognition speed. Experiments show that CCHMM approach could obtain 89.26\% recognition rate for the first candidate, while the combination. of character and ligature HMM method’s first candidate is 82.34\%},
author = {Zhao, W. and Liu, J.F. and Tang, X.L.},
booktitle = {Machine Learning and Cybernetics, 2002. Proceedings. 2002 International Conference on},
file = {:D$\backslash$:/Papers/Documents/2003/Zhao, Liu, Tang - 2003.pdf:pdf},
isbn = {0780375084},
keywords = {cascade connection hidden,handwritten word recognition,inter-model state transition probability,markov model},
number = {November},
pages = {1758--1761},
publisher = {IEEE},
title = {{Online handwritten English word recognition based on cascade connection of character HMMs}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1175338},
volume = {4},
year = {2003}
}
@inproceedings{Kundu2002,
abstract = {We describe an MD-HMM (model discriminant HMM) based HWR system (called NEHMM - non- ergodic HMM) whose system parameters are derived from the parameters of the VDHMM (variable dura- tion HMM) system described an [I]. The new HMM achieves better experimental results by more eficient utilization of variable duration information. However, more often the problem is ‘reliable computation’ of du- ration probabilities given limited databases. In the sec- ond phase of the paper, a scheme (VSLHMM - variable sequence length HMM) has been presented to avoid the computation of duration probabilities altogether with- out sacrificing the performance gain of the VDHMM system.},
author = {Kundu, A. and He, Y. and Chen, M.Y.},
booktitle = {Image Processing, 1997. Proceedings., International Conference on},
file = {:D$\backslash$:/Papers/Documents/2002/Kundu, He, Chen - 2002.pdf:pdf},
isbn = {0818681837},
pages = {304--307},
publisher = {IEEE},
title = {{Efficient utilization of variable duration information in HMM based HWR systems}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=632099},
volume = {3},
year = {2002}
}
@article{Vuong2010,
abstract = {The emergence of pen-based mobile devices such as PDAs and tablet PCs provides a new way to input mathematical expressions to computer by using handwriting which is much more natural and efficient for entering mathematics. This paper proposes a web-based handwriting mathematics system, called WebMath, for supporting mathematical problem solving. The proposed WebMath system is based on cli- ent–server architecture. It comprises four major components: a standard web server, handwriting math- ematical expression editor, computation engine and web browser with Ajax-based communicator. The handwriting mathematical expression editor adopts a progressive recognition approach for dynamic rec- ognition of handwritten mathematical expressions. The computation engine supports mathematical functions such as algebraic simplification and factorization, and integration and differentiation. The web browser provides a user-friendly interface for accessing the system using advanced Ajax-based com- munication. In this paper, we describe the different components of the WebMath system and its perfor- mance analysis. },
author = {Vuong, Ba-Quy and He, Yulan and Hui, Siu Cheung},
doi = {10.1016/j.eswa.2009.05.091},
file = {:D$\backslash$:/Papers/Documents/2010/Vuong, He, Hui - 2010.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {progressive handwriting recognition,progressive structural analysis,web-based handwriting mathematics},
month = jan,
number = {1},
pages = {886--893},
publisher = {Elsevier Ltd},
title = {{Towards a web-based progressive handwriting recognition environment for mathematical problem solving}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0957417409005193},
volume = {37},
year = {2010}
}
@article{Al-HajjMohamad2009,
abstract = {The problem addressed in this study is the offline recognition of handwritten Arabic city names. The names are assumed to belong to a fixed lexicon of about 1,000 entries. A state-of-the-art classical right-left hidden Markov model (HMM)-based recognizer (reference system) using the sliding window approach is developed. The feature set includes both baseline-independent and baseline-dependent features. The analysis of the errors made by the recognizer shows that the inclination, overlap, and shifted positions of diacritical marks are major sources of errors. In this paper, we propose coping with these problems. Our approach relies on the combination of three homogeneous HMM-based classifiers. All classifiers have the same topology as the reference system and differ only in the orientation of the sliding window. We compare three combination schemes of these classifiers at the decision level. Our reported results on the benchmark IFN/ENIT database of Arabic Tunisian city names give a recognition rate higher than 90 percent accuracy and demonstrate the superiority of the neural network-based combination. Our results also show that the combination of classifiers performs better than a single classifier dealing with slant-corrected images and that the approach is robust for a wide range of orientation angles.},
author = {{Al-Hajj Mohamad}, Ramy and Likforman-Sulem, Laurence and Mokbel, Chafic},
doi = {10.1109/TPAMI.2008.136},
file = {:D$\backslash$:/Papers/Documents/2009/Al-Hajj Mohamad, Likforman-Sulem, Mokbel - 2009.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automatic Data Processing,Automatic Data Processing: methods,Handwriting,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Markov Chains,Middle East,Models, Statistical,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reading,Subtraction Technique},
month = jul,
number = {7},
pages = {1165--77},
pmid = {19443916},
title = {{Combining slanted-frame classifiers for improved HMM-based Arabic handwriting recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19443916},
volume = {31},
year = {2009}
}
@inproceedings{Nakai2002,
abstract = {A new method isproposedfor on-line handwriting recog- nition of Kanji characters. The method employs substroke HMMs as minimum units to constitute Japanese Kanji char- acters and utilizes the direction of pen motion. The main motivation is to fully utilize the continuous speech recogni- tion algorithm by relating sentence speech to Kanji charac- te6 phonemes to substrokes, and grammar to Kanji struc- ture. The proposed system consists input feature analysis, substroke HMMs, a character structure dictionary and a de- coder. The present approach has the following advantages over the conventional methods that employ whole charac- ter HMMs. I) Much smaller memory reqiiirenient for dic- tionary and models. 2) Fast recognition by employing e@- cient substroke network search. 3) CapabiliQ of recogniz- ing characters not included in the training data if defined as a sequence of substrokes in the dictionaiy. 4) Capability of recognizing characters written by various diperetit stroke orders with multiple definitions per one character in the dic- tionary. 5) Easiness in HMM adaptation to the user with a few sample character data.},
annote = {===========================================

        Paper Index : Nakai2001

        Date:22-11-2010

        

        Why read paper ?
        

        
Build knowldge on Character recognition by HMM.

        

        Paper Overview ?
        
uses Sub stroke online system. 
HMM per sub stroke. a combination of hmm create character. 
A lot of character as for kanji japanese characters. 

        

        
          
What is these paper about ? (Summary)
        
pen direction and velocity of location pen up is used. 
direction of sub strok and substrokes are extracted. 
There is HMM model for each direction. 
Recognition is used to hmm viterbi algorith to detect sequence of sub stroke that is possible to create a chracter. 
Kanji chracter are defined as in hierarchial manar whera a character can be a set of substrokes or [2 different other characters. ]

        Results:
        
1 , 016 different characters are used to test . 
Test done on japanees dataset. 
Experiement of using substrok 95.34 
 vs. character hmm 95.95. 
 the writer vs. independent hmm. analysis 

        

        1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?
        
The large number of character the system can recognize. 

        2. What can we take from this work  ? what do we learn ? What can be incorporated into our own work ?
        
 The HMM can be part of character not all character.  The features are very simple as they use the directional (curvature of ) online strokes. 

        

        3. What are the problems of the paper ?
        
the decode system that build characters form recognizied substrokes hmm is complex and speciific for languages. 

        

        

        4. what is lacking from the work ? why does this work knot be the final  research in this subject ?
        

        
A full test on various dataset and various languages. also testing different writing styles and sizes. 
          

          
5. what about the methods causes this lack ? is there a fundamental reason ?
        

        
          
6. Could incremental Changes Fix this lack ? if so, what changes ? 

        
        

        

        Is there is any question you had about the paper ? 
        
the decode system is not presented in details. 

        
          
The final conclusion..........
        

        
May have some ideas but I think hard to use on arabic languages. 

        
==========================================================================

      },
author = {Nakai, Mitsuru and Akira, Naoto and Shimodaira, Hiroshi and Sagayama, Shigeki},
booktitle = {Document Analysis and Recognition, 2001. Proceedings. Sixth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2002/Nakai et al. - 2002.pdf:pdf},
isbn = {0769512631},
keywords = {Arabic Handwritting recognition,HMM,Japanese or Chinese Characters,Online handwriting character recognition,Read,Summarized},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
pages = {491--495},
publisher = {IEEE},
title = {{Substroke approach to HMM-based on-line Kanji handwriting recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=953838},
year = {2002}
}
@article{Nel2008,
abstract = {Static handwritten scripts originate as images on documents and do not, by definition, contain any dy- namic information. To improve the accuracy of static handwriting recognition systems, many techniques aim to estimate dynamic information from the static scripts. Mostly, the pen trajectories of the scripts are estimated. However, the efficacy of the resulting pen trajectories are rarely evaluated quantitatively. This paper proposes a protocol for the objective evaluation of automatically determined pen trajectories. A hidden Markov model is derived from a ground-truth trajectory. An estimated trajectory is then matched to the derived model. Statistics describing substitution, insertion and deletion errors are then computed from this match. The proposed algorithm is especially useful for performance comparisons between different pen trajectory estimation algorithms. ©},
author = {Nel, Emli-mari and {Du Preez}, JA and Herbst, BM},
doi = {10.1016/j.patcog.2008.05.005},
file = {:D$\backslash$:/Papers/Documents/2008/Nel, Du Preez, Herbst - 2008.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {Automatic assessment,Estimating pen trajectories of static scripts,document analysis,document processing,handwriting analysis,pattern recognition,strok recovery,text processing},
number = {12},
pages = {3773--3785},
publisher = {Elsevier},
title = {{Verification of dynamic curves extracted from static handwritten scripts}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308001726},
volume = {41},
year = {2008}
}
@article{Arica2002,
abstract = {A new analytic scheme, which uses a sequence of image segmentation and recognition algorithms, is proposed for the off-line cursive handwriting recognition problem. First, some global parameters, such as slant angle, baselines, stroke width and height, are estimated. Second, a segmentation method finds character segmentation paths by combining gray-scale and binary information. Third, a hidden Markov model (HMM) is employed for shape recognition to label and rank the character candidates. For this purpose, a string of codes is extracted from each segment to represent the character candidates. The estimation of feature space parameters is embedded in the HMM training stage together with the estimation of the HMM model parameters. Finally, information from a lexicon and from the HMM ranks is combined in a graph optimization problem for word-level recognition. This method corrects most of the errors produced by the segmentation and HMM ranking stages by maximizing an information measure in an efficient graph search algorithm. The experiments indicate higher recognition rates compared to the available methods reported in the literature},
annote = {=================================  Review Template ===========================================
Paper Index : Arica2002
Date:14 - Nov - 2010

        

        Why read paper ?
        
HMM background and cursive writing. 

        
          
Paper Overview? 
        
English cursive writing, from 
1) global estimaition parameters (whole word features) 2) character classification (normal , asending...), 3) segmentation 4)feature extraction 5) HMM to rank candidates
 6) dynamic programming and graph search to find best word  to lexical dictinary. 

        

        What is these paper about ? (Summary)
        

        
1) global estimaition parameters (whole word features) consist of 
a) binarization then use 8 bit binary to get contour. 
b) stroke width and height estimation (getting the hight where most of the word lies) by avg the (horizontal - vertical) projection 
c) basline extraction. extracting upper, lower and center basline using a new weighted local minimum algorithm. 
 2) character classification (normal , asending...),
         using information of baseline find the location of any asending , decending and normal chracters. 
 3) segmentation. Segmentaiton of characters, based on both contour and gray level image is done in steps. (see figures 6,7 and 8)
a) Step 1. from top of local maximum to the top of image (no character is cut ) peak of the character is reached then a line is drawn to top of image or word. 
b) from peak of character to the baseline moving through the character black pixels. 
c) from baseline to the buttom of image without cutting any character. 
d) a shortest path search on the paths generated to get the path of ascending and descending characters. 

        
 4)feature extraction
        
The image is scaned using  into vertical, horizontal and diagonal scan lines. then The medians of each black pixels block is computed. These medians ar coded based on there location in image. ( see figure 9). The sume of these medians for each scan line are used as features.

        
 5) HMM to rank candidates 
        
Both Single characters and part of characters are used to train and test the HMM models. 
A different HMM topology is used for ( asending, descending and normal characters. Each character has its own HMM model where training is done using baum welch. The HMM is used to generate a list of ranked possibile characters. 
Forward-backword algorithm is used to generate the HMM probabilites . 
6) dynamic programming and graph search to
 find best word  to lexical dictinary. 
Word level recognition is based on the ranked HMM lists. 
probalbe word which exist in the lexical dictinary. 
word graph is created with pointers to nodes subtree which is generated from HMM candidate lists. 
 a mean at each vertix or new character a tree is formeed based on the lexical and hmm canddidate list. Then backtrack to minimum cost. to find the word. 

        Results. 
        
The system is trained using 1000 words and tested using 2000 words. 
The result of segmentaiton is 95\% 
Ranking algorithm produce 93\% in top 1 and 99 \% in top 5
The final result of system is 88.13 with 40000 lexical words. 
It may indicate that it improve effiency with larger lexical dictinary. 

        

        1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?
        

        
The intersting part about this system is the segmentation and use of different toplolgy models for different types of characters. 
Also the feature extraction method is simple and can easily computed. 
The system also use part of character to train hmm, which means that the segmentation error are solved while training., 

        2. What can we take from this work  ? what do we learn ? What can be incorporated into our own work ?
        

        
The feature extraction can easily be experimented. using different hmm topology for characters types. 

        
          
3. What are the problems of the paper ?
        

        
The lexical words searching is time consuming, the complexitity of  overall process of segmentation. eventhough it unsegmented work can producse same result. 

        
          
4. what is lacking from the work ? why does this work knot be the final  research in this subject ?
        

        
It is specific to english words, and may not be able to move it to arabic due to dependability on segmentation algorithm. 

        

        
        
          5. what about the methods causes this lack ? is there a fundamental reason ?
        
        
        

        

        6. Could incremental Changes Fix this lack ? if so, what changes ? 
        

        
simpler segmentation algorithm, better handling for the lexical lookup of words. 

        

        Is there is any question you had about the paper ? 
        

        

        

        The final conclusion..........
        

        
Has a lot of usefull information and algorithms, good system with good words. It may indicate that it improve effiency with larger lexical dictinary. 

        
==========================================================================},
author = {Arica, Nafiz and Yarman-Vural, F.T.},
file = {:D$\backslash$:/Papers/Documents/2002/Arica, Yarman-Vural - 2002.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Arabic Handwritting recognition,Lexicon lookup,Read,Summarized,cursive handwritten text recognition,graph,handwritten word recognition,hidden markov model,optical character recognition,preprocessing,search,segmentation},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
number = {6},
pages = {801--813},
publisher = {Published by the IEEE Computer Society},
title = {{Optical character recognition for cursive handwriting}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/TPAMI.2002.1008386},
volume = {24},
year = {2002}
}
@article{Kessentini2010,
abstract = {In this paper, we present a multi-stream approach for off-line handwritten word recognition. The pro- posed approach combines low level feature streams namely, density based features extracted from 2 dif- ferent sliding windows with different widths, and contour based features extracted from upper and lower contours. The multi-stream paradigm provides an interesting framework for the integration of multiple sources of information and is compared to the standard combination strategies namely fusion of repre- sentations and fusion of decisions. We investigate the extension of 2-stream approach to N streams (N =2, ... , 4) and analyze the improvement in the recognition performance. The computational cost of this extension is discussed. Significant experiments have been carried out on two publicly available word databases: IFN/ENIT benchmark database (Arabic script) and IRONOFF database (Latin script). The multi- stream framework improves the recognition performance in both cases. Using 2-stream approach, the best recognition performance is 79.8\%, in the case of the Arabic script, on a 2100-word lexicon consisting of 946 Tunisian town/village names. In the case of the Latin script, the proposed approach achieves a rec- ognition rate of 89.8\% using a lexicon of 196 words},
annote = {===========================================

        Paper Index : Kessentini2010

        Date:22-11-2010

        
          
Why read paper ?
        
Recent arabic hmm. 

        

        Paper Overview ?
        
offline word recognition using 
multistream hmm. with contour and density  features. 
for both arabic and english on IFN and IRONOFF datasets. 

        

        What is these paper about ? (Summary)
        

        
          
1. preprocessing 
        
a) normalization then using slant and slope correction. 
b)  contour smothing to remove small blobs 
c) base line detection. 

        2) feature extraction 
        
a) contour detection 
for upper and lower . For each contour direction density histogram is computed a second fature for every point based on upper and lower point 
 third features set is loccation of contour point. there is generated for each window 15 contour feature 
b) density features
word is divided by windows with h and w. 
a set fo 15 features is computed using 8 and 14 pixel as widths. 

        
the final is 4 streams (upper contour, lower contour, density with 8 pixel width and density with 14 pixel length.). 
The streams  are independent of each other and computed using sliding windows. 
          
Classification:
        
HMM multi stream using more than one features as input. 
introduction and training , testing systems. is explained. 
comparing and triang of streams are explained n detailed . 
HMM recombinatino which is an adaptation of viterbibi search algorithm allow to decompose a single stream hmm inot tow independent component. 
HMM i sused to get most probalbe words from 1 , 2, 3, and 4 streams. 

        
          
result. 
        
Used two dataset one for arabic (IFN /ENIT ) and one for latin (IRON) both offline. 
comparison between different streams combinations. 1-2,3-2, . 
1-4 got best results (79.6\% on IFN and 89.8\% on laten)
propose a system is cbest compred to other icdar 2007 and 2005 systems. 
using 3 streams and 4 streams but with small lexicon (due to complexity) was 98 and 99 \%. 

        

        

        

        
          
1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?
        

        
The use of different streams of features on same hmm to get results. 
Simple contour and density features. 
System proved on both arabic and latin words. 
          
2. What can we take from this work  ? what do we learn ? What can be incorporated into our own work ?
        
Contour , density Features  and some ideas of building hmm topolgy and multiple streams. 

        
          
3. What are the problems of the paper ?
        
The complexitiy of handling hmm data and output probability. 

        
          
4. what is lacking from the work ? why does this work knot be the final  research in this subject ?
        

        
Lacks an optimizied algorithm to handle multiple feature set on same hmm output. 

        
          
5. what about the methods causes this lack ? is there a fundamental reason ?
        

        

        
          
6. Could incremental Changes Fix this lack ? if so, what changes ? 
        

        

        
          
Is there is any question you had about the paper ? 
        

        

        
          
The final conclusion..........
        
Method can be used on multiple features et and may need optimization 
very good analysis of reault and comparision of other results 
simple contour and density feaures but focus on hmm multiple streams

        
==========================================================================

      },
author = {Kessentini, Yousri and Paquet, Thierry and {Ben Hamadou}, AbdelMajid},
doi = {10.1016/j.patrec.2009.08.009},
file = {:D$\backslash$:/Papers/Documents/2010/Kessentini, Paquet, Ben Hamadou - 2010.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Arabic Handwritting recognition,Read,Summarized,hidden markov models,off-line handwriting recognition},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
month = jan,
number = {1},
pages = {60--70},
publisher = {Elsevier B.V.},
title = {{Off-line handwritten word recognition using multi-stream hidden Markov models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865509002232},
volume = {31},
year = {2010}
}
@inproceedings{Xiang2010,
abstract = {-Great challenges are faced in the offline recognition of cursive Arabic handwriting. This paper presents a segmentation-free system based on Hidden Markov Model (HMM) to handle this problem, where character segmentation stage is avoided prior to recognition. The system first extracts a set of robust features on binary handwritten images by sliding windows. Then the proposed system builds character HMM models and learns word HMM models using embedded training. Finally, best word maximizing the a posteriori is located through Viterbi Algorithm. Experiments that have been implemented on the benchmark IFNIENIT database show the average recognition rate of this system is 84.09\%.},
annote = {=================================  Review Template ===========================================
          
Questions  : 
Paper Index : 

          
Why read paper ?
        
On of the latest work on  arabic handwriting 
          

          
What is these paper about ? (Summary)
        
slideing window is moved through the image of words and at each the window the height image is divide into four segments. these segments is used to get features. 
2. Four different concavity directional features is computed ( average of up, down, left , right pixel locations)
3.from  Each window  segment 10 features is comptued. 
4. the features is introduced into hmm model
5.  158 differen HMM character model was build  then by concatenating models the words are recognizied. 
6. trainig (baum welch)is done as with whole words rather than single characters. and a viterbi algorithm to determeine the output hypotheses. 
7. IFN/ENIT database was used to test and train. 84\% is optianed using this system. 
          

          

          
1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?

          

        Simple features are used, which means that the computation time is minimal . HMM model is not complex.  Recongition rate may improve. 
          

          
2. What can we take from this work  ? what do we learn ? 
 What can be incorporated into our own work ?
        
we can use a silding window or similar approach to define location of intereset to compute features. Conactivity features was previously used in our system. 
          

          
3. What are the problems of the paper ?

        
        
No lexical lookup, means that the HMM may produce an illegal word. Also the process of training the hmm using all word may make the hmm style based. 
          

          
4. what is lacking from the work ? why does this work knot be the final  research in this subject ?

        
        
define the size and make use of a dictinaory of words. a lexical look up or test may be used to increase effiency of test. also a reject options to reject un correct words early. 
          

          
5. what about the methods causes this lack ? is there a fundamental reason ?

          
6. Could incremental Changes Fix this lack ? if so, what changes ? 

          

          
Is there is any question you had about the paper ? 

          

          
The final conclusion..........

        
        

        
good paper but may need improvement to increase performance. 

        
==========================================================================},
author = {Xiang, Dong and Yan, Huahua and Chen, Xianqiao and Cheng, Yanfen},
booktitle = {Computer Science and Information Technology (ICCSIT), 2010 3rd IEEE International Conference on},
file = {:D$\backslash$:/Papers/Documents/2010/Xiang et al. - 2010.pdf:pdf},
keywords = {- pauern recognition,Arabic Handwritting recognition,Read,Summarized,arabic,even in the case,hidden,markov model,offline handwritten,segmentation and recognition,the concatenation of compound,thus,where,words are modeled as},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
pages = {526--529},
publisher = {IEEE},
title = {{Offline Arabic handwriting recognition system based on HMM}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5564429},
volume = {1},
year = {2010}
}
@inproceedings{Tokuno2002,
abstract = {This paper describes context-dependent substroke hid- den Markov models (HMMs) for on-line handwritten recog- nition of cursive Kanji and Hiragana characters. As there are more than 6,000 distinctive characters including Kanji and Hiragana in Japanese, modeling each character by an HMM leads to an infeasible character-recognition system requiring huge amount of memory and enormous computa- tion time. In order to tackle this problem, we have proposed the substroke HMM approach where a modeling unit “sub- stroke” that is much smaller than a whole character is em- ployed and each character is modeled as a concatenation of only 25 kinds of substroke HMMs. One of the drawback of this approach is that the recognition accuracy deterio- rates in case of scribbled characters, and characters where the shape of the substrokes varies a lot. In this paper, we show that the context-dependent substroke modeling which depends on how the substroke connects to the adjacent sub- strokes is effective to achieve robust recognition of low qual- ity characters. The Successive State Splitting (SSS) algo- rithm which was mainly developed for speech recognition is employed to construct the context dependent substroke HMMs. Experimental results show that the correct recogni- tion rate improved from88\% to 92\% for cursive Kanji hand- writings and from 90\% to 98\% for Hiragana handwritings.},
author = {Tokuno, Junko and Inami, Nobuhito and Matsuda, Shigeki and Nakai, M. and Shimodaira, H. and Sagayama, S.},
booktitle = {Frontiers in Handwriting Recognition, 2002. Proceedings. Eighth International Workshop on},
file = {:D$\backslash$:/Papers/Documents/2002/Tokuno et al. - 2002.pdf:pdf},
isbn = {0769516920},
pages = {78--83},
publisher = {IEEE},
title = {{Context-dependent substroke model for HMM-based on-line handwriting recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1030888},
year = {2002}
}
@article{Gunter2005,
abstract = {Unconstrained handwritten text recognition is one of the most difficult problems in the field of pattern recognition. Recently, a number of classifier creation and combination methods, known as ensemble methods, have been proposed in the field of machine learning. They have shown improved recognition performance over single classifiers. In this paper, we examine the influence of the vocabulary size, the number of training samples, and the number of classifiers on the performance of three ensemble methods in the context of cursive handwriting recognition. All experiments were conducted using an off-line handwritten word recognizer based on hidden Markov models (HMMs).},
author = {Gunter, S. and Bunke, Horst},
doi = {10.1016/j.optlaseng.2004.01.004},
file = {:D$\backslash$:/Papers/Documents/2005/Gunter, Bunke - 2005.pdf:pdf},
issn = {0143-8166},
journal = {Optics and Lasers in Engineering},
keywords = {ensemble methods,ensemble size,handwritten text recognition,hidden markov model,hmm,multiple classifier combination,training set size,vocabulary size},
number = {3-5},
pages = {437--454},
publisher = {Elsevier},
title = {{Off-line cursive handwriting recognition using multiple classifier systems–on the influence of vocabulary, ensemble, and training set size}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0143816604001034},
volume = {43},
year = {2005}
}
@article{ARCavalin2009,
abstract = {We present an evaluation of incremental learning algorithms for the
estimation of hidden Markov model (HMM) parameters. The main goal
is to investigate incremental learning algorithms that can provide
as good performances as traditional batch learning techniques, but
incorporating the advantages of incremental learning for designing
complex pattern recognition systems. Experiments on handwritten characters
have shown that a proposed variant of the ensemble training algorithm,
employing ensembles of HMMs, can lead to very promising performances.
Furthermore, the use of a validation dataset demonstrated that it
is possible to reach better performances than the ones presented
by batch learning.},
author = {PauloR.Cavalina and RobertSabourina and ChingY.Suenb and AlceuS.BrittoJr},
file = {:D$\backslash$:/Papers/Documents/2009/PauloR.Cavalina et al. - 2009.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Incremental learning; Hidden Markov models; Ensemb},
month = dec,
number = {12},
pages = {3241--3253},
title = {{Evaluation of incremental learning algorithms for HMM in the recognition of alphanumeric characters}},
volume = {42},
year = {2009}
}
@article{Ishida2010,
abstract = {We propose a novel sequence alignment algorithm for recognizing handwriting gestures by a camera. In the proposed method, an input image sequence is aligned to the reference sequences by phase- synchronization of analytic signals which are transformed from original feature values. A cumulative distance is calculated simultaneously with the alignment process, and then used for the classification. A major benefit of this method is that over-fitting to sequences of incorrect categories is restricted. The proposed method exhibited higher recognition accuracy in handwriting gesture recognition, compared with the conventional dynamic time warping method which explores optimal alignment results for all categories.},
author = {Ishida, Hiroyuki and Takahashi, Tomokazu and Ide, Ichiro and Murase, Hiroshi},
doi = {10.1016/j.patcog.2010.02.021},
file = {:D$\backslash$:/Papers/Documents/2010/Ishida et al. - 2010.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Analytic signal,Classification method,Gesture recognition,Sequence alignment},
month = aug,
number = {8},
pages = {2799--2806},
publisher = {Elsevier},
title = {{A Hilbert warping method for handwriting gesture recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320310001007},
volume = {43},
year = {2010}
}
@article{Gao2004,
abstract = {In sign language recognition (SLR), the major challenges now are developing methods that solve signer-independent continuous sign problems. In this paper, SOFM/HMM is first presented for modeling signer-independent isolated signs. The proposed method uses the self-organizing feature maps (SOFM) as different signers’ feature extractor for continuous hidden Markov models (HMM) so as to transform input signs into significant and low-dimensional representations that can be well modeled by the emission probabilities of HMM. Based on these isolated sign models, a SOFM/SRN/HMM model is then proposed for signer-independent continuous SLR. This model applies the improved simple recurrent network (SRN) to segment continuous sign language in terms of transformed SOFM representations, and the outputs of SRN are taken as the HMM states in which the latticeViterbi algorithm is employed to search the best matched word sequence. Experimental results demonstrate that the proposed system has better performance compared with conventional HMM system and obtains a word recognition rate of 82.9\% over a 5113-sign vocabulary and an accuracy of 86.3\% for signer-independent continuous SLR.  2004 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
author = {Gao, Wen and Fang, Gaolin and Zhao, Debin and Chen, Yiqiang},
doi = {10.1016/j.patcog.2004.04.008},
file = {:D$\backslash$:/Papers/Documents/2004/Gao et al. - 2004.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {chinese sign language,hidden markov model,self-organizing feature map,sign language recognition,simple recurrent network},
number = {12},
pages = {2389--2402},
publisher = {Elsevier},
title = {{A Chinese sign language recognition system based on SOFM/SRN/HMM}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320304001657},
volume = {37},
year = {2004}
}
@article{Imran2010,
abstract = {Urdu script-based languages’ character recognition has some technical issues not existing in other lan- guages and makes these languages more complicated. Segmentation-based character recognition approach for handwritten Urdu, both Nasta’liq and Nasakh script-based languages, incorporates number of overhead and very less accurate as compared to segmentation free. This paper presents a segmenta- tion-free approach for recognition of online Urdu handwritten script using hybrid classifier, HMM and fuzzy logic. Trained data set consisting of HMMs for each stroke is further classified into 62 sub-patterns based on the primary stroke shape at the beginning and end using fuzzy rule. Fuzzy linguistic variables based on language structure are used to model features and provide suitable result for large variation in handwritten strokes. Twenty-six time variant structural and statistical features are extracted for the base strokes. The fuzzy classification into sub-patterns increases the efficiency and decreases the computa- tional complexity due to reduction in data set size. The hybrid HMM–fuzzy technique is efficient for large and complex data set. It provided 87.6\% and 74.1\% for Nasta’liq and Nasakh, respectively, on 1800 ligatures. },
author = {Imran, Muhammad and Anwar, Fareeha and Husain, S A and Belaid, Abdel and Sher, Muhammad and Cedex, Nancy},
doi = {10.1016/j.knosys.2010.06.007},
file = {:D$\backslash$:/Papers/Documents/2010/Imran et al. - 2010.pdf:pdf},
issn = {0950-7051},
journal = {Knowledge-Based Systems},
keywords = {Fuzzy logic,HMM,Hybrid model,Online handwriting character recognition,Segmentation free},
number = {8},
pages = {914--923},
publisher = {Elsevier B.V.},
title = {{Knowledge-Based Systems HMM and fuzzy logic : A hybrid approach for online Urdu script-based languages ’ character recognition}},
url = {http://dx.doi.org/10.1016/j.knosys.2010.06.007},
volume = {23},
year = {2010}
}
@article{YantingDong2003,
abstract = {—Weconsider the problem of estimating the pose of a target basedon a sequence of scattered waveformsmeasuredat multiple target-sensor orientations. Using a hidden Markov model (HMM) representation of the scattered-waveform sequence, pose estimation reduces to estimating the underlyingHMMstates from a sequence of observations. It is assumed that each scattered waveform must be quantized via an encoding procedure. A distortionDis defined as the error in estimating the underlying HMM states, and the rate R represents the size of the discrete-HMM codebook. Rate-distortion theory is applied to define the minimum rate required to achieve a desired distortion, denoted as RðDÞ. After deriving the rate-distortion function RðDÞ, we demonstrate that discrete-HMMperformance based on Lloyd encoding is far from this bound. Performance is improved via block coding, based on Bayes VQ. Results are presented for acanonicalHMMproblem,andthen for multiaspect acoustic scatteringfrom underwater elastic targets. Although theexamplespresented here are for multiaspect scattering and pose estimation, the results are of general applicability to discrete-HMMstate estimation.},
author = {{Yanting Dong}},
doi = {10.1109/TPAMI.2003.1206516},
file = {:D$\backslash$:/Papers/Documents/2003/Yanting Dong - 2003.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {HMM,Rate distortion,pose estimation,underwater sensing,vector quantization},
month = jul,
number = {1},
pages = {1303--883},
title = {{Rate-distortion analysis of discrete-HMM pose estimation via multiaspect scattering data}},
volume = {81},
year = {2003}
}
@inproceedings{Tokuno2006,
abstract = {This paper describes stochastic modeling of pen- coordinate information in HMMs with structured character pattern representation (SCPR) for on-line Japanese handwriting recognition. SCPR allows HMMs for Kanji character patterns to share common subpatterns. Although SCPR-based HMMs have been successfully applied to Kanji character recognition, the pen-coordinate feature has not been modeled since it is unique feature in each character pattern. In this paper, we employ mapping from a common subpattern to each occurrence in Kanji patterns and adaptation of state parameters to each character pattern in generating character HMMs by composing SCPR- based HMMs. Experimental results show that the pen- coordinate feature modeled in the SCPR-based HMMs effects significantly.},
author = {Tokuno, Junko and Yang, Yiping and da Silva, G.P. and Kitadai, Akihito and Nakagawa, Masaki},
booktitle = {Pattern Recognition, 2006. ICPR 2006. 18th International Conference on},
file = {:D$\backslash$:/Papers/Documents/2006/Tokuno et al. - 2006.pdf:pdf},
isbn = {0769525210},
issn = {1051-4651},
pages = {348--351},
publisher = {IEEE},
title = {{Pen-coordinate information modeling by scpr-based hmm for on-line japanese handwriting recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1699537},
volume = {3},
year = {2006}
}
@inproceedings{Madhvanath2007a,
abstract = {This paper describes Lipi Toolkit (LipiTk) - a generic toolkit whose aim is to facilitate development of online handwriting recognition engines for new scripts, and simplify integration of the resulting engines into real-world application contexts. The toolkit provides robust implementations of tools, algorithms, scripts and sample code necessary to support the activities of handwriting data collection and annotation, training and evaluation of recognizers, packaging of engines and their integration into pen-based applications. The toolkit is designed to be extended with new tools and algorithms to meet the requirements of specific scripts and applications. The toolkit attempts to satisfy the requirements of a diverse set of users, such as researchers, commercial technology providers, do-it- yourself enthusiasts and application developers. In this paper we describe the first version of the toolkit which focuses on isolated online handwritten shape and character recognition.},
author = {Madhvanath, Sriganesh and Vijayasenan, Deepu and Murugan, Thanigai},
booktitle = {SIGGRAPH '07: ACM SIGGRAPH 2007 courses},
file = {:D$\backslash$:/Papers/Documents/2007/Madhvanath, Vijayasenan, Kadiresan - 2007.pdf:pdf},
keywords = {api,languages - no,linguistic resources,online handwriting recognition,parts of the world,recognition,shape,such as the indic,the languages in these,toolkit,unfortunately for many of},
pages = {13},
title = {{LipiTk : A Generic Toolkit for Online Handwriting Recognition}},
year = {2007}
}
@article{Kim1997,
abstract = {-In this paper, we propose a novel recognition model of on-line cursive Korean characters using the hidden Markov model (HMM) and a level building algorithm. The model is constructed as a form of recognition network with HMMs for graphemes and Korean combination rules. Though the network represents the large character set efficiently and is flexible enough to accommodate variability of input patterns, it has a problem of recognition speed, caused by 11,172 search paths. To solve the problem, we modify a level building algorithm to be adapted directly to the Korean combination rules and apply it to the model. The modified algorithm is an efficient network search procedure, the time complexity of which depends on the number of grapheme HMMs and ligature HMMs, not the number of paths in the extensive recognition network. A test with 20,000 handwritten characters shows a recognition rate of 90.2\% and speed of 0.72 s per character. ©},
author = {Kim, H},
doi = {10.1016/S0031-3203(96)00078-7},
file = {:D$\backslash$:/Papers/Documents/1997/Kim - 1997.pdf:pdf},
journal = {Pattern Recognition},
keywords = {character recognition network,hidden markov model,level building,on-line characcter},
month = mar,
number = {3},
pages = {491--502},
title = {{An HMM-based character recognition network using level building}},
volume = {30},
year = {1997}
}
@article{Park1996,
abstract = {There are many uncertainties in handwritten character recognition. Stochastic modeling is a flexible and general method for modeling such problems and entails the use of probabilistic models to deal with uncertain or incomplete information. This paper presents an efficient scheme for off-line recognition of large-set handwritten characters in the framework of stochastic models, the first-order hidden Markov models (HMMs). To facilitate the processing of unconnected patterns and patterns with isolated noises, four types of feature vectors based on the regional projection contour transformation (RPCT) are employed. The recognition system consists of two phases. For each character, in the training phase, multiple HMMs corresponding to different feature types of RPCT are built. In the classification phase, the results of individual classifiers to produce the final recognition result for an input character are integrated, where each individual HMM classifier produces one score that is the probability of generating the test observation sequence for each character model. In this paper, several methods for integrating the results of different classifiers are considered so that a better result could be obtained. In order to verify the effectiveness of the proposed scheme, the most frequently used 520 types of Hangul characters in Korea have been considered in the experiments. Experimental results indicate that the proposed scheme is very promising for the recognition of large-set handwritten characters with numerous variations},
annote = {=================================  Review Template ===========================================

        Paper Index : Park1996

        Date:14 - Nov - 2010

        

        Why read paper ?
        
HMM background and foundation. 

        

        Main Idea of paper?
        
Single character recogniton but large number of different characters. 
offline

        

        

        What is these paper about ? (Summary)
        

        
1) Feature extraction 
a) use RPCT which define 4 projections ( horizontal , vertical , horizontal vertical , diagonal) see figure 1 and 2. 
b) each projection is then transformed into contour and sampled using 8 directional chain code. 
2) classification / Training is done in to steps 
a) a fuzzy tree classifier to generate a list of possible candidates.  [the fuzzy classifier is only trained using one of the projections]
b)HMM classification by building  four (one for each projection) HMM Model s for each characters. The decision of the 4 models is compined using either of the following methds. (1) equal weight (2) un equal weight (3) maximum voting method.  

        
The use of fuzzy tree is used to get a list of candidate so only  the HMM models of those candidat are used. This is helpful with the large number of character. 

        
The ruslt after combiing methods is 91.6\% on total of  (26000 used for testing and 52000 used for trainig) the model with 30 states per character. 

        

        

        1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?
        

        
I found interesting is the feature extraction of projection then contour detection. ( not contour on the orginal image but on the 4 different projections). 

        
Also the use of fuzzy tree to narrow number of HMM model tested while classification is very interesiting. 

        
The large number of character that the paper expermented on , can be helpful when dealing with arabic characters 

        

        2. What can we take from this work  ? what do we learn ?  What can be incorporated into our own work ?
        

        
The fuzzy tree, the use of more than one model for character can be used too.  

        
          
3. What are the problems of the paper ?
        

        
The paper can be improved using more powerfull features. The performance of the sytesm can be a problem as it trains 512 * 4 different HMM. 

        

        4. what is lacking from the work ? why does this work knot be the final  research in this subject ?
        

        

        

        

        5. what about the methods causes this lack ? is there a fundamental reason ?
        

        
The lack is form generating a new hmm for each projection then combining it. 

        
          
6. Could incremental Changes Fix this lack ? if so, what changes ?
        
More roposut features can be used, the clustring of  features can be improved (fuzzy tree classifier)

        

        Is there is any question you had about the paper ? 
        
no , 

        

        The final conclusion..........
        

        
Very good paper and with good result. 

        

        
==========================================================================},
author = {Park, H},
doi = {10.1016/0031-3203(95)00081-X},
file = {:D$\backslash$:/Papers/Documents/1996/Park - 1996.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Arabic Handwritting recognition,Read,Regional projection contour transformation,Summarized,hidden markov model,large set handwritten character recognition,multiple classifier combination},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
month = feb,
number = {2},
pages = {231--244},
title = {{Off-line recognition of large-set handwritten characters with multiple hidden Markov models}},
volume = {29},
year = {1996}
}
@inproceedings{Nishimura2002,
abstract = {The purpose of our research is to improve the recogni- tion rate of off-line character recognition systems using the HMM (Hidden Markov Model) without increasing a num- ber of HMM parameters too much. Some 2-dimensional HMM character recognition systems have been proposed to increase representational power. However, since 2–D HMM has much more complex structure and thus requires much more parameters than 1-dimensional HMM, it be- comes very hard to gather sufficient samples in order to guarantee the successful generalization. To overcome the problem, we propose amethod for character recognition us- ing 1–D HMMs in multiple directions with 2-dimensional feature extraction. To further improve the performance, some voting method useing bagging algorithmare also ex- ploited. In our experiment, the recognition rate is increased by about 1\% with the multiple directional HMM charac- ter recognition system compared to the 1–D HMMcharac- ter recognition system. The recognition rate is further in- creased by about 1\% with the HMM character recognition system using bagging algorithm.},
author = {Nishimura, Hiromitsu and Kobayashi, Makoto and Maruyama, Minoru and Nakano, Yasuaki},
booktitle = {Document Analysis and Recognition, 1999. ICDAR'99. Proceedings of the Fifth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2002/Nishimura et al. - 2002.pdf:pdf},
isbn = {0769503187},
pages = {49--52},
publisher = {IEEE},
title = {{Off-line character recognition using HMM by multiple directional feature extraction and voting with bagging algorithm}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=791722},
year = {2002}
}
@inproceedings{Recognition2001,
abstract = {The purpose of our research is to improve the recog- nition rate of an off-line handwritten character recog- nition system using HMM (Hidden Markov Model), so that we can use the syst,em for practical application. Due to the insufficient recognition rate of 1D HMM character recognition systems and the requirement for a huge number of learning samples to construct 2D HMM character recognition systems, HMM-based character recognition systems have not yet achieved sufficient recognition performance for practical use. In this research, we propose the character recognition method that integrates 4 simply structured 1D HMMs all of which are based on feature extraction using linear filters. The results of our evaluation experiment using the Hand-Printed Character Database (ETLG) showed that the first rank recognition rate of the test samples was 98.5\% and that the cumulative recognition rate of top 3 candidates was 99.3\%. Although our method is relatively easy to implement, it can work even better than 2D HMM method. These results show the pro- posed method is very effective.},
annote = {
        Paper Index : Nishimura2001

        Date:23-Nov-2010

        

        Why read paper ?
        
HMM knowldege base. 

        

        Paper Overview ?
        
HMM but focus on the difference of 1D HMM vs. the 2D HMM. 
the features are build on filter masks. 
offline and test only on seperate latin characters. 

        

        What is these paper about ? (Summary)
        

        
The paper talks about the 1D HMM used to recognize characters int the following steps. 

        Features extraction:
        
feature is a weighted sum of image where 
F(i,j)= sum (sum ( w(i)I(i,j)). (f is features , w is the mask and I is the image pixel  see page 3 eq1  )
Uses 4 different sturctures (filters masks) called sptial Integrated filter). SIF to extract features from the image by sliding the structure throught the image and computing the features.

        
          
Recognition:
        
4 HMM models for each character is generated. The final recognition is computed as sum of 4 hmm probability and the class with Max probablity is the recognizied.  

        
          
The results :
        

        
Latin hand printed characters are used to test (600 sample per class so 18,636  total samples)
comparisons between 2DHMM and 1D HMM methods the best result achieved is 1D HMM SIF 98\% 
it is supposed to be less complex than 2D HMM. 

        

        

        1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?
        

        
Simple formulation of HMM. 

        

        2. What can we take from this work  ? what do we learn ?  What can be incorporated into our own work ?
        

        

        

        3. What are the problems of the paper ?
        

        
The main problem is that it only test isolated characters, Simple features and also it seems that the high number of features for each mask. 

        

        4. what is lacking from the work ? why does this work knot be the final  research in this subject ?
        
good filters, as the filters seems to only capture some of the spatial informaition it may be difficult to capture complex characters. 

        

        

        5. what about the methods causes this lack ? is there a fundamental reason ?
        
The use of image and a masked filter it self. 

        6. Could incremental Changes Fix this lack ? if so, what changes ? 
        
More better features. 

        

        Is there is any question you had about the paper ? 
        

        

        

        The final conclusion..........
        

        
Small paper, that may provide simple HMM method to recognize character but restricted to latin only .

        
============},
author = {Nishimura, H. and Tsutsumi, M.},
booktitle = {Document Analysis and Recognition, 2001. Proceedings. Sixth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2002/Nishimura, Tsutsumi - 2002.pdf:pdf},
isbn = {0769512631},
keywords = {Arabic Handwritting recognition,HMM,Off-line recognition,Read,Summarized},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
pages = {417--421},
publisher = {IEEE},
title = {{Off-line hand-written character recognition using integrated 1D HMMs based on feature extraction filters}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=953824},
year = {2002}
}
@article{V2007,
abstract = {In this paper we present an online handwritten symbol recognition system for Telugu, a widely spoken language in India. The system is based on Hidden Markov Models (HMM) and uses a combination of time-domain and frequencydomain features. The system gives top-1 accuracy of 91.6\% and top-5 accuracy of 98.7\% on a dataset containing 29,158 train samples and 9,235 test samples. We also introduce a cost-effective and natural data collection procedure based on ACECAD® Digimemo® and describe its usage in building a Telugu handwriting dataset.},
annote = {The paper is not in arabic but indian isolated characters but it contains information about how they gathered the data set, how they selected the HMM features. },
author = {V, Jagadeesh Babu and L, Prasanth and R, Raghunath Sharma and V, Prabhakara Rao G and A, Bharath and Babu, V Jagadeesh and Prasanth, L and Sharma, R Raghunath and Rao, G V Prabhakara},
file = {:D$\backslash$:/Papers/Documents/2007/V et al. - 2007.pdf:pdf},
journal = {Learning},
number = {September},
pages = {23--26},
title = {{HMM-based Online Handwriting Recognition System for Telugu Symbols}},
year = {2007}
}
@article{Liwicki2009a,
abstract = {In this paper, we describe feature selection experiments for online handwriting recog- nition. We investigated a set of 25 online and pseudo-offline features to find out which features are important and which features may be redundant. To analyze the saliency of the features, we applied a sequential forward and a sequential backward search on the feature set. A hidden Markov model and a neural network based recognizer have been used as recognition engines. In our experiments, we obtained interesting results. Using a set of only five features, we achieved a performance similar to that of the reference system that uses all 25 features. The five selected features have a low correlation and have been the top choices during the first iterations of the forward search with both recognizers. Furthermore, for both recognizers, subsets have been identified that outper- form the reference system with statistical significance. In order to assess the results more rigorously, we have compared our recognizer with the widely used commercial recognizer from Microsoft.},
author = {Liwicki, Marcus and Bunke, Horst},
file = {:D$\backslash$:/Papers/Documents/2009/Liwicki, Bunke - 2009.pdf:pdf},
journal = {International Journal of Pattern Recognition and Artificial Intelligence},
keywords = {bidirectional long,cursive handwritten text recognition,feature selection,hidden markov model,hmm,search,sequential backward search,sequential forward,short-term memory network},
number = {5},
pages = {907--923},
title = {{BASED HANDWRITING RECOGNITION}},
volume = {23},
year = {2009}
}
@inproceedings{Santos2009,
abstract = {Different strategies for combination of complementary features in an HMM-based method for handwritten character recognition are evaluated. In addition, a noise reduction method is proposed to deal with the negative impact of low probability symbols in the training database. New sequences of observations are generated based on the original ones, but considering a noise reduction process. The experimental results based on 52 classes of alphabetic characters and more than 23,000 samples have shown that the strategies proposed to optimize the HMM- based recognition method are very promising.},
author = {Santos, Murilo and Ko, Albert and Oliveira, Luis S. and Sabourin, Robert and Koerich, Alessandro L. and Jr., Alceu S. Britto},
booktitle = {2009 10th International Conference on Document Analysis and Recognition},
doi = {10.1109/ICDAR.2009.230},
file = {:D$\backslash$:/Papers/Documents/2009/Santos et al. - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
month = jul,
pages = {666--670},
publisher = {Ieee},
title = {{Evaluation of Different Strategies to Optimize an HMM-Based Character Recognition System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277474},
year = {2009}
}
@article{Oh1995,
abstract = {Viewing a handwritten word as an alternating sequence of characters and ligatures, we proposed a circularly interconnected network of hidden Markov models to model handwritten English words of indefinite length. The recognition problem is then regarded as finding the most probable path in the network for a given input. For the search, Viterbi algorithm is applied with lexicon lookup. To overcome directional sensitivity of the path search, a back-tracking technique is employed that keeps plausible path candidates dynamically within limited storage space.},
annote = {
        Paper Index :  Oh1995

        

        Why read paper ?

        need to buidl knowdge in the hmm use in word and character recognition.  and it is one of the old paper with will give me orginal methods.
          

          
What is these paper about ? (Summary)

        The paper represents : a word recognition as a problem of finding the most probable path in HMM networks. The network conssist of HMM characters , legatures and grammer nodes.  The vertibi algorithm is used to search the hmm but a lexical lookup is used to delete illegal path. This means that some paths will disappear and the algorithm will need to fill in some more candidate to get the most probabile path. This is done using by requesting candidites which will move using backword algorithm to generate more candidates for each path . ( this means if the algorithm move backword to generate more best candidate for new paths to get the most probabile bah) The main contribution is in this candidate filling algorithm.  
The encodding is done using 16 directional chain code, where each Hmm is trained with labeled sample. (two model for each character is used ) . The baun welch is used to train the hmm. The result are without lexical lookup  60\%, using , using vertibi algorithm 81\%,  and using the time consuming candidate refiling it is 83 \%
          

          

          

          
1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?

        This early work focus on recognizing words as a probability of some sequences. it is also interesting that it trains the HMM using characters segmented from curseive words and seperated characters. 
          
2. What can we take from this work  ? what do we learn ? What can be incorporated into our own work ?

        May be the different trainig methods and trying the lexical look up. 
          
3. What are the problems of the paper ?

         it has low accurcay (83\%) and no possiblity to reject wrong outputs. also the canddiate filing is time consuming
          
4. what is lacking from the work ? why does this work knot be the final  research in this subject ?

        No 
          
5. what about the methods causes this lack ? is there a fundamental reason ?

          
6. Could incremental Changes Fix this lack ? if so, what changes ? 

          

          
Is there is any question you had about the paper ? 
        
          NO
          

          
The final conclusion..........

          

        simple features, time consuming backword search. 
          

        
      },
author = {Oh, Se-chang and HA, Jin Young and Kim, Jin-H},
file = {:D$\backslash$:/Papers/Documents/1995/Oh, HA, Kim - 1995.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Arabic Handwritting recognition,Lexicon lookup,Network search,Read,Summarized,Unconstrained handwriting recognition,back tracking,hidden markov model,ligature model},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
number = {11},
pages = {163--1704},
title = {{CONTEXT Depended Search in interconnected Hidden markov Model for unconstrained handwriting recognition.}},
volume = {28},
year = {1995}
}
@inproceedings{PDBBritto2004,
abstract = {In this paper we combine complementary features based on foreground
and background information in an HMM-based classifier to recognize
handwritten isolated characters and numeral strings. A zoning scheme
based on column and row models provides a way of dividing the character
into zones without making the features size variant. This strategy
allows us to avoid the character normalization, while it provides
a way of having information from specific zones of the character.
The experimental results on 10 digit classes, 52 character classes
and 6 classes of numeral strings of different lengths have shown
that the proposed features are highly discrimminant.},
author = {{Britto Jr.}, Alceu de S and Sabourin, Robert and Bortolozzi, Flavio and Suen, Ching Y},
booktitle = {IWFHR '04: Proceedings of the Ninth International Workshop on Frontiers in Handwriting Recognition},
doi = {http://dx.doi.org/10.1109/IWFHR.2004.43},
file = {:D$\backslash$:/Papers/Documents/2004/Britto Jr. et al. - 2004.pdf:pdf},
isbn = {0-7695-2187-8},
pages = {371--376},
title = {{Foreground and Background Information in an HMM-Based Method for Recognition of Isolated Characters and Numeral Strings}},
year = {2004}
}
@inproceedings{Hamdani2009,
abstract = {This paper presents an off-line Arabic Handwriting recognition system based on the selection of different state of the art features and the combination of multiple Hidden Markov Models classifiers. Beside the classical use of the off-line features, we add the use of on-line features and the combination of the developed systems. The designed recog- nizer is implemented using the HMM-Toolkit. In a first step, we use different features to make the classification and we compare the performance of single classifiers. In a second step, we proceed to the combination of the on-line and the off-line based systems using different combination methods. The system is evaluated using the IFN/ENIT database. The recognition rate is in maximum 63.90\% for the individual systems. The combination of the on-line and the off-line systems allows to improve the system accuracy to 81.93\% which exceeds the best result of the ICDAR 2005 competi- tion.},
author = {Hamdani, Mahdi and Abed, Haikal El and Kherallah, Monji and Alimi, Adel M.},
booktitle = {2009 10th International Conference on Document Analysis and Recognition},
doi = {10.1109/ICDAR.2009.40},
file = {:D$\backslash$:/Papers/Documents/2009/Hamdani et al. - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
month = jul,
pages = {201--205},
publisher = {Ieee},
title = {{Combining Multiple HMMs Using On-line and Off-line Features for Off-line Arabic Handwriting Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277731},
year = {2009}
}
@inproceedings{Su2007,
abstract = {A novel recognition strategy is proposed for the transcription of Chinese handwritten documents. The recognizer adapts continuous density Hidden Markov Model (HMM) as the recognition engine. It incorporates character segmentation and recognition in one step avoiding character segmentation phase. Textline is extracted and converted to observation sequence by sliding windows first. Then Baum-Welch algorithm is used to train character HMMs. Finally, best character string in maximizing a posteriori criterion is found out through Viterbi algorithm as output. Experiments are conducted on a writer-dependent Chinese handwriting database with a 1,695 lexicon. The results show that our baseline recognizer outperforms much one popular commercial handwritten character recognition product and the strategy presented in this paper is a promising research direction.},
author = {Su, T.H. and Zhang, T.W. and Qiu, Z.W.},
booktitle = {Machine Learning and Cybernetics, 2007 International Conference on},
file = {:D$\backslash$:/Papers/Documents/2007/Su, Zhang, Qiu - 2007.pdf:pdf},
keywords = {character recognition,chinese characters,handwriting recognition,hidden markov models,optical,sliding},
number = {August},
pages = {3412--3417},
publisher = {IEEE},
title = {{HMM-based system for transcribing Chinese handwriting}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4370738},
volume = {6},
year = {2007}
}
@article{Bunke1995,
abstract = {-A method for the off-line recognition of cursive handwriting based on hidden Markov models (HMMs) is described. The features used in the HMMs are based on the arcs of skeleton graphs of the words to be recognized. An algorithm is applied to the skeleton graph of a word that extracts the edges in a particular order. Given the sequence of edges extracted from the skeleton graph, each edge is transformed into a 10-dimensional feature vector. The features represent information about the location of an edge relative to the four reference lines, its curvature and the degree of the nodes incident to the considered edge. The linear model was adopted as basic HMM topology. Each letter of the alphabet is represented by a linear HMM. Given a dictionary of fixed size, an HMM for each dictionary word is built by sequential concatenation of the H M Ms representing the individual letters of the word. Training of the HM Ms is done by means of the Baum-Welch algorithm, while the Viterbi algorithm is used for recognition. An average correct recognition rate of over 98\% on the word level has been achieved in experiments with cooperative writers using two dictionaries of 150 words each.},
annote = {
        =================================  Review Template ===========================================
Questions  : 
Paper Index : Bunke1995
          

          
Why read paper ?

        build knowldge on hmm usage in cursive  recognition. 
          

          
What is these paper about ? (Summary)

          

        The paper present an ofline word recognition systems using HMM. the steps of algorithms as follwoing. 
1)  line seperation using horizontal projection, then identify four diferent base lines. 
2)  vertical projection to seperate words . then smothing. 
3) morphing and smothing to generatea skeleton of the words by using tamaura algorithm. of 4 neighbours. 
4) edge and node generation from the skeleton. 
5) detection of loops  in the skeleton. 
6) compute  10 different features for each edge. 
7)  HMM linear model which is feed using the sequence of  feature (sequence of edges). 
the hmm network consist of a network for each letter with number of states depened on possible number of edges. 
training is done using blam welch and testing is best path using vertibi. 

        
The accuracy is high (over 98\%) but on a very small data set and using small testset. The result was not compared to other systems. 
          

          

          
1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?

        
        
A method to use features extracted from the character rather than the average direction feaures. by creating a skeleton and tyring to generate edge information similar to temperal one. 
          
2. What can we take from this work  ? what do we learn ? 

          
 What can be incorporated into our own work ?

        A method to use features extracted from the character rather than the average direction feaures
          
3. What are the problems of the paper ?

        The main problem of the work is the constrained style of trained samples which make u wonder about the result if used on unconstrained or different style. Also the small number of dictinary makes comparing to other work. 
          
4. what is lacking from the work ? why does this work knot be the final  research in this subject ?

        The writing style , and the limited dictinary and limited user to train and test system. 
          
5. what about the methods causes this lack ? is there a fundamental reason ?

                  I think the reason the system will be lacking is depenedablity about the skeleton algorithm and how it segment a letter, if a letter is written differently or if there is an error then the result will be worst. 
          
6. Could incremental Changes Fix this lack ? if so, what changes ? 

          

          
Is there is any question you had about the paper ? 

        what will happens when the user write in a different style. what if data variais or have skew or, will the training be robust or 

        
          
The final conclusion..........

          

        may use the skeleton idea, but need more testing and seem it is not proved on data. 
          

          

          
==========================================================================
      },
author = {Bunke, H},
doi = {10.1016/0031-3203(95)00013-P},
file = {:D$\backslash$:/Papers/Documents/1995/Bunke - 1995.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Arabic Handwritting recognition,Cursive script recognition,Hidden Markov model,Optical character recognition,Read,Skeleton graphs,Summarized,off-line recognition},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
month = sep,
number = {9},
pages = {1399--1413},
title = {{Off-line cursive handwriting recognition using hidden markov models}},
volume = {28},
year = {1995}
}
@article{Dehghan2001,
abstract = {{A holistic system for the recognition of handwritten Farsi/Arabic words using right\}left discrete hidden Markov models (HMM)and Kohonen self-organizing vector quantization is presented. The histogram of chain-code directions of the image strips, scanned from right to left by a sliding window, is used as feature vectors. The neighborhood information preserved in the self-organizing feature map (SOFM), is used for smoothing the observation probability distributions of trained HMMs. Experiments carried out on test samples show promising performance results.  2001 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved},
annote = {=================================  Review ===========================================
          
Paper Index : Dehghan2001
          
Date:14- Nov -2010

        
          
Why read paper ?
        
HMM foundation and methods

        
          
What is these paper about ? (Summary)
        
The system start with 
1) Preprocessing which include the following 

        
a) Binarization  b) noise removal  c) slope correction  (baseline is found by horizontal projection then line is found and skew correction is processed. d) stroke width is estimated from the avg of run length of black width.

        
2) Feature extraction include. 
a) Stroke width compensation to make all strokes with at least 3 pixel width.
b) contour generation c) generation of 4 direction chain code from the contour information. d) dividing the word into vertical strips from left to right with 50\% overlap and width is twice avg stroke width. e) each vertical strip is divided into 4 horizontal  zone 
f) the histogram of each chain code is extracted from each zone. (see fig 7 in paper) 
because each frame has 4 directional X 5 vertical strips then 20 feature is computed for each vertical strip. 
3) self organizing feature map clustring. SOFM is used to cluster features (as codebook ) to decrease number of features used as input for HMM. 
4) HMM training . 
a HMM model (right to left)is created for each city (Word) int the dataset. The training is done using baum welch. 
The dataset consist fo 17,000 images of 198 city (the lexicon size) 

        
          
The reuslt is 65\%. 
        

        

        
          
1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?
        
The intersting is the features extraction method (contour and chain code) and the use of SOFM as clustring. The image is divided from right to left. 

        
          
2. What can we take from this work  ? what do we learn ? 
        What can be incorporated into our own work ?
        
 We can experminet with the features they used. 

        
          
3. What are the problems of the paper ?
        

        
The major problem is they implement one HMM model for each city or each word this means it is not scalable for general use in unconstrain dictinary. 

        
The size of the codebook is very large. also the very low result 65\% is not very promising. 

        
          
4. what is lacking from the work ? why does this work knot be the final  research in this subject ?
        

        
extending this work to work in larger dictinary, more roboust featurse

        
          
5. what about the methods causes this lack ? is there a fundamental reason ?
        

        
I think the use of SOFM and the 4-directional chain code, i belive better result can be done using 8 direction. 

        
          
6. Could incremental Changes Fix this lack ? if so, what changes ? 
        

        

        

        
          
Is there is any question you had about the paper ? 
        

        

        

        
        
          
            
The final conclusion
        
        
        ..........

        
Not so good system with a low recognition rate. 

        
==========================================================================},
author = {Dehghan, M},
doi = {10.1016/S0031-3203(00)00051-0},
file = {:D$\backslash$:/Papers/Documents/2001/Dehghan - 2001.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Arabic Handwritting recognition,Read,Summarized,arabic,farsi,handwriting recognition,handwritten word recognition,hidden markov model,parameter smoothing,self-organizing feature map},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
month = may,
number = {5},
pages = {1057--1065},
title = {{Handwritten Farsi (Arabic) word recognition: a holistic approach using discrete HMM}},
volume = {34},
year = {2001}
}
@article{Khorsheed2003,
abstract = {This paper presents a new method on off-line recognition of handwritten Arabic script. The method does not require segmentation into characters, and is applied to cursive Arabic script, where ligatures, overlaps and style variation pose challenges to the recognition system. The method trains a single hidden Markov model (HMM) with the structural features extracted from the manuscript words. TheHMMis composed of multiple character models where each model represents one letter from the alphabet. The performance of the proposed method is assessed using samples extracted from a historical handwirtten manuscript.},
annote = {=================================  Review Template ===========================================
Paper Index : Khorsheed2003
Date: 14 - Nov - 2010 

        

        Why read paper ?
        
HMM background and Arabic method. 

        

        Paper Overview ?
        
No segmentation 
skining algorithm, with line approximimation, k-clustring algorithm is used. 
HMM using Baum welch and viterbi then 
spell check. 

        What is these paper about ? (Summary)
        

        
1) preprocessing include
a) thinign algorithm then remove the wrong branching by alocatin the feature points and checking them . 
b)  link and loop extraction. 
c) line approximation. 
approximate skeletion to linkes , loop lines with each line is angle and lenght and ends points. 
2) encoding the feature vector using k-mean clustring with symbol codebook. 
each symbol with a set of features. 
3) HMM 1 single model for whole word by concatentaitn oor repeating character models 
each one has states based on number os segment in it ( eldad with more states than el heah)  viterbi is used to pobtain the obitmal and near optimal path ( best and top 5) 
a spell check is added to remove illiegal words. 

        
The result is test on old manuscript with 405 characters sample to trrain and 12960 to test. 
thre result is 72\% without spell check and 87\% with spell check. 

        

        

        1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?
        

        
Advantage is no segmentation used and a single hmm models is used for the recognition. 

        

        2. What can we take from this work  ? what do we learn ?  What can be incorporated into our own work ?
        

        
The large number of feature must be reduced by a feature clustring algorithms. 

        
          
3. What are the problems of the paper ?
        

        
The dependablity on the thining and line approximation algorithms which I belive are features affected by noise and writing style.  

        
          
4. what is lacking from the work ? why does this work knot be the final  research in this subject ?
        

        
Tested only on one manuscript and using only one or two writing styles. Also the low recognition rate, and dependability upon non powerful features. 

        
          
5. what about the methods causes this lack ? is there a fundamental reason ?
        

        
dependability upon non powerful features, using only one model of HMM for recognition which may yeild some illiegale words with high probability. 
          
6. Could incremental Changes Fix this lack ? if so, what changes ? 
        

        

        
          
Is there is any question you had about the paper ? 
        

        

        
The final conclusion..........

        
Paper has some ideas but is neural (not good , not bad), 

        
==========================================================================},
author = {Khorsheed, M.S.},
doi = {10.1016/S0167-8655(03)00050-3},
file = {:D$\backslash$:/Papers/Documents/2003/Khorsheed - 2003.pdf:pdf},
issn = {0167-8655},
journal = {Pattern Recognition Letters},
keywords = {Arabic Handwritting recognition,Read,Summarized,arabic character recognition,cursive script,handwritten,hmm,off-line recognition,viterbi algorithm},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
number = {14},
pages = {2235--2242},
publisher = {Elsevier},
title = {{Recognising handwritten Arabic manuscripts using a single hidden Markov model}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865503000503},
volume = {24},
year = {2003}
}
@article{Rodriguez-Serranoa2009,
abstract = {Handwritten word-spotting is traditionally viewed as an image matching task between one or multiple query word-images and a set of candidate word-images in a database. This is a typical instance of the query-by-example paradigm. In this article, we introduce a statistical framework for the word-spotting problem which employs hidden Markov models (HMMs) to model keywords and a Gaussian mixture model (GMM) for score normalization. We explore the use of two types of HMMs for the word modeling part: continuous HMMs (C-HMMs) and semi-continuous HMMs (SC-HMMs), i.e. HMMs with a shared set of Gaussians. We show on a challenging multi-writer corpus that the proposed statistical framework is always superior to a traditional matching system which uses dynamic time warping (DTW) for word- image distance computation. A very important finding is that the SC-HMM is superior when labeled training data is scarce—as low as one sample per keyword—thanks to the prior information which can be incorporated in the shared set of Gaussians. ©},
author = {Rodriguez-Serranoa, J.A. and Perronninb, F.},
doi = {10.1016/j.patcog.2009.02.005},
file = {:D$\backslash$:/Papers/Documents/2009/Rodriguez-Serranoa, Perronninb - 2009.pdf:pdf},
journal = {Pattern Recognition},
number = {1},
pages = {2106--2116},
title = {{Handwritten word-spotting using hidden Markov models and universal vocabularies}},
url = {http://www.comp.leeds.ac.uk/scsjars/pubs/rodriguez\_wordspotting\_HMM.pdf},
volume = {42},
year = {2009}
}
@article{Graves2009,
abstract = {Recognizing lines of unconstrained handwritten text is a challenging task. The difficulty of segmenting cursive or overlapping characters; and analyze its use of context. Last; combined with the need to exploit surrounding context; despite their well-known shortcomings. This paper proposes an alternative approach based on a novel type of recurrent neural network; has led to low recognition rates for even the best current recognizers. Most recent progress in the field has been made either through improved preprocessing or through advances in language modeling. Relatively little work has been done on the basic recognition algorithms. Indeed; measure the individual influence of its hidden layers; most systems rely on the same hidden Markov models that have been used for decades in speech and handwriting recognition; our approach achieves word recognition accuracies of 79.7 percent on online data and 74.1 percent on offline data; significantly outperforming a state-of-the-art HMM-based system. In addition; specifically designed for sequence labeling tasks where the data is hard to segment and contains long-range bidirectional interdependencies. In experiments on two large unconstrained handwriting databases; suggesting reasons for the network’s superior performance.; we demonstrate the network’s robustness to lexicon size; we provide an in-depth discussion of the differences between the network and HMMs},
author = {Graves, Alex and Liwicki, Marcus and Fern\'{a}ndez, S. and Bertolami, Roman and Bunke, Horst and Schmidhuber, J.},
file = {:D$\backslash$:/Papers/Documents/2008/Graves et al. - 2008.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Handwriting recognition,bidirectional long short-term memory,connectionist temporal classification,hidden Markov model.,offline handwriting,online handwriting,recurrent neural networks},
number = {5},
pages = {855--868},
publisher = {Published by the IEEE Computer Society},
title = {{A novel connectionist system for unconstrained handwriting recognition}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/TPAMI.2008.137},
volume = {31},
year = {2008}
}
@inproceedings{Siriboon2002,
abstract = {Researchers have extensively applied Hidden Markov Model (HMM) to handwritten recognition in English, Chinese, and other languages. Most researchers have been using the left-right topology for handwritten and speech recognition. This research studied the effect of HMM topology on isolated on- line Thai handwritten recognition. The left-right, fully connected and the proposed topologies (left-right-left) were compared. The number of state of a character HMM for each topology was varied from 15 to 35 nodes and the one with the best training observations probability was selected. The feature used was Chain code-like with modification to represent originated quadrant position. The recognition results showed that the proposed topology increases the recognition rate in comparison to the most widely used left-right topology.},
annote = {===========================================Paper Index : Siriboon2002
          
Date:22-11-2010

        
          
Why read paper ?
        
HMM background 

        
          
Paper Overview ?
        
HMM or chain code features with online 
the paper focus on toplogy change of hmm and comparison. 

        
          
What is these paper about ? (Summary)
        
online data are resampled to make point ahve same distance. 
chain code extracted. 
there is tow types of chain code one for upper part of character other for lower partof character. 
training HMM one for each character where trainig HMM using baum welch. 
Different topolgy of hmm is teat ( FC (fully connected), LR (left right), LRL (left - right - left)).  
see fig 3. 

        
          
Result :
        
no discription of data, only tested topology vs. no of states and the parameters of hmm. 
best result was on LRL with best No of states is 95.67\%. 

        

        
          
1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?
        
The simple chain code features. 
          
2. What can we take from this work  ? what do we learn ? What can be incorporated into our own work ?
        

        
Changing the chain code from upper to lower to get more feature and distinguish characters. 

        
          
3. What are the problems of the paper ?
        

        
No data discriptions and analysis number of classes or number of sample per class. 

        
          
4. what is lacking from the work ? why does this work knot be the final  research in this subject ?
        

        
          
5. what about the methods causes this lack ? is there a fundamental reason ?
        

        
          
6. Could incremental Changes Fix this lack ? if so, what changes ? 
        

        

        
          
Is there is any question you had about the paper ? 

        
        

        
          
The final conclusion..........
        
Simple but with no real indication of comparing system with others. 

        
==========================================================================

      },
author = {Siriboon, Kritawan and Jirayusakul, Apirak and Kruatrachue, Boontee},
booktitle = {Proceedings of the First International Symposium on Cyber Worlds (CW’02)},
file = {:D$\backslash$:/Papers/Documents/2002/Siriboon, Jirayusakul, Kruatrachue - 2002.pdf:pdf},
keywords = {Arabic Handwritting recognition,HMM,Read,Summarized,on-line handwriting recognition},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
pages = {0142},
publisher = {Published by the IEEE Computer Society},
title = {{Hmm topology selection for on-line thai handwritten recognition}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/CW.2002.1180872},
year = {2002}
}
@article{Rodriguez-Serrano2010,
abstract = {In this paper we propose a novel approach for writer adaptation in a handwritten word-spotting task. The method exploits the fact that the semi-continuous hidden Markov model separates the word model parameters into (i) a codebook of shapes and (ii) a set of word-specific parameters. Our main contribution is to employ this property to derive writer-specific word models by statistically adapting an initial universal codebook to each document. This process is unsupervised and does not even require the appearance of the keyword(s) in the searched document. Experimental results show an increase in performance when this adaptation technique is applied. To the best of our knowledge, this is the first work dealing with adaptation for word-spotting. The preliminary version of this paper obtained an IBM Best Student Paper Award at the 19th International Conference on Pattern Recognition.},
author = {Rodr\'{\i}guez-Serrano, Jos\'{e} a. and Perronnin, Florent and S\'{a}nchez, Gemma and Llad\'{o}s, Josep},
doi = {10.1016/j.patrec.2010.01.007},
file = {:D$\backslash$:/Papers/Documents/2010/Rodr\'{\i}guez-Serrano et al. - 2010.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
month = jun,
number = {8},
pages = {742--749},
publisher = {Elsevier B.V.},
title = {{Unsupervised writer adaptation of whole-word HMMs with application to word-spotting}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865510000097},
volume = {31},
year = {2010}
}
@inproceedings{Zhang2009a,
abstract = {—The purpose of this paper is to improve recognition rate of off-line handwritten character recognition system.We apply the statistical characteristics of the percentage of pixels and structural characteristics of boundary chain code of character projection, after train based on HMM to obtain corresponding parameters, then integrate different classifiers through the Bagging algorithm in Voting method. Experimental results indicate that this approach can further improve the performance.},
author = {Zhang, Yan and Yao, Xiaodong and Chang, Ching},
booktitle = {Computational Intelligence and Software Engineering, 2009. CiSE 2009. International Conference on},
file = {:D$\backslash$:/Papers/Documents/2009/Zhang, Yao, Chang - 2009.pdf:pdf},
keywords = {- handwriten recognition,Handwritten Character Recognition Using HMM Model ,bagging,hmm model},
pages = {1--4},
publisher = {IEEE},
title = {{Handwritten Character Recognition Using HMM Model Based on Bagging Method}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5366197},
year = {2009}
}
@article{Huang2008,
abstract = {In this paper a hidden Markov model (HMM)-based binarization algorithm is presented. This algorithm performs well for images with nonuniform background. To test the usefullness of the proposed technique some images of composite documents of printed characters were used. These characters were extracted through the proposed binarization algorithms and used in a commercial OCR. A comparative study of various binarization techniques is also presented},
author = {Huang, Songtao and Ahmadi, Majid and Sid-Ahmed, MA},
doi = {10.1016/j.patcog.2008.03.004},
file = {:D$\backslash$:/Papers/Documents/2008/Huang, Ahmadi, Sid-Ahmed - 2008.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {binarization,hmm,ocr,stroke,thresholding},
number = {9},
pages = {2890--2900},
publisher = {Elsevier},
title = {{A hidden Markov model-based character extraction method}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308000885},
volume = {41},
year = {2008}
}
@inproceedings{Koerich2004,
abstract = {To support large vocabulary handwriting recognition in standard computer platforms, a fast algorithm for hidden Markov model alignment is necessary. To address this prob- lem, we propose a non–heuristic fast decoding algorithm which is based on hidden Markov model representation of characters. The decoding algorithm breaks up the compu- tation of word likelihoods into two levels: state level and character level. Given an observation sequence, the two level decoding enables the reuse of character likelihoods to decode all words in the lexicon, avoiding repeated compu- tation of state sequences. In an 80,000–word recognition task, the proposed decoding algorithm is about 15 times faster than a conventional Viterbi algorithm, while main- taining the same recognition accuracy},
author = {Koerich, A.L. and Sabourin, Robert and Suen, C.Y.},
booktitle = {Frontiers in Handwriting Recognition, 2004. IWFHR-9 2004. Ninth International Workshop on},
file = {:D$\backslash$:/Papers/Documents/2004/Koerich, Sabourin, Suen - 2004.pdf:pdf},
isbn = {0769521878},
issn = {1550-5235},
pages = {232--237},
publisher = {IEEE},
title = {{Fast two-level HMM decoding algorithm for large vocabulary handwriting recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1363916},
year = {2004}
}
@inproceedings{ARGolubitsky2008,
abstract = {The process of recognizing individual handwritten characters is one
of classifying curves. Typically, handwriting recognition systems�
even �online� systems�require entire characters be completed before
recognition is attempted. This paper presents another approach for
real-time recognition: certain characteristics of a curve can be
computed as the curve is being written, and these characteristics
are used to classify the character in constant time when the pen
is lifted. We adapt an earlier approach of representing curves in
a functional basis and reduce real-time stroke modelling to the Hausdorff
moment problem.},
address = {Ontario, Canada},
author = {Golubitsky, Oleg and Watt, Stephen M},
booktitle = {CASCON '08 : Proceedings of the 2008 conference of the center for advanced studies on collaborative research},
file = {:D$\backslash$:/Papers/Documents/2008/Golubitsky, Watt - 2008.pdf:pdf},
pages = {72--80},
title = {{Online Stroke Modeling for Handwriting Recognition}},
year = {2008}
}
@article{Pal2004,
abstract = {Intensive research has been done on optical character recognition (OCR) and a large number of articles have been published on this topic during the last few decades. Many commercial OCR systems are now available in the market. But most of these systems work for Roman, Chinese, Japanese andArabic characters. There are no sucient number of work on Indian language character recognition although there are 12 major scripts in India. In this paper, we present a review of the OCR work done on Indian language scripts. The review is organizedinto 5 sections. Sections 1 and2 cover introduction andproperties on Indian scripts. In Section 3, we discuss dierent methodologies in OCR development as well as research work done on Indian scripts recognition. In Section 4, we discuss the scope of future work and further steps needed for Indian script OCR development. In Section 5 we conclude the paper.},
author = {Pal, U and Chaudhuri, BB},
doi = {10.1016/j.patcog.2004.02.003},
file = {:D$\backslash$:/Papers/Documents/2004/Pal, Chaudhuri - 2004.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {indian script,indian script ocr,ocr survey,optical character recognition},
number = {9},
pages = {1887--1899},
publisher = {Elsevier},
title = {{Indian script character recognition: a survey}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S003132030400055X},
volume = {37},
year = {2004}
}
@article{Vinciarelli2002,
abstract = {This work presents the application of HMM adaptation techniques to the problem of Off-Line Cursive Script Recognition. Rather than training a new model for each writer,one first creates a unique model with a mixed database and then adapts it for each different writer using his own small dataset. Experiments on a publicly available benchmark database show that an adapted system has an accuracy higher than 80\% even when less than 30 word samples are used during adaptation,while a system trained using the data of the single writer only needs at least 200 words in order to achieve the same performance as the adapted models.  2002 Elsevier Science B.V. All rights reserved.},
author = {Vinciarelli, a},
doi = {10.1016/S0167-8655(02)00021-1},
file = {:D$\backslash$:/Papers/Documents/2002/Vinciarelli - 2002.pdf:pdf},
journal = {Pattern Recognition Letters},
keywords = {hmm,hmm bayesian adaptation,hmm maximum likelihood adaptation,maximum a posteriori adaptation,off-line cursive script recognition},
month = jun,
number = {8},
pages = {905--916},
title = {{Writer adaptation techniques in HMM based Off-Line Cursive Script Recognition}},
volume = {23},
year = {2002}
}
@article{Liu2004a,
abstract = {Online handwriting recognition is gaining renewed interest owing to the increase of pen computing applications and new pen input devices. The recognition of Chinese characters is different from western handwriting recognition and poses a special challenge. To provide an overview of the technical status and inspire future research, this paper reviews the advances in online Chinese character recognition (OLCCR), with emphasis on the research works from the 1990s. Compared to the research in the 1980s, the research efforts in the 1990s aimed to further relax the constraints of handwriting, namely, the adherence to standard stroke orders and stroke numbers and the restriction of recognition to isolated characters only. The target of recognition has shifted from regular script to fluent script in order to better meet the requirements of practical applications. The research works are reviewed in terms of pattern representation, character classification, learning/adaptation, and contextual processing. We compare important results and discuss possible directions of future research.},
author = {Liu, Cheng-Lin and Jaeger, Stefan and Nakagawa, Masaki},
doi = {10.1109/TPAMI.2004.1262182},
file = {:D$\backslash$:/Papers/Documents/2004/Liu, Jaeger, Nakagawa - 2004.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automatic Data Processing,China,Computer Graphics,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Natural Language Processing,Numerical Analysis, Computer-Assisted,Pattern Recognition, Automated,Reading,Reproducibility of Results,Review Literature as Topic,Sensitivity and Specificity,Signal Processing, Computer-Assisted,Subtraction Technique,Technology Assessment, Biomedical,User-Computer Interface,Vocabulary, Controlled},
month = feb,
number = {2},
pages = {198--213},
pmid = {15376895},
title = {{Online recognition of Chinese characters: the state-of-the-art.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15376895},
volume = {26},
year = {2004}
}
@article{Bertolami2008,
author = {Bertolami, R and Bunke, H},
doi = {10.1016/j.patcog.2008.04.003},
file = {:D$\backslash$:/Papers/Documents/2008/Bertolami, Bunke - 2008.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {offline handwritten text line,recognition},
month = nov,
number = {11},
pages = {3452--3460},
title = {{Hidden Markov model-based ensemble methods for offline handwritten text line recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308001349},
volume = {41},
year = {2008}
}
@article{Vuori2002,
abstract = {We have considered problems involved in the self-supervised learning process of an on-line handwriting recognition system. Our system is able to recognize isolated characters by comparing them to prototype characters with a method based on the Dynamic Time Warping algorithm. The recognition system is adapted by adding new prototypes, inac- tivating confusing or erroneous ones, and reshaping existing prototypes with a method based on the Learning Vector Quantization. We have analyzed the sources oferroneous learning samples and studied the inuence ofsuch samples on the performance of the recognizer via simulations. In these simulations, two adaptation strategies combined with four methods for inactivating prototypes were applied. The results of the simulations showed that the adaptation strategies are able to improve the system’s recognition rate and the prototype inactivation methods do reduce the harmful eects of erroneous learning samples.? 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.},
author = {Vuori, V},
doi = {10.1016/S0031-3203(01)00083-8},
file = {:D$\backslash$:/Papers/Documents/2002/Vuori - 2002.pdf:pdf},
journal = {Pattern Recognition},
keywords = {adaptation,dtw,dynamic time warping,erroneous learning samples,intelligent user interface,isolated character recognition,k nearest neighbor rule,learning vector quantization,lvq,on-line recognition,unconstrained writing style},
month = apr,
number = {4},
pages = {915--925},
title = {{Influence of erroneous learning samples on adaptation in on-line handwriting recognition}},
volume = {35},
year = {2002}
}
@article{Gunter2004,
abstract = {In off-line handwriting recognition, classifiers based on hidden Markov models (HMMs) have become very popular.However, while there exist well-established training algorithms which optimize the transition and output probabilities of a given HMM architecture, the architecture itself, and in particular the number of states, must be chosen “by hand”. Also the number of training iterations and the output distributions need to be defined by the system designer. In this paper we examine several optimization strategies for an HMM classifier that works with continuous feature values. The proposed optimization strategies are evaluated in the context of a handwritten word recognition task},
author = {Gunter, Simon and Bunke, Horst},
doi = {10.1016/j.patcog.2004.04.006},
file = {:D$\backslash$:/Papers/Documents/2004/Gunter, Bunke - 2004.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {gaussian mixture,handwritten word recognition,hidden markov model,hmm,state number optimization,training strategy},
number = {10},
pages = {2069--2079},
publisher = {Elsevier},
title = {{HMM-based handwritten word recognition: on the optimization of the number of states, training iterations and Gaussian components}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320304001633},
volume = {37},
year = {2004}
}
@article{Nishimura2003,
abstract = {Recognition of variously deformed character patterns is a salient subject for off-line hand-printed character recognition. Sufficient recognition performance for practical use has not been achieved despite reports of many recognition techniques. Our research examines effective recognition techniques for deformed characters, extending conventional recognition techniques using an on-line character writing information containing writing pressure data. This study extends conventional recognition techniques using on-line character writing information containing writing pressure information. A recognition system using simple pattern matching and HMM was made for evaluation experiments using Common Hand- printed English character patterns from the ETL6 database to determine effectiveness of the proposed extending recognition method. Character recognition performance is increased in both expansion recognition methods using on-line writing information.},
author = {Nishimura, Hiromitsu and Timikawa, Takehiko},
file = {:D$\backslash$:/Papers/Documents/2003/Nishimura, Timikawa - 2003.pdf:pdf},
journal = {Document Analysis and Recognition},
pages = {168},
title = {{Off-line Character Recognition using On-line Character Writing Information}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICDAR.2003.1227653},
volume = {1},
year = {2003}
}
@inproceedings{Perdisci2006a,
author = {Perdisci, Roberto and Gu, Guofei and Lee, Wenke},
booktitle = {Sixth International Conference on Data Mining (ICDM'06)},
month = dec,
pages = {488--498},
publisher = {IEEE},
title = {{Using an Ensemble of One-Class SVM Classifiers to Harden Payload-based Anomaly Detection Systems}},
url = {http://roberto.perdisci.googlepages.com/DM352\_Perdisci\_Roberto.pdf},
year = {2006}
}
@inproceedings{Lowd2005,
author = {Lowd, D. and Meek, C.},
booktitle = {Second Conference on Email and Anti-Spam, CEAS 2005},
title = {{Good word attacks on statistical spam filters}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Good+Word+Attacks+on+Statistical+Spam+Filters\#0},
year = {2005}
}
@misc{Roli2009,
author = {Roli, Fabio},
title = {{Keynote Address: Adversarial Pattern Recognition}},
url = {http://prag.diee.unica.it/pra/node/778},
year = {2009}
}
@inproceedings{Nelson2008,
author = {Nelson, Blaine and Barreno, Marco and Chi, Fuching Jack and Joseph, Anthony D. and Rubinstein, Benjamin I. P. and Saini, Udam and Sutton, Charles and Tygar, J. D. and Xia, Kai},
booktitle = {First Usenix Workshop on Large-Scale Exploits and Emergent Threats},
publisher = {USENIX},
title = {{Exploiting Machine Learning to Subvert Your Spam Filter}},
url = {http://www.usenix.org/event/leet08/tech/full\_papers/nelson/nelson.pdf},
year = {2008}
}
@inproceedings{Barreno2006,
abstract = {Machine learning systems offer unparalled flexibility in dealing with evolving input in a variety of applications, such as intrusion detection systems and spam e-mail filtering. However, machine learning algorithms themselves can be a target of attack by a malicious adversary. This paper provides a framework for answering the question, “Can machine learning be secure?” Novel contributions of this paper include a taxonomy of different types of attacks on machine learning techniques and systems, a variety of defenses against those attacks, a discussion of ideas that are important to security for machine learning, an analytical model giving a lower bound on attacker’s work function, and a list of open problems.},
address = {New York, New York, USA},
author = {Barreno, Marco and Nelson, Blaine and Sears, Russell and Joseph, Anthony D. and Tygar, J. D.},
booktitle = {Proceedings of the 2006 ACM Symposium on Information, computer and communications security - ASIACCS '06},
keywords = {adversarial learning,computer networks,computer security,game theory,intrusion detection,machine learning,security metrics,spam filters,statistical learning},
number = {March},
pages = {16},
publisher = {ACM Press},
title = {{Can machine learning be secure?}},
url = {http://portal.acm.org/citation.cfm?doid=1128817.1128824},
year = {2006}
}
@inproceedings{Dalvi2004,
address = {New York, New York, USA},
author = {Dalvi, Nilesh and Domingos, Pedro and Sanghai, Sumit and Verma, Deepak},
booktitle = {Proceedings of 2004 ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD 2004},
keywords = {cost-sensitive learning,game theory,naive bayes,spam detection},
pages = {99--108},
publisher = {ACM Press},
title = {{Adversarial classification}},
url = {http://portal.acm.org/citation.cfm?doid=1014052.1014066},
year = {2004}
}
@misc{Mason2005,
author = {Mason, Justin},
title = {{The Life of a SpamAssassin Rule}},
url = {http://taint.org/2005/08/06/024026a.html},
year = {2005}
}
@article{Fawcettc,
author = {Fawcett, Tom},
journal = {SigKDD Explorations},
number = {2},
title = {{“In vivo” spam filtering: A challenge problem for data mining}},
url = {http://home.comcast.net/\~{}tom.fawcett/public\_html/papers/spam-KDDexp.pdf},
volume = {5},
year = {2003}
}
@misc{Biggio2009,
author = {Biggio, Battista and Fumera, Giorgio and Roli, Fabio},
title = {{Multiple Classifier Systems for Adversarial Classification Tasks}},
url = {http://www.slideshare.net/pragroup/multiple-classifier-systems-for-adversarial-classification-tasks},
year = {2009}
}
@inbook{Biggio2009,
abstract = {Pattern classification systems are currently used in security applications like intrusion detection in computer networks, spam filtering and biometric identity recognition. These are adversarial classification problems, since the classifier faces an intelligent adversary who adaptively modifies patterns (e.g., spam e-mails) to evade it. In these tasks the goal of a classifier is to attain both a high classification accuracy and a high hardness of evasion, but this issue has not been deeply investigated yet in the literature. We address it under the viewpoint of the choice of the architecture of a multiple classifier system. We propose a measure of the hardness of evasion of a classifier architecture, and give an analytical evaluation and comparison of an individual classifier and a classifier ensemble architecture.  We finally report an experimental evaluation on a spam filtering task.},
author = {Biggio, Battista and Fumera, Giorgio and Roli, Fabio},
booktitle = {Multiple Classifier Systems},
editor = {Haindl, Michal and Kittler, Josef and Roli, Fabio},
keywords = {evasion},
mendeley-tags = {evasion},
publisher = {Springer},
title = {{Multiple Classifier Systems for Adversarial Classification Tasks}},
url = {http://www.slideshare.net/pragroup/multiple-classifier-systems-for-adversarial-classification-tasks},
year = {2007}
}
@article{Jorgensen2008,
author = {Jorgensen, Zach and Zhou, Yan and Inge, Meador},
journal = {Journal of Machine Learning Research},
keywords = {adversarial learning,good word attack,multiple instance learning,spam ltering},
pages = {1115--1146},
title = {{A Multiple Instance Learning Strategy for Combating Good Word Attacks on Spam Filters}},
url = {http://jmlr.csail.mit.edu/papers/volume9/jorgensen08a/jorgensen08a.pdf},
volume = {8},
year = {2008}
}
@inproceedings{Wittel2004,
author = {Wittel, Gregory L and Wu, S Felix},
booktitle = {CEAS-2004},
title = {{On Attacking Statistical Spam Filters}},
year = {2004}
}
@inproceedings{Chinavle2008,
author = {Chinavle, Deepak and Kolari, Pranam and Oates, Tim and Finin, Tim},
booktitle = {Proceedings of the 18th ACM Conference on Information and Knowledge Management},
keywords = {adversarial classification,ensembles,non-stationarity,retraining,spam,weblogs},
title = {{Ensembles in Adversarial Classification for Spam}},
year = {2008}
}
@article{Lowd2005a,
address = {New York, New York, USA},
author = {Lowd, Daniel and Meek, Christopher},
journal = {Proceeding of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining - KDD '05},
keywords = {adversarial classi cation,linear classi ers,spam},
pages = {641},
publisher = {ACM Press},
title = {{Adversarial learning}},
url = {http://portal.acm.org/citation.cfm?doid=1081870.1081950},
year = {2005}
}
@misc{Lowd,
author = {Lowd, Daniel and Meek, Christopher and Domingos, Pedro},
title = {{Foundations of Adversarial Learning}}
}
@inproceedings{Biggio2008,
author = {Biggio, Battista and Fumera, Giorgio and Roli, Fabio},
booktitle = {12th Joint IAPR International Workshop on Structural and Syntactic Pattern Recognition (SSPR 2008)},
publisher = {Springer-Verlag},
title = {{Adversarial Pattern Classification Using Multiple Classifiers and Randomisation}},
year = {2008}
}
@article{Zhou2006,
author = {Zhou, Yan and Jorgensen, Zach and Inge, Meador},
number = {Mi},
title = {{Countering Good Word Attacks on Statistical Spam Filters with Instance Differentiation and Multiple Instance Learning}},
year = {2006}
}
@inproceedings{Perdisci2006,
author = {Perdisci, R. and Dagon, D. and Lee, W. and Fogla, P. and Sharif, M.},
booktitle = {2006 IEEE Symposium on Security and Privacy (S\&P'06)},
pages = {17--31},
publisher = {IEEE},
title = {{Misleading Worm Signature Generators Using Deliberate Noise Injection}},
url = {http://roberto.perdisci.googlepages.com/Perdisci-MisleadingWSG.pdf},
year = {2006}
}
@inproceedings{Globerson2006,
author = {Globerson, Amir and Roweis, Sam},
booktitle = {23rd International Conference on Machine Learning},
pages = {353--360},
title = {{Nightmare at Test Time: Robust Learning by Feature Deletion}},
url = {http://www.cs.toronto.edu/\~{}roweis/papers/robust\_icml06.pdf},
year = {2006}
}
@article{Forrest2009a,
address = {New York, New York, USA},
author = {Forrest, Stephanie and Nguyen, ThanhVu and Weimer, Westley and {Le Goues}, Claire},
file = {::},
journal = {Proceedings of the 11th Annual conference on Genetic and evolutionary computation - GECCO '09},
keywords = {all or part of,also at the santa,fe institute,genetic programming,nm,or hard copies of,permission to make digital,santa fe,software engineering,software repair,this work for},
pages = {947},
publisher = {ACM Press},
title = {{A genetic programming approach to automated software repair}},
url = {http://portal.acm.org/citation.cfm?doid=1569901.1570031},
year = {2009}
}
@article{Seljebotn2009a,
author = {Seljebotn, DS},
file = {::},
journal = {Proceedings of the 8th Python in Science Conference},
keywords = {cython,numpy,python,scipy},
mendeley-tags = {cython,numpy,python,scipy},
number = {SciPy},
pages = {15--22},
title = {{Fast numerical computations with Cython}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Fast+numerical+computations+with+Cython\#0 http://conference.scipy.org/proceedings/SciPy2009/paper\_2/},
year = {2009}
}
@article{Pancratov2008b,
author = {Pancratov, Cosmin and Kurzer, Jacob M and Shaw, Kelly A and Trawick, Matthew L},
title = {{Why Computer Architecture Matters: Thinking Through Trade-Offs In Your Code}},
year = {2008}
}
@article{Pancratov2008c,
author = {Pancratov, C. and Kurzer, J.M. and Shaw, K.A. and Trawick, M.L.},
file = {::},
journal = {Computing in Science $\backslash$\& Engineering},
number = {5},
pages = {74--79},
title = {{Why Computer Architecture Matters: Thinking through Trade-offs in Your Code}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Why+Computer+Architecture+Matters:+Thinking+through+trade-offs+in+your+code\#0},
volume = {10},
year = {2008}
}
@article{Pennycook,
author = {Pennycook, S J and Hammond, S D and Jarvis, S A and Mudalige, G R},
file = {::},
journal = {Performance Computing},
keywords = {ac,cfd,dcs,gpu,lu,performance model,saj,sdh,sjp,uk,warwick,wavefront},
title = {{Performance Analysis of a Hybrid MPI / CUDA Implementation of the NAS-LU Benchmark Categories and Subject Descriptors}}
}
@article{Sears2000a,
author = {Sears, Chris B.},
journal = {Atlanta Linux Showcase},
title = {{The elements of cache programming style}},
url = {http://portal.acm.org/citation.cfm?id=1268397},
year = {2000}
}
@article{Bolza,
author = {Bolz, Carl Friedrich and Cuni, Antonio},
file = {::},
journal = {Compute},
title = {{Tracing the Meta-Level: PyPy’s Tracing JIT Compiler}}
}
@phdthesis{Cuni2010,
author = {Cuni, Antonio},
booktitle = {Science},
file = {::},
keywords = {.NET,JIT,pypy,python},
mendeley-tags = {.NET,JIT,pypy,python},
pages = {102},
school = {Universita di Genova},
title = {{High performance implementation of Python for CLI /. NET with JIT compiler generation for dynamic languages}},
year = {2010}
}
@article{Mugridgea,
author = {Mugridge, R.},
file = {::},
journal = {Proceedings of the Agile Development Conference, 2003. ADC 2003},
pages = {47--52},
publisher = {Ieee},
title = {{Test driven development and the scientific method}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1231452}
}
@phdthesis{Cuni2010b,
author = {Cuni, Antonio},
booktitle = {Science},
file = {::},
keywords = {.NET,JIT,pypy,python},
mendeley-tags = {.NET,JIT,pypy,python},
pages = {102},
school = {Universita di Genova},
title = {{High performance implementation of Python for CLI /. NET with JIT compiler generation for dynamic languages}},
year = {2010}
}
@article{Walfield2007,
author = {Walfield, Neal H. and Brinkmann, Marcus},
doi = {10.1145/1278901.1278907},
file = {::},
issn = {01635980},
journal = {ACM SIGOPS Operating Systems Review},
keywords = {GNU,Hurd,Kernel,Microkernel,OS,Operating System,access controls,multi-server,naming,structure},
mendeley-tags = {GNU,Hurd,Kernel,Microkernel,OS,Operating System},
month = jul,
number = {4},
pages = {30},
title = {{A critique of the GNU hurd multi-server operating system}},
url = {http://portal.acm.org/citation.cfm?doid=1278901.1278907},
volume = {41},
year = {2007}
}
@article{Behnel2009a,
author = {Behnel, S and Bradshaw, R and Seljebotn, DS},
file = {::},
journal = {SciPy Conference–Pasadena, CA, August 18-23},
keywords = {cython,numpy,python,scipy},
mendeley-tags = {cython,numpy,python,scipy},
number = {SciPy},
pages = {4--14},
title = {{Cython tutorial}},
url = {http://wstein.org/home/dagss/cython-tutorial-preprint.pdf http://conference.scipy.org/proceedings/SciPy2009/paper\_1/},
year = {2009}
}
@article{Lee2010a,
address = {New York, New York, USA},
author = {Lee, Victor W. and Hammarlund, Per and Singhal, Ronak and Dubey, Pradeep and Kim, Changkyu and Chhugani, Jatin and Deisher, Michael and Kim, Daehyun and Nguyen, Anthony D. and Satish, Nadathur and Smelyanskiy, Mikhail and Chennupaty, Srinivas},
file = {::},
journal = {Proceedings of the 37th annual international symposium on Computer architecture - ISCA '10},
keywords = {GPGPU,cpu architecture,gpu architecture,mance measurement,perfor-,performance analysis,software optimization,throughput comput-},
mendeley-tags = {GPGPU},
pages = {451},
publisher = {ACM Press},
title = {{Debunking the 100X GPU vs. CPU myth}},
url = {http://portal.acm.org/citation.cfm?doid=1815961.1816021},
year = {2010}
}
@article{Wilbers2009a,
author = {Wilbers, IM and Langtangen, HP and \O deg\aa rd, \AA smund},
file = {::},
journal = {Proceedings of MekIT},
keywords = {compiled languages,cython,numerical algorithms,numpy,python,scipy},
mendeley-tags = {cython,numpy,python,scipy},
title = {{Using Cython to Speed up Numerical Python Programs}},
url = {http://www.williamstein.org/home/was/tmp/simula\_pdf\_file.pdf},
year = {2009}
}
@article{Royce1970,
author = {Royce, WW},
file = {::},
journal = {proceedings of IEEE WESCON},
keywords = {History,Methodology,Software Engineering,Waterfall},
mendeley-tags = {History,Methodology,Software Engineering,Waterfall},
number = {August},
pages = {1--9},
title = {{Managing the development of large software systems}},
url = {http://www.pi.informatik.tu-darmstadt.de/fileadmin/user\_upload/Group\_PI/LV\_\_SE\_RE/R\_01\_Wasserfallmodell\_\_Folien\_\_Schwaiger.pdf},
year = {1970}
}
@phdthesis{Li2008a,
author = {Li, P.},
booktitle = {Dissertations available from ProQuest},
file = {::},
school = {University of Pennsylvania},
title = {{Programmable concurrency in a pure and lazy language}},
url = {http://repository.upenn.edu/dissertations/AAI3328611},
year = {2008}
}
@article{Thiruvathukal2008c,
author = {Thiruvathukal, Editors George K and L\"{a}ufer, Konstantin and Messmer, By Peter and Mullowney, Paul J and Granger, Brian E},
file = {::},
journal = {Compare A Journal Of Comparative Education},
keywords = {GPGPU,GPU,Languages},
mendeley-tags = {GPGPU,GPU,Languages},
title = {{GPUlib: GPU Computing in High-Level Languages}},
year = {2008}
}
@article{Royce1970a,
author = {Royce, WW},
file = {::},
journal = {proceedings of IEEE WESCON},
keywords = {History,Methodology,Software Engineering,Waterfall},
mendeley-tags = {History,Methodology,Software Engineering,Waterfall},
number = {August},
pages = {1--9},
title = {{Managing the development of large software systems}},
url = {http://www.pi.informatik.tu-darmstadt.de/fileadmin/user\_upload/Group\_PI/LV\_\_SE\_RE/R\_01\_Wasserfallmodell\_\_Folien\_\_Schwaiger.pdf},
year = {1970}
}
@article{Meisner2003,
author = {Meisner, Eric},
file = {::},
number = {2},
pages = {2--3},
title = {{Naive Bayes Classifier example}},
year = {2003}
}
@article{Wainwright2007,
author = {Wainwright, Martin J. and Jordan, Michael I.},
doi = {10.1561/2200000001},
file = {::},
issn = {1935-8237},
journal = {Foundations and Trends® in Machine Learning},
number = {1–2},
pages = {1--305},
title = {{Graphical Models, Exponential Families, and Variational Inference}},
url = {http://www.nowpublishers.com/product.aspx?product=MAL\&doi=2200000001},
volume = {1},
year = {2007}
}
@article{Jiang,
author = {Jiang, Liangxiao and Zhang, Harry and Cai, Zhihua and Su, Jiang},
file = {::},
journal = {Learning},
keywords = {bayesian,data mining and knowledge,decision trees,discovery,learning algorithms,networks},
pages = {1--12},
title = {{Learning Tree Augmented Naive Bayes for Ranking}}
}
@article{Squire2004,
author = {Squire, David},
file = {::},
pages = {1--8},
title = {{CSE5230 Tutorial : The ID3 Decision Tree Algorithm}},
year = {2004}
}
@article{Zhou2006,
author = {Zhou, Mian and Wei, Hong},
file = {::},
journal = {18th International Conference on Pattern Recognition (ICPR'06)},
number = {1},
pages = {404--407},
publisher = {Ieee},
title = {{Face Verification Using GaborWavelets and AdaBoost}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1698918},
year = {2006}
}
@article{Hongxin2005,
author = {Hongxin, Zhang},
file = {::},
title = {{Boosting: Combining Classifiers}},
year = {2005}
}
@article{Meir2003,
author = {Meir, R. and Ratsch, G.},
file = {::},
journal = {Lecture Notes in Computer Science},
pages = {118--183},
publisher = {Springer},
title = {{An introduction to boosting and leveraging}},
url = {http://www.springerlink.com/index/8574X0TM63NVJBEM.pdf},
volume = {2600},
year = {2003}
}
