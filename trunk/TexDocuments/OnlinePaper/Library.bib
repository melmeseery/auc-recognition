Automatically generated by Mendeley 0.9.8.2
Any changes to this file will be lost if it is regenerated by Mendeley.
@book{MyScript,
year = {2010},
author = { Vision Objects},
title = {MyScript Note Edition },
publisher = {Vision ObjectsÂ© 2010 },
address = {},

}

@inproceedings{Hamdani2009,
author = {Hamdani, Mahdi and Abed, Haikal El and Kherallah, Monji and Alimi, Adel M.},
isbn = {978-1-4244-4500-4},
booktitle = {2009 10th International Conference on Document Analysis and Recognition},
month = {July},
pages = {201--205},

    location = {Barcelona, Spain},
     address ={Barcelona, Spain},
title = {{Combining Multiple HMMs Using On-line and Off-line Features for Off-line Arabic Handwriting Recognition}},
year = {2009}
}
@article{Mezghani3332005,
 author = {Mezghani, N , Mitiche, A. , Cheriet, M.},
 title = {A new representation of shape and its use for high performance in online Arabic character recognition by an associative memory},
 journal = {Int. J. Doc. Anal. Recognit.},
 volume = {7},
 issue = {4},
 month = {September},
 year = {2005},
 issn = {1433-2833},
 pages = {201--210},
 numpages = {10},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {Arabic characters, Histograms, Kohonen memory, Online recognition, Representation},
}
@book{MATLAB,
year = {2009},
author = {MATLAB},
title = {version 7.9 (R2009b)},
publisher = {The MathWorks Inc.},
address = {Natick, Massachusetts}
}

@inproceedings{Pastor2005,
 author = {Pastor, Moises and Toselli, Alejandro and Vidal, Enrique},
 title = {Writing Speed Normalization for On-Line Handwritten Text Recognition},
 booktitle = {Proceedings of the Eighth International Conference on Document Analysis and Recognition},
 series = {ICDAR '05},
 year = {2005},
 isbn = {0-7695-2420-6},
 pages = {1131--1135},
 numpages = {5},
address={Seoul, South Korea},
 acmid = {1107087},


}
@article{Liu2003,
author = {Liu, C},

issn = {00313203},
journal = {Pattern Recognition},
keywords = {art,discriminative learning,feature extraction,handwritten digit recognition,pattern classi\"{y}cation,support,the state of the},
month = oct,
number = {10},
pages = {2271--2285},
title = {{Handwritten digit recognition: benchmarking of state-of-the-art techniques}},
volume = {36},
year = {2003}
}

@article{Liu2009,
author = {Liu, Cheng-Lin and Suen, Ching Y.},
doi = {10.1016/j.patcog.2008.10.007},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {bangla numeral recognition,farsi numeral recognition},
month = dec,
number = {12},
pages = {3287--3295},
title = {{A new benchmark on the recognition of handwritten Bangla and Farsi numeral characters}},

volume = {42},
year = {2009}
}

@inproceedings{Abdelazeem2007,
  editor    = {Dimitris A. Karras and
               Chunping Li and
               Zoran Majkic and
               S. R. Mahadeva Prasanna},
  title     = {International Conference on Artificial Intelligence and
               Pattern Recognition, AIPR-07, Orlando, Florida, USA, July
               9-12, 2007},
  booktitle = {Artificial Intelligence and Pattern Recognition},
  publisher = {ISRST},
  year      = {2007},
  isbn      = {978-0-9727412-3-1},

}


@inproceedings{Abdelazeem2009,
author = {Sherif Abdelazeem},
title = {A Novel Domain-Specific Feature Extraction Scheme for Arabic Handwritten Digits Recognition},
booktitle ={Proceedings of the 2009 International Conference on Machine Learning and Applications  },
 series = {ICMLA '09},

isbn = {978-0-7695-3926-3},
year = {2009},
pages = {247-252},
month={ 13-15 December},
address={Miami Beach, Florida },


}


 @article{Jaeger2001,
  author    = {Stefan J{\"a}ger and
               Stefan Manke and
               J{\"u}rgen Reichert and
               Alex Waibel},
  title     = {Online handwriting recognition: the NPen++ recognizer},
  journal   = {IJDAR},
  volume    = {3},
  number    = {3},
  year      = {2001},
  pages     = {169-180},

}


 @inproceedings{ICDAR2009,
    abstract = {{This paper describes the Online Arabic handwriting recognition competition held at ICDAR 2009. This first competition uses the ADAB-database with Arabic online handwritten words. This year, 3 groups with 7 systems are participating in the competition. The systems were tested on known data (sets 1 to 3) and on one test dataset which is unknown to all participants (set 4). The systems are compared on the most important characteristic of classification systems,the recognition rate. Additionally, the relative speed of the different systems were compared. A short description of the participating groups, their systems, the experimental setup, and the performed results are presented.}},
     author={Abed, Haikal El and Margner, Volker and Kherallah, Monji and Alimi, Adel M},
    keywords = {arabic, competition, ifn-enit-db, ocr, post-lr, scripts},
    location = {Barcelona, Spain},
     address ={Barcelona, Spain},
    pages = {1383--1387},
    priority = {2},
    month={July},
    title = {{ICDAR 2009 Arabic Handwriting Recognition Competition}},
    booktitle={2009 10th International Conference on Document Analysis and Recognition},
    year = {2009}
}

@INPROCEEDINGS{Mezghani2002,
author={Mezghani, N. and Mitiche, A. and Cheriet, M.},
booktitle={ Proceedings of the Eighth International Workshop on Frontiers in Handwriting Recognition, 2002.},
 title={On-line recognition of handwritten Arabic characters using a Kohonen neural network},
year={2002},
month={6-8 Aug},
volume={},
number={},
address={Ontario, Canada},
pages={ 490 - 495},
abstract={ Neural networks have been applied to various pattern classification and recognition problems for their learning ability, discrimination power and generalization ability The neural network most referenced in the pattern recognition literature are the multi-layer perceptron, the Kohonen associative memory and the Capenter-Grossberg ART network. The Kohonen memory runs an unsupervised clustering algorithm. It is easily trained and has attractive properties such as topological ordering and good generalization. In this study an on-line system for the recognition of handwriting Arabic characters using a Kohonen network is investigated. The input of the neural network is a feature vector of elliptic Fourier coefficients extracted from the handwritten dynamic representation. Experimental results show that the network successfully recognizes both clearly and roughly written characters with good performance.},
keywords={ Capenter-Grossberg ART network; Kohonen associative memory; Kohonen neural network; discrimination power; elliptic Fourier coefficients; feature vector; generalization; generalization ability; handwritten Arabic characters; handwritten dynamic representation; learning ability; multilayer perceptron; online recognition; pattern classification; pattern recognition; topological ordering; unsupervised clustering algorithm; ART neural nets; generalisation (artificial intelligence); handwritten character recognition; learning (artificial intelligence); multilayer perceptrons; online operation; pattern classification; self-organising feature maps;},

ISSN={ },}

@article{Chakraborty2002,
 author = {Chakraborty, Basabi and Chakraborty, Goutam},
 title = {A new feature extraction technique for on-line recognition of handwritten alphanumeric characters},
 journal = {Inf. Sci. Appl.},
 volume = {148},
 issue = {1-4},
 month = {December},
 year = {2002},
 pages = {55--70},
 numpages = {16},
 publisher = {Elsevier Science Inc.},
 address = {New York, NY, USA},
 keywords = {artificial neural network, feature extraction, handwritten character recognition, on-line recognition, quickprop learning algorithm},
}

@inproceedings{Vinciarelli2003,
 author = {Vinciarelli, Alessandro and Perrone, Michael},
 title = {Combining Online and Offline Handwriting Recognition},
 booktitle = {Proceedings of the Seventh International Conference on Document Analysis and Recognition - Volume 2},
 series = {ICDAR '03},
 year = {2003},
 isbn = {0-7695-1960-1},
 pages = {844--},
 acmid = {939568},
 publisher = {IEEE Computer Society},
 address = { },
}


@article{Kherallah2008,
 author = {Kherallah, Monji and Haddad, Lobna and Alimi, Adel M. and Mitiche, Amar},
 title = {On-line handwritten digit recognition based on trajectory and velocity modeling},
 journal = {Pattern Recognition Letters},
 volume = {29},
 issue = {5},
 month = {April},
 year = {2008},
 issn = {0167-8655},
 pages = {580--594},
 numpages = {15},
 publisher = {Elsevier Science Inc.},
 address = {New York, NY, USA},
 keywords = {Beta velocity modeling, Digit recognition, Elliptic trajectory modeling, Handwriting modeling, Stroke overlapping},
}

@inproceedings{DSMadasu2005b,
author = {Madasu, V and Lovell, B C},
booktitle = {Digital Image Computing: Technqiues and Applications, 2005. DICTA ' 05. Proceedings},
doi = {10.1109/DICTA.2005.1578131},
file = {:D$\backslash$:/Papers/Documents/2005/Madasu, Lovell - 2005(2).pdf:pdf},
pages = {223--228},
title = {{Automatic Segmentation and Recognition of Bank Cheque Fields}},
year = {2005}
}
@article{Oh1995,
abstract = {Viewing a handwritten word as an alternating sequence of characters and ligatures, we proposed a circularly interconnected network of hidden Markov models to model handwritten English words of indefinite length. The recognition problem is then regarded as finding the most probable path in the network for a given input. For the search, Viterbi algorithm is applied with lexicon lookup. To overcome directional sensitivity of the path search, a back-tracking technique is employed that keeps plausible path candidates dynamically within limited storage space.},
author = {Oh, Se-chang and HA, Jin Young and Kim, Jin-H},
file = {:D$\backslash$:/Papers/Documents/1995/Oh, HA, Kim - 1995.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Lexicon lookup,Network search,Unconstrained handwriting recognition,back tracking,hidden markov model,ligature model},
number = {11},
pages = {163--1704},
title = {{Pergamon CONTEXT Depended Search in interconnected Hidden markov Model for unconstrained handwriting recognition.}},
volume = {28},
year = {1995}
}
@inproceedings{Zhang2009b,
author = {Zhang, Yang and Shi, Guangshun and Yang, Jufeng},
booktitle = {Document Analysis and Recognition, 2009. ICDAR'09. 10th International Conference on},
doi = {10.1109/ICDAR.2009.99},
file = {:D$\backslash$:/Papers/Documents/2009/Zhang, Shi, Yang - 2009.pdf:pdf},
issn = {1520-5363},
pages = {1255--1259},
publisher = {IEEE},
title = {{HMM-Based Online Recognition of Handwritten Chemical Symbols}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5277669},
year = {2009}
}
@inproceedings{Huang2004,
author = {Huang, Xiangsheng and Li, S.Z. and Wang, Yangsheng},
booktitle = {Conference on Computer Vision and Pattern Recognition Workshop, 2004. CVPRW'04},
file = {:D$\backslash$:/Papers/Documents/2004/Huang, Li, Wang - 2004.pdf:pdf},
pages = {66--66},
title = {{Learning with cascade for classification of non-convex manifolds}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1384859},
year = {2004}
}
@article{Amara2003,
author = {Amara, Najoua Essoukri Ben},
doi = {10.1007/s10032-002-0092-6},
file = {:D$\backslash$:/Papers/Documents/2003/Amara - 2003.pdf:pdf},
journal = {International Journal on Document Analysis and Recognition},
keywords = {Reference From Doctor,arabic optical character,arabic writing,hybrid features,multiple classifiers,recognition-aocr},
mendeley-tags = {Reference From Doctor},
month = jul,
number = {4},
pages = {195--212},
title = {{Classification of Arabic script using multiple sources of information: State of the art and perspectives}},
volume = {5},
year = {2003}
}
@article{DSFarah2006,
abstract = {Automatic handwriting recognition has a variety of applications in
real world problems, such as mail sorting and check processing. Recently,
it has been demonstrated that combining the decisions of several
classifiers and integrating multiple information sources can lead
to better recognition results. This article presents an approach
for recognizing handwritten Arabic literal (legal) amounts. The proposed
system uses a set of holistic structural features to describe the
words. These features are presented to three classifiers: multilayer
neural network, k nearest neighbor, and fuzzy k nearest neighbor.
The classification results are then combined using several schemes;
we retained the score summation one for this work. A syntactic post-classification
process is then carried out to find the best match among the candidate
words. The performance of this approach is superior to the system
which ignores all contextual information and simply relies on the
recognition scores of the recognizers.},
author = {Farah, Nadir and Souici, Labiba and Sellami, Mokhtar},
doi = {DOI: 10.1016/j.engappai.2005.05.005},
file = {:D$\backslash$:/Papers/Documents/2006/Farah, Souici, Sellami - 2006.pdf:pdf},
issn = {0952-1976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {Arabic word recognition},
number = {1},
pages = {29--39},
title = {{Classifiers combination and syntax analysis for Arabic literal amount recognition}},
url = {http://www.sciencedirect.com/science/article/B6V2M-4GHBP7C-1/2/bc87267a3a3a694e878d339e250b5e34},
volume = {19},
year = {2006}
}
@conference{ARMaddouri2008,
abstract = {Baseline extraction is hailed as an important step in handwriting
primitive extraction process, seen the insights it proffers into
the position and the length of the word. It further facilitates feature
extraction. As regards Arabic words, tow baselines can be extracted:
an upper baseline and a lower one. These tow lines divide the word
into three parts, namely, Ascender and upper diacritic points above
the upper baseline, Descender and lower diacritic points under the
lower baseline. The main content of the word lies between the two
baselines, it generally involves loops. In this paper we start with
a presentation of six baseline extraction methods. These methods
are developed and evaluated with reference to IFN/ENIT-database .
Some of them are combined in order to improve baseline position.
A comparison between these methods is made on the basis of the IFN/ENIT-database.
Results on the set a of IFN/ENIT-database evince that the Skeletonbased
method and the Min-Max \& Primitives achieve very promising results
reaching about 77\% of good results and about 87\% of acceptable results},
author = {Maddouri, Samia Snoussi and Samoud, Fadoua Bouafif and Bouriel, Kaouthar and Ellouze, Noureddine and Abed, Haikal El},
booktitle = {The 11th International Conference on Frontiers in Handwriting Recognition},
file = {:D$\backslash$:/Papers/Documents/2008/Maddouri et al. - 2008.pdf:pdf},
keywords = { Entropy, Hough transform., Skeleton, projection,Baseline},
title = {{Baseline Extraction: Comparison of Six Methods on IFN/ENIT Database}},
year = {2008}
}
@inproceedings{PDBAthitsos2005,
abstract = {This paper proposes a method for efficient nearest neighbor classification
in non-Euclidean spaces with computationally expensive similarity/distance
measures. Efficient approximations of such measures are obtained
using the BoostMap algorithm, which produces embeddings into a real
vector space. A modification to the BoostMap algorithm is proposed,
which uses an optimization cost that is more appropriate when our
goal is classification accuracy as opposed to nearest neighbor retrieval
accuracy. Using the modified algorithm, multiple approximate nearest
neighbor classifiers are obtained, that provide a wide range of trade-offs
between accuracy and efficiency. The approximations are automatically
combined to form a cascade classifier, which applies the slower and
more accurate approximations only to the hardest cases. The proposed
method is experimentally evaluated in the domain of handwritten digit
recognition using shape context matching. Results on theMNIST database
indicate that a speed-up of two to three orders of magnitude is gained
over brute force search, with minimal losses in classification accuracy.},
address = {San Diego, CA, USA},
author = {Athitsos, Vassilis and Alon, Jonathan and Sclaroff, Stan},
booktitle = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2005)},
doi = {http://dx.doi.org/10.1109/CVPR.2005.141},
file = {:D$\backslash$:/Papers/Documents/2005/Athitsos, Alon, Sclaroff - 2005.pdf:pdf},
isbn = {0-7695-2372-2},
keywords = { Classifier Cascade,MNIST},
pages = {486--493},
publisher = {IEEE Computer Society},
title = {{Efficient Nearest Neighbor Classification Using a Cascade of Approximate Similarity Measures.}},
year = {2005}
}
@article{Gorbe2009,
author = {Gorbe, M.J.C.S.E.J. and Zamora, F. and Prat, D.L.A.M.F. and Vilar, JM},
doi = {10.1109/ICDAR.2009.209},
file = {:D$\backslash$:/Papers/Documents/2009/Gorbe et al. - 2009.pdf:pdf},
journal = {cafre.dsic.upv.es},
pages = {1260--1264},
title = {{Improving a DTW-based recognition engine for on-line handwritten characters by using MLPs}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Improving+a+DTW-based+Recognition+Engine+for+On-line+Handwritten+Characters+by+Using+MLPs\#0},
year = {2009}
}
@article{Markowska-Kaczmar2005,
author = {Markowska-Kaczmar, U. and Kubacki, P.},
file = {:D$\backslash$:/Papers/Documents/2005/Markowska-Kaczmar, Kubacki - 2005.pdf:pdf},
journal = {Design},
publisher = {IEEE Computer Society},
title = {{Support vector machines in handwritten digits classification}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ISDA.2005.87},
year = {2005}
}
@conference{ARElAbed2009,
abstract = {The recognition of handwritten characters, words, and text arouses
great interest today. To develop the best working system is subject
of many papers published. With this paper, methods to improve the
performance of existing word recognition systems are discussed. The
availability of a sufficient data sets for training and testing the
system assumed, optimization algorithms are presented. The usage
of different feature sets and the combination of different recognizers
are proposed. Tests with Arabic handwriting recognition systems using
the reference IfN/ENIT-database show the usefulness of the proposed
methods. An improvement of the recognition rate of up to 28\% of the
best single system is achieved.},
author = {Abed, Haikal El and Margner, Volker},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Abed, Margner - 2009.pdf:pdf},
title = {{How to Improve a Handwriting Recognition System}},
year = {2009}
}
@article{Blumenstein2007,
abstract = {This paper describes and analyses the performance of a novel feature extraction technique for the recognition of segmented/cursive characters that may be used in the context of a segmentation-based handwritten word recognition system. The Modified Direction Feature (MDF) extraction technique builds upon the Direction Feature (DF) technique proposed previously that extracts direction information from the structure of character contours. This principal was extended so that the direction information is integrated with a technique for detecting transitions between background and foreground pixels in the character image. In order to improve on the DF extraction technique, a number of modifications were undertaken. With a view to describe the character contour more effectively, a re-design of the direction number determination technique was performed. Also, an additional global feature was introduced to improve the recognition accuracy for those characters that were most frequently confused with patterns of similar appearance. MDF was tested using a neural network-based classifier and compared to the DF and Transition Feature (TF) extraction techniques. MDF outperformed both DF and TF techniques using a benchmark dataset and compared favourably with the top results in the literature. A recognition accuracy of above 89\% is reported on characters from the CEDAR dataset.},
author = {Blumenstein, M and Liu, X Y},
file = {:D$\backslash$:/Papers/Documents/2007/Blumenstein, Liu - 2007.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Handwritten Character Recognition,Image Processing and Computer Vision,Neural Networks.,Pattern Recognition,Reference From Doctor},
mendeley-tags = {Reference From Doctor},
number = {2},
pages = {376--388},
title = {{An Investigation of the Modified Direction Feature for Cursive Character Recognition An Investigation of the Modified Direction Feature for Cursive Character Recognition}},
volume = {40},
year = {2007}
}
@article{DSAlMuhtaseb2009,
abstract = {This paper presents a minimal Arabic text that covers

the different basic shapes of Arabic alphabet (viz. standalone, initial,

medial, and terminal). It is designed with minimal repetition of

character shapes in the minimal text. The novelty of the suggested

script could be seen from different perspectives. It enables the

collection of handwritten text from different writers with minimized

effort and time. It is enough for a writer to write three lines of

meaningful Arabic text to cover all possible character shapes, a total

of 125 shapes. The written text is designed to have even distribution

of letter frequencies. This assures enough samples of all character

shapes when text is collected from enough number of writers. The

same is true for printed Arabic text. This is especially useful when

using large number of features with classifiers that require large

number of samples for each category. Hidden Markov Models and

Neural networks are two examples of these classifiers. The use of
the

minimal text enables proper training, as all Arabic character shapes

are present with adequate frequency, hence resulting in higher

recognition rates. This is not the case with natural text where the

frequency of some Arabic characters differ widely, where in some

cases 100 folds or more. The proposed minimal text may be used to

build a data base of handwritten Arabic text collected of many

writers. This covers the need for a database in the research of Arabic

handwritten text recognition and benchmarking.

In addition, this paper presents statistical analysis of Arabic

corpora for estimating the number of occurrences of the different

shapes of Arabic characters in large corpora. The frequency of Arabic

characters could be used in different applications. In this research

work, it was utilized in enhancing the search for the minimal Arabic

text.},
author = {Al-Muhtaseb, Husni A and Mahmoud, Sabri A and Qahwahi, Rami S},
file = {:D$\backslash$:/Papers/Documents/2009/Al-Muhtaseb, Mahmoud, Qahwahi - 2009.pdf:pdf},
journal = {INTERNATIONAL JOURNAL OF CIRCUITS, SYSTEMS AND SIGNAL PROCESSING},
keywords = { Arabic OCR databases, Minimal Arabic script.,Arabic text recognition},
number = {3},
pages = {142--153},
title = {{A Novel Minimal Script for Arabic Text Recognition Databases and Benchmarks}},
volume = {3},
year = {2009}
}
@article{MCZhang2006,
abstract = {In this paper, we propose a novel local steerable phase (LSP) feature
extracted from the face image using steerable filters for face recognition.
The new type of local feature is semi-invariant under common image
deformations and distinctive enough to provide useful identity information.
Phase information provided by steerable filters is locally stable
with respect to scale changes, noise and brightness changes. Phase
features from multiple scales and orientations are concatenated to
an augmented feature vector which is used to evaluate similarity
between face images. We use a nearest-neighbor classifier based on
the local weighted phase-correlation for final classification. The
experimental results on FERET dataset show an encouraging recognition
performance.},
author = {Zhang, Xiaoxun and Jia, Yunde},
file = {:D$\backslash$:/Papers/Documents/2006/Zhang, Jia - 2006.pdf:pdf},
journal = {Pattern Recognition Letters},
keywords = {Steerable filters; Phase feature; Face recognition},
pages = {1927Ã¯Â¿Â½1933},
title = {{Face recognition with local steerable phase feature}},
volume = {27},
year = {2006}
}
@article{Lorigo2006,
abstract = {The automatic recognition of text on scanned images has enabled many applications such as searching for words in large volumes of documents, automatic sorting of postal mail, and convenient editing of previously printed documents. The domain of handwriting in the Arabic script presents unique technical challenges and has been addressed more recently than other domains. Many different methods have been proposed and applied to various types of images. This paper provides a comprehensive review of these methods. It is the first survey to focus on Arabic handwriting recognition and the first Arabic character recognition survey to provide recognition rates and descriptions of test data for the approaches discussed. It includes background on the field, discussion of the methods, and future research directions.},
author = {Lorigo, Liana M and Govindaraju, Venu},
doi = {10.1109/TPAMI.2006.102},
file = {:D$\backslash$:/Papers/Documents/2006/Lorigo, Govindaraju - 2006.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Arabs,Artificial Intelligence,Documentation,Documentation: methods,Handwriting,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Models, Statistical,Online Systems,Pattern Recognition, Automated,Pattern Recognition, Automated: methods},
month = may,
number = {5},
pages = {712--24},
pmid = {16640258},
title = {{Offline Arabic handwriting recognition: a survey.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16640258},
volume = {28},
year = {2006}
}
@article{Khorsheed2002,
abstract = {Off-line recognition requires transferring the text under consideration into an image file. This represents the only available solution to bring the printed materials to the electronic media. However, the transferring process causes the system to lose the temporal information of that text. Other complexities that an off-line recognition system has to deal with are the lower resolution of the document and the poor binarisation, which can contribute to readability when essential features of the characters are deleted or obscured. Recognising Arabic script presents two additional challenges: orthography is cursive and letter shape is context sensitive. Certain character combinations form new ligature shapes, which are often font-dependent. Some ligatures involve vertical stacking of characters. Since not all letters connect, word boundary location becomes an interesting problem, as spacing may separate not only words, but also certain characters within a word. Various techniques have been implemented to achieve high recognition rates. These techniques have tackled different aspects of the recognition system. This review is organised into five major sections, covering a general overview, Arabic writing characteristics, Arabic text recognition system, Arabic OCR software and conclusions.},
author = {Khorsheed, M. S.},
doi = {10.1007/s100440200004},
file = {:D$\backslash$:/Papers/Documents/2002/Khorsheed - 2002.pdf:pdf},
issn = {1433-7541},
journal = {Pattern Analysis \& Applications},
keywords = {Reference From Doctor,arabic ocr,feature extraction,fourier transform,hidden markov models,horizontal projection,hough transform,networks,neural,off-line recognition,preprocessing segmentation,vertical projection},
mendeley-tags = {Reference From Doctor},
month = may,
number = {1},
pages = {31--45},
title = {{Off-Line Arabic Character Recognition - A Review}},
url = {http://www.springerlink.com/openurl.asp?genre=article\&id=doi:10.1007/s100440200004},
volume = {5},
year = {2002}
}
@inproceedings{DSXu2003,
abstract = {This paper describes a system being developed to recognize date information
handwritten on Canadian bank cheques. A segmentation based strategy
is adopted in this system. In order to achieve high performances
in terms of efficiency and reliability, a knowledge-based module
is proposed for the date segmentation and a cursive month word recognition
module is implemented based on a combination of classifiers. The
interaction between the segmentation and recognition stages is properly
established by using multihypotheses generation and evaluation modules.
As a result, promising performance is obtained on a test set from
a real life standard cheque database},
annote = {Edited in 2 march 2010},
author = {Xu, Qizhi and Lam, Louisa and Suen, C Y},
booktitle = {Document Analysis and Recognition, 2003. Proceedings. Seventh International Conference on},
file = {:D$\backslash$:/Papers/Documents/2003/Xu, Lam, Suen - 2003.pdf:pdf},
pages = {704--708},
title = {{Automatic segmentation and recognition system for handwritten dates on Canadian bank cheques}},
year = {2003}
}
@inproceedings{Nishimura2002,
abstract = {The purpose of our research is to improve the recogni- tion rate of off-line character recognition systems using the HMM (Hidden Markov Model) without increasing a num- ber of HMM parameters too much. Some 2-dimensional HMM character recognition systems have been proposed to increase representational power. However, since 2Ã¢â¬âD HMM has much more complex structure and thus requires much more parameters than 1-dimensional HMM, it be- comes very hard to gather sufficient samples in order to guarantee the successful generalization. To overcome the problem, we propose amethod for character recognition us- ing 1Ã¢â¬âD HMMs in multiple directions with 2-dimensional feature extraction. To further improve the performance, some voting method useing bagging algorithmare also ex- ploited. In our experiment, the recognition rate is increased by about 1\% with the multiple directional HMM charac- ter recognition system compared to the 1Ã¢â¬âD HMMcharac- ter recognition system. The recognition rate is further in- creased by about 1\% with the HMM character recognition system using bagging algorithm.},
author = {Nishimura, Hiromitsu and Kobayashi, Makoto and Maruyama, Minoru and Nakano, Yasuaki},
booktitle = {Document Analysis and Recognition, 1999. ICDAR'99. Proceedings of the Fifth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2002/Nishimura et al. - 2002.pdf:pdf},
isbn = {0769503187},
pages = {49--52},
publisher = {IEEE},
title = {{Off-line character recognition using HMM by multiple directional feature extraction and voting with bagging algorithm}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=791722},
year = {2002}
}
@inproceedings{Han2007,
abstract = {This paper presents a systematic multi-path HMM topology design algorithm to better model online handwriting of East Asian characters. This data-driven algorithm solves three key problems in HMM topology design. First, HMM path number determination is formalized as a clustering problem using Subsequence Direction Histogram Vector (SDHV) as feature of both writing order and style. Second, Curvature Scale Space-based (CSS-based) substroke segmentation is used to calculate the optimal state number and initial state parameters. Third, Self-rotation restricted corner state and imaginary stroke state are designed to determine state connectivity and Gaussian mixture number in order to achieve better state alignment. Experiments on large character sets demonstrate both a significant relative error reduction rate and high recognition accuracy using the proposed algorithm.},
author = {Han, Shi and Chang, Ming and Zou, Yu and Chen, Xinjian and Zhang, Dongmei},
booktitle = {Document Analysis and Recognition, 2007. ICDAR 2007. Ninth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2007/Han et al. - 2007.pdf:pdf},
issn = {1520-5363},
pages = {604--608},
publisher = {IEEE},
title = {{Systematic Multi-Path HMM Topology Design for Online Handwriting Recognition of East Asian Characters}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4376986},
volume = {2},
year = {2007}
}
@inproceedings{ARBroumandnia2007,
abstract = {This paper presents a novel holistic Handwritten Farsi /Arabic Word
Recognition scheme in situation where we face with word rotation
and scale change. Image words features are extracted by exploiting
rotation and scale invariance characteristics of M-Band packet wavelet
transform performed on polar transform version of images of handwritten
Farsi/Arabic words. The extracted features construct a feature vector
for each word image. This vector is employed in recognition phase
by finding the similar words based on the least Mahalanobis distance
of feature vectors. This scheme is robust against rotation and scaling.
Experimental results, obtained from testing different handwritten
texts with various orientations and scales, show that proposed scheme
outperforms Fourier-wavelet and Zernike moments algorithms. The robustness
of new scheme has been tested with images corrupted by Gaussian noise
and compared with similar schemes. Experimental results show that
the accuracy of our algorithm reaches 95.8 percents.},
author = {Broumandnia, A and Shanbehzadeh, J and Nourani, M},
booktitle = {AICCSA '07. IEEE/ACS International Conference on Computer Systems and Applications, 2007.},
file = {:D$\backslash$:/Papers/Documents/2007/Broumandnia, Shanbehzadeh, Nourani - 2007.pdf:pdf},
keywords = { Farsi/Arabic Handwritings Recognition, Wavelet Transform,Pattern Recognition},
publisher = {IEEE},
title = {{Handwritten Farsi/Arabic Word Recognition}},
year = {2007}
}
@article{Dehghan2001,
abstract = {{A holistic system for the recognition of handwritten Farsi/Arabic words using right\}left discrete hidden Markov models (HMM)and Kohonen self-organizing vector quantization is presented. The histogram of chain-code directions of the image strips, scanned from right to left by a sliding window, is used as feature vectors. The neighborhood information preserved in the self-organizing feature map (SOFM), is used for smoothing the observation probability distributions of trained HMMs. Experiments carried out on test samples show promising performance results. Ã®â¬Â¨ 2001 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved},
author = {Dehghan, M},
doi = {10.1016/S0031-3203(00)00051-0},
file = {:D$\backslash$:/Papers/Documents/2001/Dehghan - 2001.pdf:pdf},
journal = {Pattern Recognition},
keywords = {arabic,farsi,handwriting recognition,handwritten word recognition,hidden markov model,parameter smoothing,self-organizing feature map},
month = may,
number = {5},
pages = {1057--1065},
title = {{Handwritten Farsi (Arabic) word recognition: a holistic approach using discrete HMM}},
volume = {34},
year = {2001}
}
@incollection{ARBelaid2008,
abstract = {This paper summarizes techniques proposed for off-line Arabic word recognition. This point of view concerns the human reading favoring an interactive mechanism between global memorization and local verification sim- plifying the recognition of complex scripts such as Arabic. According to this consideration, specific papers are analyzed with comments on strategies.},
author = {Belaid, Abdel and Choisy, Christophe},
booktitle = {SACH},
file = {:D$\backslash$:/Papers/Documents/2008/Belaid, Choisy - 2008.pdf:pdf},
keywords = {Read},
mendeley-tags = {Read},
pages = {36Ã¯Â¿Â½56},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Human Reading Based Strategies for Off-Line Arabic Word Recognition}},
year = {2008}
}
@article{FE9Shi2002,
abstract = {In this paper, the authors study on the use ofgradient and curvature
ofthe gray scale character image to improve the accuracy ofhandwritten
numeral recognition. Three procedures, based on curvature coe2cient,
bi-quadratic interpolation and gradient vector interpolation, are
proposed for calculating the curvature ofthe equi-gray scale curves
ofan input image. Then two procedures to compose a feature vector
ofthe gradient and the curvature are described. The e2ciency ofthe
feature vectors are tested by recognition experiments for the handwritten
numeral database IPTP CDROM1 and NIST SD3 and SD7. The experimental
results show the usefulness of the curvature feature and recognition
rate of 99.49\% and 98.25\%, which are one ofthe highest rates ever
reported for these databases (H. Kato et al., Technical Report ofIEICE,
PRU95-3, 1995, p. 17; R.A. Wilkinson et al., Technical Report NISTIR
4912, August 1992; J. Geist et al., Technical Report NISTIR 5452,
June 1994), are achieved, respectively},
author = {Shi, Meng and Fujisawa, Yoshiharu and Wakabayashi, Tetsushi and Kimura, Fumitaka},
doi = {http://dx.doi.org/10.1016/S0031-3203(01)00203-5},
file = {:D$\backslash$:/Papers/Documents/2002/Shi et al. - 2002.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Handwritten digits},
number = {10},
pages = {2051--2059},
title = {{Handwritten numeral recognition using gradient and curvature of gray scale image.}},
volume = {35},
year = {2002}
}
@article{Alma'adeed2002,
abstract = {Hidden Markov Models (HMM) have been used with some success in recognizing printed Arabic words. In this paper, a complete scheme for torallj, unconstrained Arabic handwritten word recognition based on a Model discriminant HMM is presented. A complere svstem able to classiJj Arabic-Handwritten words of one hundred different writers is proposed and discussed. The system first attempts to remove some of variation in the images that do nor affect the identity of the handwritten word. Next, the system codes the skeleton and edge of rhe word so that feature i!rformation about the lines in the skeleton is extracted. Then a classification process based on the HMM approach is used. The output is a word in the dicrionary A detaiedl experimenr is carried out and successful recognition results are reported},
author = {Alma'adeed, S. and Higgens, C. and Elliman, D.},
doi = {10.1109/ICPR.2002.1047981},
file = {:D$\backslash$:/Papers/Documents/2002/Alma'adeed, Higgens, Elliman - 2002.pdf:pdf},
isbn = {0-7695-1695-X},
journal = {Object recognition supported by user interaction for service robots},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {481--484},
publisher = {IEEE Comput. Soc},
title = {{Recognition of off-line handwritten Arabic words using hidden Markov model approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1047981},
year = {2002}
}
@article{DueTrier1996,
abstract = {-This paper presents an overview of feature extraction methods for off-line recognition of segmented (isolated) characters. Selection of a feature extraction method is probably the single most important factor in achieving high recognition performance in character recognition systems. Different feature extraction methods are designed for different representations 6f the characters, such as solid binary characters, character contours, skeletons (thinned characters) or gray-level subimages of each individual character. The feature extraction methods are discussed in terms of invariance properties, reconstructability and expected distortions and variability of the characters. The problem of choosing the appropriate feature extraction method for a given application is also discussed. When a few promising feature extraction methods have been identified, they need to be evaluated experimentally to find the best method for the given application.},
author = {{Due Trier}, Oivind R. and Jain, Anil.K. and Taxt, Torfinn.},
file = {:D$\backslash$:/Papers/Documents/1996/Due Trier, Jain, Taxt - 1996.pdf:pdf},
journal = {Pattern recognition},
keywords = {Character representation Invariance,Feature extraction,Optical character recognition,Reconstructability},
number = {4},
pages = {641--662},
publisher = {Elsevier},
title = {{Feature extraction methods for character recognition-a survey}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0031320395001182},
volume = {29},
year = {1996}
}
@article{Burrow2004,
author = {Burrow, Peter},
file = {:D$\backslash$:/Papers/Documents/2004/Burrow - 2004.pdf:pdf},
journal = {Report of Master of Science School of Informatics, University of Edinburgh},
publisher = {Citeseer},
title = {{Arabic handwriting recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.404\&amp;rep=rep1\&amp;type=pdf},
year = {2004}
}
@article{Graves2009,
abstract = {Recognizing lines of unconstrained handwritten text is a challenging task. The difficulty of segmenting cursive or overlapping characters; and analyze its use of context. Last; combined with the need to exploit surrounding context; despite their well-known shortcomings. This paper proposes an alternative approach based on a novel type of recurrent neural network; has led to low recognition rates for even the best current recognizers. Most recent progress in the field has been made either through improved preprocessing or through advances in language modeling. Relatively little work has been done on the basic recognition algorithms. Indeed; measure the individual influence of its hidden layers; most systems rely on the same hidden Markov models that have been used for decades in speech and handwriting recognition; our approach achieves word recognition accuracies of 79.7 percent on online data and 74.1 percent on offline data; significantly outperforming a state-of-the-art HMM-based system. In addition; specifically designed for sequence labeling tasks where the data is hard to segment and contains long-range bidirectional interdependencies. In experiments on two large unconstrained handwriting databases; suggesting reasons for the networkÃ¢â¬â¢s superior performance.; we demonstrate the networkÃ¢â¬â¢s robustness to lexicon size; we provide an in-depth discussion of the differences between the network and HMMs},
author = {Graves, Alex and Liwicki, Marcus and Fern\'{a}ndez, S. and Bertolami, Roman and Bunke, Horst and Schmidhuber, J.},
file = {:D$\backslash$:/Papers/Documents/2008/Graves et al. - 2008.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {HMM,Handwriting recognition,bidirectional long short-term memory,connectionist temporal classification,hidden Markov model.,offline handwriting,online handwriting,recurrent neural networks},
mendeley-tags = {HMM},
number = {5},
pages = {855--868},
publisher = {Published by the IEEE Computer Society},
title = {{A novel connectionist system for unconstrained handwriting recognition}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/TPAMI.2008.137},
volume = {31},
year = {2008}
}
@article{Mahmoud2008,
abstract = {This paper describes a technique for the recognition of optical off-line handwritten Arabic (Indian) numerals using hidden Markov models (HMM). The success of HMM in speech recognition encouraged researchers to apply it to text recognition. In this work we did not follow the general trend of using sliding windows in the direction of the writing line to generate features. Instead we generated features based on the digit as a unit. Angle-, distance-, horizontal-, and vertical-span features are extracted from Arabic (Indian) numerals and used in training and testing the HMM. These features proved to be simple and effective. In addition to the HMM the nearest neighbor classifier is used. The results of both classifiers are then compared. Several experiments were conducted for estimating the suitable number of states for the HMM. The best results were achieved with an HMM model with 10 states. In addition, we experimented with different number of features. The best results were achieved with 120 feature vector representing a digit. A database of 44 writers, each writer wrote 48 samples of each digit resulting in a database of 21,120 samples. The data were size normalized to enable the technique to be size invariant. In extracting the features the center of gravity of the digit is used to make the technique translation invariant. The randomization technique was used to generate Arabic (Indian) numbers for training and testing the HMM classifier. The randomization was done on the number of digits per number and on the digit sequence. About 2171 Arabic (Indian) numbers were generated, totaling 21,120 digits. 1700 numbers (totaling 16,657 digits) were used in training the HMM and 471 numbers (totaling 4463 digits) are used in testing the HMM. The samples of the first 24 writers were used in training the nearest neighbor classifier and the remaining 20 writers' samples were used in testing. The achieved average recognition rates are 97.99\% and 94.35\% using the HMM and the nearest neighbor classifiers, respectively. The classification errors were analyzed and it was clear that some errors may be attributed to bad data, some to deformation and unbalanced proportion of digit segments, different writing styles of some digits, errors between digit pairs were specified and analyzed, and genuine errors. It was clear that the real misclassification of genuine data, in the case of HMM was nearly 1\%. This proves the effectiveness of the presented technique to writer-independent off-line Arabic (Indian) handwritten digit recognition. The technique is writer independent as separate writers' data were used in training of the classifiers and other writers' data were used in the testing phase.},
annote = {=================================  Review Template ===========================================

Paper Index : Mahmoud2008

Date:15 - Nov- 2010



Why read paper ?

HMM background - digit recognition.



Paper overview?



offline diigts
no sliding windows, counting pixels for featrues.



What is these paper about ? (Summary)



1) features extraction using
a) angular span
which draw lines to dsegment digit from center of gravity of digt to cover every alpha then count number of pixel in slice/ no. of pixel in digit. (pixel density)
b) distance
draw concentric circles from center of gravity then compute density in each circle
c) horizontal and vertical
divide the cdigit into 20- vertical and horizontal strip then compute density in each strip.
2) HMM traing by giving 20 features in sequence to get 120 obersvation fo 10 features for each digit. Each digit have his HMM model and each has 5 state model.
3) a comparison with KNN and HMM
To test the numerical string a randomizied order is generated from a images in the dataset.


the data is collected from 44 writer X 48 tiems with result in 21000 sampels


different feature vector lenght is test but best is 120 features.
best result with HMM with 10 state for each digit is 98.8 \%
Knn result is 94.35\%

1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?

Simple features are only counting black pixels.

2. What can we take from this work  ? what do we learn ? What can be incorporated into our own work ?

 The division of features into sequence of vectors for each digits, HMM model of training and building for each digit.

3. What are the problems of the paper ?






4. what is lacking from the work ? why does this work knot be the final  research in this subject ?

Improvement on recognition rate can be done if using more robosut features.



5. what about the methods causes this lack ? is there a fundamental reason ?




6. Could incremental Changes Fix this lack ? if so, what changes ?

Some more robosut features.


Is there is any question you had about the paper ?





The final conclusion..........



Good paper can use the features and method to present feature vector to hmm.


==========================================================================},
author = {Mahmoud, Sabri},
file = {:D$\backslash$:/Papers/Documents/2008/Mahmoud - 2008.pdf:pdf},
issn = {0165-1684},
journal = {Signal Processing},
keywords = {Arabic (Indian) numeral recognition,Arabic Handwritting recognition,HMM,Handwritten digit recognition,Independent writer recognition,Normalization,OCR,Read,Summarized},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
number = {4},
pages = {844--857},
title = {{Recognition of writer-independent off-line handwritten Arabic (Indian) numerals using hidden Markov models}},
url = {http://portal.acm.org/citation.cfm?id=1330786},
volume = {88},
year = {2008}
}
@inproceedings{PDB17Domeniconi2001,
abstract = {SVMs suffer from the problem of large memory requirement and CPU time
when trained in batch mode on large data sets. We overcome these
limitations,and at the same time make SVMs suitable for learning
with data streams,by constructing incremental learning algorithms.
We first introduce and compare different incremental learning techniques,and
show that they are capable of producing performance results similar
to the batch algorithm, and in some cases superior condensation properties.
We then consider the problem of training SVMs using stream data.
Our objective is to maintain an updated representation of recent
batches of data. We apply incremental schemes to the problem and
show that their accuracy is comparable to the batch algorithm.},
address = {San Jose, California, USA},
author = {Domeniconi, Carlotta and Gunopulos, Dimitrios},
booktitle = {Proceedings of the 2001 IEEE International Conference on Data Mining},
editor = {Cercone, Nick and Lin, Tsau Young and Wu, Xindong},
file = {:D$\backslash$:/Papers/Documents/2001/Domeniconi, Gunopulos - 2001.pdf:pdf},
isbn = {0-7695-1119-8},
pages = {589--592},
publisher = {IEEE Computer Society},
title = {{Incremental Support Vector Machine Construction.}},
year = {2001}
}
@inproceedings{Mane2009,
author = {Mane, Vanita and Ragha, Lena},
booktitle = {Proceedings of the International Conference on Advances in Computing, Communication and Control},
file = {:D$\backslash$:/Papers/Documents/2009/Mane, Ragha - 2009.pdf:pdf},
pages = {410--415},
publisher = {ACM},
title = {{Handwritten character recognition using elastic matching and PCA}},
url = {http://portal.acm.org/citation.cfm?id=1523103.1523184},
year = {2009}
}
@inproceedings{DSXu2001,
abstract = {Segmenting handwritten date fields on bank cheque images into three
subimages corresponding to the day, month and year is the first and
critical step of our date recognition system. The paper describes
a knowledge-based segmentation system, which introduces different
kinds of knowledge at different segmentation stages to improve the
performance. The knowledge includes information on the writing style,
syntactic and semantic constraints, etc. Results have shown that
the system is very effective compared with a previous structural
feature based method},
author = {Xu, Qizhi and Lam, L and Suen, C Y},
booktitle = {Document Analysis and Recognition, 2001. Proceedings. Sixth International Conference on},
doi = {10.1109ICDAR.2001.953818},
file = {:D$\backslash$:/Papers/Documents/2001/Xu, Lam, Suen - 2001.pdf:pdf},
keywords = {bank cheque images;date recognition system;handwri},
pages = {384--388},
title = {{A knowledge-based segmentation system for handwritten dates on bank cheques}},
year = {2001}
}
@article{ARPlamondon2006,
abstract = {The study of rapid strokes is a direct or indirect prerequisite in many fundamental research projects, as well as in the design of many practical applications dealing with handwriting. This paper outlines a family of models, derived from the Kinematic Theory of Human Movements. It explains how the nested models in this family can be used coherently, in the context of a multi-level representation paradigm, to analyze both the trajectory and the velocity of strokes with a progressive amount of detail. In the context of a comprehensive survey of previously published work, this paper highlights many new features of stroke production, when the vectorial version of the theory is fully exploited. In this perspective, the Kinematic Theory is depicted as a potential tool to facilitate communications among researchers working in the multi-disciplinary field of Graphonomics.},
author = {Plamondon, ReÃ¯Â¿Â½jean and Djioua, Moussa},
file = {:D$\backslash$:/Papers/Documents/2006/Plamondon, Djioua - 2006.pdf:pdf},
journal = {Human Movement Science},
keywords = {DeltaÃ¯Â¿Â½logno,Handwriting strokes,Kinematic Theory},
pages = {586--607},
title = {{A multi-level representation paradigm for handwriting stroke generation}},
volume = {25},
year = {2006}
}
@article{ARAbdullah2008,
author = {Abdulla, Shubair and Nassiri, Amer Al and Salam, Rosalina Abdul},
file = {:D$\backslash$:/Papers/Documents/2008/Abdulla, Nassiri, Salam - 2008.pdf:pdf},
journal = {The international Jornal of Information Technology},
pages = {200--210},
title = {{Off-line Arabic Handwritten Word Segmentation Using Rational Invariant Segments Features}},
volume = {5},
year = {2008}
}
@inproceedings{Lam,
abstract = {In the business transactions of large corporations such as utility companies and banks, many cheques must be processed on a regular basis. In this paper, we describe algorithms currently under development to automatically process the information contained on them. These procedures are designed to preprocess the scanned image of a cheque, locate and extract different items of information from it, and produce recognition results for these items by classifiers developed for each function},
author = {Lam, L. and Suen, C.Y. and Guillevic, D. and Strathy, N.W. and Cheriet, M. and Liu, K. and Said, J.N.},
booktitle = {1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century},
doi = {10.1109/ICSMC.1995.538133},
file = {:D$\backslash$:/Papers/Documents/1995/Lam et al. - 1995.pdf:pdf},
isbn = {0-7803-2559-1},
pages = {2353--2358},
publisher = {Ieee},
title = {{Automatic processing of information on cheques}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=538133},
year = {1995}
}
@article{ARVellasques2008,
abstract = {In this paper we propose a method to evaluate segmentation cuts for
handwritten touching digits. The idea of this method is to work as
a filter in segmentation-based recognition system. This kind of system
usually rely on over-segmentation methods, where several segmentation
hypotheses are created for each touching group of digits and then
assessed by a general-purpose classifier. The novelty of the proposed
methodology lies in the fact that unnecessary segmentation cuts can
be identified without any attempt of classification by a general-purpose
classifier, reducing the number of paths in a segmentation graph,
what can consequently lead to a reduction in computational cost.
An cost-based approach using ROC (receiver operating characteristics)
was deployed to optimize the filter. Experimental results show that
the filter can eliminate up to 83\% of the unnecessary segmentation
hypothesis and increase the overall performance of the system.},
author = {Vellasquesa, E and Oliveiraa, L S and Jr.a, A S Britto and Koericha, A L and Sabourinb, R},
file = {:D$\backslash$:/Papers/Documents/2008/Vellasquesa et al. - 2008.pdf:pdf},
journal = {Pattern Recognition},
keywords = { Filtering, Segmentation,Handwriting recognition},
pages = {3044--3053},
title = {{Filtering segmentation cuts for digit string recognition}},
volume = {41},
year = {2008}
}
@inproceedings{Okumur2005,
abstract = {An on-line handwritten character recognition technique based on a new HMM is proposed. In the proposed HMM, not only pen-direction feature but also pen-coordinate fea- ture are separately utilized for describing the shape vari- ation of on-line characters accurately. Specijcally speak- ing, the proposed HMM outputs a pen-coordinate feature at each inter-state transition and outputs a pen-direction fea- ture at each intra-state transition, i.e., self-transition. Thus, each state of the proposed HMM can specify the starting position and the direction of a line segment by its incoming inter-state transition and intra-state transition, respectively. The results of recognition experiments on 10-stroke Chinese characters show that the proposed HMM outperforms the conventional HMM which does not use the pen-coordinate feature because of its non-stationarit},
author = {Okumur, D. and Uchida, Seiichi and Sakoe, Hiroaki},
booktitle = {2005 Eight International Conference on Document Analysis and Recognition.},
file = {:D$\backslash$:/Papers/Documents/2005/Okumur, Uchida, Sakoe - 2005.pdf:pdf},
publisher = {IEEE Computer Society},
title = {{An hmm implementation for on-line handwriting recognition-based on pen-coordinate feature and pen-direction feature}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICDAR.2005.50},
year = {2005}
}
@inproceedings{DSChandra2008,
abstract = {Preprocessing is an important step for automatic check processing
in Indian scenario where there is huge variation in writing style,
especially the way in which Courtesy Amount is terminated and the
fractional (Paisa) amount is written. Courtesy Amount Recognition
(CAR) and Legal Amount Recognition (LAR) form the core of automated
check processing system. For CAR identification, a number of approaches
have been suggested. However, most of these do not provide strong
and comprehensive preprocessing techniques. We propose an algorithm
that automatically detects the courtesy amount region, preprocesses
this region, segments the courtesy amount into individual characters
before feeding it to an ICR engine. For detecting the courtesy-amount
region, a Most Probable Region (MPR) is detected, based on configurable
rules and semantic analysis. The presented algorithm intelligently
removes currency symbols (dasiaRs.psila), terminal characters (dasia/psila,
dasia=psila, dasia/-psila), and delimiters (dasia,psila, dasia.psila)
with a high degree of accuracy. Results show that the ICR rates have
increased from 51\% to 90\% using our algorithm.},
author = {Chandra, L and Gupta, R and Kumar, P and Ganotra, D},
booktitle = {TENCON 2008 - 2008 IEEE Region 10 Conference},
doi = {10.1109/TENCON.2008.4766626},
file = {:D$\backslash$:/Papers/Documents/2008/Chandra et al. - 2008.pdf:pdf},
keywords = {automatic bank check processing;courtesy amount re},
pages = {1--5},
title = {{Automatic courtesy amount recognition for Indian banks checks}},
year = {2008}
}
@conference{ARDreuw2009,
abstract = {We present a writer adaptive training and writer clus- tering approach
for an HMM based Arabic handwriting recognition system to handle
different handwriting styles and their variations. Additionally,
a writing variant model refinement for specific writing variants
is proposed. Current approaches try to compensate the impact of dif-
ferent writing styles during preprocessing and normaliza- tion steps.
Writer adaptive training with a CMLLR based feature adaptation is
used to train writer dependent models. An unsupervised writer clustering
with Bayesian information criterion based stopping condition for
a CMLLR based fea- ture adaptation during a two-pass decoding process
is used to cluster different handwriting styles of unknown test writ-
ers. The proposed methods are evaluated on the IFN/ENIT Arabic handwriting
database.},
author = {Dreuw, Philippe and Rybach, David and Gollan, Christian and Ney, Hermann},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Dreuw et al. - 2009.pdf:pdf},
title = {{Writer Adaptive Training and Writing Variant Model Refinement for Offline Arabic Handwriting Recognition}},
year = {2009}
}
@article{Chen2009,
author = {Chen, Jin and Wang, Cheng and Wang, Runsheng},
doi = {10.1016/j.neucom.2009.03.013},
file = {:D$\backslash$:/Papers/Documents/2009/Chen, Wang, Wang - 2009.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Binary tree,Computational complexity,multiclass classification,support vector machine},
month = aug,
number = {13-15},
pages = {3370--3375},
publisher = {Elsevier},
title = {{Adaptive binary tree for fast SVM multiclass classification}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231209001106},
volume = {72},
year = {2009}
}
@article{Loncaric1998,
author = {Loncaric, Sven},
file = {:D$\backslash$:/Papers/Documents/1998/Loncaric - 1998.pdf:pdf},
issn = {0031-3203},
journal = {Pattern recognition},
keywords = {Survey},
mendeley-tags = {Survey},
number = {8},
pages = {983--1001},
publisher = {Elsevier},
title = {{A survey of shape analysis techniques}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031202397001222},
volume = {31},
year = {1998}
}
@inproceedings{DSKim2001,
abstract = {A sophisticated methodology of legal amount recognition based on the
word segmentation hypotheses is introduced for automatic bank check
processing. Word segmentation hypotheses are derived according to
the grapheme level segmentation results of the legal amount. Novel
hybrid schemes of HMM-MLP classifiers are also introduced for producing
the ordered legal word recognition results with reliable decision
values. These values can be used for obtaining an optimal word segmentation
path of over-segmentation hypotheses as well as an efficient rejection
criterion of word recognition result. Simulation was performed with
CENPARMI bank check database and shows quite encouraging results},
author = {Kim, Kye Kyung and Kim, Jin Ho and Chung, Yun Koo and Suen, C Y},
booktitle = {Document Analysis and Recognition, 2001. Proceedings. Sixth International Conference on},
doi = {10.1109/ICDAR.2001.953928},
file = {:D$\backslash$:/Papers/Documents/2001/Kim et al. - 2001.pdf:pdf},
keywords = { ;, ;hidden Markov models;image segmentation;multilay,CENPARMI;HMM;bank check database;bank check proces},
pages = {964--967},
title = {{Legal amount recognition based on the segmentation hypotheses for bank check processing}},
year = {2001}
}
@article{Verma2004,
author = {Verma, B and Blumenstein, M and Ghosh, M},
doi = {10.1016/j.patrec.2004.02.013},
file = {:D$\backslash$:/Papers/Documents/2004/Verma, Blumenstein, Ghosh - 2004.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = jul,
number = {9},
pages = {975--988},
title = {{A novel approach for structural feature extraction: Contour vs. direction}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865504000558},
volume = {25},
year = {2004}
}
@article{Vuori2002,
abstract = {We have considered problems involved in the self-supervised learning process of an on-line handwriting recognition system. Our system is able to recognize isolated characters by comparing them to prototype characters with a method based on the Dynamic Time Warping algorithm. The recognition system is adapted by adding new prototypes, inac- tivating confusing or erroneous ones, and reshaping existing prototypes with a method based on the Learning Vector Quantization. We have analyzed the sources oferroneous learning samples and studied the inÃ®â¬Å¾uence ofsuch samples on the performance of the recognizer via simulations. In these simulations, two adaptation strategies combined with four methods for inactivating prototypes were applied. The results of the simulations showed that the adaptation strategies are able to improve the systemÃ¢â¬â¢s recognition rate and the prototype inactivation methods do reduce the harmful eÃ®â¬Â·ects of erroneous learning samples.? 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.},
author = {Vuori, V},
doi = {10.1016/S0031-3203(01)00083-8},
file = {:D$\backslash$:/Papers/Documents/2002/Vuori - 2002.pdf:pdf},
journal = {Pattern Recognition},
keywords = {adaptation,dtw,dynamic time warping,erroneous learning samples,intelligent user interface,isolated character recognition,k nearest neighbor rule,learning vector quantization,lvq,on-line recognition,unconstrained writing style},
month = apr,
number = {4},
pages = {915--925},
title = {{Influence of erroneous learning samples on adaptation in on-line handwriting recognition}},
volume = {35},
year = {2002}
}
@article{JinhaiCai1999,
author = {{Jinhai Cai}},
doi = {10.1109/34.754622},
file = {:D$\backslash$:/Papers/Documents/1999/Jinhai Cai - 1999.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = mar,
number = {6},
pages = {105--270},
title = {{Integration of structural and statistical information for unconstrained handwritten numeral recognition}},
volume = {64},
year = {1999}
}
@article{DSGorski2001,
abstract = {This paper presents the current state of the A2iA CheckReaderTM Ã¯Â¿Â½
a commercial bank check recognition system. The system is designed
to process the flow of payment documents associated with the check
clearing process: checks themselves, deposit slips, money orders,
cash tickets, etc. It processes document images and recognizes document
amounts whatever their style and type Ã¯Â¿Â½ cursive, hand- or machine
printed Ã¯Â¿Â½ expressed as numerals or as phrases. The system is adapted
to read payment documents issued in different English- or Frenchspeaking
countries. It is currently in use at more than 100 large sites in
five countries and processes daily over 10 million documents. The
average read rate at the document level varies from 65 to 85\% with
a misread rate corresponding to that of a human operator (1\%).},
author = {{Nikolai Gorski Valery Anisimov}, Emmanuel Augustin Olivier Baret Sergey Maximov},
file = {:D$\backslash$:/Papers/Documents/2001/Nikolai Gorski Valery Anisimov - 2001.pdf:pdf},
journal = {International Journal of Document Analysis and Processing},
keywords = { Automatic reading , Document analysis , Intelligent, Payment systems ,Bank check processing ,Handwriting recognition },
pages = {196Ã¯Â¿Â½206},
title = {{Industrial bank check processing: the A2iA CheckReaderTM}},
volume = {3},
year = {2001}
}
@inproceedings{El-Hajj2005,
abstract = {In this paper we describe a 1D HMM off-line handwriting recognition system employing an analytical approach. The system is supported by a set of robust language independent features extracted on binary images. Parameters such as lower and upper baselines are used to derive a subset of baseline dependent features. Thus, word variability due to lower and upper parts of words is better taken into account. In addition, the proposed system learns character models without character pre-segmentation. Experiments that have been conducted on the benchmark IFN/ENIT database of Tunisian handwritten country/village names, show the advantage of the proposed approach and of the baseline- dependant features.},
author = {El-Hajj, R. and Likforman-Sulem, L. and Mokbel, C.},
booktitle = {Eighth International Conference on Document Analysis and Recognition (ICDAR'05)},
doi = {10.1109/ICDAR.2005.53},
file = {:D$\backslash$:/Papers/Documents/2005/El-Hajj, Likforman-Sulem, Mokbel - 2005.pdf:pdf},
isbn = {0-7695-2420-6},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {893--897},
publisher = {Ieee},
title = {{Arabic Handwriting Recognition Using Baseline Dependant Features and Hidden Markov Modeling}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1575673},
year = {2005}
}
@article{ARKumara2008,
abstract = {This paper proposes a new approach for classifying multivariate time-series
with applications to the problem of writer independent online handwritten
character recognition. Each time-series is approximated by a sum
of piecewise polynomials in a suitably defined Reproducing Kernel
Hilbert Space (RKHS). Using the associated kernel function a large
margin classification formulation is proposed which can discriminate
between two such functions belonging to the RKHS. The associated
problem turns out to be an instance of convex quadratic programming.
The resultant classification scheme applies to many time-series discrimination
tasks and shows encouraging results when applied to online handwriting
recognition tasks.},
author = {Kumara, Karthik and Agrawal, Rahul and Bhattacharyya, Chiranjib},
file = {:D$\backslash$:/Papers/Documents/2008/Kumara, Agrawal, Bhattacharyya - 2008.pdf:pdf},
journal = {Pattern Recognition Letters},
keywords = {Time-series classification; Kernels; Online handwr},
pages = {933Ã¯Â¿Â½937},
title = {{A large margin approach for writer independent online handwriting classification}},
volume = {29},
year = {2008}
}
@inproceedings{ARAburas2008,
abstract = {Optical Characters Recognition (OCR) is one of the active subjects
of research since the early days of computer science. Even if Arabic
characters are used by more than a half a billion people; Arabic
characters recognition has not received enough interests by the researchers.
Little research progress has been achieved comparing to what has
been done with Latin and Chinese. The cursive nature of the Arabic
characters makes it more difficult to achieve a high accuracy in
character recognition since even printed Arabic characters are in
cursive form. This paper presents the main challenges (difficulties)
researchers are facing and up to dated solutions (the common methods)
are used for Arabic text recognition.},
address = {Kuala Lumpur, Malaysia},
author = {Aburas, Abdurazzag Ali and Gumah, Mohamed E},
booktitle = {ITSim 2008. International Symposium on Information Technology},
file = {:D$\backslash$:/Papers/Documents/2008/Aburas, Gumah - 2008.pdf:pdf},
keywords = { Arabic Handwriting,Survey},
organization = {IEEE},
pages = {1--6},
title = {{Arabic handwriting recognition: Challenges and solutions}},
volume = {2},
year = {2008}
}
@inproceedings{Zhu2009,
author = {Zhu, Xiaoyuan and Ge, Y. and Guo, F. and Zhen, L.},
booktitle = {2009 10th International Conference on Document Analysis and Recognition},
doi = {10.1109/ICDAR.2009.6},
file = {:D$\backslash$:/Papers/Documents/2009/Zhu et al. - 2009.pdf:pdf},
pages = {1246--1250},
publisher = {IEEE},
title = {{A Probabilistic Framework for Soft Target Learning in Online Cursive Handwriting Recognition}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICDAR.2009.6},
year = {2009}
}
@inproceedings{PDBFavat1994,
abstract = {this paper outli4es the philosophy, desrgn and implementation of the
Gradient, Structural, bvily (GSC) recognition algorithm, which has
been used successfully in several aGG"d rcading applications at CEDAR.
The GSC algorithm takes a quasi multidio approach to feature generation.
This philosophy coupled with the appropriaie *tf,aatim function results
in a recognizer which has both high accuracy and good -'et-cc behavior.
This allows it to be used in higher level digit string and word ggliti@
algorithms which search for digit/character boundaries. Tests of
the GSC Ner oDs tandardd igit, charactera nd non-characterd atabasesa
rer eported.},
author = {{J.T. FavatA G Srikantan} and Srihari, S N},
booktitle = {Proc. IWFHR},
file = {:D$\backslash$:/Papers/Documents/1994/J.T. FavatA G Srikantan, Srihari - 1994.pdf:pdf},
pages = {57--66},
title = {{Handprinted Character/DigitR ecognitionu singa Multiple Feature/ResolutioPnh itosophy}},
year = {1994}
}
@article{Nakai2002a,
abstract = {This paper discusses the use of pen pressure as a fearure in wrirer-independenr on-line handwriting recognirion. We propose hvo kinds of features related io pen pressure: one is the pressure represenring pen ups and downs in a conrin- uous manner: rhe other is rhe rime-derivarive of the pres- sure represenring rhe temporal parrern of rhe pen pressure. Combining eirher of rhem wirh the exisring fearure (velocity vecror), a 3-dimensional fearure is composed for charac- rer recognition. Some techniques of inrerpolaring rhe pen pressure during rhe pen-up inrerval is also proposed for a pre-processing purpose. Through experimenral evaluarion using 1,016 elemenrary Kanji characters compared wirh rhe baseline performance using velociry vecror only, rhe addi- tional use of pen pressure improved rhe performance from 97.5\% IO 98.1\% for careful wrirings and from 91.1\% ro 93. I\% for cursive writings.},
author = {Nakai, M and Sudo, T and Shimodaira, H},
file = {:D$\backslash$:/Papers/Documents/2002/Nakai, Sudo, Shimodaira - 2002.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {220--223},
title = {{Pen Pressure Features for Writer-independent On-line Handwriting Recognition based on substroke HMM}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICPR.2002.1047834},
year = {2002}
}
@article{Al-HajjMohamad2009,
abstract = {The problem addressed in this study is the offline recognition of handwritten Arabic city names. The names are assumed to belong to a fixed lexicon of about 1,000 entries. A state-of-the-art classical right-left hidden Markov model (HMM)-based recognizer (reference system) using the sliding window approach is developed. The feature set includes both baseline-independent and baseline-dependent features. The analysis of the errors made by the recognizer shows that the inclination, overlap, and shifted positions of diacritical marks are major sources of errors. In this paper, we propose coping with these problems. Our approach relies on the combination of three homogeneous HMM-based classifiers. All classifiers have the same topology as the reference system and differ only in the orientation of the sliding window. We compare three combination schemes of these classifiers at the decision level. Our reported results on the benchmark IFN/ENIT database of Arabic Tunisian city names give a recognition rate higher than 90 percent accuracy and demonstrate the superiority of the neural network-based combination. Our results also show that the combination of classifiers performs better than a single classifier dealing with slant-corrected images and that the approach is robust for a wide range of orientation angles.},
author = {{Al-Hajj Mohamad}, Ramy and Likforman-Sulem, Laurence and Mokbel, Chafic},
doi = {10.1109/TPAMI.2008.136},
file = {:D$\backslash$:/Papers/Documents/2009/Al-Hajj Mohamad, Likforman-Sulem, Mokbel - 2009.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automatic Data Processing,Automatic Data Processing: methods,Handwriting,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Markov Chains,Middle East,Models, Statistical,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reading,Subtraction Technique},
month = jul,
number = {7},
pages = {1165--77},
pmid = {19443916},
title = {{Combining slanted-frame classifiers for improved HMM-based Arabic handwriting recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19443916},
volume = {31},
year = {2009}
}
@article{Mozaffari2007,
author = {Mozaffari, Saeed and Faez, Karim and M$\backslash$$\backslash$"argner, V.},

journal = {Machine Learning and Data Mining in Pattern Recognition},
keywords = {arabic handwritten digit recognition,farsi,fractal theory,iterated function system,on-line and off-line},
pages = {868--882},
publisher = {Springer},
title = {{Application of Fractal Theory for On-Line and Off-Line Farsi Digit Recognition}},

year = {2007}
}
@article{AR3AlMuhtaseb2008,
abstract = {This paper describes a technique for automatic recognition of off-line printed Arabic text using Hidden Markov Models. In this work different sizes of overlapping and nonoverlapping hierarchical windows are used to generate 16 features from each vertical sliding strip. Eight different Arabic fonts were used for testing (viz. Arial, Tahoma, Akhbar, Thuluth, Naskh, Simplified Arabic, Andalus, and Traditional Arabic). It was experimentally proven that different fonts have their highest recognition rates at different numbers of states (5 or 7) and codebook sizes (128 or 256). Arabic text is cursive, and each character may have up to four different shapes based on its location in a word. This research work considered each shape as a different class, resulting in a total of 126 classes (compared to 28 Arabic letters). The achieved average recognition rates were between 98.08\% and 99.89\% for the eight experimental fonts. The main contributions of this work are the novel hierarchical sliding window technique using only 16 features for each sliding window, considering each shape of Arabic characters as a separate class, bypassing the need for segmenting Arabic text, and its applicability to other languages.},
annote = {Comments:
Different printed Arabic fonts
16 Features extracted from Vertical sliding windows (Mainly number of black pixels).
HMM for recognition and segmentation.


Details:
 The database was extracted from the books of Saheh Al-Bukhari and Saheh Muslem. The training phase, 2500 lines were used for
training and the remaining 266 lines for testing.
 For each file the text was formatted to appear as a white font color in a black background. Moreover, each image in the Ã¢â¬ËtifÃ¢â¬â¢ file has been side reversed through a mirroring tool to speed up the training and recognition testing processes. Featrues are extracted from overlapping moving vertical window of three-pixel width and a text line of height TLH. from each window, 16 different feature are extracted by dividing the window into parts of non overlapping 8 parts of 1/8 height, 4 parts of 1/4 height and overlapping 1/2 height and one whole window. From each part, the number of black pixel is computed and used as feautres.


The HMM used is in HTK library, its structure allows nonlinear variations in the horizontal position. HTK models the feature vector with a mixture of Gaussians.
It uses the Viterbi algorithm in the recognition phase, which searches for the most likely sequence of a character given the input feature vector.


Result on the arabic text was 99.94 \%, the method was also used on english texts and result was 98.9\%},
author = {Al-Muhtaseb, Husni A and Mahmouda, Sabri A and Qahwaji, Rami S},
file = {:D$\backslash$:/Papers/Documents/2008/Al-Muhtaseb, Mahmouda, Qahwaji - 2008.pdf:pdf},
journal = {Signal Processing},
keywords = {Arabic Handwriting,Arabic Handwritting recognition,HMM,Read,Summarized},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
pages = {2902Ã¯Â¿Â½2912},
title = {{Recognition of off-line printed Arabic text using Hidden Markov Models}},
volume = {88},
year = {2008}
}
@inproceedings{PDBFumera2003,
abstract = {The aim of this paper is to evaluate the potential usefulness of the
reject option for text categorisation (TC) tasks. The reject option
is a technique used in statistical pattern recognition for improving
classification reliability. Our work is motivated by the fact that,
although the reject option proved to be useful in several pattern
recognition problems, it has not yet been considered for TC tasks.
Since TC tasks differ from usual pattern recognition problems in
the performance measures used and in the fact that documents can
belong to more than one category, we developed a specific rejection
technique for TC problems. The performance improvement achievable
by using the reject option was experimentally evaluated on the Reuters
dataset, which is a standard benchmark for TC systems.},
address = {Mantova, Italy},
author = {Fumera, Giorgio and Pillai, Ignazio and Roli, Fabio},
booktitle = {12th International Conference on Image Analysis and Processing (ICIAP 2003)},
doi = {http://csdl.computer.org/comp/proceedings/iciap/2003/1948/00/19480582abs.htm},
file = {:D$\backslash$:/Papers/Documents/2003/Fumera, Pillai, Roli - 2003.pdf:pdf},
isbn = {0-7695-1948-2},
pages = {582--587},
publisher = {IEEE Computer Society},
title = {{Classification with reject option in text categorisation systems.}},
year = {2003}
}
@article{ARALEMAMI1990,
abstract = {Arabic characters are always in cursive script. Handwritten words
were entered into an IBM PC via a graphics tablet and a segmentation
process applied to the points; the length and the slope of each segment
was then found, and the slope categorized to one of four directions.
In the learning process, specifications of the strokes of each character
are fed to the computer. In the recognition process, the parameters
of each stroke are found and special rules applied to select the
collection of strokes which best matches the features of one of the
stored characters. The results are promising, and suggestions for
improvements leading to 100\% recognition are proposed.},
author = {AL-EMAMI, SAMIR and USHER, MIKE},
file = {:D$\backslash$:/Papers/Documents/1990/AL-EMAMI, USHER - 1990.pdf:pdf},
journal = {IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,},
number = {12},
pages = {704--710},
title = {{On-Line Recognition of Handwritten Arabic Characters}},
volume = {7},
year = {1990}
}
@article{ARRhee2009,
abstract = {Problems with local ambiguities in handwritten mathematical expressions
(MEs) are often resolved at global level. Therefore, keeping local
ambiguities is desirable for high accuracy, with a hope that they
may be resolved by later global analyses. We propose a layered search
framework for handwritten ME recognition. From given handwritten
input strokes, ME structures are expanded by adding symbol hypotheses
one by one, representing ambiguities of symbol identities and spatial
relationships as numbers of branches in the expansion. We also propose
a novel heuristic predicting how likely the set of remaining input
strokes forms valid spatial relationships with the current partially
interpreted structure. Further complexity reduction is achieved by
delaying the symbol identity decision. The elegance of our approach
is that the search result would be unchanged even if we prune out
unpromising branches of the search. Therefore, we can examine a much
larger number of local hypotheses with a limited amount of computing
resource in making global level decisions. The experimental evaluation
shows promising results of the efficiency of the proposed approach
and the performance of our system, which results from the system's
capacity to examine a large number of possibilities},
author = {Rhee, Taik Heon and Kim, Jin Hyung},
doi = {10.1016/j.patcog.2008.10.036},
file = {:D$\backslash$:/Papers/Documents/2009/Rhee, Kim - 2009.pdf:pdf},
journal = {Pattern Recognition},
keywords = { Admissible heuristic, Layered searchtree, Structural analysis, expression recognition,Delayed decisionofsymbolidentity,Handwritten mathematical},
month = dec,
number = {12},
pages = {3192--3201},
title = {{Efficient search strategy instructural analysis for handwritten mathematical expression recognition}},
volume = {42},
year = {2009}
}
@article{Vinciarelli2002,
abstract = {This work presents the application of HMM adaptation techniques to the problem of Off-Line Cursive Script Recognition. Rather than training a new model for each writer},
author = {Vinciarelli, a},
journal = {Pattern Recognition Letters},
keywords = {hmm,hmm bayesian adaptation,hmm maximum likelihood adaptation,maximum a posteriori adaptation,off-line cursive script recognition},
month = jun,
number = {8},
pages = {905--916},
title = {{Writer adaptation techniques in HMM based Off-Line Cursive Script Recognition}},
volume = {23},
year = {2002}
}
@inproceedings{Kornai,
abstract = {The system described in this paper applies Hidden Markov technology to the task of recognizing the hand- written legal amount on personal checks. We argue that the most significant source of error in handwrit- ing recognition is the segmentation process. In tradi- tional handwriting OCR systems, recognition is per- formed at the character level, using the output of an independent segmentation step. Using a fixed stepsize series of vertical slices from the image, the HMM sys- tem described in this paper avoids taking segmentation decisions early in the recognition process.},
author = {Kornai, a. and Mohiuddin, K.M. and Connell, S.D.},
booktitle = {1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century},
doi = {10.1109/ICSMC.1995.538206},
file = {:D$\backslash$:/Papers/Documents/1995/Kornai, Mohiuddin, Connell - 1995.pdf:pdf},
isbn = {0-7803-2559-1},
pages = {2800--2805},
publisher = {Ieee},
title = {{An HMM-based legal amount field OCR system for checks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=538206},
year = {1995}
}
@article{Abd-Almageed2009,
author = {Abd-Almageed, Wael and Kumar, Jayant and Doermann, David},
doi = {10.1109/ICDAR.2009.276},
file = {:D$\backslash$:/Papers/Documents/2009/Abd-Almageed, Kumar, Doermann - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {768--772},
publisher = {Ieee},
title = {{Page Rule-Line Removal Using Linear Subspaces in Monochromatic Handwritten Arabic Documents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277504},
year = {2009}
}
@inproceedings{DSDing2008,
abstract = {A new courtesy amount recognition module of CENPARMIpsilas check reading
system (CRS) is proposed in this paper. The module consists of 3
main segments: pre-processing, segmentation and recognition, and
post-processing. A new feedback-based segmentation algorithm is adopted
for the segmentation task. Besides one individual numeral recognizer
for numerals from dasia0psila to dasia9psila, one convolutional neural
network(CNN) recognizer for ldquo00rdquo and ldquo000rdquo numeral
strings is also integrated into our module for the recognition task.
The experimental results on the Quebec Bell Check database show that
the recognition rate of the courtesy amount has improved from 41.2\%
to 74.3\%.},
author = {Ding, Wu and Suen, C Y and Krzyzak, A},
booktitle = {Pattern Recognition, 2008. ICPR 2008. 19th International Conference on},
doi = {10.1109/ICPR.2008.4761532},
file = {:D$\backslash$:/Papers/Documents/2008/Ding, Suen, Krzyzak - 2008.pdf:pdf},
issn = {1051-4651},
keywords = { ;image recognition;image segmentation;neural nets,CRS;check reading system;convolutional neural netw},
pages = {1--4},
title = {{A new courtesy amount recognition module of a Check Reading System}},
year = {2008}
}
@conference{ARSaabni2009b,
abstract = {In this paper, we present a multi-level recognizer for online Arabic
handwriting. In Arabic script (handwritten and printed), cursive
writing Ã¯Â¿Â½ is not a style Ã¯Â¿Â½ it is an inherent part of the script.
In addition, the connection between letters is done with almost no
ligatures, which complicates segmenting a word into individual letters.
In this work, we have adopted the holistic approach and avoided segmenting
words into individual letters. To reduce the search space, we apply
a series of filters in a hierarchicalmanner. The earlier filters
perform light processing on a large number of candidates, and the
later filters perform heavy processing on a small number of candidates.
In the first filter, global features and delayed strokes patterns
are used to reduce candidate word-part models. In the second filter,
local features are used to guide a dynamic time warping (DTW) classification.
The resulting k top ranked candidates are sent for shape-context
based classifier, which determines the recognized word-part. In this
work, we have modified the classic DTW to enable different costs
for the different operations and control their behavior. We have
performed several experimental tests and have received encouraging
results.},
author = {Saabni, Raid and El-Sana, Jihad},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Saabni, El-Sana - 2009(2).pdf:pdf},
title = {{Hierarchical On-line Arabic Handwriting Recognition}},
year = {2009}
}
@article{Gauthier2002,
author = {Gauthier, Nadii and Arti\`{e}res, T and Dorizzi, Bernadette},
file = {:D$\backslash$:/Papers/Documents/2002/Gauthier, Arti\`{e}res, Dorizzi - 2002.pdf:pdf},
journal = {end Recognition, 2001.},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {412--416},
title = {{Strategies for combining on-line and off-line information in an on-line handwriting recognition system}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=953823},
year = {2002}
}
@article{Broumandnia2008,
author = {Broumandnia, a and Shanbehzadeh, J and Rezakhahvarnoosfaderani, M},
doi = {10.1016/j.imavis.2007.09.004},
file = {:D$\backslash$:/Papers/Documents/2008/Broumandnia, Shanbehzadeh, Rezakhahvarnoosfaderani - 2008.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {farsi handwritings,holistic word recognition,m-band packet wavelet,row shift invariant},
month = jun,
number = {6},
pages = {829--842},
title = {{Persian/arabic handwritten word recognition using M-band packet wavelet transform}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885607001643},
volume = {26},
year = {2008}
}
@inproceedings{DSFeritas2000,
abstract = {This paper presents a system that is being developed for the recognition
of the handwritten legal amount in Brazilian bank checks. Our strategy
used to approach the handwritten legal amount recognition problem
puts on evidence the keywords: "mil", "reals/real", "centavos/centavo"
which are almost always present in each amount. The recognizer, based
on hidden markov models, does a global word analysis, therefore,
it does not carry out an explicit segmentation of words into characters
or pseudo-characters. In this context, each word image is transformed
into a sequence of observations using pre-processing and feature
extraction stages. Our system, when tested on our database simulating
Brazilian bank checks, shows the viability of our approach.},
address = {Washington, DC, USA},
author = {Freitas, Cinthia Obladen de Almendra and Yacoubi, Abdenaim El and Bortolozzi, Fl\'{a}vio and Sabourin, Robert},
booktitle = {SIBGRAPI '00: Proceedings of the 13th Brazilian Symposium on Computer Graphics and Image Processing},
file = {:D$\backslash$:/Papers/Documents/2000/Freitas et al. - 2000.pdf:pdf},
isbn = {0-7695-0878-2},
pages = {97--104},
publisher = {IEEE Computer Society},
title = {{Brazilian Bank Check Handwritten Legal Amount Recognition}},
year = {2000}
}
@inproceedings{Koerich2004,
abstract = {To support large vocabulary handwriting recognition in standard computer platforms, a fast algorithm for hidden Markov model alignment is necessary. To address this prob- lem, we propose a nonÃ¢â¬âheuristic fast decoding algorithm which is based on hidden Markov model representation of characters. The decoding algorithm breaks up the compu- tation of word likelihoods into two levels: state level and character level. Given an observation sequence, the two level decoding enables the reuse of character likelihoods to decode all words in the lexicon, avoiding repeated compu- tation of state sequences. In an 80,000Ã¢â¬âword recognition task, the proposed decoding algorithm is about 15 times faster than a conventional Viterbi algorithm, while main- taining the same recognition accuracy},
author = {Koerich, A.L. and Sabourin, Robert and Suen, C.Y.},
booktitle = {Frontiers in Handwriting Recognition, 2004. IWFHR-9 2004. Ninth International Workshop on},
file = {:D$\backslash$:/Papers/Documents/2004/Koerich, Sabourin, Suen - 2004.pdf:pdf},
isbn = {0769521878},
issn = {1550-5235},
pages = {232--237},
publisher = {IEEE},
title = {{Fast two-level HMM decoding algorithm for large vocabulary handwriting recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1363916},
year = {2004}
}
@inproceedings{Santos2009,
abstract = {Different strategies for combination of complementary features in an HMM-based method for handwritten character recognition are evaluated. In addition, a noise reduction method is proposed to deal with the negative impact of low probability symbols in the training database. New sequences of observations are generated based on the original ones, but considering a noise reduction process. The experimental results based on 52 classes of alphabetic characters and more than 23,000 samples have shown that the strategies proposed to optimize the HMM- based recognition method are very promising.},
author = {Santos, Murilo and Ko, Albert and Oliveira, Luis S. and Sabourin, Robert and Koerich, Alessandro L. and Jr., Alceu S. Britto},
booktitle = {2009 10th International Conference on Document Analysis and Recognition},
doi = {10.1109/ICDAR.2009.230},
file = {:D$\backslash$:/Papers/Documents/2009/Santos et al. - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
month = jul,
pages = {666--670},
publisher = {Ieee},
title = {{Evaluation of Different Strategies to Optimize an HMM-Based Character Recognition System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277474},
year = {2009}
}
@article{ARJawahar2009,
abstract = {Search and retrieval is gaining importance in the ink domain due to
the increase in the availability of online handwritten data. However,
the problem is challenging due to variations in handwriting between
various writers, digitizers and writing conditions. In this paper,
we propose a retrieval mechanism for online handwriting, which can
handle different writing styles, specifically for Indian languages.
The proposed approach provides a keyboard-based search interface
that enables to search handwritten data from any platform, in addition
to pen-based and example-based queries. One of the major advantages
of this framework is that information retrieval techniques such as
ranking relevance, detecting stopwords and controlling word forms
can be extended to work with search and retrieval in the ink domain.
The framework also allows cross-lingual document retrieval across
Indian languages.},
address = {New York, NY, USA},
author = {Jawahar, C V and Balasubramanian, A and Meshesha, Million and Namboodiri, Anoop M},
doi = {http://dx.doi.org/10.1016/j.patcog.2008.08.017},
file = {:D$\backslash$:/Papers/Documents/2009/Jawahar et al. - 2009.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recogn.},
keywords = { Handwriting synthesis, Indian language scripts, Information retrieval, Online handwriting,Search and retrieval},
number = {7},
pages = {1445--1457},
publisher = {Elsevier Science Inc.},
title = {{Retrieval of online handwriting by synthesis and matching}},
volume = {42},
year = {2009}
}
@inproceedings{Almaksour2009,
author = {Almaksour, Abdullah and Anquetil, Eric},
booktitle = {Document Analysis and Recognition, 2009. ICDAR'09. 10th International Conference on},
doi = {10.1109/ICDAR.2009.23},
file = {:D$\backslash$:/Papers/Documents/2009/Almaksour, Anquetil - 2009.pdf:pdf},
issn = {1520-5363},
pages = {81--85},
publisher = {IEEE},
title = {{Fast Incremental Learning Strategy Driven by Confusion Reject for Online Handwriting Recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5277781},
year = {2009}
}
@inproceedings{PDB7Chen2004,
abstract = {This paper presents a new approach called Hierarchical Support Vector
Machines (HSVM), to address multi-class problems. The method solves
a series of max-cut problems to hierarchically and recursively partition
the set of classes into two-subsets, till pure leaf nodes that have
only one class label, are obtained. The SVM is applied at each internal
node to construct the discriminant function for a binary meta-class
classifier. Because max-cut unsupervised decomposition uses distance
measures to investigate the natural class groupings, HSVM has a fast
and intuitive SVM training process that requires little tuning and
yields both high accuracy levels and good generalization. The HSVM
method was applied to Hyperion hyperspectral data collected over
the Okavango Delta of Botswana. Classification accuracies and generalization
capability are compared to those achieved by the Best Basis Binary
Hierarchical Classifier, a Random Forest CART binary decision tree
classifier and Binary Hierarchical Support Vector Machines.},
author = {Chen, Yangchi and Crawford, M M and Ghosh, J},
booktitle = {Geoscience and Remote Sensing Symposium, 2004. IGARSS '04. Proceedings. 2004 IEEE International},
file = {:D$\backslash$:/Papers/Documents/2004/Chen, Crawford, Ghosh - 2004.pdf:pdf},
keywords = {SVM},
month = sep,
pages = {949--952},
publisher = {IEEE International},
title = {{Integrating support vector machines in a hierarchical output space decomposition framework}},
volume = {2},
year = {2004}
}
@inproceedings{DSAlamri2009,
abstract = {In this paper, we propose a new approach on segmentation and recognition
of off-line unconstrained Arabic handwritten numerals, which failed
to be segmented with connected component analysis. In our approach,
the touching numerals are automatically segmented when a set of parameters
is chosen. Models with different sets of parameters for each numeral
pair are designed for recognition. Each image in each model is recognized
as an isolated numeral. After normalizing and binarizing the images,
gradient features are extracted and recognized using SVMs. Finally,
a post-processing is proposed by based on the optimal combinations
of the recognition probabilities for each model. Experiments were
conducted on the CENPARMI Arabic, Dari, and Urdu touching numeral
pair databases [1,12].},
address = {MÃ¯Â¿Â½nster, Germany},
author = {Alamri, Huda and He, Chun Lei and Suen, Ching Y},
booktitle = {Procedings CAIP (13th International Conference Computer Analysis of Images and Pattern s)},
file = {:D$\backslash$:/Papers/Documents/2009/Alamri, He, Suen - 2009.pdf:pdf},
keywords = { Arabic Digit Recognition, Gradient features.,Numeral pair segmentation},
pages = {165--172},
title = {{A New Approach for Segmentation and Recognition of Arabic Handwritten Touching Numeral Pairs}},
year = {2009}
}
@article{Al-Omari2001,
abstract = {A recognition system for identijjing hand-written Indian (Arabic) numerals one to nine (5- 9 has been developed. A graphical user interface was developed using advanced object oriented techniques that incorporates Matlab@ as a technical tool. The process involved extracting a feature vector to represent the handwritten sketch based on the Ã¢â¬ÅobjectÃ¢â¬ï¿½ centroid and boundary points. A template vector was derived for each digit by taking the average feature vector of 30 handwritten sketches made by 30 different students. The test sketch is compared against all nine templates and a distance measure is performed to make the recognition. An overall hit ratio of 87.22\% was achieved in the preliminary results. The ratio reached IOO\% for some of the digits. But there was misinterpretation between similar digits like (7 and (9). This study is meant to be a seed toward building a recognition system for Arabic language characters.},
author = {Al-Omari, F.},
doi = {10.1109/AICCSA.2001.933955},
file = {:D$\backslash$:/Papers/Documents/2001/Al-Omari - 2001.pdf:pdf},
isbn = {0-7695-1165-1},
journal = {Proceedings ACS/IEEE International Conference on Computer Systems and Applications},
keywords = {Reference From Doctor,artificial intelligence,character recognition,image segmentation,pattern recognition,template},
mendeley-tags = {Reference From Doctor},
pages = {83--88},
publisher = {IEEE Comput. Soc},
title = {{Handwritten Indian numeral recognition system using template matching approaches}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=933955},
year = {2001}
}
@conference{ARICDAR2007,
abstract = {This paper describes the Arabic handwriting recognition competition
held at ICDAR 2007. This second competition (the first was at ICDAR
2005) again uses the IFN/ENITdatabase with Arabic handwritten Tunisian
town names. Today, more than 54 research groups from universities,
research centers, and industry are working with this database worldwide.
This year, 8 groups with 14 systems are participating in the competition.
The systems were tested on known data and on two datasets which are
unknown to the participants. The systems are compared on the most
important characteristic, the recognition rate. Additionally, the
relative speed of the different systems were compared. A short description
of the participating groups, their systems, and the results achieved
are finally presented.},
author = {Margner, Volker and Abed, Haikal El},
booktitle = {ICDAR},
file = {:D$\backslash$:/Papers/Documents/2007/Margner, Abed - 2007.pdf:pdf},
title = {{ICDAR 2007 - Arabic Handwriting Recognition Competition}},
year = {2007}
}
@inproceedings{Sadri2003,
author = {Sadri, J and Suen, CY and Bui, TD},
booktitle = {Proceedings of Second Iranian Conference on Machine Vision and Image Processing},
file = {:D$\backslash$:/Papers/Documents/2003/Sadri, Suen, Bui - 2003.pdf:pdf},
keywords = {feature extraction,machine learning,mlp neural network,multiple support vector classifiers,ocr,optical character recognition,support,svm,vector machine},
number = {1},
pages = {300--307},
publisher = {Citeseer},
title = {{Application of support vector machines for recognition of handwritten Arabic/Persian digits}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.147.1765\&amp;rep=rep1\&amp;type=pdf},
volume = {1},
year = {2003}
}
@inproceedings{DSZiaratban2007,
abstract = {The study of handwritten words is tied to the development of recognition
methods to be used in real-world applications involving handwritten
words, such as handwritten texts, bank checks, and postal envelopes,
among others. In this paper an approach for Farsi bank checks was
proposed in which the legal amounts are used to aid the recognition
results of courtesy amounts. The legal amounts which are set of some
of 40 specified words are divided into their sub- words. Some if-then
rules are extracted from validation set to validate the recognized
digits. These rules are used to confirm, correct or reject the recognized
digit. The experimental results reveal a recognition rate of 85.33\%
without the legal amounts, and a reliability rate 99.31\% with a rejection
rate of 3.67\%.},
author = {Ziaratban, M and Faez, K and Ezoji, M},
booktitle = {Ninth International Conference on Document Analysis and Recognition, 2007. ICDAR 2007.},
doi = {10.1109/ICDAR.2007.4377090},
file = {:D$\backslash$:/Papers/Documents/2007/Ziaratban, Faez, Ezoji - 2007.pdf:pdf},
issn = {1520-5363},
keywords = { ;,Farsi bank checks;courtesy amount;handwritten text},
pages = {1123--1127},
title = {{Use of Legal Amount to Confirm or Correct the Courtesy Amount on Farsi Bank Checks}},
volume = {2},
year = {2007}
}
@inproceedings{FEAbdullah2007,
abstract = {Vehicle license plate recognition has been intensively studied in
many countries. Due to the different types of license plates being
used, the requirement of an automatic license plate recognition system
is different for each country. In this paper, an automatic license
plate recognition system is proposed for Malaysian vehicles with
standard license plates using blob labeling and clustering for segmentation,
seven popular and one proposed edge detectors for feature extraction
and neural networks for classification.There were eight experiments
conducted using eight different edge dectectors: Kirsch, Sobel, Laplacian,
Wallis, Prewitt, Frei Chen and a proposed edge detector. The result
had shown kirsch edge detectors is the best technique for feature
exractor while the proposed achieved better results compared to Prewitt,
Frei Chen and Wallis.},
address = {Washington, DC, USA},
author = {Abdullah, Siti Norul Huda Sheikh and Khalid, Marzuki and Yusof, Rubiyah and Omar, Khairuddin},
booktitle = {AMS '07: Proceedings of the First Asia International Conference on Modelling \& Simulation},
doi = {http://dx.doi.org/10.1109/AMS.2007.25},
file = {:D$\backslash$:/Papers/Documents/2007/Abdullah et al. - 2007.pdf:pdf},
isbn = {0-7695-2845-7},
pages = {502--506},
publisher = {IEEE Computer Society},
title = {{Comparison of Feature Extractors in License Plate Recognition}},
year = {2007}
}
@article{Liwicki2009,
author = {Liwicki, Marcus and Bunke, Horst},
doi = {10.1016/j.patcog.2008.10.030},
file = {:D$\backslash$:/Papers/Documents/2009/Liwicki, Bunke - 2009(2).pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {multiple classifier combination,off-line handwriting recognition,on-line handwriting recognition},
month = dec,
number = {12},
pages = {3254--3263},
title = {{Combining diverse on-line and off-line systems for handwritten text line recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308004652},
volume = {42},
year = {2009}
}
@article{YantingDong2003,
abstract = {Ã¢â¬âWeconsider the problem of estimating the pose of a target basedon a sequence of scattered waveformsmeasuredat multiple target-sensor orientations. Using a hidden Markov model (HMM) representation of the scattered-waveform sequence, pose estimation reduces to estimating the underlyingHMMstates from a sequence of observations. It is assumed that each scattered waveform must be quantized via an encoding procedure. A distortionDis defined as the error in estimating the underlying HMM states, and the rate R represents the size of the discrete-HMM codebook. Rate-distortion theory is applied to define the minimum rate required to achieve a desired distortion, denoted as RÃÂ°DÃÅ¾. After deriving the rate-distortion function RÃÂ°DÃÅ¾, we demonstrate that discrete-HMMperformance based on Lloyd encoding is far from this bound. Performance is improved via block coding, based on Bayes VQ. Results are presented for acanonicalHMMproblem,andthen for multiaspect acoustic scatteringfrom underwater elastic targets. Although theexamplespresented here are for multiaspect scattering and pose estimation, the results are of general applicability to discrete-HMMstate estimation.},
author = {{Yanting Dong}},
doi = {10.1109/TPAMI.2003.1206516},
file = {:D$\backslash$:/Papers/Documents/2003/Yanting Dong - 2003.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {HMM,Rate distortion,pose estimation,underwater sensing,vector quantization},
month = jul,
number = {1},
pages = {1303--883},
title = {{Rate-distortion analysis of discrete-HMM pose estimation via multiaspect scattering data}},
volume = {81},
year = {2003}
}
@article{FE3Lauer2007,
abstract = {This article focuses on the problems of feature extraction and the
recognition of handwritten digits. A trainable feature extractor
based on the LeNet5 convolutional neural network architecture is
introduced to solve the first problem in a black box scheme without
prior knowledge on the data. The classification task is performed
by support vector machines to enhance the generalization ability
of LeNet5. In order to increase the recognition rate, new training
samples are generated by affine transformations and elastic distortions.
Experiments are performed on the well-known MNIST database to validate
the method and the results show that the system can outperform both
SVMs and LeNet5 while providing performances comparable to the best
performance on this database. Moreover, an analysis of the errors
is conducted to discuss possible means of enhancement and their limitations.},
author = {Lauer, Fabien and Suen, Ching Y and Bloch, Gerard},
file = {:D$\backslash$:/Papers/Documents/2007/Lauer, Suen, Bloch - 2007.pdf:pdf},
journal = {Pattern Recognition},
keywords = { Handwritten digits,Features Extraction},
pages = {1816--1824},
title = {{A trainable feature extractor for handwritten digit recognition}},
volume = {40},
year = {2007}
}
@inproceedings{PDBLi2003,
abstract = {We introduce a new method, called CS4, to construct committees of
decision trees for classification. The method considers different
top-ranked features as the root nodes of member trees. This idea
is particularly suitable for dealing with high-dimensional bio-medical
data as top-ranked features in this type of data usually possess
similar merits for classification. To make a decision, the committee
combines the power of individual trees in a weighted manner. Unlike
Bagging or Boosting which uses bootstrapped training data, our method
builds all the member trees of a committee using exactly the same
set of training data. We have tested these ideas on UCI data sets
as well as recent bio-medical data sets of gene expression or proteomic
profiles that are usually described by more than 10,000 features.
All the experimental results show that our method is efficient and
that the classification performance are superior to C4.5 family algorithms.},
address = {Melbourne, Florida, USA},
author = {Li, Jinyan and Liu, Huiqing},
booktitle = {Proceedings of the 3rd IEEE International Conference on Data Mining (ICDM 2003), 19-22 December 2003},
doi = {http://csdl.computer.org/comp/proceedings/icdm/2003/1978/00/19780585abs.htm},
file = {:D$\backslash$:/Papers/Documents/2003/Li, Liu - 2003.pdf:pdf},
isbn = {0-7695-1978-4},
pages = {585},
publisher = {IEEE Computer Society, Washington, DC, USA},
title = {{Ensembles of Cascading Trees}},
year = {2003}
}
@misc{DSChan,
author = {N, WINN IE CHA},
file = {:D$\backslash$:/Papers/Documents/2002/N - 2002.pdf:pdf},
institution = {MIT},
title = {{IMPROVING THE AUTOMATIC PROCESSING OF HANDWRITTEN BANK CHECKS}},
year = {2002}
}
@inproceedings{ARBoussellaa2007,
abstract = {This paper presents a new color document image segmentation system
suitable for historical Arabic manuscripts. Our system is composed
of a hybrid method which couple together background light intensity
normalization algorithm and k-means clustering with maximum likelihood
(ML) estimation, for foreground/ background separation. Firstly,
the background normalization algorithm performs separation between
foreground and background. This foreground is used in later steps.
Secondly, our algorithm proceeds on luminance and distort the contrast.
These distortions are corrected with a gamma correction and contrast
adjustment. Finally, the new enhanced foreground image is segmented
to foreground/background on the basis of ML estimation. The initial
parameters for the ML method are estimated by k-means clustering
algorithm. The segmented image is used to produce a final restored
document image. The techniques are tested on a set of Arabic historical
manuscripts documents from the National Tunisian Library. The performance
of the algorithm is demonstrated on by real color manuscripts distorted
with show-through effects, uneven background color and localized
spot.},
address = {Seoul, Korea},
author = {Boussellaa, Wafa and Zahour, Abderrazak and Alimi, Adel},
booktitle = {SAC '07: Proceedings of the 2007 ACM symposium on Applied computing},
doi = {http://doi.acm.org/10.1145/1244002.1244141},
file = {:D$\backslash$:/Papers/Documents/2007/Boussellaa, Zahour, Alimi - 2007.pdf:pdf},
isbn = {1-59593-480-4},
keywords = { Arabic historical color manuscript image., foreground/background, k-means, light intensity normalisation, maximum likelihood, restoration,Segmentation},
pages = {605--609},
publisher = {ACM},
title = {{A Methodology for the Separation of Foreground/Background in Arabic Historical Manuscripts using Hybrid Methods}},
year = {2007}
}
@article{Tsu1997,
author = {Tsu, Kamihama},
file = {:D$\backslash$:/Papers/Documents/1997/Tsu - 1997.pdf:pdf},
journal = {Test},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {866--869},
title = {{F. Kimura+, N. Kayahara+, Y. Miyake+, M. Shridhar++ + Faculty of Engineering, Mie University 15 15 Kamihama Tsu 5 14, JAPAN}},
year = {1997}
}
@article{Nel2008,
abstract = {Static handwritten scripts originate as images on documents and do not, by definition, contain any dy- namic information. To improve the accuracy of static handwriting recognition systems, many techniques aim to estimate dynamic information from the static scripts. Mostly, the pen trajectories of the scripts are estimated. However, the efficacy of the resulting pen trajectories are rarely evaluated quantitatively. This paper proposes a protocol for the objective evaluation of automatically determined pen trajectories. A hidden Markov model is derived from a ground-truth trajectory. An estimated trajectory is then matched to the derived model. Statistics describing substitution, insertion and deletion errors are then computed from this match. The proposed algorithm is especially useful for performance comparisons between different pen trajectory estimation algorithms. ÃÂ©},
author = {Nel, Emli-mari and {Du Preez}, JA and Herbst, BM},
doi = {10.1016/j.patcog.2008.05.005},
file = {:D$\backslash$:/Papers/Documents/2008/Nel, Du Preez, Herbst - 2008.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {Automatic assessment,Estimating pen trajectories of static scripts,document analysis,document processing,handwriting analysis,pattern recognition,strok recovery,text processing},
number = {12},
pages = {3773--3785},
publisher = {Elsevier},
title = {{Verification of dynamic curves extracted from static handwritten scripts}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308001726},
volume = {41},
year = {2008}
}
@inproceedings{PDBMozaffari2005,
abstract = {A Statistical method embedded with statistical features is proposed
for Farsi/Arabic handwritten zip code recognition in this paper.
The numeral is first smoothed and the skeleton is obtained. A set
of feature points are then detected and the skeleton is decomposed
into primitives. A primitive code includes the information of each
primitive and a global code is derived from the primitive codes to
describe the topological structure of the skeleton. By using the
average and variance of X and Y changes in each primitive, the Direction
and curvature of the skeleton can be statistically described.

Since the global codes have different lengths, we applied PCA algorithm
to normalize their lengths. Thanks to statistically description of
the skeleton, we can use the nearest neighbor classifier for recognition.


According to experimental results, classification rate of 94.44\% is
obtained for numerals on the test sets gathered from various people
with different educational background and different ages. Our database
includes 480 samples per digit. We used 280 samples of each digit
for training and the rest (200) for test.},
address = {Seoul, Korea},
author = {Mozaffari, Saeed and Faez, Karim and Ziaratban, Majid},
booktitle = {Eighth International Conference on Document Analysis and Recognition (ICDAR 2005)},
isbn = {0-7695-2420-6},
pages = {237--241},
publisher = {IEEE Computer Society},
title = {{Structural Decomposition and Statistical Description of Farsi/Arabic Handwritten Numeric Characters.}},
year = {2005}
}
@inproceedings{DSMelegy2007,
abstract = {The domain of automatic handwriting recognition has a variety of applications
in real world problems such as cheque processing, office automation
and data entry applications. In this paper an approach for describing
the role of holistic structural features in the recognition of offline
handwritten Arabic literal amounts has been presented. Our proposed
system attempts to recognize words from their overall shape. The
extracted features are presented to several classifiers. The system
is trained and tested using an Arabic handwritten database.},
author = {El-Melegy, M T and Abdelbaset, A A},
booktitle = {Information and Communications Technology, 2007. ICICT 2007. ITI 5th International Conference on},
doi = {10.1109/ITICT.2007.4475631},
file = {:D$\backslash$:/Papers/Documents/2007/El-Melegy, Abdelbaset - 2007.pdf:pdf},
keywords = {Arabic handwritten database;automatic handwriting },
pages = {125--129},
title = {{Global features for offline recognition of handwritten Arabic literal amounts}},
year = {2007}
}
@article{Agarwal1995,
author = {Agarwal, a. and Granowetter, L. and Hussein, K. and Gupta, a. and Wang, P.S.P.},
doi = {10.1109/ICDAR.1995.602011},
file = {:D$\backslash$:/Papers/Documents/1995/Agarwal et al. - 1995.pdf:pdf},
isbn = {0-8186-7128-9},
journal = {Proceedings of 3rd International Conference on Document Analysis and Recognition},
keywords = {all checks,block detection,cessing,check analysis and pro-,heuristics,image processing,optical character recognition,pattern recognition,segmentation,some courtesy amount,the same place on},
pages = {748--751},
publisher = {IEEE Comput. Soc. Press},
title = {{Detection of courtesy amount block on bank checks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=602011},
year = {1995}
}
@article{Salah2002,
author = {a.a. Salah and Alpaydin, E. and Akarun, L.},
doi = {10.1109/34.990146},
file = {:D$\backslash$:/Papers/Documents/2002/Salah, Alpaydin, Akarun - 2002.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = mar,
number = {3},
pages = {420--425},
title = {{A selective attention-based method for visual pattern recognition with application to handwritten digit recognition and face recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=990146},
volume = {24},
year = {2002}
}
@article{Rodriguez-Serranoa2009,
abstract = {Handwritten word-spotting is traditionally viewed as an image matching task between one or multiple query word-images and a set of candidate word-images in a database. This is a typical instance of the query-by-example paradigm. In this article, we introduce a statistical framework for the word-spotting problem which employs hidden Markov models (HMMs) to model keywords and a Gaussian mixture model (GMM) for score normalization. We explore the use of two types of HMMs for the word modeling part: continuous HMMs (C-HMMs) and semi-continuous HMMs (SC-HMMs), i.e. HMMs with a shared set of Gaussians. We show on a challenging multi-writer corpus that the proposed statistical framework is always superior to a traditional matching system which uses dynamic time warping (DTW) for word- image distance computation. A very important finding is that the SC-HMM is superior when labeled training data is scarceÃ¢â¬âas low as one sample per keywordÃ¢â¬âthanks to the prior information which can be incorporated in the shared set of Gaussians. ÃÂ©},
author = {Rodriguez-Serranoa, J.A. and Perronninb, F.},
doi = {10.1016/j.patcog.2009.02.005},
file = {:D$\backslash$:/Papers/Documents/2009/Rodriguez-Serranoa, Perronninb - 2009.pdf:pdf},
journal = {Pattern Recognition},
number = {1},
pages = {2106--2116},
title = {{Handwritten word-spotting using hidden Markov models and universal vocabularies}},
url = {http://www.comp.leeds.ac.uk/scsjars/pubs/rodriguez\_wordspotting\_HMM.pdf},
volume = {42},
year = {2009}
}
@article{MCHotta2009,
abstract = {zzzzzzzzzzzzzzzzzz},
author = {Hotta, Kazuhiro},
file = {:D$\backslash$:/Papers/Documents/2009/Hotta - 2009.pdf:pdf},
journal = {Pattern Recognition},
pages = {619--628},
title = {{Adaptive weighting of local classifiers by particle filters for robust tracking}},
volume = {42},
year = {2009}
}
@article{Elms1998,
abstract = {. A method for word recognition based on the use of hidden Markov models (HMMs) is described. An evaluation of its performance is presented using a test set of real printed documents that have been subjected to se- vere photocopy and fax transmission distortions. A com- parison with a commercial OCR package highlights the inherent advantages of a segmentation-free recognition strategy when the word images are severely distorted, as well as the importance of using contextual knowledge. The HMM method makes only one quarter of the num- ber of word errors made by the commercial package when tested on word images taken from faxed pages.},
author = {a.J. Elms and Procter, S. and Illingworth, J.},
doi = {10.1007/s100320050003},
file = {:D$\backslash$:/Papers/Documents/1998/Elms, Procter, Illingworth - 1998.pdf:pdf},
issn = {1433-2833},
journal = {International Journal on Document Analysis and Recognition},
keywords = {Reference From Doctor,hidden markov,ocr,word recognition},
mendeley-tags = {Reference From Doctor},
month = feb,
number = {1},
pages = {18--36},
title = {{The advantage of using an HMM-based approach for faxed word recognition}},
url = {http://www.springerlink.com/openurl.asp?genre=article\&id=doi:10.1007/s100320050003},
volume = {1},
year = {1998}
}
@article{Ball2009,
author = {Ball, Gregory R. and Srihari, Sargur N.},
doi = {10.1109/ICDAR.2009.249},
file = {:D$\backslash$:/Papers/Documents/2009/Ball, Srihari - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {26--30},
publisher = {Ieee},
title = {{Semi-supervised Learning for Handwriting Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277806},
year = {2009}
}
@inproceedings{DSXu2002,
abstract = { This paper describes an off-line system which recognizes unconstrained
handwritten month words extracted from Canadian bank cheques. A segmentation
based grapheme level HMM (hidden Markov model) classifier and two
multilayer perceptron classifiers with different architectures and
different features have been developed in CENPARMI for the recognition
of month words. In this paper, a combination method with an effective
conditional topology is presented, and the most widely used combination
rules including Vote, Sum and Product, are experimented. A new modified
Product rule is also proposed, which has produced the best recognition
rate of 85.36\% when tested on a real-life standard Canadian bank
cheque database.},
author = {Xu, Qizhi and Kim, Jin Ho and Lam, L and Suen, C Y},
booktitle = {Frontiers in Handwriting Recognition, 2002. Proceedings. Eighth International Workshop on},
doi = {10.1109/IWFHR.2002.1030895},
file = {:D$\backslash$:/Papers/Documents/2002/Xu et al. - 2002.pdf:pdf},
keywords = {CENPARMI; Canadian bank cheques; Hidden Markov Mod},
pages = {111--116},
title = {{Recognition of handwritten month words on bank cheques}},
year = {2002}
}
@inproceedings{PDBFu2006,
abstract = {Band ratios have many useful applications in hyperspectral image analysis.
While optimal ratios have been chosen empirically in previous research,
we propose a principled algorithm for the automatic selection of
ratios directly from data. First, a robust method is used to estimate
the Kullback-Leibler divergence (KLD) between different sample distributions
and evaluate the optimality of individual ratio features. Then, the
boosting framework is adopted to select multiple ratio features iteratively.
Multiclass classification is handled by using a pairwise classification
framework. The algorithm can also be applied to the selection of
discriminant bands. Experimental results on both simple material
identification and complex land cover classification demonstrate
the potential of this ratio selection algorithm. 1. Introduction},
address = {Hong Kong, China},
author = {Fu, Zhouyu and Caelli, Terry and Liu, Nianjun and Robles-Kelly, Antonio},
booktitle = {18th International Conference on Pattern Recognition (ICPR 2006)},
doi = {http://doi.ieeecomputersociety.org/10.1109/ICPR.2006.334},
file = {:D$\backslash$:/Papers/Documents/2006/Fu et al. - 2006.pdf:pdf},
isbn = {0-7695-2521-0},
pages = {1059--1062},
publisher = {IEEE Computer Society},
title = {{Boosted Band Ratio Feature Selection for Hyperspectral Image Classification.}},
year = {2006}
}
@article{Khorsheed2003,
abstract = {This paper presents a new method on off-line recognition of handwritten Arabic script. The method does not require segmentation into characters, and is applied to cursive Arabic script, where ligatures, overlaps and style variation pose challenges to the recognition system. The method trains a single hidden Markov model (HMM) with the structural features extracted from the manuscript words. TheHMMis composed of multiple character models where each model represents one letter from the alphabet. The performance of the proposed method is assessed using samples extracted from a historical handwirtten manuscript.},
author = {Khorsheed, M.S.},
doi = {10.1016/S0167-8655(03)00050-3},
file = {:D$\backslash$:/Papers/Documents/2003/Khorsheed - 2003.pdf:pdf},
issn = {0167-8655},
journal = {Pattern Recognition Letters},
keywords = {arabic character recognition,cursive script,handwritten,hmm,off-line recognition,viterbi algorithm},
number = {14},
pages = {2235--2242},
publisher = {Elsevier},
title = {{Recognising handwritten Arabic manuscripts using a single hidden Markov model}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865503000503},
volume = {24},
year = {2003}
}
@misc{PDB11He2001,
abstract = {Size normalization is an important pre-processing technique in character
recognition. Although various effective learning-based methods have
been proposed, the role of the original data in a database is always
ignored. In this paper, we have conducted experiments to investigate
its effects with neural networks and support vector machines and
have found that the performance of handwritten numeric recognition
systems deteriorates dramatically due to low size resolution. For
the MNIST dataset, this study shows that enlarging the size from
20 * 20 to 26 * 26 by bilinear interpolation can improve the performance
significantly. After constructing a smaller database of difficult
original patterns from NIST, we find that normalizing the original
data to a size larger than 20 * 20 in MNIST increases the recognition
rate further.},
author = {He, Chun Lei and Zhang, Ping and Dong, Jianxiong and Suen, Ching Y and Bui, Tien D},
file = {:D$\backslash$:/Papers/Documents/2001/He et al. - 2001.pdf:pdf},
keywords = { MNIST,Arabic Handwriting},
title = {{The Role of Size Normalization on the Recognition Rate of Handwritten Numerals}},
year = {2001}
}
@article{ARKherallah2009,
abstract = {One of the most promising methods of interacting with small portable
computing devices, such as personal digital assistants, is the use
of handwriting. In order to make this communication method more natural,
we propose to observe visually the writing process on an ordinary
paper and to automatically recover the pen trajectory from numerical
tablet sequences. On the basis of this work, we developed a handwriting
recognition system based on visual coding and genetic algorithm Ã¯Â¿Â½Ã¯Â¿Â½GAÃ¯Â¿Â½Ã¯Â¿Â½.
The system is applied on Arabic script. In this paper, we will present
the different steps of the handwriting recognition system. We focus
our contribution on the encoding system and the fitness function
conception used as basic steps of the GA. A new approach based on
visual indices similarity is developed to calculate the evaluation
function. We optimize the times cooling of our system to give the
final output (proposed words). Several experimentations are developed
using an Arabic data set words extracted from Ã¯Â¿Â½Ã¯Â¿Â½LMCAÃ¯Â¿Â½Ã¯Â¿Â½ database elaborated
in our laboratory by 24 participants. The results obtained are very
promising and prove that our new method based on hybridization between
visual codes and GA is a powerful method.},
author = {Kherallah, M and Bouri, F and Alimi, A M},
journal = {Engineering Applications of Artificial Intelligence},
keywords = { Beta-elliptical representation, Stroke overlapping, Visual encoding,Arabic script,Word recognition},
pages = {153-170},
title = {{On-line Arabic handwriting recognition system based on visual encoding and genetic algorithm}},
volume = {22},
year = {2009}
}
@article{Makhoul1998,
author = {Makhoul, J},
doi = {10.1016/S0031-3203(97)00152-0},
file = {:D$\backslash$:/Papers/Documents/1998/Makhoul - 1998.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = sep,
number = {9},
pages = {1285--1294},
title = {{a Script-Independent Methodology for Optical Character Recognition}},
volume = {31},
year = {1998}
}
@inproceedings{ARPechwitz2002,
abstract = {In this paper we are presenting a new database with handwritten Arabic
town/village names. For each name the ground truth information, e.g.
the sequence of character shapes, some style information, and the
baseline are coded. 411 writers filled forms with about 26400 names
containing more than 210000 characters. The database is described
in detail. It is designed for training and testing recognition systems
for handwritten Arabic words. The IFN/ENIT-database is available
for the purpose of research.},
address = {Hammamet, Tunis},
author = {Pechwitz, M and Maddouri, S Snoussi and MÃ¯Â¿Â½rgner, V and Ellouze, N and Amiri, H},
booktitle = {i7th Colloque International Francophone sur l'Ecrit et le Document , CIFED 2002, Oct. 21-23, 2002, Hammamet, Tunis, (2002)},
file = {:D$\backslash$:/Papers/Documents/2002/Pechwitz et al. - 2002.pdf:pdf},
keywords = { Arabic OCR, Database, Handwriting, Recognition system,Arabic},
title = {{IFN/ENIT-DATABASE OF HANDWRITTEN ARABIC WORDS}},
year = {2002}
}
@inproceedings{DSMuntean2007,
abstract = {In spite of evolution of electronic techniques, a large number of
applications continue to rely on the use of paper as the dominant
medium. Bank checks are a widely known example. When filled by hand,
the processing of the written information requires either a human
or a special software which has intelligent abilities. This paper
examines the issue of reading the amount of money written on the
checks. Genetic Programming (GP) technique is used for dealing with
this problem. A new type of input representation is proposed: histograms.
Several numerical experiments with GP are performed by using large
datasets taken from the MNIST benchmarking set. Preliminary results
show a good behavior of the method.},
author = {Muntean, O and Oltean, M},
booktitle = {Bio-inspired, Learning, and Intelligent Systems for Security, 2007. BLISS 2007. ECSIS Symposium on},
doi = {10.1109/BLISS.2007.27},
file = {:D$\backslash$:/Papers/Documents/2007/Muntean, Oltean - 2007.pdf:pdf},
keywords = {MNIST benchmarking set;electronic techniques;genet},
pages = {102--105},
title = {{Processing Bank Checks with Genetic Programming and Histograms}},
year = {2007}
}
@article{ARBahlmann2005,
abstract = {Abstract. The selection of valuable features is crucial in pattern
recognition. In this paper we deal with the issue that part of features
originate from directional instead of common linear data. Both for
directional and linear data a theory for a statistical modeling exists.
However, none of these theories gives an integrated solution to problems,
where linear and directional variables are to be combined in a single,
multivariate probability density function. We describe a general
approach for a unified statistical modeling, given the constraint
that variances of the circular variables are small. The method is
practically evaluated in the context of our online handwriting recognition
system frog on hand and the so-called tangent slope angle feature.
Recognition results are compared with two alternative modeling approaches.
The proposed solution gives significant improvements in recognition
accuracy, computational speed and memory requirements},
author = {Bahlmann, Claus},
file = {:D$\backslash$:/Papers/Documents/2005/Bahlmann - 2005.pdf:pdf},
journal = {Pattern Recognition},
pages = {115 Ã¯Â¿Â½ 125},
title = {{Directional features in online handwriting recognition}},
volume = {39},
year = {2005}
}
@inproceedings{DSMorita2001,
abstract = {This paper describes an off-line system under development to process
unconstrained handwritten dates on Brazilian bank cheques in an omni-writer
context. We show here some improvements on our previous work on isolated
month word recognition using hidden Markov models (HMM). After preprocessing,
a word image is explicitly segmented into characters or pseudo-characters
and represented by two feature sequences of equal length, which are
combined using HMM. The word models are generated from the concatenation
of appropriate character models. In addition to the small date database,
we also make use of the legal amount database to increase the frequency
of characters in the training and the validation sets. Although this
study deals with a limited lexicon, the many similarities among the
word classes can affect the performance of the recognition. Experiments
show an increase in the average recognition rate from 84\% to 91\%.
Finally, we present our perspectives of future work},
author = {Morita, M and {El Yacoubi}, A and Sabourin, R and Bortolozzi, F and Suen, C Y},
booktitle = {Document Analysis and Recognition, 2001. Proceedings. Sixth International Conference on},
doi = {10.1109/ICDAR.2001.953930},
file = {:D$\backslash$:/Papers/Documents/2001/Morita et al. - 2001.pdf:pdf},
keywords = { ;hidden Markov models;image segmentation;,Brazilian bank cheques;HMM;Handwritten month word },
pages = {972--976},
title = {{Handwritten month word recognition on Brazilian bank cheques}},
year = {2001}
}
@inproceedings{ARAlamri2008,
abstract = {This paper presents the work toward developing a new comprehensive
database for Arabic off-line handwriting recognition. The database
includes: isolated Indian digits, numerical strings, Arabic isolated
letters,i and a collection of 70 Arabic words. Also, the database
includes a free format sample of an Arabic date. A data entry form
was designed to collect written samples from Arabic native speakers.
Our database is advanced in terms of the variety of sets, words and
number of the participants involved. The databases have been divided
into respective training, testing and validation sets which will
be available in the future for the handwriting recognition community.},
address = {Montreal, Canada},
author = {Alamri, Huda and Sadri, Javad and Suen, Ching Y and Nobile, Nicola},
booktitle = {Eleventh International Conference on Frontiers in Handwriting Recognition},
file = {:D$\backslash$:/Papers/Documents/2008/Alamri et al. - 2008.pdf:pdf},
keywords = { Arabic OCR, Farsi handwritten recognition, Handwritten Segmentation,Arabic Handwritten Recognition},
month = aug,
pages = {664--669},
title = {{A Novel Comprehensive Database for Arabic Off-Line Handwriting Recognition}},
year = {2008}
}
@inproceedings{Watt2009,
author = {Golubitsky, Oleg and Watt, Stephen M},
booktitle = {10th International Conference on Document Analysis and Recognition},
doi = {10.1109/ICDAR.2009.229},
file = {:D$\backslash$:/Papers/Documents/2009/Golubitsky, Watt - 2009.pdf:pdf},
pages = {1265--1269},
title = {{Online Recognition of Multi-Stroke Symbols with Orthogonal Series}},
year = {2009}
}
@inproceedings{DSZhang2002,
abstract = { A segmentation based courtesy amount recognition (CAR) system is
presented in this paper. A two-stage segmentation module has been
proposed, namely the global segmentation stage and the local segmentation
stage. At the global segmentation stage, a courtesy amount is coarsely
segmented into sub-images according to the spatial relationships
of the connected components. These sub-images are then verified by
the recognition module and the rejected sub-images are sequentially
split using contour analysis at the local segmentation stage. Two
neural network classifiers are combined into a recognition module.
The isolated digit classifier divides the input patterns into ten
numeral classes (0-9), while the holistic double zeros classifier
recognizes the cursive and touching double zeros. Experimental results
show that the system reads 66.5\% bank checks correctly at 0\% misreading
rate.},
author = {Zhang, L Q and Suen, C Y},
booktitle = {Frontiers in Handwriting Recognition, 2002. Proceedings. Eighth International Workshop on},
doi = {10.1109/IWFHR.2002.1030926},
file = {:D$\backslash$:/Papers/Documents/2002/Zhang, Suen - 2002.pdf:pdf},
keywords = { ; image classification; image segmentation; neura,CAR system; bank checks; connected components; cur},
pages = {298--302},
title = {{Recognition of courtesy amounts on bank checks based on a segmentation approach}},
year = {2002}
}
@article{Bazzi1999,
abstract = {We present an omnifont, unlimited-vocabulary OCR system for English and Arabic. The system is based on Hidden Markov Models (HMM), an approach that has proven to be very successful in the area of automatic speech recognition. In this paper we focus on two aspects of the OCR system. First, we address the issue of how to perform OCR on omnifont and multi-style data, such as plain and italic, without the need to have a separate model for each style. The amount of training data from each style, which is used to train a single model, becomes an important issue in the face of the conditional independence assumption inherent in the use of HMMs. We demonstrate mathematically and empirically how to allocate training data among the different styles to alleviate this problem. Second, we show how to use a word-based HMM system to perform character recognition with unlimited vocabulary. The method includes the use of a trigram language model on character sequences. Using all these techniques, we have achieved character error rates of 1.1 percent on data from the University of Washington English Document Image Database and 3.3 percent on data from the DARPA Arabic OCR Corpus.},
author = {Bazzi, I. and Schwartz, R. and Makhoul, J.},
doi = {10.1109/34.771314},
file = {:D$\backslash$:/Papers/Documents/1999/Bazzi, Schwartz, Makhoul - 1999.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Arabic OCR,Hidden Markov Models,Omnifont OCR,Optical character recognition,Reference From Doctor,language modeling,segmentation-free recognition.,speech recognition},
mendeley-tags = {Reference From Doctor},
month = jun,
number = {6},
pages = {495--504},
title = {{An omnifont open-vocabulary OCR system for English and Arabic}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=771314},
volume = {21},
year = {1999}
}
@conference{ARDaifallah2009,
abstract = {In this paper, we introduce an on-line Arabic handwritten recognition
system based on new stroke segmentation algorithm. The proposed algorithm
uses an over segmentation method that has the advantage of giving
all correct segments at least. It is based on arbitrary segmentation
followed by segmentation enhancement, consecutive joints connection
and finally segmentation point locating. The proposed system gives
an excellent recognition rate up to 97\% and 92\% for words and letter
recognition.},
author = {Daifallah, Khaled and Zarka, Dr. Nizar and Jamous, Hassan},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Daifallah, Zarka, Jamous - 2009.pdf:pdf},
title = {{Recognition-Based Segmentation Algorithm for On-Line Arabic Handwriting}},
year = {2009}
}
@article{Liu2004a,
abstract = {Online handwriting recognition is gaining renewed interest owing to the increase of pen computing applications and new pen input devices. The recognition of Chinese characters is different from western handwriting recognition and poses a special challenge. To provide an overview of the technical status and inspire future research, this paper reviews the advances in online Chinese character recognition (OLCCR), with emphasis on the research works from the 1990s. Compared to the research in the 1980s, the research efforts in the 1990s aimed to further relax the constraints of handwriting, namely, the adherence to standard stroke orders and stroke numbers and the restriction of recognition to isolated characters only. The target of recognition has shifted from regular script to fluent script in order to better meet the requirements of practical applications. The research works are reviewed in terms of pattern representation, character classification, learning/adaptation, and contextual processing. We compare important results and discuss possible directions of future research.},
author = {Liu, Cheng-Lin and Jaeger, Stefan and Nakagawa, Masaki},
doi = {10.1109/TPAMI.2004.1262182},
file = {:D$\backslash$:/Papers/Documents/2004/Liu, Jaeger, Nakagawa - 2004.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automatic Data Processing,China,Computer Graphics,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Natural Language Processing,Numerical Analysis, Computer-Assisted,Pattern Recognition, Automated,Reading,Reproducibility of Results,Review Literature as Topic,Sensitivity and Specificity,Signal Processing, Computer-Assisted,Subtraction Technique,Technology Assessment, Biomedical,User-Computer Interface,Vocabulary, Controlled},
month = feb,
number = {2},
pages = {198--213},
pmid = {15376895},
title = {{Online recognition of Chinese characters: the state-of-the-art.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15376895},
volume = {26},
year = {2004}
}
@inproceedings{Zalewski2008,
abstract = {Medicine has benefited widely from the use of computational techniques, which are often employed in the analysis of data generated in medical clinics. Among the computational techniques used in these analyses are those from Knowledge Discovery in Databases (KDD). In order to apply KDD techniques in the analysis of clinical data, it is often necessary to map them into an adequate structured format. This paper presents an extension in a methodology to map medical forms into struc- tured datasets, in which a sub-system for handwritten digit recognition is added to the overall mapping system},
author = {Zalewski, Willian and Lee, H. and Caetano, A. and Lorena, A. and Maletzke, A. and Fagundes, J. and Saddy, C. and Coy, R. and Wu, F.},
booktitle = {Advances in Bioinformatics and Computational Biology},
file = {:D$\backslash$:/Papers/Documents/2008/Zalewski et al. - 2008.pdf:pdf},
keywords = {digit recognition,machine learning,medical forms},
pages = {178--181},
publisher = {Springer},
title = {{Evaluation of Models for the Recognition of Hadwritten Digits in Medical Forms}},
url = {http://www.springerlink.com/index/l8217ww668114618.pdf},
year = {2008}
}
@inproceedings{Augustin,
abstract = {This paper presents a novel research investigation on legal amount recognition of unconstrained cursive handwritten Chinese character in the environment of A2iA CheckReaderÃ¢âÂ¢ Ã¢â¬â a commercial bank check recognition system. The following problems and their solutions are described: character set of Chinese legal amounts, preprocessing (slant detection and correction), segmentation, feature extraction, grammar, automatic annotation of Chinese characters before and during training, and neural training and recognition. The system is trained with 47.8 thousand real bank checks, and validated with 12 thousand real bank checks. The recognition rate at the character level is 93.5\%, and the recognition rate at the legal amount level is 60\%. This is the first successful commercial product in this domain},
author = {Augustin, E. and Suen, C.Y. and Baret, O. and Cheriet, M.},
booktitle = {Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.},
doi = {10.1109/ICPR.2004.1334322},
file = {:D$\backslash$:/Papers/Documents/2004/Augustin et al. - 2004.pdf:pdf},
isbn = {0-7695-2128-2},
pages = {610--613},
publisher = {Ieee},
title = {{Recognition of unconstrained legal amounts handwritten on chinese bank checks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1334322},
year = {2004}
}
@article{Awaidah2009a,
author = {Awaidah, Sameh M. and Mahmoud, Sabri a.},
doi = {10.1016/j.sigpro.2008.12.022},
file = {:D$\backslash$:/Papers/Documents/2009/Awaidah, Mahmoud - 2009.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
month = jun,
number = {6},
pages = {1176--1184},
title = {{A multiple feature/resolution scheme to Arabic (Indian) numerals recognition using hidden Markov models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S016516840900005X},
volume = {89},
year = {2009}
}
@inproceedings{Siriboon2002,
abstract = {Researchers have extensively applied Hidden Markov Model (HMM) to handwritten recognition in English, Chinese, and other languages. Most researchers have been using the left-right topology for handwritten and speech recognition. This research studied the effect of HMM topology on isolated on- line Thai handwritten recognition. The left-right, fully connected and the proposed topologies (left-right-left) were compared. The number of state of a character HMM for each topology was varied from 15 to 35 nodes and the one with the best training observations probability was selected. The feature used was Chain code-like with modification to represent originated quadrant position. The recognition results showed that the proposed topology increases the recognition rate in comparison to the most widely used left-right topology.},
annote = {===========================================

Paper Index : Siriboon2002

Date:22-11-2010



Why read paper ?

HMM background



Paper Overview ?

HMM or chain code features with online
the paper focus on toplogy change of hmm and comparison.



What is these paper about ? (Summary)

online data are resampled to make point ahve same distance.
chain code extracted.
there is tow types of chain code one for upper part of character other for lower partof character.
training HMM one for each character where trainig HMM using baum welch.
Different topolgy of hmm is teat ( FC (fully connected), LR (left right), LRL (left - right - left)).
see fig 3.



Result :

no discription of data, only tested topology vs. no of states and the parameters of hmm.
best result was on LRL with best No of states is 95.67\%.





1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?

The simple chain code features.

2. What can we take from this work  ? what do we learn ? What can be incorporated into our own work ?



Changing the chain code from upper to lower to get more feature and distinguish characters.



3. What are the problems of the paper ?



No data discriptions and analysis number of classes or number of sample per class.



4. what is lacking from the work ? why does this work knot be the final  research in this subject ?




5. what about the methods causes this lack ? is there a fundamental reason ?




6. Could incremental Changes Fix this lack ? if so, what changes ?






Is there is any question you had about the paper ?






The final conclusion..........

Simple but with no real indication of comparing system with others.


==========================================================================

      },
author = {Siriboon, Kritawan and Jirayusakul, Apirak and Kruatrachue, Boontee},
booktitle = {Proceedings of the First International Symposium on Cyber Worlds (CWÃ¢â¬â¢02)},
file = {:D$\backslash$:/Papers/Documents/2002/Siriboon, Jirayusakul, Kruatrachue - 2002.pdf:pdf},
keywords = {Arabic Handwritting recognition,HMM,Read,Summarized,on-line handwriting recognition},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
pages = {0142},
publisher = {Published by the IEEE Computer Society},
title = {{Hmm topology selection for on-line thai handwritten recognition}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/CW.2002.1180872},
year = {2002}
}
@inproceedings{Tokuno2006,
abstract = {This paper describes stochastic modeling of pen- coordinate information in HMMs with structured character pattern representation (SCPR) for on-line Japanese handwriting recognition. SCPR allows HMMs for Kanji character patterns to share common subpatterns. Although SCPR-based HMMs have been successfully applied to Kanji character recognition, the pen-coordinate feature has not been modeled since it is unique feature in each character pattern. In this paper, we employ mapping from a common subpattern to each occurrence in Kanji patterns and adaptation of state parameters to each character pattern in generating character HMMs by composing SCPR- based HMMs. Experimental results show that the pen- coordinate feature modeled in the SCPR-based HMMs effects significantly.},
author = {Tokuno, Junko and Yang, Yiping and da Silva, G.P. and Kitadai, Akihito and Nakagawa, Masaki},
booktitle = {Pattern Recognition, 2006. ICPR 2006. 18th International Conference on},
file = {:D$\backslash$:/Papers/Documents/2006/Tokuno et al. - 2006.pdf:pdf},
isbn = {0769525210},
issn = {1051-4651},
pages = {348--351},
publisher = {IEEE},
title = {{Pen-coordinate information modeling by scpr-based hmm for on-line japanese handwriting recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1699537},
volume = {3},
year = {2006}
}
@conference{ARMargner2009,
abstract = {This paper describes the Online Arabic handwriting recognition competition
held at ICDAR 2009. This first competition uses the ADAB-database
with Arabic online handwritten words. This year, 3 groups with 7
systems are participating in the competition. The systems were tested
on known data (sets 1 to 3) and on one test dataset which is unknown
to all participants (set 4). The systems are compared on the most
important characteristic of classification systems, the recognition
rate. Additionally, the relative speed of the different systems were
compared. A short description of the participating groups, their
systems, the experimental setup, and the performed results are presented.},
author = {Abed, Haikal El and Margner, Volker and Kherallah, Monji and Alimi, Adel M},
booktitle = {2009 10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Abed et al. - 2009.pdf:pdf},
title = {{ICDAR 2009 Online Arabic Handwriting Recognition Competition}},
year = {2009}
}
@article{Pal2009,
author = {Pal, Umapada and Roy, Rami Kumar and Roy, Kaushik and Kimura, Fumitaka},
doi = {10.1109/ICDAR.2009.171},
file = {:D$\backslash$:/Papers/Documents/2009/Pal et al. - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {456--460},
publisher = {Ieee},
title = {{Indian Multi-Script Full Pin-code String Recognition for Postal Automation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277632},
year = {2009}
}
@inproceedings{ARMoussa2008,
abstract = {In this paper, we present multilingual automatic identification of
Arabic and Latin in both handwritten and printed script. The proposed
scheme is based, Firstly, on morphological transform of line text
images, secondly on fractal analysis features of both (i): original
texture of 2-D images, (ii): vertical and horizontal profile projection.
We used two techniques to obtain only 12 features based on fractal
multidimension. The proposed system has been tested for 1000 prototypes
with various typefaces, scriptors styles and sizes. The accuracy
discrimination rate is about of 96.64 \% by using KNN, and 98.72 \%
by using RBF. Experimental results show the importance of the proposed
approach.},
address = {Tampa, Florida, USA},
author = {Moussa, S Ben and Zahour, A and Benabdelhafid, A and Alimi, A M},
booktitle = {19th International Conference on Pattern Recognition (ICPR 2008)},
file = {:D$\backslash$:/Papers/Documents/2008/Moussa et al. - 2008.pdf:pdf},
month = dec,
title = {{Fractal-Based System for Arabic/Latin, Printed/Handwritten Script Identification}},
year = {2008}
}
@article{ARCavalin2009,
abstract = {We present an evaluation of incremental learning algorithms for the
estimation of hidden Markov model (HMM) parameters. The main goal
is to investigate incremental learning algorithms that can provide
as good performances as traditional batch learning techniques, but
incorporating the advantages of incremental learning for designing
complex pattern recognition systems. Experiments on handwritten characters
have shown that a proposed variant of the ensemble training algorithm,
employing ensembles of HMMs, can lead to very promising performances.
Furthermore, the use of a validation dataset demonstrated that it
is possible to reach better performances than the ones presented
by batch learning.},
author = {PauloR.Cavalina and RobertSabourina and ChingY.Suenb and AlceuS.BrittoJr},
file = {:D$\backslash$:/Papers/Documents/2009/PauloR.Cavalina et al. - 2009.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Incremental learning; Hidden Markov models; Ensemb},
month = dec,
number = {12},
pages = {3241--3253},
title = {{Evaluation of incremental learning algorithms for HMM in the recognition of alphanumeric characters}},
volume = {42},
year = {2009}
}
@article{Bhattacharya2005,
author = {Bhattacharya, U. and Chaudhuri, B.B.},
doi = {10.1109/ICDAR.2005.84},
file = {:D$\backslash$:/Papers/Documents/2005/Bhattacharya, Chaudhuri - 2005.pdf:pdf},
isbn = {0-7695-2420-6},
journal = {Eighth International Conference on Document Analysis and Recognition (ICDAR'05)},
pages = {789--793},
publisher = {Ieee},
title = {{Databases for Research on Recognition of Handwritten Characters of Indian Scripts}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1575653},
year = {2005}
}
@article{Zanchettin2006,
author = {Zanchettin, C. and Cavalcanti, G.D.C. and Doria, R.C. and Silva, E.F.a. and Rabelo, J.C.B. and Bezerra, B.L.D.},
doi = {10.1109/IJCNN.2006.1716535},
file = {:D$\backslash$:/Papers/Documents/2006/Zanchettin et al. - 2006.pdf:pdf},
isbn = {0-7803-9490-9},
journal = {The 2006 IEEE International Joint Conference on Neural Network Proceedings},
number = {000185},
pages = {3210--3217},
publisher = {Ieee},
title = {{A neural architecture to identify courtesy amount delimiters}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1716535},
year = {2006}
}
@article{Gader1997,
abstract = {An off-line handwritten word recognition system is described. Images of handwritten words are matched to lexicons of candidate strings. A word image is segmented into primitives. The best match between sequences of unions of primitives and a lexicon string is found using dynamic programming. Neural networks assign match scores between characters and segments. Two particularly unique features are that neural networks assign confidence that pairs of segments are compatible with character confidence assignments and that this confidence is integrated into the dynamic programming. Experimental results are provided on data from the U.S. Postal Service.},
author = {Gader, P D and Mohamed, M and Chiang, J H},
doi = {10.1109/3477.552199},
file = {:D$\backslash$:/Papers/Documents/1997/Gader, Mohamed, Chiang - 1997.pdf:pdf},
issn = {1083-4419},
journal = {IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = jan,
number = {1},
pages = {158--64},
pmid = {18255853},
title = {{Handwritten word recognition with character and inter-character neural networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18255853},
volume = {27},
year = {1997}
}
@article{Fujisawa2008,
abstract = {This paper presents an overview on the last 40-years of technical advances in the field of character and document recognition. Representative developments in each decade are described. Then, key technical developments in the specific area of Kanji recognition in Japan are highlighted. The main part of the paper discusses robustness design principles, which have proven to be effective to solve complex problems in postal address recognition. Included are the hypothesis-driven principle, deferred decision/multiple-hypotheses principle, information integration principle, alternative solution principle, and perturbation principle. Finally, future prospects, the Ã¢â¬Ëlong-tailÃ¢â¬â¢ phenomena, and promising new applications are discussed.},
annote = {(Reading order = 4) Mainly industrial view from 60 til 90's.


Application of character is form reading, bank check and postal address reading . Discuss comercial systems in OCR by ibm, hitachi from 60,70,80 and 90's.
Mentions state of art in
M. Cheriet, N. Kharma, C.-L. Liu, C. Y. Suen; Character Recognition Systems: A Guide for Students and Practitioners, John Wiley \& Sone, November 2007, ISBN: 978-0-471-41570-
Focus on Kanji characters, the approaches of recognition can be structural or statistical. Mentions also the directional features are effictive.


Mentions Character segmentation algorithms and the integration of linguistics information to add knowldge which helps recognition.




Robustness desing to datl with uncertainity and variablity by
1)Principles Expected effects
P1 Hypothesis-driven principle When type of a problem is uncertain, set up hypotheses and test them
P2 Deferred decision/multiple hypotheses principle Do not decide; leave decision to next experts carrying over multiple hypotheses
 P3a Process integration Solve a problem by multiple different-field experts as a team
 P3b Information integration principle Combination-based integration Decide as a team of multiple same-field experts
 P3c Corroboration-based integration Utilize other input information; seek more evidence
P4 Alternative solutions principle Solve a problem by multiple alternative approaches
P5 Perturbation principle Modify problem slightly and try again},
author = {Fujisawa, H},
doi = {10.1016/j.patcog.2008.03.015},
file = {:D$\backslash$:/Papers/Documents/2008/Fujisawa - 2008.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Character Recognition,Japanese or Chinese Characters,OCR,Postal Adress Design,Read,Robustness design,Survey},
mendeley-tags = {Read,Survey},
month = aug,
number = {8},
pages = {2435--2446},
title = {{Forty years of research in character and document recognitionÃ¢â¬âan industrial perspective}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308000964},
volume = {41},
year = {2008}
}
@inproceedings{PDB14Hamamura2003,
abstract = {In this paper, a new method of composing a multiclass classifier using
pairwise classifiers is proposed. A Ã¯Â¿Â½Resemblance ModelÃ¯Â¿Â½ is exploited
to calculate a posteriori probability for combining pairwise classifiers.
We proved the validity of this model by using approximation of a
posteriori probability formula. Using this theory, we can obtain
the optimal decision. An experimental result of handwritten numeral
recognition is presented, supporting the effectiveness of our method.},
address = {Edinburgh, Scotland, UK},
author = {Hamamura, Tomoyuki and Mizutani, Hiroyuki and Irie, Bunpei},
booktitle = {7th International Conference on Document Analysis and Recognition (ICDAR 2003)},
doi = {http://csdl.computer.org/comp/proceedings/icdar/2003/1960/02/196020809abs.htm},
file = {:D$\backslash$:/Papers/Documents/2003/Hamamura, Mizutani, Irie - 2003.pdf:pdf},
isbn = {0-7695-1960-1},
pages = {809--813},
publisher = {IEEE Computer Society},
title = {{A Multiclass Classification Method Based on Multiple Pairwise Classifiers.}},
volume = {2-Volume S},
year = {2003}
}
@article{Liu2003,
author = {Liu, C},
doi = {10.1016/S0031-3203(03)00085-2},
file = {:D$\backslash$:/Papers/Documents/2003/Liu - 2003.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {art,discriminative learning,feature extraction,handwritten digit recognition,pattern classi\"{y}cation,support,the state of the},
month = oct,
number = {10},
pages = {2271--2285},
title = {{Handwritten digit recognition: benchmarking of state-of-the-art techniques}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320303000852},
volume = {36},
year = {2003}
}
@article{MCZhang2007,
abstract = {This paper presents a novel cascade ensemble classifier system for
the recognition of handwritten digits. This new system aims at attaining
a very high recognition rate and a very high reliability at the same
time, in other words, achieving an excellent recognition performance
of handwritten digits. The trade-offs among recognition, error, and
rejection rates of the new recognition system are analyzed. Three
solutions are proposed: (i) extracting more discriminative features
to attain a high recognition rate, (ii) using ensemble classifiers
to suppress the error rate and (iii) employing a novel cascade system
to enhance the recognition rate and to reduce the rejection rate.
Based on these strategies, seven sets of discriminative features
and three sets of random hybrid features are extracted and used in
the different layers of the cascade recognition system. The novel
gating networks (GNs) are used to congregate the confidence values
of three parallel artificial neural networks (ANNs) classifiers.
The weights of the GNs are trained by the genetic algorithms (GAs)
to achieve the overall optimal performance. Experiments conducted
on the MNIST handwritten numeral database are shown with encouraging
results: a high reliability of 99.96\% with minimal rejection, or
a 99.59\% correct recognition rate without rejection in the last cascade
layer.},
author = {Zhang, Ping and Bui, Tien D and Suen, ChingY.},
file = {:D$\backslash$:/Papers/Documents/2007/Zhang, Bui, Suen - 2007.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Handwritten digit recognition; Hybrid feature extr},
pages = {3415 Ã¯Â¿Â½ 3429},
title = {{Anovel cascade ensemble classifier system with a high recognition performance on handwritten digits}},
volume = {40},
year = {2007}
}
@inproceedings{Iwata2009,
author = {Iwata, Kazumasa and Kise, Koichi and Nakai, Tomohiro and Iwamura, Masakazu and Uchida, Seiichi and Omachi, Shinichiro},
booktitle = {Document Analysis and Recognition, 2009. ICDAR'09. 10th International Conference on},
doi = {10.1109/ICDAR.2009.192},
file = {:D$\backslash$:/Papers/Documents/2009/Iwata et al. - 2009.pdf:pdf},
issn = {1520-5363},
pages = {1236--1240},
publisher = {IEEE},
title = {{Capturing digital ink as retrieving fragments of document images}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5277653},
year = {2009}
}
@article{Vuong2010,
abstract = {The emergence of pen-based mobile devices such as PDAs and tablet PCs provides a new way to input mathematical expressions to computer by using handwriting which is much more natural and efficient for entering mathematics. This paper proposes a web-based handwriting mathematics system, called WebMath, for supporting mathematical problem solving. The proposed WebMath system is based on cli- entÃ¢â¬âserver architecture. It comprises four major components: a standard web server, handwriting math- ematical expression editor, computation engine and web browser with Ajax-based communicator. The handwriting mathematical expression editor adopts a progressive recognition approach for dynamic rec- ognition of handwritten mathematical expressions. The computation engine supports mathematical functions such as algebraic simplification and factorization, and integration and differentiation. The web browser provides a user-friendly interface for accessing the system using advanced Ajax-based com- munication. In this paper, we describe the different components of the WebMath system and its perfor- mance analysis. Ã®â¬â},
author = {Vuong, Ba-Quy and He, Yulan and Hui, Siu Cheung},
doi = {10.1016/j.eswa.2009.05.091},
file = {:D$\backslash$:/Papers/Documents/2010/Vuong, He, Hui - 2010.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {progressive handwriting recognition,progressive structural analysis,web-based handwriting mathematics},
month = jan,
number = {1},
pages = {886--893},
publisher = {Elsevier Ltd},
title = {{Towards a web-based progressive handwriting recognition environment for mathematical problem solving}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0957417409005193},
volume = {37},
year = {2010}
}
@inproceedings{PDBLuo2005,
abstract = {We present two optimization algorithms for the design of a cascade
of classifiers, which is becoming a popular choice formany classification
problems. Both algorithms represent each node classifier of a cascade
using a high-level abstraction model and attempt to jointly optimize
the setting of the thresholding parameters of all the node classifiers
within the cascade. We applied both algorithms to optimize the famous
Viola and Jones face detector and one of them in particular greatly
improved the performance. We believe both algorithms can serve as
a useful post-processing process for general cascaded classifier
design},
address = {San Diego, CA, USA},
author = {Luo, Huitao},
booktitle = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2005)},
doi = {http://dx.doi.org/10.1109/CVPR.2005.266},
file = {:D$\backslash$:/Papers/Documents/2005/Luo - 2005.pdf:pdf},
isbn = {0-7695-2372-2},
pages = {480--485},
publisher = {IEEE Computer Society},
title = {{Optimization Design of Cascaded Classifiers.}},
year = {2005}
}
@inproceedings{DSSAMOUD2008,
abstract = {This paper presents an automatic extraction of handwritten Arabic
components of complex documents. Two methods are developed for this
extraction. The first one is based on Mathematical Morphology (MM).
The second one is based on Hough Transform (HT). The developed methods
are evaluated on CENPARMI-Arabic Checks Database, in order to extract
the handwritten components existing in the check: numerical amount,
literal amount and date zone. We present a concept for automatic
evaluation of the results, based on label tools for the different
parts of used documents. We achieve a correct classification rate
of 98\% for numerical amount, 96\% for literal amount, and 98\% for
date, extracted by Hough Transform method.},
author = {SAMOUD, Fadoua BOUAFIF and MADDOURI, Samia SNOUSSI and ABED, Haikal E L and ELLOUZE, Noureddine},
booktitle = {The 11th International Conference on Frontiers in Handwriting Recognition},
file = {:D$\backslash$:/Papers/Documents/2008/SAMOUD et al. - 2008.pdf:pdf},
keywords = { CENPARMIDatabase., Extraction methods, Hough Transform, Mathematical Morphology,Document processing},
title = {{COMPARISON OF TWO HANDWRITTEN ARABIC ZONES EXTRACTION METHODS OF COMPLEX DOCUMENTS}},
year = {2008}
}
@inproceedings{FE6Tsymbal2002,
abstract = {This paper shows the importance of the use of class information in
feature extraction for classification and inappropriateness of conventional
PCA to feature extraction for classification. We consider two eigenvector-based
approaches that take into account the class information. The first
approach is parametric and optimizes the ratio of between-class variance
to within-class variance of the transformed data. The second approach
is a nonparametric modification of the first one based on local calculation
of the between-class covariance matrix. We compare the two approaches
with each other, with conventional PCA, and with plain nearest neighbor
classification without feature extraction.},
address = {Pensacola Beach, Florida, USA},
author = {Tsymbal, Alexey and Puuronen, Seppo and Pechenizkiy, Mykola and Baumgarten, Matthias and Patterson, David W},
booktitle = {Proceedings of the Fifteenth International Florida Artificial Intelligence Research Society Conference, May 14-16, 2002, Pensacola Beach, Florida, USA},
editor = {Haller, Susan M and Simmons, Gene},
file = {:D$\backslash$:/Papers/Documents/2002/Tsymbal et al. - 2002.pdf:pdf},
isbn = {1-57735-141-X},
keywords = {Features Extraction},
month = may,
pages = {354--358},
publisher = {AAAI Press},
title = {{Eigenvector-Based Feature Extraction for Classification.}},
year = {2002}
}
@article{MCLee1999,
abstract = {This paper presents a recognition system which obtains a recognition
rate higher than 99\% for the printed Korean characters of multifont
and multisize. We recognize a given input by "rst identifying the
character type of the input and then recognizing its constituent
graphemes. In order to improve the performance we incorporated three
new ideas in our system: the expansion of the subimage areas used
by the grapheme classi"ers, an algorithm to accurately segment the
horizontal vowel's subimage areas, and a validation process to evaluate
the result of the type classi"er. Through experiments we con"rmed
that our system performs well in a multi-font and multi-size environment
and that those three ideas actually contributed to improve the performance
signi"cantly},
author = {Lee, Jin-Soo and Kwon, Oh-Jun and Bang, Sung-Yang},
file = {:D$\backslash$:/Papers/Documents/1999/Lee, Kwon, Bang - 1999.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Korean characters; OCR; Neural networks; Multi-fon},
pages = {1935--1945},
title = {{Highly accurate recognition of printed Korean characters through an improved two-stage classication method}},
volume = {32},
year = {1999}
}
@incollection{ARCheriet2007,
abstract = {From the administrative point of view, cheque processing involves
all tasks a bank officer may perform to process an incoming cheque
for a client. This includes: accessing account numbers, verifying
names and signatures on the cheque, verifying the date of the cheque,
matching the legal amount with the courtesy amount and verifying
the credit of the cheque writer. However, from the technical point
of view, cheque processing could involve capturing the cheque image,
separating the foreground of the cheque from its background, extracting
fields of interest and recognizing each of them. This work employs
theories and methodologies from various fields ranging from Natural
language processing, Optical Character Recognition to Banking.

The motivation of the work on Cheque processing is not less than the
motivation of the entire research in artificial intelligence, which
aims to program the computer to carry out tedious routine processes,
freeing time and space for humans to perform tasks that require higher
levels of intelligence. A major advantage of such study is that it
can be easily adjusted to serve more than 20 different countries
(all of them use Arabic as their first language). In addition, legal
amounts are widely found in documents other than bank cheques (e.g.
business sell/purchase forms). Therefore, this study will be applicable
to a wide range of applications. Moreover, similar languages (e.g.
Urdu, Farisi) which use the same alphabet can benefit from these
studies.

The remaining sections provide a description of datasets available
for researchers as well as a detailed description of one system that
processes legal amounts and one system dedicated for processing of
courtesy amount},
author = {Cheriet, M and Al-Ohali, Y and Ayat, N E and Suen, C Y},
booktitle = {Digital Document Processing},
doi = {http://dx.doi.org/10.1007/978-1-84628-726-8\_10},
file = {:D$\backslash$:/Papers/Documents/2007/Cheriet et al. - 2007.pdf:pdf},
keywords = { Cheque processing,Arabic Handwriting},
pages = {213--234},
publisher = {Springer London},
series = {Advances in Pattern Recognition},
title = {{Arabic Cheque Processing System: Issues and Future Trends}},
year = {2007}
}
@article{Mohamed1996,
author = {Mohamed, Magdi and Gader, Paul},
doi = {10.1109/TNB.2008.2005325},
file = {:D$\backslash$:/Papers/Documents/1996/Mohamed, Gader - 1996.pdf:pdf},
issn = {1558-2639},
journal = {IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = oct,
number = {8},
pages = {548--554},
pmid = {20952322},
title = {{Hidden Word Recognition using segmentatino free hidden markov modeling and segmentation - based dynamic programming techniques}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20952322},
volume = {18},
year = {1996}
}
@phdthesis{ThesisSaid1997,
abstract = {Automatic processing of documents with the purpose to scan different
documents, recognize them, extract, and process different data items
obtained from them could be achieved by top-down and bottom-up approaches.
The former processes documents starting from the document class and
ends with the pixel representation of the different items that should
be extracted. The latter, however, processes documents in a reversed
manner. In this thesis, a top-down formal approach for automatic
processing of documents and bank cheques is proposed. This approach
will view a document as a hierarchy of related items: (a) the background
which contains simple or complex scenes that should be eliminated,
and (b) the foreground which contains (i) base lines that must be
removed and (ii) handwritten data, such as the date, the legal amount,
and the courtesy amount, that should be extracted with minimum distortion.
The novelty of this new approach is to eliminate the background,
first, by introducing a new recursive dynamic thresholding technique
that could be used globally or locally on a given cheque image. As
a second step, base lines that intersect the handwritten data are
recognized and removed with the challenge of minimizing the distortion
on the extracted items. Two methods are proposed to tackle this difficulty.
The first method detects the handwritten data that intersects with
the base lines that should be eliminated and uses morphological and
topological processing to identify and fill the gaps resulting from
the elimination of the detected base lines. The second method proposed
a new dynamic morphological processing technique which acts as a
detector and a preserver of the handwritten data that intersect,
with the base lines. The second method highly increased the efficiency
of item extraction by more than 80\% and enhanced the quality of the
extracted items when combined with local processing techniques. In
a step to study the reliability of the proposed top-down automatic
item extraction system, a quantitative analysis technique is investigated
and an experimental study is performed comparing the top-down formal
approach with another newly developed bottom-up approach using the
same training set of 500 real-life bank cheques and two testing sets
of 200 bank cheques obtained from the CENPARMI database. The purpose
of the quantitative performance analysis technique is to subject
the extracted items of the top-down and the bottom-up approaches
to the same item processing system that is able to recognize these
corresponding items and provide quantitative results to indicate
the reliability of both approaches. The experimental results showed
that the reliability of the top-down approach on the training set.
first testing set, and second testing set are 89.20\%, 87.91\%, and
90.10\% respectively while those on the bottom-up approach are 91.35\%,
91.30\%, and 93.10\%, respectively. Finally, in a step towards the
construction of a highly reliable system, a feasibility study has
been conducted by combining both approaches. The result is quite
encouraging and a reliability of 97.09\% has been achieved when these
two systems are combined},
annote = {Thesis Advisor:Suen, Ching Y},
author = {Said, Joseph Nassif},
file = {:D$\backslash$:/Papers/Documents/1997/Said - 1997.pdf:pdf},
school = {Concordia University.},
title = {{Automatic processing of documents and bank cheques}},
year = {1997}
}
@inproceedings{Abed2009,
abstract = {Arabic character and text recognition methods for printed or handwritten characters are known since many years. We present in the first part of this paper a state of the art of Arabic text classification techniques and existing recognition systems. In the second part we discuss how evaluation methods and competitions help to support the development of text recognition systems and methods. Based on the results of the last Arabic handwriting recognition competitionwe show a concept to develop efficient recognition systems. On the basis of the actual situation of research future trends are de- scribed in the last part of this paper},
author = {Abed, Haikal El},
booktitle = {Innovations in Information Technology,},
file = {:D$\backslash$:/Papers/Documents/2009/Abed - 2009.pdf:pdf},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {692--696},
title = {{Arabic text recognition systems-state of the art and future trends}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4781781},
year = {2009}
}
@article{Neves2008,
author = {Neves, R.F.P. and Mello, C.a.B. and Silva, M.S. and Bezerra, B.L.D.},
doi = {10.1109/IWSSIP.2008.4604375},
file = {:D$\backslash$:/Papers/Documents/2008/Neves et al. - 2008.pdf:pdf},
isbn = {978-80-227-2856-0},
journal = {2008 15th International Conference on Systems, Signals and Image Processing},
keywords = {2 presents a sample,all of,check and the distribution,check processing,checks,fig,identification code,in spite of the,locations of the,them have to use,these areas in specific,thresholding,tsallis entropy,variety of banks},
month = jun,
pages = {93--96},
publisher = {Ieee},
title = {{A new technique to threshold the courtesy amount of Brazilian bank checks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4604375},
volume = {2},
year = {2008}
}
@article{Koerich2003,
author = {Koerich, Alessandro L.},
doi = {10.1007/s10032-003-0113-0},
file = {:D$\backslash$:/Papers/Documents/2003/Koerich - 2003.pdf:pdf},
journal = {International Journal on Document Analysis and Recognition},
keywords = {Reference From Doctor,handwriting recognition,hidden markov models,large vocabu-,lary,level building algorithm},
mendeley-tags = {Reference From Doctor},
month = oct,
number = {2},
pages = {126--144},
title = {{Lexicon-driven HMM decoding for large vocabulary handwriting recognition with multiple character models}},
volume = {6},
year = {2003}
}
@inproceedings{ARSubramanian2009,
abstract = {Text from Arabic optical handwriting recognition (OHR) systems can
provide key indexing information. In particular, the text is rich
in named entities (NEs) and detection of such entities is critical
for search applications. Traditional approaches for detecting NEs
in optical character recognition (OCR) output look for these NEs
in the single-best recognition results. Due to the inevitable presence
of recognition errors in the single-best output, such approaches
usually result in low recall. Given that a lattice is more likely
to contain the correct answer, we explore NE detection from word
lattices produced by our Arabic handwriting recognition system. Since
the improvement in recall is accompanied by a large number of false
positives, we use confidence scores based on posterior scores to
control precision. We show a 7\% improvement in true detects for the
same false acceptance rate on using lattices instead of 1-best hypothesis
for NE lookup.},
address = {Barcelona, Spain},
author = {Subramanian, Krishna and Prasad, Rohit and Natarajan, Prem},
booktitle = {AND '09: Proceedings of The Third Workshop on Analytics for Noisy Unstructured Text Data},
doi = {http://doi.acm.org/10.1145/1568296.1568308},
file = {:D$\backslash$:/Papers/Documents/2009/Subramanian, Prasad, Natarajan - 2009.pdf:pdf},
isbn = {978-1-60558-496-6},
pages = {63--68},
publisher = {ACM},
title = {{Robust named entity detection using an Arabic offline handwriting recognition system}},
year = {2009}
}
@inproceedings{ARHUSSAIN2000,
abstract = {The goal to produce effective Optical Character

Recognition (OCR) methods has lead to the

development of a number of algorithms. The

purpose of these is to take the hand-written or

printed text and to translate it into a

corresponding digital form. The multitude

requirements and developments are well

represented in the literature ( see for example

Abuhaiba [ 1 J and Suen [2 J ).

The primary objective of this paper is to provide

an insight into a robust system which has been

successfully developed and employed to

recognise Latin and Arabic characters and

whose workings has been described by the

authors in a sister publication [ 3 J .The focus

here is to discuss the main components used in

the multi-stage system, paying particular

attention to the nonnalisation process used for

orientation and size for a given bitmapped

character. The effectiveness of the approach is

demonstrated through its workings for the Arabic

and Latin case, both for characters and numbers.},
author = {HUSSAIN, FIAZ and COWELL, JOHN},
booktitle = {IEEE International Conference on Information Visualization (IV'00)},
file = {:D$\backslash$:/Papers/Documents/2000/HUSSAIN, COWELL - 2000.pdf:pdf},
keywords = { Latin, OCR, confusion matrix., fonts, nonnalisation, pattern recognition,Arabic},
title = {{Character Recognition of Arabic and Latin Scripts}},
year = {2000}
}
@article{Mozaffari2006,
abstract = {This paper presents a new comprehensive database for isolated offline handwritten Farsi/Arabic numbers and characters for use in optical character recognition research. The database is freely available for academic use. So far no such a freely database in Farsi language is available. Grayscale images of 52,380 characters and 17,740 numerals are included. Each image was scanned from Iranian school entrance exam forms during the years 2004-2006 at 300 dpi. The only restriction imposed on the writers is to write each character within a rectangular box. The number of samples in each class of the database is non-uniform corresponding to their real life distributions. Also, for comparison purposes, each dataset has been properly divided into respective training and test sets.},
author = {Mozaffari, Saeed and Faez, Karim and Faradji, Farhad and Ziaratban, Majid and Golzan, S.M.},
 journal = {Electrical Engineering},
keywords = {arabic,comparative database,farsi,isolated characters or assuming,isolated numbers and characters,it is notable that,most of the above,ocr,offline,that the farsi,work was done on},
title = {{A comprehensive isolated Farsi/Arabic character database for handwritten OCR research}},

year = {2006}
}
@article{Elbaati2009,
author = {Elbaati, Abdelkarim and Boubaker, Houcine and Kherallah, Monji and Ennaji, Abdellatif and Abed, Haikal El and Alimi, Adel M.},
doi = {10.1109/ICDAR.2009.262},
file = {:D$\backslash$:/Papers/Documents/2009/Elbaati et al. - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {411--415},
publisher = {Ieee},
title = {{Arabic Handwriting Recognition Using Restored Stroke Chronology}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277647},
year = {2009}
}
@inproceedings{DSDimauro2002,
abstract = { This paper presents a new database for off-line handwriting recognition.
The database, that is particularly devoted to research on bank-check
recognition, up to now includes instances of isolated digits and
characters, basic words of worded amounts, and signatures. Pattern
images are stored using a standard image format, and hence they are
easily usable by several commercial and scientific image processing
packages.},
author = {Dimauro, G and Impedovo, S and Modugno, R and Pirlo, G},
booktitle = {Frontiers in Handwriting Recognition, 2002. Proceedings. Eighth International Workshop on},
doi = {10.1109/IWFHR.2002.1030964},
file = {:D$\backslash$:/Papers/Documents/2002/Dimauro et al. - 2002.pdf:pdf},
keywords = { ; visual databases;,bank-check processing; bank-cheque processing; dat},
pages = {524--528},
title = {{A new database for research on bank-check processing}},
year = {2002}
}
@article{DSKoch2005,
abstract = {In this paper, we propose a method for the automatic extraction of
numerical fields in handwritten documents. The approach exploits
the known syntactic structure of the numerical field to extract,
combined with a set of contextual morphological features to find
the best label for each connected component. Applying a Markov model
based syntactic analyzer on the overall document allows to localize/extract
fields of interest. Reported results on the extraction of zip codes,
phone numbers and customer codes from handwritten incoming mail documents
demonstrate the interest of the proposed approach.},
author = {Koch, G and Heutte, L and Paquet, T},
doi = {DOI: 10.1016/j.patrec.2004.10.006},
file = {:D$\backslash$:/Papers/Documents/2005/Koch, Heutte, Paquet - 2005.pdf:pdf},
issn = {0167-8655},
journal = {Pattern Recognition Letters},
keywords = {Document analysis},
number = {8},
pages = {1118--1127},
title = {{Automatic extraction of numerical sequences in handwritten incoming mail documents}},
url = {http://www.sciencedirect.com/science/article/B6V15-4DTTHDM-5/2/2325ca93a5882505f71e923c7a1d52e9},
volume = {26},
year = {2005}
}
@article{Halavati2007,
abstract = {Persian is a fully cursive handwriting in which each character may take different forms in different parts of the word, characters overlap and there is a wide range of possible styles. These complexities make automatic recognition of Persian a very hard task. This paper presents a novel approach on recognition of such writings systems which is based on the description of input stream by a sequence of fuzzy linguistic terms; representation of character patterns with the same descriptive language; and comparison of inputs with character patterns using a novel elastic pattern matching approach. As there is no general benchmark for recognition of Persian handwriting, the approach has been tested on the set of words in first primary Iranian school books including 1250 words resulting in 78\% correct recognition without dictionary and 96\% with dictionary.},
author = {Halavati, Ramin and Shouraki, Saeed Bagheri},
file = {:D$\backslash$:/Papers/Documents/2007/Halavati, Shouraki - 2007.pdf:pdf},
journal = {International Journal of Pattern Recognition and Artificial Intelligence},
keywords = {elastic pattern matching,fuzzy modeling,online handwriting recognition},
number = {3},
pages = {491--513},
title = {{USING ELASTIC FUZZY PATTERN RECOGNITION}},
volume = {21},
year = {2007}
}
@article{Kessentini2010,
abstract = {In this paper, we present a multi-stream approach for off-line handwritten word recognition. The pro- posed approach combines low level feature streams namely, density based features extracted from 2 dif- ferent sliding windows with different widths, and contour based features extracted from upper and lower contours. The multi-stream paradigm provides an interesting framework for the integration of multiple sources of information and is compared to the standard combination strategies namely fusion of repre- sentations and fusion of decisions. We investigate the extension of 2-stream approach to N streams (N =2, ... , 4) and analyze the improvement in the recognition performance. The computational cost of this extension is discussed. Significant experiments have been carried out on two publicly available word databases: IFN/ENIT benchmark database (Arabic script) and IRONOFF database (Latin script). The multi- stream framework improves the recognition performance in both cases. Using 2-stream approach, the best recognition performance is 79.8\%, in the case of the Arabic script, on a 2100-word lexicon consisting of 946 Tunisian town/village names. In the case of the Latin script, the proposed approach achieves a rec- ognition rate of 89.8\% using a lexicon of 196 words},
annote = {===========================================

        Paper Index : Kessentini2010

        Date:22-11-2010



Why read paper ?

Recent arabic hmm.



        Paper Overview ?

offline word recognition using
multistream hmm. with contour and density  features.
for both arabic and english on IFN and IRONOFF datasets.



        What is these paper about ? (Summary)




1. preprocessing

a) normalization then using slant and slope correction.
b)  contour smothing to remove small blobs
c) base line detection.

        2) feature extraction

a) contour detection
for upper and lower . For each contour direction density histogram is computed a second fature for every point based on upper and lower point
 third features set is loccation of contour point. there is generated for each window 15 contour feature
b) density features
word is divided by windows with h and w.
a set fo 15 features is computed using 8 and 14 pixel as widths.


the final is 4 streams (upper contour, lower contour, density with 8 pixel width and density with 14 pixel length.).
The streams  are independent of each other and computed using sliding windows.

Classification:

HMM multi stream using more than one features as input.
introduction and training , testing systems. is explained.
comparing and triang of streams are explained n detailed .
HMM recombinatino which is an adaptation of viterbibi search algorithm allow to decompose a single stream hmm inot tow independent component.
HMM i sused to get most probalbe words from 1 , 2, 3, and 4 streams.



result.

Used two dataset one for arabic (IFN /ENIT ) and one for latin (IRON) both offline.
comparison between different streams combinations. 1-2,3-2, .
1-4 got best results (79.6\% on IFN and 89.8\% on laten)
propose a system is cbest compred to other icdar 2007 and 2005 systems.
using 3 streams and 4 streams but with small lexicon (due to complexity) was 98 and 99 \%.









1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?



The use of different streams of features on same hmm to get results.
Simple contour and density features.
System proved on both arabic and latin words.

2. What can we take from this work  ? what do we learn ? What can be incorporated into our own work ?

Contour , density Features  and some ideas of building hmm topolgy and multiple streams.



3. What are the problems of the paper ?

The complexitiy of handling hmm data and output probability.



4. what is lacking from the work ? why does this work knot be the final  research in this subject ?



Lacks an optimizied algorithm to handle multiple feature set on same hmm output.



5. what about the methods causes this lack ? is there a fundamental reason ?






6. Could incremental Changes Fix this lack ? if so, what changes ?






Is there is any question you had about the paper ?






The final conclusion..........

Method can be used on multiple features et and may need optimization
very good analysis of reault and comparision of other results
simple contour and density feaures but focus on hmm multiple streams


==========================================================================

      },
author = {Kessentini, Yousri and Paquet, Thierry and {Ben Hamadou}, AbdelMajid},
doi = {10.1016/j.patrec.2009.08.009},
file = {:D$\backslash$:/Papers/Documents/2010/Kessentini, Paquet, Ben Hamadou - 2010.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Arabic Handwritting recognition,Read,Summarized,hidden markov models,off-line handwriting recognition},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
month = jan,
number = {1},
pages = {60--70},
publisher = {Elsevier B.V.},
title = {{Off-line handwritten word recognition using multi-stream hidden Markov models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865509002232},
volume = {31},
year = {2010}
}
@inproceedings{DSGorski1999,
abstract = {The paper presents new A2iA bank check recognition systems designed
to process handwritten and/or printed checks issued in France, UK
or USA. All the systems have identical architecture and design principles.
However, each of them contains a country-specific part and is trained
with country-specific data. Each system performs location, extraction,
segmentation and recognition of courtesy and legal amounts in a document
image, as well as deciding whether to accept or reject the check.
The recognition rate is 80-90\%. In the production mode, the check
acceptance rate is 60-75\%, with the misread rate corresponding to
that of a human operator (close to 1\%)},
author = {Gorski, N and Anisimov, V and Augustin, E and Baret, O and Price, D and Simon, J.-C.},
booktitle = {Proceedings of the Fifth International Conference on Document Analysis and Recognition, 1999. ICDAR '99.},
doi = {10.1109/ICDAR.1999.791840},
file = {:D$\backslash$:/Papers/Documents/1999/Gorski et al. - 1999.pdf:pdf},
keywords = { ;,A2iA Check Reader;A2iA bank check recognition syst},
month = sep,
pages = {523--526},
title = {{A2iA Check Reader: a family of bank check recognition systems}},
year = {1999}
}
@article{Bouslama1999,
author = {Bouslama, Faouzi},
file = {:D$\backslash$:/Papers/Documents/1999/Bouslama - 1999.pdf:pdf},
journal = {International Journal of pattern recogntion and Artificial Intelligence},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
number = {7},
pages = {1027--1040},
title = {{Structural and fuzzy techniques in the recognition of online Arabic characters}},
url = {http://www.worldscinet.com/abstract?id=pii:S0218001499000574},
volume = {13},
year = {1999}
}
@article{PDB2Zhao2007,
abstract = {In an object recognition task where an image is represented as a constellation
of image patches, often many patches correspond to the cluttered
background. If such patches are used for object class recognition,
they will adversely affect the recognition rate. In this paper, we
present a statistical method for selecting the image patches which
characterize the target object class and are capable of discriminating
between the positive images containing the target objects and the
complementary negative images. This statistical method select those
images patches from the positive images which, when used individually,
have the power of discriminating between the positive and negative
images in the evaluation data. Another contribution of this paper
is the part-based probabilistic method for object recognition. This
Bayesian approach uses a common reference frame instead of reference
patch to avoid the possible occlusion problem. We also explore different
feature representation using PCA an 2D PCA. The experiment demonstrates
our approach has outperformed most of the other known methods on
a popular benchmark data set while approaching the best known results.},
author = {Zhao, Zhipeng and Vashist, Akshay and Elgammal, Ahmed M and Muchnik, Ilya B and Kulikowski, Casimir A},
doi = {http://dx.doi.org/10.1080/00207160601167045},
file = {:D$\backslash$:/Papers/Documents/2007/Zhao et al. - 2007.pdf:pdf},
journal = {Int. J. Comput. Math.},
keywords = { Class recognition, Feature selection, Object detection, Pattern representation and modeling,Computer vision},
number = {9},
pages = {1285--1297},
title = {{Combinatorial and statistical methods for part selection for object recognition.}},
volume = {84},
year = {2007}
}
@inproceedings{PDBNunes2004,
abstract = {This paper presents an optimized Hill-Climbing algorithm to select
subset of features for handwritten character recognition. The search
is conducted taking into account a random mutation strategy and the
initial relevance of each feature in the recognition process. A first
set of experiments have shown a reduction in the original number
of features used in an MLP-based character recognizer from 132 to
77 features (reduction of 42\%) without a significant loss in terms
of recognition rates, which are 99.1\% for 30,089 digits and 93.0\%
for 11,941 uppercase characters, both handwritten samples from the
NIST SD19 database. Additional experiments have been done by considering
some loss in terms of recognition rate during the feature subset
selection. A byproduct of these experiments is a cascade classifier
based on feature subsets of different sizes, which is used to reduce
the complexity of the classification task by 86.54\% on the digit
recognition experiment. The proposed feature selection method has
shown to be an interesting strategy to implement a wrapper approach
without the need of complex and expensive hardware architectures.},
address = {Lisbon, Portugal},
author = {Nunes, Carlos M and {de Souza Britto Jr.}, Alceu and Kaestner, Celso A A and Sabourin, Robert},
booktitle = {Structural, Syntactic, and Statistical Pattern Recognition, Joint IAPR International Workshops, SSPR 2004 and SPR 2004, 2004 Proceedings},
doi = {http://springerlink.metapress.com/openurl.asp?genre=article\&issn=0302-9743\&volume=3138\&spage=1018},
editor = {Fred, Ana L N and Caelli, Terry and Duin, Robert P W and Campilho, Aur\'{e}lio C and de Ridder, Dick},
file = {:D$\backslash$:/Papers/Documents/2004/Nunes et al. - 2004.pdf:pdf},
isbn = {3-540-22570-6},
month = aug,
pages = {1018--1025},
publisher = {Springer},
title = {{Feature Subset Selection Using an Optimized Hill Climbing Algorithm for Handwritten Character Recognition.}},
year = {2004}
}
@article{ARFrias-Martinez2006,
abstract = {The problem of automatic signature recognition has received little
attention in comparison with the problem of signature verification
despite its potential applications for accessing security-sensitive
facilities and for processing certain legal and historical documents.
This paper presents an efficient off-line human signature recognition
system based on support vector machines (SVM) and compares its performance
with a traditional classification technique, multi-layer perceptrons
(MLP). In both cases we propose two approaches to the problem: (1)
construct each feature vector using a set of global geometric and
moment-based characteristics from each signature and (2) construct
the feature vector using the bitmap of the corresponding signature.
We also present a mechanism to capture the intrapersonal variability
of each user using just one original signature. Our results empirically
show that SVM, which achieves up to 71\% correct recognition rate,
outperforms MLP.},
annote = {Special Section on Innovative Production Machines and Systems (I*PROMS)},
author = {Frias-Martinez, E and Sanchez, A and Velez, J},
doi = {DOI: 10.1016/j.engappai.2005.12.006},
file = {:D$\backslash$:/Papers/Documents/2006/Frias-Martinez, Sanchez, Velez - 2006.pdf:pdf},
issn = {0952-1976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {Multi-layer perceptrons},
number = {6},
pages = {693--704},
title = {{Support vector machines versus multi-layer perceptrons for efficient off-line signature recognition}},
url = {http://www.sciencedirect.com/science/article/B6V2M-4JFGF83-2/2/aece9ce4b6ffffb81b9b6cf4f0861706},
volume = {19},
year = {2006}
}
@conference{ARYin2009,
abstract = {With rejection strategies in a handwriting recognition system, we
are able to improve the reliability and accuracy of the recognized
characters. In this paper, we propose several rejection strategies
with multiple classifiers for handwritten character recognition.
First, the rejection strategy for the single classifier is introduced,
which is composed of three stages: initial scaling, confidence measure
calculation, and rejection performing. Then, we analyze rejection
strategies for multiple classifiers. We divided our rejection strategies
into two categories: (1) for voting combination; and (2) for linear
combination with multiple classifiers. In the voting combination
style, three rejection strategies, OR, AND, and VOTING, are proposed.
And for the linear combination one, rejection strategies for average
and weighted combination are analyzed respectively. We also experiment
and compare our rejection strategies with handwritten digit recognition.},
author = {Yin, Xu-Cheng and Hao, Hong-Wei and Tang, Yun-Feng and Sun, Jun and Naoi, Satoshi},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Yin et al. - 2009.pdf:pdf},
title = {{Rejection Strategies with Multiple Classifiers for Handwritten Character Recognition}},
year = {2009}
}
@article{Gunter2005,
abstract = {Unconstrained handwritten text recognition is one of the most difficult problems in the field of pattern recognition. Recently, a number of classifier creation and combination methods, known as ensemble methods, have been proposed in the field of machine learning. They have shown improved recognition performance over single classifiers. In this paper, we examine the influence of the vocabulary size, the number of training samples, and the number of classifiers on the performance of three ensemble methods in the context of cursive handwriting recognition. All experiments were conducted using an off-line handwritten word recognizer based on hidden Markov models (HMMs).},
author = {Gunter, S. and Bunke, Horst},
doi = {10.1016/j.optlaseng.2004.01.004},
file = {:D$\backslash$:/Papers/Documents/2005/Gunter, Bunke - 2005.pdf:pdf},
issn = {0143-8166},
journal = {Optics and Lasers in Engineering},
keywords = {ensemble methods,ensemble size,handwritten text recognition,hidden markov model,hmm,multiple classifier combination,training set size,vocabulary size},
number = {3-5},
pages = {437--454},
publisher = {Elsevier},
title = {{Off-line cursive handwriting recognition using multiple classifier systemsÃ¢â¬âon the influence of vocabulary, ensemble, and training set size}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0143816604001034},
volume = {43},
year = {2005}
}
@inproceedings{DSZhou2001,
abstract = {The proposed feedback-based approach is implemented in two steps.
In the first step, segmentation is done according to the structural
features between the connected components in the legal amounts. In
the second step, a feedback process is introduced to re-segment the
parts that could not be identified in the first step. Then a multiple
neural network classifier is used to verify the re-segmentation result.
The confidence value produced by the classifier is used to determine
the best segmentation points. This approach is tested on a CENPARMI
database and the result indicates that the correct segmentation rate
increased by 13.4\% from the previous approach},
author = {Zhou, Jun and Suen, C Y and Liu, Ke},
booktitle = {Document Analysis and Recognition, 2001. Proceedings. Sixth International Conference on},
doi = {10.1109/ICDAR.2001.953914},
file = {:D$\backslash$:/Papers/Documents/2001/Zhou, Suen, Liu - 2001.pdf:pdf},
keywords = { ;image classification;image segmentation;neural n,CENPARMI database;bank cheques;confidence value;fe},
pages = {887--891},
title = {{A feedback-based approach for segmenting handwritten legal amounts on bank cheques}},
year = {2001}
}
@article{PDB1Zhon2002,
abstract = {Neural network ensemble is a learning paradigm where many neural networks
are jointly used to solve a

problem. In this paper, the relationship between the ensemble and
its component neural networks is analyzed

from the context of both regression and classification, which reveals
that it may be better to ensemble many

instead of all of the neural networks at hand. This result is interesting
because at present, most approaches

ensemble all the available neural networks for prediction. Then, in
order to show that the appropriate neural

networks for composing an ensemble can be effectively selected from
a set of available neural networks, an

approach named GASEN is presented. GASEN trains a number of neural
networks at first. Then it assigns

random weights to those networks and employs genetic algorithm to
evolve the weights so that they can

characterize to some extent the fitness of the neural networks in
constituting an ensemble. Finally it selects

some neural networks based on the evolved weights to make up the ensemble.
A large empirical study shows

that, comparing with some popular ensemble approaches such as Bagging
and Boosting, GASEN can

generate neural network ensembles with far smaller sizes but stronger
generalization ability. Furthermore, in

order to understand the working mechanism of GASEN, the bias-variance
decomposition of the error is

provided in this paper, which shows that the success of GASEN may
lie in that it can significantly reduce the

bias as well as the variance.},
author = {Zhon, Zhi-Hua and Wu, Jianxin and Tang, Wei},
doi = {http://dx.doi.org/10.1016/S0004-3702(02)00190-X},
file = {:D$\backslash$:/Papers/Documents/2002/Zhon, Wu, Tang - 2002.pdf:pdf},
institution = {National Laboratory for Novel Software Technology, Nanjing University, Nanjing 210093, P.R.China},
journal = {Artif. Intell.},
keywords = { Bagging, Bias - Variance Decomposition, Boosting, Genetic Algorithm, Neural Networks,MultiClassifier Systems},
number = {1-2},
pages = {239--263},
title = {{Ensembling Neural Networks: Many Could Be Better Than All.}},
volume = {137},
year = {2002}
}
@inproceedings{DSMarisa2002b,
abstract = {This paper presents an HMM-MLP hybrid system to recognize complex
date images written on Brazilian bank cheques. The system first segments
implicitly a date image into sub-fields through the recognition process
based on an HMM-based approach. Afterwards, the three obligatory
date sub-fields are processed by the system (day, month and year).
A neural approach has been adopted to work with strings of digits
and a Markovian strategy to recognize and verify words. We also introduce
the concept of meta-classes of digits, which is used to reduce the
lexicon size of the day and year and improve the precision of their
segmentation and recognition. Experiments show interesting results
on date recognition.},
address = {Niagara-on-the-Lake, CA},
author = {{Morita M Sabourin R.}, Bortolozzi F and C.Y, Suen},
booktitle = {8th International Workshop on Frontiers of Handwriting Recognition (IWFHR'8)},
file = {:D$\backslash$:/Papers/Documents/2002/Morita M Sabourin R., C.Y - 2002.pdf:pdf},
month = aug,
pages = {105--110},
title = {{Segmentation and Recognition of Handwritten Dates}},
year = {2002}
}
@inproceedings{Recognition2001,
abstract = {The purpose of our research is to improve the recog- nition rate of an off-line handwritten character recog- nition system using HMM (Hidden Markov Model), so that we can use the syst,em for practical application. Due to the insufficient recognition rate of 1D HMM character recognition systems and the requirement for a huge number of learning samples to construct 2D HMM character recognition systems, HMM-based character recognition systems have not yet achieved sufficient recognition performance for practical use. In this research, we propose the character recognition method that integrates 4 simply structured 1D HMMs all of which are based on feature extraction using linear filters. The results of our evaluation experiment using the Hand-Printed Character Database (ETLG) showed that the first rank recognition rate of the test samples was 98.5\% and that the cumulative recognition rate of top 3 candidates was 99.3\%. Although our method is relatively easy to implement, it can work even better than 2D HMM method. These results show the pro- posed method is very effective.},
annote = {
        Paper Index : Nishimura2001

        Date:23-Nov-2010



        Why read paper ?

HMM knowldege base.



        Paper Overview ?

HMM but focus on the difference of 1D HMM vs. the 2D HMM.
the features are build on filter masks.
offline and test only on seperate latin characters.



        What is these paper about ? (Summary)



The paper talks about the 1D HMM used to recognize characters int the following steps.

        Features extraction:

feature is a weighted sum of image where
F(i,j)= sum (sum ( w(i)I(i,j)). (f is features , w is the mask and I is the image pixel  see page 3 eq1  )
Uses 4 different sturctures (filters masks) called sptial Integrated filter). SIF to extract features from the image by sliding the structure throught the image and computing the features.



Recognition:

4 HMM models for each character is generated. The final recognition is computed as sum of 4 hmm probability and the class with Max probablity is the recognizied.



The results :



Latin hand printed characters are used to test (600 sample per class so 18,636  total samples)
comparisons between 2DHMM and 1D HMM methods the best result achieved is 1D HMM SIF 98\%
it is supposed to be less complex than 2D HMM.





        1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?



Simple formulation of HMM.



        2. What can we take from this work  ? what do we learn ?  What can be incorporated into our own work ?






        3. What are the problems of the paper ?



The main problem is that it only test isolated characters, Simple features and also it seems that the high number of features for each mask.



        4. what is lacking from the work ? why does this work knot be the final  research in this subject ?

good filters, as the filters seems to only capture some of the spatial informaition it may be difficult to capture complex characters.





        5. what about the methods causes this lack ? is there a fundamental reason ?

The use of image and a masked filter it self.

        6. Could incremental Changes Fix this lack ? if so, what changes ?

More better features.



        Is there is any question you had about the paper ?






        The final conclusion..........



Small paper, that may provide simple HMM method to recognize character but restricted to latin only .


============},
author = {Nishimura, H. and Tsutsumi, M.},
booktitle = {Document Analysis and Recognition, 2001. Proceedings. Sixth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2002/Nishimura, Tsutsumi - 2002.pdf:pdf},
isbn = {0769512631},
keywords = {Arabic Handwritting recognition,HMM,Off-line recognition,Read,Summarized},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
pages = {417--421},
publisher = {IEEE},
title = {{Off-line hand-written character recognition using integrated 1D HMMs based on feature extraction filters}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=953824},
year = {2002}
}
@article{FE10Teow2002,
abstract = {We use well-established results in biological vision to construct
a model for handwritten digit recognition. We show

empirically that the features extractedby our model are linearly separable
over a large training set (MNIST). Using only a

linear discriminant system on these features, our model is relatively
simple yet outperforms other models on the same data set.

In particular, the best result is obtainedby applying triowise linear
support vector machines with soft voting on vision-based

features extractedfrom deslantedimages.},
annote = {Other then in review no...},
author = {Teow, Loo-Nin and Loe, Kia Fock},
file = {:D$\backslash$:/Papers/Documents/2002/Teow, Loe - 2002.pdf:pdf},
journal = {Pattern Recognition},
keywords = { Handwritten digits, MNIST},
pages = {2355--2364},
title = {{Robust vision based features and classification schemes for off line handwritten digit recognition}},
volume = {35},
year = {2002}
}
@incollection{ARAbdulKader2008,
abstract = {Abstract. In this paper we present a novel approach for the recognition
of offline Arabic handwritten text motivated by the Arabic lettersÃ¯Â¿Â½
conditional joining rules. A lexicon of Arabic words can be expressed
in terms of a new alphabet of PAWs (Part of Arabic Word). PAWs can
be expressed in terms of letters. The recognition problem is decomposed
into two problems to solve simultaneously. To find the best matching
word for an input image, a Two-Tier Beam search is performed. In
Tier One, the search is constrained by a letter to PAW lexicon. In
Tier Two, the search is constrained by a PAW to word lexicon. The
searches are driven by a PAW recognizer. Experiments conducted on
the standard IFN/ENIT database [6] of handwritten Tunisian town names
show word error rates of about 11\%. This result compares to the results
of the commonly used HMM based approaches.},
author = {AbdulKader, Ahmad},
booktitle = {Arabic and Chinese Handwriting Recognition},
file = {:D$\backslash$:/Papers/Documents/2008/AbdulKader - 2008.pdf:pdf},
keywords = { IFN/INIT, Neural Networks,Arabic Handwriting},
pages = {70--81},
publisher = {Springer-Verlag Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Two-Tier Arabic Offline Handwriting Recognition Based on Conditional Joining Rules}},
volume = {Volume 476},
year = {2008}
}
@article{Shridhar2009,
author = {Shridhar, M and Houle, GF and Kimura, F},
file = {:D$\backslash$:/Papers/Documents/2009/Shridhar, Houle, Kimura - 2009.pdf:pdf},
journal = {ieeexplore.ieee.org},
number = {Figure 1},
pages = {170--173},
title = {{Document Recognition Strategies for Bank Cheques}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5189604},
year = {2009}
}
@inproceedings{DShonggang2005,
abstract = {In this paper, a method based on signal matching to binarize low signal-noise
rate bank check image is proposed. This method can extract information
from the check image interfered with both complex background and
imprinted seal. With the prior knowledge, the image projection function
without noise is the source signal, the projection function of image
binarized by iterative threshold will match the source signal, and
the threshold which projection function matches best is the optimum
threshold. Experimental results showed that significant improvement
in the binarization quality in comparison with other well-established
algorithms},
author = {Honggang, Zhang and Guang, Chen and Gang, Liu and Jun, Guo},
booktitle = {Information, Communications and Signal Processing, 2005 Fifth International Conference on},
doi = {10.1109/ICICS.2005.1689294},
file = {:D$\backslash$:/Papers/Documents/2005/honggang et al. - 2005.pdf:pdf},
keywords = {bank check image binarization;image projection fun},
pages = {1430--1433},
title = {{Bank Check Image Binarization Based on Signal matching}},
year = {2005}
}
@inproceedings{Madhvanath2007b,
author = {Madhvanath, Sriganesh and Vijayasenan, Deepu and Kadiresan, T.M.},
booktitle = {ACM SIGGRAPH 2007 courses},
file = {:D$\backslash$:/Papers/Documents/2007/Madhvanath, Vijayasenan, Kadiresan - 2007.pdf:pdf},
keywords = {api,languages - no,linguistic resources,online handwriting recognition,parts of the world,recognition,shape,such as the indic,the languages in these,toolkit,unfortunately for many of},
pages = {13},
publisher = {ACM},
title = {{Lipitk: A generic toolkit for online handwriting recognition}},
url = {http://portal.acm.org/citation.cfm?id=1281500.1281524},
year = {2007}
}
@inproceedings{ARAbed2007,
abstract = {Preprocessing and feature extraction are very important steps in automatic
cursive handwritten word recognition. Based on an offline recognition
system for Arabic handwritten words which uses a semi-continuous
1-dimensional Hidden Markov Model recognizer, different preprocessing
combined with different feature sets are presented. The dependencies
of the feature sets from preprocessing steps are discussed and their
performances are compared using the IFN/ENIT-database of handwritten
Arabic words. As the lower and upper baseline of each word are part
of the ground truth of the database, the dependency of the feature
set from the accuracy of the estimated baseline is evaluated},
author = {Abed, Haikal El and Margner, Volker},
booktitle = {Proceedings of the Ninth International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2007/Abed, Margner - 2007(2).pdf:pdf},
pages = {974--978},
title = {{Comparison of Different Preprocessing and Feature Extraction Methods for Offline Recognition of Handwritten ArabicWords}},
volume = {2},
year = {2007}
}
@article{Sternby2009a,
abstract = {After a long period of focus on western and East Asian scripts there is now a general trend in the on-line handwriting recognition community to explore recognition of other scripts such as Arabic and various Indic scripts. One difficulty with the Arabic script is the number and position of diacritic marks associated to Arabic characters. This paper explores the application of a template matching scheme to the recog- nition of Arabic script with a novel algorithm for dynamically treating the diacritical marks. Template based systems are robust to conditions with scarce training data and in experiments the proposed system outperformed a reference system based on the promising state-of-the-art network technique of BLSTM. Experiments have been conducted in an environment similar to that of many handheld devices with promising results both in terms of memory consumption and response time.},
author = {Sternby, Jakob and Morwing, Jonas and Andersson, Jonas and Friberg, Christer},
doi = {10.1016/j.patcog.2008.12.017},
file = {:D$\backslash$:/Papers/Documents/2009/Sternby et al. - 2009(2).pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Arabic,Branch-and-bound,Diacritic,Graph,HWR,Modeling,On-line,Template,Trie},
month = dec,
number = {12},
pages = {3278--3286},
publisher = {Elsevier},
title = {{On-line Arabic handwriting recognition with templates}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308005347},
volume = {42},
year = {2009}
}
@inproceedings{Blumenstein,
abstract = {This paper describes a neural network-based technique for cursive character recognition applicable to segmentation-based word recognition systems. The proposed research builds on a novel feature extraction technique that extracts direction information from the structure of character contours. This principal is extended so that the direction information is integrated with a technique for detecting transitions between background and foreground pixels in the character image. The proposed technique is compared with the standard direction feature extraction technique, providing promising results using segmented characters from the CEDAR benchmark database.},
author = {Blumenstein, M. and Liu, X.Y. and Verma, B.},
booktitle = {2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541)},
doi = {10.1109/IJCNN.2004.1381140},
file = {:D$\backslash$:/Papers/Documents/2004/Blumenstein, Liu, Verma - 2004.pdf:pdf},
isbn = {0-7803-8359-1},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {2983--2987},
publisher = {Ieee},
title = {{A modified direction feature for cursive character recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1381140},
year = {2004}
}
@article{Cho2007,
author = {Cho, S.J. and Kim, J.},
file = {:D$\backslash$:/Papers/Documents/2007/Cho, Kim - 2007.pdf:pdf},
journal = {Digital Document Processing},
pages = {121--141},
publisher = {Springer},
title = {{A Bayesian Network Approach for On-line Handwriting Recognition}},
url = {http://www.springerlink.com/index/n12828qg1502873h.pdf},
volume = {1},
year = {2007}
}
@article{Bunke1995,
abstract = {-A method for the off-line recognition of cursive handwriting based on hidden Markov models (HMMs) is described. The features used in the HMMs are based on the arcs of skeleton graphs of the words to be recognized. An algorithm is applied to the skeleton graph of a word that extracts the edges in a particular order. Given the sequence of edges extracted from the skeleton graph, each edge is transformed into a 10-dimensional feature vector. The features represent information about the location of an edge relative to the four reference lines, its curvature and the degree of the nodes incident to the considered edge. The linear model was adopted as basic HMM topology. Each letter of the alphabet is represented by a linear HMM. Given a dictionary of fixed size, an HMM for each dictionary word is built by sequential concatenation of the H M Ms representing the individual letters of the word. Training of the HM Ms is done by means of the Baum-Welch algorithm, while the Viterbi algorithm is used for recognition. An average correct recognition rate of over 98\% on the word level has been achieved in experiments with cooperative writers using two dictionaries of 150 words each.},
author = {Bunke, H},
doi = {10.1016/0031-3203(95)00013-P},
file = {:D$\backslash$:/Papers/Documents/1995/Bunke - 1995.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Cursive script recognition,HMM,Hidden Markov model,Optical character recognition,Skeleton graphs,off-line recognition},
mendeley-tags = {HMM},
month = sep,
number = {9},
pages = {1399--1413},
title = {{Off-line cursive handwriting recognition using hidden markov models}},
volume = {28},
year = {1995}
}

@article{Kim2006,
author = {Kim, D. and Choi, H. and Kim, J.},
file = {:D$\backslash$:/Papers/Documents/2006/Kim, Choi, Kim - 2006.pdf:pdf},
journal = {Ubiquitous Computing Systems},
keywords = {3d space handwriting,bayesian network,gnition,ligature model,online handwriting reco-},
pages = {41--56},
publisher = {Springer},
title = {3d space handwriting recognition with ligature model},
url = {http://www.springerlink.com/index/q872002003062745.pdf},
year = {2006}
}
@inproceedings{Tokuno2002,
abstract = {This paper describes context-dependent substroke hid- den Markov models (HMMs) for on-line handwritten recog- nition of cursive Kanji and Hiragana characters. As there are more than 6,000 distinctive characters including Kanji and Hiragana in Japanese, modeling each character by an HMM leads to an infeasible character-recognition system requiring huge amount of memory and enormous computa- tion time. In order to tackle this problem, we have proposed the substroke HMM approach where a modeling unit Ã¢â¬Åsub- strokeÃ¢â¬ï¿½ that is much smaller than a whole character is em- ployed and each character is modeled as a concatenation of only 25 kinds of substroke HMMs. One of the drawback of this approach is that the recognition accuracy deterio- rates in case of scribbled characters, and characters where the shape of the substrokes varies a lot. In this paper, we show that the context-dependent substroke modeling which depends on how the substroke connects to the adjacent sub- strokes is effective to achieve robust recognition of low qual- ity characters. The Successive State Splitting (SSS) algo- rithm which was mainly developed for speech recognition is employed to construct the context dependent substroke HMMs. Experimental results show that the correct recogni- tion rate improved from88\% to 92\% for cursive Kanji hand- writings and from 90\% to 98\% for Hiragana handwritings.},
author = {Tokuno, Junko and Inami, Nobuhito and Matsuda, Shigeki and Nakai, M. and Shimodaira, H. and Sagayama, S.},
booktitle = {Frontiers in Handwriting Recognition, 2002. Proceedings. Eighth International Workshop on},
file = {:D$\backslash$:/Papers/Documents/2002/Tokuno et al. - 2002.pdf:pdf},
isbn = {0769516920},
pages = {78--83},
publisher = {IEEE},
title = {{Context-dependent substroke model for HMM-based on-line handwriting recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1030888},
year = {2002}
}
@article{ARAdankon2008,
abstract = {The support vector machine (SVM) is a powerful classifier which has
been used successfully in many pattern recognition problems. It has
also been shown to perform well in the handwriting recognition field.
The least squares SVM (LS-SVM), like the SVM, is based on the margin-maximization
principle performing structural risk minimization. However, it is
easier to train than the SVM, as it requires only the solution to
a convex linear problem, and not a quadratic problem as in the SVM.
In this paper, we propose to conduct model selection for the LS-SVM
using an empirical error criterion. Experiments on handwritten character
recognition show the usefulness of this classifier and demonstrate
that model selection improves the generalization performance of the
LS-SVM},
author = {M.Adankon, Mathias and MohamedCheriet},
file = {:D$\backslash$:/Papers/Documents/2008/M.Adankon, MohamedCheriet - 2008.pdf:pdf},
journal = {Pattern Recognition},
month = dec,
number = {12},
pages = {3264--3270},
title = {{Model selection for the LS-SVM Application to handwriting recognition}},
volume = {42},
year = {2008}
}
@inproceedings{MCRodriguez2002,
abstract = {This paper analyses the application of hierarchical classifiers based
on the k-NN rule to the automatic classification of handwritten characters.
The discriminating capacity of a k-NN classifier increases as the
size of the reference pattern set (RPS) increases. This supposes
aproblem for k-NN classifiers in real applications: the high computational
cost required when the RPS is large. In order to accelerate the process
of calculating the distance to each pattern of the RPS, some authors
propose the use of condensing techniques. These methods try to reduce
the size of the RPS without losing classification power. Our alternative
proposal is based on incremental learning and hierarchical classifiers
with rejection techniques that reduce the computational cost of the
classifier. We have used 133,944 characters (72,105 upper-case characters
and 61,839 lower-case characters) of the NIST Special Data Bases
3 and 7 as experimental data set. The binary image of the character
is transformed to gray image. The best non-hierarchical classifier
achieves a hit rate of 94.92\% (upper-case) and 87,884\% (lower-case).
The hierarchical classifier achieves the same hit ratio, but with
3 times lower computational cost than the cost of the best non-hierarchical
classifier found in our experimentation and 14\% less than Hart's
Algorithm.},
author = {Rodriguez, C and Boto, F and Soraluze, I and P\'{e}rez, A},
booktitle = {ICPR '02: Proceedings of the 16 th International Conference on Pattern Recognition (ICPR'02) Volume 3},
file = {:D$\backslash$:/Papers/Documents/2002/Rodriguez et al. - 2002.pdf:pdf},
isbn = {0-7695-1695-X},
pages = {30098},
title = {{An Incremental and Hierarchical K-NN classifier for Hadwritten characters}},
volume = {3},
year = {2002}
}
@article{Bertolami2008,
author = {Bertolami, R and Bunke, H},
doi = {10.1016/j.patcog.2008.04.003},
file = {:D$\backslash$:/Papers/Documents/2008/Bertolami, Bunke - 2008.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {offline handwritten text line,recognition},
month = nov,
number = {11},
pages = {3452--3460},
title = {{Hidden Markov model-based ensemble methods for offline handwritten text line recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308001349},
volume = {41},
year = {2008}
}
@article{Touj2005,
author = {Touj, Sameh and Amara, Najoua Ben and Amiri, Hamid},
file = {:D$\backslash$:/Papers/Documents/2005/Touj, Amara, Amiri - 2005.pdf:pdf},
journal = {International Arab Journal of Information},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
number = {4},
pages = {318----325},
title = {{Arabic handwritten words recognition based on a planar hidden Markov model}},
url = {http://www.ccis2k.org/iajit/PDF/vol.2,no.4/9-Sameh.pdf},
volume = {2},
year = {2005}
}
@inproceedings{Pechwitz2003,
abstract = {An offline recognition system for Arabic handwritten words is presented. The recognition system is based on a semi-continuous 1-dimensional HMM. From each binary word image normalization parameterswere estimated. First height, length, and baseline skew are normalized, then fea- tures are collected using a sliding window approach. This paper presents these methods in more detail. Some parame- ters were modified and the consequent effect on the recogni- tion results are discussed. Significant tests were performed using the new IFN/ENIT - database of handwritten Ara- bic words. The comprehensive database consists of 26459 Arabic words (Tunisian town/village names) handwritten by 411 different writers and is free for non-commercial re- search. In the performed tests we achieved maximal recognition rates of about 89\% on a word level.},
author = {Pechwitz, Mario and Maergner, Volker},
booktitle = {Proceedings of the Seventh International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2003/Pechwitz, Maergner - 2003.pdf:pdf},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {0--4},
title = {{HMM Based Approach for Handwritten Arabic Word Recognition Using the IFN / ENIT - Database}},
year = {2003}
}
@inproceedings{ARWang2008,
abstract = {A word segmentation method based on Inductive Learning for non-segmented
language uses only surface information of a character string; it
has an advantage that is entirely not dependent on any specific language.
The method extracts recursively a character string that occur frequently
in text as word candidates, extracts segmentation rule with context
information to deal with segmentation ambiguity. The method classifies
those extracted word candidates to different ranking according to
extraction situation, segments a text into words with extracted word
candidates. Though proofread process erroneous segmentation was corrected,
ranking of word candidates and segmentation rules was renewed. Evaluation
experiments showed availability of the method for Japanese and Chinese
word segmentation.},
author = {Wang, Zhongjian and Araki, Kenji and Tochinai, Koji},
booktitle = {2008 International Symposium on Computational Intelligence and Design},
file = {:D$\backslash$:/Papers/Documents/2008/Wang, Araki, Tochinai - 2008.pdf:pdf},
title = {{Word Segmentation Method Based on Inductive Learning and Segmentation Rule}},
year = {2008}
}
@inproceedings{ARMargner2006,
abstract = {The great success and high recognition rates of both OCR systems and
recognition systems for handwritten words are unconceivable without
the availability of huge datasets of real world data. This chapter
gives a short survey of datasets used for recognition with special
focus on their application. The main part of this chapter deals with
Arabic handwriting, datasets for recognition systems, and their availability.
A description of different datasets and their usability is given,
and the results of a competition are presented. Finally, a strategy
for the development of Arabic handwriting recognition systems based
on datasets and competitions is presented.},
address = {University of Maryland, College Park, MD},
author = {Margner, Volker and Abed, Haikal El},
booktitle = {SACH06 Proceedings of the 2006 conference on Arabic and Chinese handwriting recognition},
file = {:D$\backslash$:/Papers/Documents/2006/Margner, Abed - 2006.pdf:pdf},
pages = {161--169},
title = {{Databases and Competitions: Strategies to Improve Arabic Recognition Systems}},
year = {2006}
}
@conference{FE11Hamamoto,
abstract = {We study a Gabor filter-based feature extraction method for handwritten
numeral character recognition. The performance of the Gabor filter-based
method is demonstrated on the ETL-1 database. Experimental results
suggest that the Gabor jilter-based method should be considered in
recognition of handwritten numeric characters..},
author = {Hamamoto, Yoshihiko and Uchimura, Shunji and Masamizu, K and Tomita, Shingo},
booktitle = {Procedding of the 1996 International conference on pattern Recognition ICDAR},
doi = {http://computer.org/proceedings/icdar/7128/vol\_2/71280819abs.htm},
file = {:D$\backslash$:/Papers/Documents/1996/Hamamoto et al. - 1996.pdf:pdf},
pages = {819--823},
publisher = {IEEE},
title = {{Recognition of handprinted Chinese characters using Gabor features.}},
year = {1996}
}
@article{Mello2007,
author = {Mello, C. and Bezerra, B. and Zanchettin, C. and Macario, V.},
doi = {10.1109/ICDAR.2007.4378702},
file = {:D$\backslash$:/Papers/Documents/2007/Mello et al. - 2007.pdf:pdf},
isbn = {0-7695-2822-8},
issn = {1520-5363},
journal = {Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)},
month = sep,
number = {Icdar},
pages = {193--197},
publisher = {Ieee},
title = {{An Efficient Thresholding Algorithm for Brazilian Bank Checks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4378702},
year = {2007}
}
@inproceedings{ARHuang2006,
abstract = {This paper presents a combined approach for online handwriting symbols
recognition. The basic idea of this approach is to employ a set of
left-right HMMs to generate a new feature vector as input, and then
use SNN as a classifier to finally identify unknown symbols. The
new feature vector consists of global features and several pairs
of maximum probabilities with their associated different model labels
for an observation pattern. A recogniser based on this method inherits
the practical and dynamical modeling abilities from HMM, and robust
discriminating ability from SNN for classification tasks. This hybrid
technique also reduces the dimensions of feature vectors significantly,
complexity, and solves size problem when using only SNN. The experimental
results show that this approach outperforms several classifiers reported
in recent research, and can achieve recognition rates of 97.41\%,
91.81\% and 91.63\% for digits and upper/lower case characters respectively
on the UNIPEN database benchmarks.},
address = {P\{\'{o}\}voa de Varzim, Portugal},
author = {Huang, B Q and Kechadi, M.-T.},
booktitle = {ICIAR 2006, LNCS 4142, pp. 897Ã¯Â¿Â½905, 2006.},
editor = {Campilho, Aur\'{e}lio C and Kamel, Mohamed S},
file = {:D$\backslash$:/Papers/Documents/2006/Huang, Kechadi - 2006(2).pdf:pdf},
month = sep,
pages = {897--905},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{An HMM-SNN Method for Online Handwriting Symbol Recognition}},
volume = {4142},
year = {2006}
}
@article{Kim1997,
abstract = {-In this paper, we propose a novel recognition model of on-line cursive Korean characters using the hidden Markov model (HMM) and a level building algorithm. The model is constructed as a form of recognition network with HMMs for graphemes and Korean combination rules. Though the network represents the large character set efficiently and is flexible enough to accommodate variability of input patterns, it has a problem of recognition speed, caused by 11,172 search paths. To solve the problem, we modify a level building algorithm to be adapted directly to the Korean combination rules and apply it to the model. The modified algorithm is an efficient network search procedure, the time complexity of which depends on the number of grapheme HMMs and ligature HMMs, not the number of paths in the extensive recognition network. A test with 20,000 handwritten characters shows a recognition rate of 90.2\% and speed of 0.72 s per character. ÃÂ©},
author = {Kim, H},
doi = {10.1016/S0031-3203(96)00078-7},
file = {:D$\backslash$:/Papers/Documents/1997/Kim - 1997.pdf:pdf},
journal = {Pattern Recognition},
keywords = {character recognition network,hidden markov model,level building,on-line characcter},
month = mar,
number = {3},
pages = {491--502},
title = {{An HMM-based character recognition network using level building}},
volume = {30},
year = {1997}
}
@article{Bazzi1997,
abstract = {We present a set of techniques for omnifont, unlimited-vocabulary OCR, within the context of a system based on Hidden Markov Models (HMM). First, we address the issue of how to perform OCR on omnqont and multi-style data, such as plain and italic, without the need to have a separate model for each style. The amount of training data from each style, which is used to train a single model, becomes an important issue in the face of the conditional independence assumption inherent in the use of HMMs. We demonstrate mathematically and empirically how to allocate training data among the different styles to alleviate this problem. Second, we show how to use a word-based HMM system to perform character recognition with unlimited vocabulary. The method includes the use of a trigram language model on character sequences. Using all these techniques, we have achieved character error rates of 1.1\% on data from the University of Washington English Document Image Database and 3.3\% on data from the DARPA Arabic OCR Corpus.},
author = {Bazzi, I. and LaPre, C. and Makhoul, J. and Raphael, C. and Schwartz, R.},
doi = {10.1109/ICDAR.1997.620630},
file = {:D$\backslash$:/Papers/Documents/1997/Bazzi et al. - 1997.pdf:pdf},
isbn = {0-8186-7898-4},
journal = {Proceedings of the Fourth International Conference on Document Analysis and Recognition},
keywords = {Reference From Doctor,character recognition,hidden markov models,recognition},
mendeley-tags = {Reference From Doctor},
pages = {842--846},
publisher = {IEEE Comput. Soc},
title = {{Omnifont and unlimited-vocabulary OCR for English and Arabic}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=620630},
year = {1997}
}
@article{Goraine1992,
author = {Goraine, H.},
doi = {10.1109/2.144444},
file = {:D$\backslash$:/Papers/Documents/1992/Goraine - 1992.pdf:pdf},
journal = {Computer},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = jul,
number = {7},
pages = {71--74},
title = {{Off-line Arabic character recognition}},
volume = {25},
year = {1992}
}
@article{PDB15Golfarelli1997,
abstract = {AbstractÃ¯Â¿Â½In this work, we address the problem of performance evaluation
in biometric verification systems. By formulating the optimum Bayesian
decision criterion for a verification system and by assuming the
data distributions to be multinormals, we derive two statistical
expressions for calculating theoretically the false acceptance and
false rejection rates. Generally, the adoption of a Bayesian parametric
model does not allow for obtaining explicit expressions for the calculation
of the system errors. As far as biometric verification systems are
concerned, some hypotheses can be reasonably adopted, thus allowing
simple and affordable expressions to be derived. By using two verification
system prototypes, based on hand shape and human face, respectively,
we show our results are well founded.},
author = {Golfarelli, Matteo and Maio, Dario and Maltoni, Davide},
doi = {http://www.computer.org/tpami/tp1997/i0786abs.htm},
file = {:D$\backslash$:/Papers/Documents/1997/Golfarelli, Maio, Maltoni - 1997.pdf:pdf},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
number = {7},
pages = {786--796},
title = {{On the Error-Reject Trade-Off in Biometric Verification Systems.}},
volume = {19},
year = {1997}
}
@article{MCWang2008,
abstract = {We propose a new hierarchical design method, weighted support vector
(WSV) k-means clustering, to design a binary hierarchical classification
structure. This method automatically selects the classes to be separated
at each node in the hierarchy, and allows visualization of clusters
of highdimensional support vector data; no prior hierarchical designs
address this. At each node in the hierarchy, we use an SVRDM (support
vector representation and discrimination machine) classifier, which
offers generalization and good rejection of unseen false objects
(rejection is not achieved with the standard SVMs). We give the basis
and new insight into why a Gaussian kernel provides good rejection.
Recognition and rejection test results on a real IR (infrared) database
show that our proposed method outperforms the standard one-vs-rest
methods and the use of standard SVM classifiers.},
author = {Yu-Chiang and Wang, Frank and Casasent, David},
file = {:D$\backslash$:/Papers/Documents/2008/Yu-Chiang, Wang, Casasent - 2008.pdf:pdf},
journal = {Neural Networks},
keywords = {Automatic target recognition; Hierarchical classif},
pages = {502Ã¯Â¿Â½510},
title = {{New support vector-based design method for binary hierarchical classifiers for multi-class classification problems}},
volume = {21},
year = {2008}
}
@article{DSSouiciMeslati2004,
abstract = {The challenge of hybrid learning systems is to use the information
provided by one source of information to compensate information missing
from the other source. The neuroÃ¯Â¿Â½symbolic combination represents
a promising research way. The synergy between the symbolic (theoretical)
and neural (empirical) approaches makes their combination more effective
than each of them used alone. In this article, we describe an Arabic
literal amount recognition system that uses a neuro-symbolic classifier.
For this purpose, we first extract structural features from the words
contained in the amounts vocabulary. Then, we build a symbolic knowledge
base that reflects a classification of words according to their features.
In a third step, we use a translation algorithm (from rules to neural
network) to determine the neural network architecture and to initialize
its connections with specific values rather than random values, as
is the case in classical neural networks. This construction approach
provides the network with theoretical knowledge and reduces the training
stage, which remains necessary because of styles and writing conditions
variability. After this empirical training stage using real examples,
the network acquires a final topology, which allows it to recognize
new handwritten amounts.},
author = {Souici-Meslati, Labiba and Sellami, Mokhtar},
file = {:D$\backslash$:/Papers/Documents/2004/Souici-Meslati, Sellami - 2004.pdf:pdf},
journal = {The Arabian Journal for Science and Engineering},
keywords = { neuro-symbolic integration; literal amounts,Artificial intelligence; pattern recognition; hand},
number = {2B},
pages = {177--194},
title = {{A HYBRID APPROACH FOR ARABIC LITERAL AMOUNTS RECOGNITION}},
volume = {29},
year = {2004}
}
@inproceedings{Mihov2005,
author = {Mihov, Stoyan and Schulz, K.U. and Ringlstetter, Christoph and Dojchinova, Veselka and Nakova, Vanja},
booktitle = {German Research},
file = {:D$\backslash$:/Papers/Documents/2005/Mihov et al. - 2005.pdf:pdf},
keywords = {comparative broad range of,contents,contents and formats,corpora,cyrillic documents,evaluation,genres and documents types,ground truth data,meta-data,mixed-alphabet documents,optical character recognition,postcor- w,public corpora,r,rection of ocr results,should be covered,t,the collection of new,which means that a},
publisher = {IEEE Computer Society},
title = {{A Corpus for Comparative Evaluation of OCR Software and Postcorrection Techniques}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICDAR.2005.6},
year = {2005}
}
@article{ARBasu2009,
abstract = {A novel hierarchical approach is presented here for optical character
recognition (OCR) of handwritten Bangla words. Instead of dealing
with isolated characters as found in selected works [T.K. Bhowmik,
U. Bhattacharya, S.K. Parui, Recognition of Bangla handwritten characters
using an MLP classifier based on stroke features, in: Proceedings
of the ICONIP, Kolkata, India, 2004, pp. 814Ã¯Â¿Â½819; K. Roy, U. Pal,
F. Kimura, Bangla handwritten character recognition, in: Proceedings
of the Second Indian International Conference on Artificial Intelligence
(IICAI), 2005, pp. 431Ã¯Â¿Â½443; S. Basu, N. Das, R. Sarkar, M. Kundu,
M. Nasipuri, D.K. Basu, Handwritten Bangla alphabet recognition using
an MLP based classifier, in: Proceedings of the Second National Conference
on Computer Processing of Bangla, Dhaka, 2005, pp. 285Ã¯Â¿Â½291; A.F.R.
Rahman, R. Rahman, M.C. Fairhurst, Recognition of handwritten Bengali
characters: a novel multistage approach, Pattern Recognition 35,
2002, pp. 997Ã¯Â¿Â½1006; U. Bhattacharya, S.K. Parui, M. Sridhar, F. Kimura,
Twostage recognition of handwritten Bangla alphanumeric characters
using neural classifiers, in: Proceedings of the Second Indian International
Conference on Artificial Intelligence (IICAI), 2005, pp. 1357Ã¯Â¿Â½1376;
U. Bhattacharya, M. Sridhar, S.K. Parui, On recognition of handwritten
Bangla characters, in: Proceedings of the ICVGIP-06, Lecture Notes
in Computer Science, vol. 4338, 2006, pp. 817Ã¯Â¿Â½828], the present approach
segments a word image on Matra hierarchy, then recognizes the individual
word segments and finally identifies the constituent characters of
the word image through intelligent combination of recognition decisions
of the associated word segments. Due to possible appearances of consecutive
characters of Bangla words on overlapping character positions, segmentation
of Bangla word images is not easy. For successful OCR of handwritten
Bangla text, not only recognition but also segmentation of word images
are important. In this respect the present hierarchical approach
deals with both segmentation and recognition of handwritten Bangla
word images for a complete solution to handwritten word recognition
problem, an essential area of OCR of handwritten Bangla text. In
dealing with certain category of word segments, created on Matra
hierarchy, a sophisticated recognition technique, viz., two-pass
approach [S. Basu, C. Chaudhury, M. Kundu, M. Nasipuri, D.K. Basu,
A two pass approach to pattern classification, in: N.R. Pal et al.
(Ed.), Lecture Notes in Computer Science, vol. 3316, ICONIP, Kolkata,
2004, pp. 781Ã¯Â¿Â½786] is employed here. The degree of sophistication
of the classification technique is also rationally tuned depending
on various categories of word segments to be recognized. For example,
the two-pass approach is employed here for recognizing middle zone
character segments, whereas recognition of middle zone modified shapes
of Bangla script is done through simple template matching. Considering
learning and generalization abilities of multi layer perceptrons
(MLPs), MLP based pattern classifiers are used here for most of the
classification related tasks. A powerful feature set is also designed
under this work for recognition of complex character patterns using
three types of topological features, viz., longest-run features,
modified shadow features and octant-centroid features. In a nutshell,
the work deals with a practical problem of OCR of Bangla text involving
recognition as well as segmentation of constituent characters of
handwritten Bangla words.},
author = {{Subhadip Basu Nibaran Das}, Ram Sarkar Mahantapas Kundu Mita Nasipuri? Dipak Kumar Basu},
file = {:D$\backslash$:/Papers/Documents/2009/Subhadip Basu Nibaran Das - 2009.pdf:pdf},
journal = {Pattern Recognition},
pages = {1467--1484},
title = {{A hierarchical approach to recognition of handwritten Bangla characters}},
volume = {42},
year = {2009}
}
@article{MCKussul2005,
abstract = {We have developed a novel neural classifier LImited Receptive Area
(LIRA) for the image recognition. The classifier LIRA contains three
neuron layers: sensor, associative and output layers. The sensor
layer is connected with the associative layer with no modifiable
random connections and the associative layer is connected with the
output layer with trainable connections. The training process converges
sufficiently fast. This classifier does not use floating point and
multiplication operations. The classifier was tested on two image
databases. The first database is the MNIST database. It contains
60,000 handwritten digit images for the classifier training and 10,000
handwritten digit images for the classifier testing. The second database
contains 441 images of the assembly microdevice. The problem under
investigation is to recognize the position of the pin relatively
to the hole. A random procedure was used for partition of the database
to training and testing subsets. There are many results for the MNIST
database in the literature. In the best cases, the error rates are
0.7, 0.63 and 0.42\%. The classifier LIRA gives error rate of 0.61\%
as a mean value of three trials. In task of the pinÃ¯Â¿Â½hole position
estimation the classifier LIRA also shows sufficiently good results.},
author = {Kussul, Ernst and Baidyk, Tatiana},
file = {:D$\backslash$:/Papers/Documents/2005/Kussul, Baidyk - 2005.pdf:pdf},
journal = {Image and Vision Computing},
pages = {971Ã¯Â¿Â½981},
title = {{Improved method of handwritten digit recognition tested on MNIST database}},
volume = {22},
year = {2005}
}
@article{Liu2009,
author = {Liu, Cheng-Lin and Suen, Ching Y.},
doi = {10.1016/j.patcog.2008.10.007},
file = {:D$\backslash$:/Papers/Documents/2009/Liu, Suen - 2009.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {bangla numeral recognition,farsi numeral recognition},
month = dec,
number = {12},
pages = {3287--3295},
title = {{A new benchmark on the recognition of handwritten Bangla and Farsi numeral characters}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308004457},
volume = {42},
year = {2009}
}
@inproceedings{ARKavianifar1999,
abstract = {English and Chinese are languages, which have tremendously attracted
interests of character recognition researchers. In contrast, research
in the field of character recognition for Arabic / Persian scripts
face major problems mainly related to the unique characteristics
of these two like being cursive, multiple shapes of one character
in different positions in a word and connectivity of characters on
the baseline. The proposed work consists of three major phases. After
digitizing the text, the original image is transformed into a gray
scale image using a 300-dpi scanner. Different steps of preprocessing
are then applied on the image file. In the next phase, sub-words
of all words are recognized and global features for each word are
extracted. Contour tracing plays a very important role in the phase
of feature extraction.},
author = {Kavianifar, Mandana and Amin, Adnan},
booktitle = {Proceedings of the Fifth International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/1999/Kavianifar, Amin - 1999.pdf:pdf},
title = {{Preprocessing and Structural Feature Extraction for a Multi-Fonts Arabic / Persian OCR}},
year = {1999}
}
@inproceedings{PDB12Prevost2003,
abstract = {Handwriting recognition is such a complex classification problem that
it is quite usual now to make co-operate several classification methods
at the preprocessing stage or at the classification stage. In this
paper, we present an original two stages recognizer. The first stage
is a model-based classifier that stores an exhaustive set of character
models. The second stage is a discriminative classifier that separates
the most ambiguous pairs of classes. This hybrid architecture is
based on the idea that the correct class almost systematically belongs
to the two more relevant classes found by the first classifier. Experiments
on Unipen database show a 30\% improvement on a 62 classes recognition
problem.},
address = {Edinburgh, Scotland, UK},
author = {Prevost, Lionel and Michel-Sendis, Christian and Moises, Alvaro and Oudot, Lo\"{\i}c and Milgram, Maurice},
booktitle = {7th International Conference on Document Analysis and Recognition (ICDAR 2003)},
doi = {http://csdl.computer.org/comp/proceedings/icdar/2003/1960/01/196010031abs.htm},
file = {:D$\backslash$:/Papers/Documents/2003/Prevost et al. - 2003.pdf:pdf},
isbn = {0-7695-1960-1},
keywords = {Handwritten digits},
pages = {31--},
publisher = {IEEE Computer Society},
title = {{Combining model-based and discriminative classifiers : application to handwritten character recognition.}},
volume = {2},
year = {2003}
}
@article{ARLiwicki2008,
abstract = {In this paper we present a multiple classifier system (MCS) for on-line
handwriting recognition. The MCS combines several individual recognition
systems based on hidden Markov models (HMMs) and bidirectional long
short-term memory networks (BLSTM). Beside using two different recognition
architectures (HMM and BLSTM), we use various feature sets based
on on-line and off-line features to obtain diverse recognizers. Furthermore,
we generate a number of different neural network recognizers by changing
the initialization parameters. To combine the word sequences output
by the recognizers, we incrementally align these sequences using
the recognizer output voting error reduction framework (ROVER). For
deriving the final decision, different voting strategies are applied.
The best combination ensemble has a recognition rate of 84.13\%, which
is significantly higher than the 83.64\% achieved if only one recognition
architecture (HMM or BLSTM) is used for the combination, and even
remarkably higher than the 81.26\% achieved by the best individual
classifier. To demonstrate the high performance of the classification
system, the results are compared with two widely used commercial
recognizers from Microsoft and Vision Objects.},
author = {Liwicki, Marcus and HorstBunkeb},
file = {:D$\backslash$:/Papers/Documents/2008/Liwicki, HorstBunkeb - 2008.pdf:pdf},
journal = {Pattern Recognition},
keywords = {On-line handwriting recognition; Off-line handwrit},
month = dec,
number = {12},
pages = {3254--3263},
title = {{Combining diverse on-line and off-line systems for handwritten text line recognition}},
volume = {42},
year = {2008}
}
@inproceedings{PDBPong2006,
abstract = {We describe a method for optimal construction of a detection cascade
comprising 3D models of increasing levelof- detail (LOD). An LOD
3D model hierarchy of the target object is first generated. By analyzing
detection performance of each individual model in the LOD hierarchy,
an optimization framework that allows trade-off between speed and
accuracy is formulated. The formulation allows models to be explicitly
selected for inclusion in the final detection cascade while achieving
optimal running time with respect to a target detection performance.},
author = {Pong, Hon-Keat and Cham, Tat-Jen},
booktitle = {Proceedings of the 18th International Conference on Pattern Recognition (ICPR'06)},
file = {:D$\backslash$:/Papers/Documents/2006/Pong, Cham - 2006.pdf:pdf},
publisher = {IEEE Computer Society},
title = {{Optimal Cascade Construction for Detection using 3D Models}},
year = {2006}
}
@article{Slimane2009,
author = {Slimane, Fouad and Ingold, Rolf and Kanoun, Slim and Alimi, Adel M. and Hennebert, Jean},
doi = {10.1109/ICDAR.2009.155},
file = {:D$\backslash$:/Papers/Documents/2009/Slimane et al. - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {946--950},
publisher = {Ieee},
title = {{A New Arabic Printed Text Image Database and Evaluation Protocols}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277558},
year = {2009}
}
@inproceedings{Zhang2009a,
abstract = {Ã¢â¬âThe purpose of this paper is to improve recognition rate of off-line handwritten character recognition system.We apply the statistical characteristics of the percentage of pixels and structural characteristics of boundary chain code of character projection, after train based on HMM to obtain corresponding parameters, then integrate different classifiers through the Bagging algorithm in Voting method. Experimental results indicate that this approach can further improve the performance.},
author = {Zhang, Yan and Yao, Xiaodong and Chang, Ching},
booktitle = {Computational Intelligence and Software Engineering, 2009. CiSE 2009. International Conference on},
file = {:D$\backslash$:/Papers/Documents/2009/Zhang, Yao, Chang - 2009.pdf:pdf},
keywords = {- handwriten recognition,Handwritten Character Recognition Using HMM Model ,bagging,hmm model},
pages = {1--4},
publisher = {IEEE},
title = {{Handwritten Character Recognition Using HMM Model Based on Bagging Method}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5366197},
year = {2009}
}
@article{DSElnagar2003,
abstract = {A new approach to separating single touching handwritten digit strings
is presented. The image of the connected numerals is normalized,
preprocessed and then thinned before feature points are detected.
Potential segmentation points are determined based on decision line
that is estimated from the deepest/highest valley/hill in the image.
The partitioning path is determined precisely and then the numerals
are separated before restoration is applied. Experimental results
on the NIST Database 19, CEDAR CD-ROM and our own collection of images
show that our algorithm can get a successful recognition rate of
96\%, which compares favorably with those reported in the literature.},
author = {Elnagar, Ashraf and Alhajj, Reda},
doi = {DOI: 10.1016/S0031-3203(02)00097-3},
file = {:D$\backslash$:/Papers/Documents/2003/Elnagar, Alhajj - 2003.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {Character segmentation},
number = {3},
pages = {625--634},
title = {{Segmentation of connected handwritten numeral strings}},
url = {http://www.sciencedirect.com/science/article/B6V14-4771RWD-3/2/7cbc7f3ab0340029eb6aaaff3e9693b8},
volume = {36},
year = {2003}
}
@inproceedings{ARMello2008,
abstract = {In this paper, we describe an approach for the problem of segmenting
overlapping characters. We are working with digit segmentation for
bank check processing. Our method is based on the idea of a hypothetical
ball traversing the number. The inertia of the movement segments
the overlapping digits. Rules are defined for this movement. Our
initial proposal achieved very good results with O(n2) complexity.},
address = {Sao Paulo, Brazil},
annote = {Last edited 2 march 2010},
author = {A.B.Mello, Carlos and Roe, Edward and B.Lacerda, Everton},
booktitle = {DocEng '08: Proceeding of the eighth ACM symposium on Document engineering},
doi = {http://doi.acm.org/10.1145/1410140.1410199},
file = {:D$\backslash$:/Papers/Documents/2008/A.B.Mello, Roe, B.Lacerda - 2008.pdf:pdf},
isbn = {978-1-60558-081-4},
keywords = { overlapping digits., segmentation,Document processing},
pages = {271--274},
publisher = {ACM},
title = {{Segmentation of Overlapping Cursive Handwritten Digits}},
year = {2008}
}
@article{Liu2004b,
author = {Liu, X.Y. and Blumenstein, M.},
doi = {10.1109/IWFHR.2004.40},
file = {:D$\backslash$:/Papers/Documents/2004/Liu, Blumenstein - 2004.pdf:pdf},
isbn = {0-7695-2187-8},
journal = {Ninth International Workshop on Frontiers in Handwriting Recognition},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {353--358},
publisher = {Ieee},
title = {{Experimental Analysis of the Modified Direction Feature for Cursive Character Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1363936},
year = {2004}
}
@article{Imran2010,
abstract = {Urdu script-based languagesÃ¢â¬â¢ character recognition has some technical issues not existing in other lan- guages and makes these languages more complicated. Segmentation-based character recognition approach for handwritten Urdu, both NastaÃ¢â¬â¢liq and Nasakh script-based languages, incorporates number of overhead and very less accurate as compared to segmentation free. This paper presents a segmenta- tion-free approach for recognition of online Urdu handwritten script using hybrid classifier, HMM and fuzzy logic. Trained data set consisting of HMMs for each stroke is further classified into 62 sub-patterns based on the primary stroke shape at the beginning and end using fuzzy rule. Fuzzy linguistic variables based on language structure are used to model features and provide suitable result for large variation in handwritten strokes. Twenty-six time variant structural and statistical features are extracted for the base strokes. The fuzzy classification into sub-patterns increases the efficiency and decreases the computa- tional complexity due to reduction in data set size. The hybrid HMMÃ¢â¬âfuzzy technique is efficient for large and complex data set. It provided 87.6\% and 74.1\% for NastaÃ¢â¬â¢liq and Nasakh, respectively, on 1800 ligatures. Ã®â¬â},
author = {Imran, Muhammad and Anwar, Fareeha and Husain, S A and Belaid, Abdel and Sher, Muhammad and Cedex, Nancy},
doi = {10.1016/j.knosys.2010.06.007},
file = {:D$\backslash$:/Papers/Documents/2010/Imran et al. - 2010.pdf:pdf},
issn = {0950-7051},
journal = {Knowledge-Based Systems},
keywords = {Fuzzy logic,HMM,Hybrid model,Online handwriting character recognition,Segmentation free},
number = {8},
pages = {914--923},
publisher = {Elsevier B.V.},
title = {{Knowledge-Based Systems HMM and fuzzy logic : A hybrid approach for online Urdu script-based languages Ã¢â¬â¢ character recognition}},
url = {http://dx.doi.org/10.1016/j.knosys.2010.06.007},
volume = {23},
year = {2010}
}
@article{MCCao95,
abstract = {Multiple experts system is shown to be a promising strategy for handwritten
recognition. This paper presents a multiple experts system using
neural networks. In the proposed system, the authors have developed:
(11 an incremental clustering neural network algorithm with merging
and canceling process, (2) a modified directional histogram feature
extraction method, and (3) a subclass method with learning rejection
neuron strategy. Our experimental results on a large set of data
show the efficiency and robustness of the proposed system.},
author = {{JUN CAOt}, M AHMADI and SHRIDHAR, M},
journal = {Pattern Recoynition},
number = {2},
pages = {153 160,},
title = {{Recognition of handwritten Numerals With Multiple Feature and Multistage Classifier }},
volume = {28},
year = {1995}
}
@inproceedings{Kundu2002,
abstract = {We describe an MD-HMM (model discriminant HMM) based HWR system (called NEHMM - non- ergodic HMM) whose system parameters are derived from the parameters of the VDHMM (variable dura- tion HMM) system described an [I]. The new HMM achieves better experimental results by more eficient utilization of variable duration information. However, more often the problem is Ã¢â¬Ëreliable computationÃ¢â¬â¢ of du- ration probabilities given limited databases. In the sec- ond phase of the paper, a scheme (VSLHMM - variable sequence length HMM) has been presented to avoid the computation of duration probabilities altogether with- out sacrificing the performance gain of the VDHMM system.},
author = {Kundu, A. and He, Y. and Chen, M.Y.},
booktitle = {Image Processing, 1997. Proceedings., International Conference on},
file = {:D$\backslash$:/Papers/Documents/2002/Kundu, He, Chen - 2002.pdf:pdf},
isbn = {0818681837},
pages = {304--307},
publisher = {IEEE},
title = {{Efficient utilization of variable duration information in HMM based HWR systems}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=632099},
volume = {3},
year = {2002}
}
@inproceedings{DSShah2008,
abstract = {In this paper, we present the creation of the first comprehensive
database for research and development on handwritten recognition
of Dari language. This new handwritten database consists of many
aspects of Dari scripts such as: handwritten isolated characters,
isolated digits, numeral strings of various lengths, many words/terms,
dates, and some special symbols. For each handwritten image in this
database, very useful ground truth information is provided to facilitate
successful recognition experiments on the images. The data has been
archived into two different formats - Gray level and Binary. The
contents of the database are frequently used in several kinds of
documents such as scientific and business documents. The overall
structure of the database has been designed in such a way to make
it convenient for conducting recognition experiments on the handwritten
Dari scripts.},
address = {Montreal, Canada},
author = {Shah, M I and Sadri, J and Suen, C Y and Nobile, N},
booktitle = {Eleventh International Conference on Frontiers in Handwriting Recognition},
file = {:D$\backslash$:/Papers/Documents/2008/Shah et al. - 2008.pdf:pdf},
keywords = { (OCR), Dari Handwritten Database, Dari Handwritten Recognition, Farsi and Arabic Hand-written Recognition., Handwritten Recognition,Optical},
month = aug,
pages = {635--640},
title = {{A New Multipurpose Comprehensive Database for Handwritten Dari Recognition}},
year = {2008}
}
@conference{ARLopresti2006,
abstract = {Two methods, Symbolic Indirect Correlation (SIC) and Style Constrained
Classification (SCC), are proposed for recognizing handwritten Arabic
and Chinese words and phrases. SIC reassembles variablelength segments
of an unknown query that match similar segments of labeled reference
words. Recognition is based on the correspondence between the order
of the feature vectors and of the lexical transcript in both the
query and the references. SIC implicitly incorporates language context
in the form of letter n-grams. SCC is based on the notion that the
style (distortion or noise) of a character is a good predictor of
the distortions arising in other characters, even of a different
class, from the same source. It is adaptive in the sense that, with
a long-enough field, its accuracy converges to that of a style-specific
classifier trained on the writer of the unknown query. Neither SIC
nor SCC requires the query words to appear among the references.},
author = {Lopresti, Daniel and Nagy, George and Seth, Sharad and Zhang, Xiaoli},
booktitle = {SACH06},
file = {:D$\backslash$:/Papers/Documents/2006/Lopresti et al. - 2006.pdf:pdf},
pages = {xx--yy},
title = {{Multi-character Field Recognition for Arabic and Chinese Handwriting}},
year = {2006}
}
@inproceedings{ARICDAR2005,
abstract = {This paper describes the Arabic handwriting recognition competition for ICDAR 2005. With the presentation of the IFN/ENIT-database in the year 2002 a database with handwritten Arabic town names was made available for free to non commercial research groups. Till now more than 30 groups are working with this data worldwide. By announcing a competition of Arabic handwriting recognition systems based on the IFN/ENIT-database, we hope to contribute to the development of Arabic handwriting recognition systems. The use of the same database by different research groups allows the comparison of different systems. We compare the systems on the most important characteristic: recognition rate, but also features like word length, writing style, and character connectivity will be discussed.},
author = {Margner, V and Pechwitz, M and Abed, H El},
booktitle = {Proceedings of the 2005 Eight International Conference on Document Analysis and Recognition (ICDARÃ¯Â¿Â½05)},
file = {:D$\backslash$:/Papers/Documents/2005/Margner, Pechwitz, Abed - 2005.pdf:pdf},
title = {{ICDAR 2005 Arabic Handwriting Recognition Competition}},
year = {2005}
}
@article{DSFarah2005,
abstract = {Given the number and variety of methods used for handwriting recognition,
it has been shown that there is no single method that can be called
the best. In recent years, the combination of different classifiers
and the use of contextual information have become major areas of
interest in improving recognition results. This paper addresses a
case study on the combination of multiple classifiers and the integration
of syntactic level information for the recognition of handwritten
Arabic literal amounts. To the best of our knowledge, this is the
first time either of these methods has been applied to Arabic word
recognition. Using three individual classifiers with high level global
features, we performed word recognition experiments. A parallel combination
method was tested for all possible configuration cases of the three
chosen classifiers. A syntactic analyzer makes a final decision on
the candidate words generated by the best configuration scheme. The
effectiveness of contextual knowledge integration in our application
is confirmed by the obtained results.},
author = {Farah, Nadir and Souici, Labiba and Sellami, Mokhtar},
file = {:D$\backslash$:/Papers/Documents/2005/Farah, Souici, Sellami - 2005.pdf:pdf},
journal = {Journal of Computer Science and Technology},
keywords = { Arabic literal amounts, contextual knowledge, multiclassifier systems,handwriting recognition},
month = may,
number = {3},
pages = {402--410},
title = {{Arabic Word Recognition by Classifiers and Context}},
volume = {20},
year = {2005}
}
@article{Khosravi2007,
author = {Khosravi, H and Kabir, E},
doi = {10.1016/j.patrec.2006.12.022},
file = {:D$\backslash$:/Papers/Documents/2007/Khosravi, Kabir - 2007.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {arabic,dataset,digit variety,farsi digits,handwriting,persian},
month = jul,
number = {10},
pages = {1133--1141},
title = {{Introducing a very large dataset of handwritten Farsi digits and a study on their varieties}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865507000037},
volume = {28},
year = {2007}
}
@article{Amin1998,
abstract = {Machine simulation of human reading has been the subject of intensive research for almost three decades.A large number of research papers and reports have already been published on Latin, Chinese and Japanese characters.However,littlework has been conductedonthe automaticrecognition of Arabic characters because of the complexity of printed and handwritten text, and this problem is still an open research field. The main objective of this paper is to present the state of Arabic character recognition research throughout the last two decades.Ã®â¬Â¨1998 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved},
author = {Amin, a},
doi = {10.1016/S0031-3203(97)00084-8},
file = {:D$\backslash$:/Papers/Documents/1998/Amin - 1998.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Arabic characters,Feature extraction,Handwriting recognition,Hidden Markov Models,Neural Network classifiers,Off-line recognition,Optical character recognition,Segmentation},
month = mar,
number = {5},
pages = {517--530},
title = {{Off-line Arabic character recognition the state of the art}},
volume = {31},
year = {1998}
}
@article{Eid2007,
address = {New York, New York, USA},
author = {Eid, Mohamad a. and Mansour, Mohamed and {El Saddik}, Abdulmotaleb H. and Iglesias, Rosa},
doi = {10.1145/1290144.1290161},
file = {:D$\backslash$:/Papers/Documents/2007/Eid et al. - 2007.pdf:pdf},
isbn = {9781595937834},
journal = {Proceedings of the international workshop on Educational multimedia and multimedia education - Emme '07},
pages = {103},
publisher = {ACM Press},
title = {{A haptic multimedia handwriting learning system}},
url = {http://portal.acm.org/citation.cfm?doid=1290144.1290161},
year = {2007}
}
@article{Ouyang2009,
author = {Ouyang, Jie and Patel, Nilesh and Sethi, Ishwar},
doi = {10.1016/j.patcog.2009.01.033},
file = {:D$\backslash$:/Papers/Documents/2009/Ouyang, Patel, Sethi - 2009.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {distributed data mining},
month = sep,
number = {9},
pages = {1786--1794},
title = {{Induction of multiclass multifeature split decision trees from distributed data}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320309000661},
volume = {42},
year = {2009}
}
@inproceedings{Saloum2001,
abstract = {Z suggest in this paper a method to recognition the Arabic hand-written text. First I explain a one step method for line thinning and introduce the concept of undetermined color in order to reduce the neighborhoods which increase the program speed, then Z spoke about the kind of different critical points which help us in distinguishing a letter from another. Then I gave a suitable method for building the text model on witch the process of recognition will take place.},
author = {Saloum, SS},
booktitle = {Int. Conf Comput. Syst. Appli},
file = {:D$\backslash$:/Papers/Documents/2001/Saloum - 2001.pdf:pdf},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {106--109},
title = {{Arabic hand-written text recognition}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/AICCSA.2001.933959},
year = {2001}
}
@article{Zadrozny2002,
abstract = {This paper presents a method for obtaining class membership probability esti- mates for multiclass classification problems by coupling the probability estimates produced by binary classifiers. This is an extension for arbitrary code matrices of a method due to Hastie and Tibshirani for pairwise coupling of probability estimates. Experimental results with Boosted Naive Bayes show that our method produces calibrated class membership probability estimates, while having similar classification accuracy as loss-based decoding, a method for obtaining the most likely class that does not generate probability estimates},
author = {Zadrozny, Bianca and Elkan, C.},
file = {:D$\backslash$:/Papers/Documents/2002/Zadrozny, Elkan - 2002.pdf:pdf},
journal = {Advances in neural information processing systems},
pages = {1041--1048},
publisher = {Citeseer},
title = {{Reducing multiclass to binary by coupling probability estimates}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.8948\&amp;rep=rep1\&amp;type=pdf},
volume = {2},
year = {2002}
}
@inproceedings{Su2007,
abstract = {A novel recognition strategy is proposed for the transcription of Chinese handwritten documents. The recognizer adapts continuous density Hidden Markov Model (HMM) as the recognition engine. It incorporates character segmentation and recognition in one step avoiding character segmentation phase. Textline is extracted and converted to observation sequence by sliding windows first. Then Baum-Welch algorithm is used to train character HMMs. Finally, best character string in maximizing a posteriori criterion is found out through Viterbi algorithm as output. Experiments are conducted on a writer-dependent Chinese handwriting database with a 1,695 lexicon. The results show that our baseline recognizer outperforms much one popular commercial handwritten character recognition product and the strategy presented in this paper is a promising research direction.},
author = {Su, T.H. and Zhang, T.W. and Qiu, Z.W.},
booktitle = {Machine Learning and Cybernetics, 2007 International Conference on},
file = {:D$\backslash$:/Papers/Documents/2007/Su, Zhang, Qiu - 2007.pdf:pdf},
keywords = {character recognition,chinese characters,handwriting recognition,hidden markov models,optical,sliding},
number = {August},
pages = {3412--3417},
publisher = {IEEE},
title = {{HMM-based system for transcribing Chinese handwriting}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4370738},
volume = {6},
year = {2007}
}
@inproceedings{PDB10Bhattacharya2003,
abstract = {This paper proposes a simple voting scheme for off-line recognition
of handprinted numerals. One of the main features of the proposed
scheme is that this is not script dependent. Another interesting
feature is that it is sufficiently fast for real-life applications.
In contrast to the usual practices, here we studied the efficiency
of a majority voting approach when all the classifiers involved are
multilayer perceptron (MLP) of different sizes and respective features
are based on wavelet transforms at different resolution levels. The
rationale for this approach is to explore how one can improve the
recognition performance without adding much to the requirements for
computational time and resources. For simplicity and efficiency,
in the present work, we considered only three coarse-to-fine resolution
levels of wavelet representation. We primarily simulated the proposed
technique on a database of off-line handprinted Bangla (a major Indian
script) numerals. We achieved 97.16\% correct recognition rate on
a test set of 5000 Bangla numerals. In this simulation we used two
other disjoint sets (one for training and the other for validation
purpose) of sizes 6000 and 1000 respectively. We have also tested
our approach on MNIST database for handwritten English digits. The
result is comparable with state-of-the-art technologies.},
address = {Edinburgh, Scotland, UK},
author = {Bhattacharya, Ujjwal and Chaudhuri, B B},
booktitle = {7th International Conference on Document Analysis and Recognition (ICDAR 2003)},
doi = {http://csdl.computer.org/comp/proceedings/icdar/2003/1960/01/196010016abs.htm},
file = {:D$\backslash$:/Papers/Documents/2003/Bhattacharya, Chaudhuri - 2003.pdf:pdf},
isbn = {0-7695-1960-1},
keywords = { Arabic Handwriting, MNIST,MultiClassifier Systems},
month = aug,
pages = {16--20},
publisher = {IEEE Computer Society},
title = {{A Majority Voting Scheme for Multiresolution Recognition of Handprinted Numerals.}},
volume = {2},
year = {2003}
}
@article{PDBSRIKANTAN1996,
author = {SRIKANTAN, GEETHA and LAM, STEPHEN W and SRIHARI, SARGUR N},
file = {:D$\backslash$:/Papers/Documents/1996/SRIKANTAN, LAM, SRIHARI - 1996.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Read},
mendeley-tags = {Read},
number = {7},
pages = {1147--1160},
title = {{GRADIENT-BASED CONTOUR ENCODING FOR CHARACTER RECOGNITION}},
volume = {29},
year = {1996}
}
@article{Al-Ohali2003,
author = {Al-Ohali, Y. and Cheriet, Mohamed and Suen, Ching},
file = {:D$\backslash$:/Papers/Documents/2003/Al-Ohali, Cheriet, Suen - 2003.pdf:pdf},
journal = {Pattern Recognition},
keywords = {arabic ocr,cheque processing,database of indian digits,databases of arabic handwriting,image processing},
number = {1},
pages = {111--122},
publisher = {Citeseer},
title = {{Databases for recognition of handwritten Arabic cheques}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.2091\&amp;rep=rep1\&amp;type=pdf},
volume = {36},
year = {2003}
}
@inproceedings{Srihari2006,
author = {Srihari, S.N. and Ball, G.R. and Srinivasan, Harish},
booktitle = {Proceedings of the 2006 conference on Arabic and Chinese handwriting recognition},
file = {:D$\backslash$:/Papers/Documents/2006/Srihari, Ball, Srinivasan - 2006.pdf:pdf},
pages = {57--69},
publisher = {Springer-Verlag},
title = {{Versatile search of scanned Arabic handwriting}},
url = {http://portal.acm.org/citation.cfm?id=1792262.1792266},
year = {2006}
}
@conference{ARDC2009,
abstract = {A new method for recognition of isolated handwritten English digits
is presented here. This method is based on Support Vector Machines
(SVMs). Mean and standard deviation of each digit is considered as
the features. Using these features, multiple SVM classifiers are
trained to separate different classes of digits. Support vector machine
are based on the concept of decision planes that defines the decision
boundaries. The decision plane is one that separates between the
set of digits having different class membership. The approach works
in four steps 1) Preprocessing 2) Feature extraction 3) Classification
4) detection. A database of 100 different representation of each
digit is constructed for the training database. The digits are first
manually segmented into 5 classes to minimize the time required to
obtain the hyperplane. Then the input is again check against the
two classes by 2-class SVM classifier. Experiments show that the
proposed features can provide a very good recognition result using
Support Vector Machines at a recognition rate 97\%, compared with
91.25\% obtained by MLP neural network classifier using the same features
and test set.},
author = {C, Shubhangi D and Hiremath, P S},
booktitle = {International Conference on Advances in Computing, Communication and Control (ICAC3Ã¯Â¿Â½09)},
file = {:D$\backslash$:/Papers/Documents/2009/C, Hiremath - 2009.pdf:pdf},
keywords = { English handwritten digits, structural features,Multi-class SVM classifier},
title = {{Multi-Class SVM Classifier for English Handwritten Digit Recognition using Manual Class Segmentation}},
year = {2009}
}
@inproceedings{Said1999,
abstract = {The p ap er intr duc o es a metho d of Ã®â¬Ånding the neighÃ®â¬Â­ b orho d of the optimal numb o er of hidden neur ons for 70 an err or b ackpr op agation neur al network with a sinÃ®â¬Â­ gle hidden layerÃ®â¬Â® It is b ase d on a study of the curvaÃ®â¬Â­ tur e of the err or functionÃ®â¬Â¬ during the tr aining phase 60 of the networkÃ®â¬Â® The metho d assur es c onver genc e and byp asses lo al minimasÃ®â¬Â® Exp c erimental r esults show the 50 uniqueness of the metho dÃ®â¬Â§s solution r gar e dless of the initial values of the networkÃ®â¬Â§s p ar ametersÃ®â¬Â® Two neur al 40 networks wer e builtÃ®â¬Â¬ one for r c gnizing unc e o onstr aine d handwritten English numer als and the other for A aÃ®â¬Â­ r bic numer alsÃ®â¬Â® R c gnition r e o esults and c omp arison with 30 other metho ds ar e also pr esente dÃ®â¬Â® 20},
author = {Said, F.N. and Yacoub, A. and Suen, C.Y.},
booktitle = {Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318)},
doi = {10.1109/ICDAR.1999.791768},
file = {:D$\backslash$:/Papers/Documents/1999/Said, Yacoub, Suen - 1999.pdf:pdf},
isbn = {0-7695-0318-7},
keywords = {Reference From Doctor,character recognition,english and},
mendeley-tags = {Reference From Doctor},
pages = {237--240},
publisher = {Ieee},
title = {{Recognition of English and Arabic numerals using a dynamic number of hidden neurons}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=791768},
year = {1999}
}
@inproceedings{PDB19Madeed2004,
abstract = {In this paper we present a new database for off-line Arabic handwriting
recognition, together with associated preprocessing procedures. We
have developed a new database for the collection, storage and retrieval
of Arabic handwritten text (AHDB). This is an advance both in terms
of the size of the database as well as the number of different writers
involved. We further designed an innovative, simple yet powerful,
in place tagging procedure for our database. It enables us to easily
extract the bitmaps of words. We also constructed a preprocessing
class, which contains some useful preprocessing operations. In this
paper the most popular words in Arabic writing were identified for
the first time, using an associated program.},
author = {Al-M\'{a}adeed, Somaya and Elliman, Dave and Higgins, Colin},
booktitle = {Int. Arab J. Inf. Technol.},
doi = {http://www.iajit.org/ABSTRACTS-1.htm\#06},
file = {:D$\backslash$:/Papers/Documents/2004/Al-M\'{a}adeed, Elliman, Higgins - 2004.pdf:pdf},
number = {1},
title = {{A Data Base for Arabic Handwritten Text Recognition Research.}},
volume = {1},
year = {2004}
}
@incollection{DSCheriet2008,
abstract = {Automatic recognition of Arabic handwritten text presents a problem
worth solving; it has increasingly more interest, especially in recent
years. In this paper, we address the most frequently encountered
problems when dealing with Arabic handwriting recognition, and we
briefly present some lessons learned from several serious attempts.
We show why morphological analysis of Arabic handwriting could improve
the accuracy of Arabic handwriting recognition. In general, Arabic
Natural Language Processing could provide some error handling techniques
that could be used effectively to improve the overall accuracy during
post-processing. We give a summary of techniques concerning Arabic
handwriting recognition research. We conclude with a case study about
the recognition of Tunisian city names, and place emphasis on visual-based
strategies for Arabic Handwriting Recognition (AHR).},
author = {Cheriet, Mohamed},
booktitle = {Arabic and Chinese Handwriting Recognition},
file = {:D$\backslash$:/Papers/Documents/2008/Cheriet - 2008.pdf:pdf},
pages = {1--21},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Visual Recognition of Arabic Handwriting: Challenges and New Directions}},
volume = {4768},
year = {2008}
}
@article{Ishida2010,
abstract = {We propose a novel sequence alignment algorithm for recognizing handwriting gestures by a camera. In the proposed method, an input image sequence is aligned to the reference sequences by phase- synchronization of analytic signals which are transformed from original feature values. A cumulative distance is calculated simultaneously with the alignment process, and then used for the classification. A major benefit of this method is that over-fitting to sequences of incorrect categories is restricted. The proposed method exhibited higher recognition accuracy in handwriting gesture recognition, compared with the conventional dynamic time warping method which explores optimal alignment results for all categories.},
author = {Ishida, Hiroyuki and Takahashi, Tomokazu and Ide, Ichiro and Murase, Hiroshi},
doi = {10.1016/j.patcog.2010.02.021},
file = {:D$\backslash$:/Papers/Documents/2010/Ishida et al. - 2010.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Analytic signal,Classification method,Gesture recognition,Sequence alignment},
month = aug,
number = {8},
pages = {2799--2806},
publisher = {Elsevier},
title = {{A Hilbert warping method for handwriting gesture recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320310001007},
volume = {43},
year = {2010}
}
@inproceedings{ARSabri2006,
abstract = {Arabic character recognition algorithm using Modified Fourier Spectrum
(MFS) is presented. The MFS descriptors are estimated by applying
the Fast Fourier Transform (FFT) to the Arabic character primary
part contour. Ten descriptors are estimated from the Fourier spectrum
of the character primary part contour by subtracting the imaginary
part from the real part (and not from the amplitude of the Fourier
spectrum as is usually the case). These descriptors are then used
in the training and testing of Arabic characters. The computation
of the MFS descriptors requires less computation time than the computation
of the Fourier descriptors. Experimental results have shown that
the MFS features are suitable for Arabic character recognition. Average
recognition rate of 95.9\% was achieved for the model classes. The
analysis of the errors indicates that this recognition rate can be
improved by using the Ã¯Â¿Â½holeÃ¯Â¿Â½ feature of a character and use cleaning
corrupted data.},
address = {London, UK},
author = {Mahmoud, Sabri A and Mahmoud, Ashraf S},
booktitle = {2006 International Conference on Geometric Modeling and Imaging (GMAI 2006)},
doi = {http://doi.ieeecomputersociety.org/10.1109/GMAI.2006.8},
file = {:D$\backslash$:/Papers/Documents/2006/Mahmoud, Mahmoud - 2006.pdf:pdf},
isbn = {0-7695-2604-7},
pages = {155--159},
publisher = {IEEE Computer Society},
title = {{Arabic Character Recognition using Modified Fourier Spectrum (MFS).}},
year = {2006}
}
@article{Natarajan2009,
author = {Natarajan, Prem and Subramanian, Krishna and Bhardwaj, Anurag and Prasad, Rohit},
doi = {10.1109/ICDAR.2009.278},
file = {:D$\backslash$:/Papers/Documents/2009/Natarajan et al. - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {971--975},
publisher = {Ieee},
title = {{Stochastic Segment Modeling for Offline Handwriting Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277556},
year = {2009}
}
@article{Hamid2001,
abstract = {The segmentation and recognition of Arabic handwritten text has been an area of great interest in the past few years. However, a small number of research papers and reports have been published in this area due to the dificult problems associated with Arabic handwritten text processing. In this work a technique is presented that segments handwritten Arabic text. A conventional algorithm is used for the initial segmentation of the text into connected blocks of characters. The algorithm then generates pre- segmentation points for these blocks. A neural network is subsequently used to verify the accuracy of these segmentation points. Two major problems were encountered: The segmentation phase proved to be successful in vertical segmentation of connected blocks of characters. However, it couldnÃ¢â¬â¢t segment characters that were overlapping horizontally. Second, segmentation of handwritten Arabic text depends largely on contextual information, and not only on topographic features extracted from these characters.},
author = {Hamid, a. and Haraty, R.},
doi = {10.1109/AICCSA.2001.933960},
file = {:D$\backslash$:/Papers/Documents/2001/Hamid, Haraty - 2001.pdf:pdf},
isbn = {0-7695-1165-1},
journal = {Proceedings ACS/IEEE International Conference on Computer Systems and Applications},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {110--113},
publisher = {IEEE Comput. Soc},
title = {{A neuro-heuristic approach for segmenting handwritten Arabic text}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=933960},
year = {2001}
}
@article{DSZhou2002,
abstract = {This paper investigates verification schemes and their applications
to the recognition of both isolated and touching handwritten numerals.
Definitions and functionality analyses of the verifiers are given.
The measurement of precision rate is used to assess the system reliability
in a class-specific manner. Verification-enhanced systems are proposed
with extensive experiments conducted on both isolated and touching
numerals. Two databases for touching numerals are built/organized
to serve as standard data sets. Experimental results indicate a substantial
improvement in system precision rates by the verification scheme,
which proves the effectiveness of the proposed systems and justifies
the important role of verifiers in OCR systems.},
author = {Zhou, Jie and Krzyzak, Adam and Suen, Ching Y},
doi = {DOI: 10.1016/S0031-3203(01)00109-1},
file = {:D$\backslash$:/Papers/Documents/2002/Zhou, Krzyzak, Suen - 2002.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {Handwritten numerals recognition},
number = {5},
pages = {1179--1189},
title = {{Verification--a method of enhancing the recognizers of isolated and touching handwritten numerals}},
url = {http://www.sciencedirect.com/science/article/B6V14-454609Y-K/2/1325f84ab8bc2015a1ff4639d7f3ccda},
volume = {35},
year = {2002}
}
@article{Cheriet2009,
author = {Cheriet, Mohamed and Bunke, Horst and Hu, Jianying and Kimura, Fumitaka and Suen, Ching Y.},
doi = {10.1016/j.patcog.2009.03.013},
file = {:D$\backslash$:/Papers/Documents/2009/Cheriet et al. - 2009.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
month = dec,
number = {12},
pages = {3129--3130},
publisher = {Elsevier},
title = {{New Frontiers in Handwriting Recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320309000971},
volume = {42},
year = {2009}
}
@article{Abed2007,
author = {Abed, Haikal El},
file = {:D$\backslash$:/Papers/Documents/2007/Abed - 2007.pdf:pdf},
journal = {Analysis},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {2--6},
title = {{ICDAR 2007 - Arabic Handwriting Recognition Competition}},
year = {2007}
}
@inproceedings{DSGuillevic1994,
abstract = {We describe the cursive script recognition module of a cheque processing
system currently under development at the Centre for Pattern Recognition
and Machine Intelligence (CENPARMI). Common systems perform recognition
either on a character by character basis, or on a word level. The
present study investigates the recognition at a higher level of abstraction,
at the sentence level. Our computational theory is based on a psychological
model of the reading process of a fast reader. In this paper, we
discuss the processing of the legal amount written on cheques. The
preprocessing and feature extraction modules as well as the word
classifier are presented. Preliminary results are not only promising,
but they also support our computational theory},
author = {Guillevic, Didier and Suen, Ching Y},
booktitle = {In International Workshop on Frontiers of Handwriting Recognition},
file = {:D$\backslash$:/Papers/Documents/1994/Guillevic, Suen - 1994.pdf:pdf},
pages = {216--223},
title = {{Cursive Script Recognition: A Sentence Level Recognition Scheme}},
year = {1994}
}
@article{Intrator1999,
author = {Intrator, Nathan and Steinherz, Tal and Rivlin, Ehud},
doi = {10.1007/s100320050040},
file = {:D$\backslash$:/Papers/Documents/1999/Intrator, Steinherz, Rivlin - 1999.pdf:pdf},
issn = {1433-2833},
journal = {International Journal on Document Analysis and Recognition},
keywords = {Reference From Doctor,cursive,handwritten,offline,recognition,segmentation,survey,word},
mendeley-tags = {Reference From Doctor},
month = dec,
number = {2-3},
pages = {90--110},
title = {{Offline cursive script word recognition ? a survey}},
url = {http://www.springerlink.com/Index/10.1007/s100320050040},
volume = {2},
year = {1999}
}
@conference{ARBenjelil2009,
abstract = {Arabic and Latin script identification in printed and handwritten
nature present several difficulties because the Arabic (printed or
handwritten) and the handwritten Latin scripts are cursive scripts
of nature. To avoid all possible confusions which can be generated,
we propose in this paper an accurate and suitable designed system
for script identification at word level which is based on steerable
pyramid transform. The features extracted from pyramid sub bands
serve to classify the scripts on only one script among the scripts
to identify. The encouraging and promising results obtained are presented
in this research paper.},
author = {Benjelil, Mohamed and Kanoun, Slim and Mullot, RÃ¯Â¿Â½my and Alimi, Adel M},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Benjelil et al. - 2009.pdf:pdf},
title = {{Arabic and Latin script identification in printed and handwritten types Based on Steerable Pyramid Features}},
year = {2009}
}
@article{ARZiaratban2008,
abstract = {In this study, a structural method described with

statistical features is proposed for isolated Farsi/Arabic

handwritten character recognition. All the characterÃ¯Â¿Â½s dots

are first removed, and the characterÃ¯Â¿Â½s body is thinned. A

set of feature points are then extracted and the skeleton is

decomposed into segments named primitives. Novel

statistical features are extracted from each segment. Three

basic characteristics behind the extracted features can

accurately describe the direction and curvatures of each

primitive. Since the numbers of primitives for characters

are not the same, three algorithms are applied to equalize

the lengths of features. Also another method is used for

reducing the recognition time based on the size of the

feature vectors.

Experimental results show the prominence of the

proposed features. The best recognition rate is obtained by

using the PCA algorithm for equalizing the feature vectors

that is 1.34\% more than wavelet features. Our dataset

includes 19118 samples. We used 11471 samples for

training and the rest (7647) for test.},
author = {Ziaratban, Majid and Faez, Karim and Allahveiradi, Farshid},
file = {:D$\backslash$:/Papers/Documents/2008/Ziaratban, Faez, Allahveiradi - 2008.pdf:pdf},
keywords = { Statistical description, hybrid feature extraction.,Farsi handwritten},
title = {{Novel Statistical Description for the Structure of Isolated Farsi/Arabic Handwritten Characters}},
year = {2008}
}
@article{ARCheriet2009b,
abstract = {CFHR 2008 Panel Discussion},
author = {Cheriet, Mohamed and MounimElYacoubi and Fujisawa, Hiromichi and Lopresti, Daniel and Lorette, Guy},
file = {:D$\backslash$:/Papers/Documents/2008/Cheriet et al. - 2008.pdf:pdf},
journal = {Pattern Recognition},
number = {12},
pages = {3131--3135},
title = {{Handwriting recognition research:Twenty years of achievement...and beyond}},
volume = {42},
year = {2008}
}
@article{Park1996,
abstract = {There are many uncertainties in handwritten character recognition. Stochastic modeling is a flexible and general method for modeling such problems and entails the use of probabilistic models to deal with uncertain or incomplete information. This paper presents an efficient scheme for off-line recognition of large-set handwritten characters in the framework of stochastic models, the first-order hidden Markov models (HMMs). To facilitate the processing of unconnected patterns and patterns with isolated noises, four types of feature vectors based on the regional projection contour transformation (RPCT) are employed. The recognition system consists of two phases. For each character, in the training phase, multiple HMMs corresponding to different feature types of RPCT are built. In the classification phase, the results of individual classifiers to produce the final recognition result for an input character are integrated, where each individual HMM classifier produces one score that is the probability of generating the test observation sequence for each character model. In this paper, several methods for integrating the results of different classifiers are considered so that a better result could be obtained. In order to verify the effectiveness of the proposed scheme, the most frequently used 520 types of Hangul characters in Korea have been considered in the experiments. Experimental results indicate that the proposed scheme is very promising for the recognition of large-set handwritten characters with numerous variations},
author = {Park, H},
doi = {10.1016/0031-3203(95)00081-X},
file = {:D$\backslash$:/Papers/Documents/1996/Park - 1996.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Regional projection contour transformation,hidden markov model,large set handwritten character recognition,multiple classifier combination},
month = feb,
number = {2},
pages = {231--244},
title = {{Off-line recognition of large-set handwritten characters with multiple hidden Markov models}},
volume = {29},
year = {1996}
}
@conference{ARKESSENTINI2009,
abstract = {Generally, handwritten word recognition systems use script specific
methodologies. In this paper, we present a unified approach for multi-lingual
recognition of alphabetic scripts. The proposed system operates independently
of the nature of the script using the multi-stream paradigm. The
experiments have been carried out on a multi-script database composed
of Arabic and Latin handwritten words from the IFN/ENIT and the IRONOFF
public databases and show interesting recognition performances with
only 1.5\% of script confusion and an overall word recognition rate
of 84.5\% using a multi-script lexicon of 1142 words.},
author = {KESSENTIN, Yousri and PAQUET, Thierry and HAMADOU, AbdelMajid B E N},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/KESSENTIN, PAQUET, HAMADOU - 2009.pdf:pdf},
title = {{A Multi-Lingual Recognition System for Arabic and Latin Handwriting}},
year = {2009}
}
@article{DSHussein1999,
abstract = {A knowledge-based segmentation algorithm to enhance recognition of
courtesy amounts on bank checks is proposed in this paper. This algorithm
uses multiple contextual cues to enhance segmentation and recognition.
The system described extracts context from the handwritten numerals
and uses a syntax parser based on a deterministic finite automaton
to provide adequate feedback to enhance recognition. Further feedback
is provided by a simple legal amount decoder that determines word
count and recognizes several key words (e.g. thousand and hundred).
This provides an additional semantic constraint on the dollar section.
The segmentation analysis module presented is capable of handling
a number of commonly used styles for courtesy amount representation.
Both handwritten and machine written courtesy and legal amounts were
utilized to test the efficacy of the preprocessor for the check recognition
system described in this paper. The substitution error was reduced
by 30-40\% depending on the input check mix.},
annote = {Last edited 2 march 2010},
author = {Hussein, Karim M and Agarwal, Arun and Gupta, Amar and Wang, Patrick S P},
doi = {DOI: 10.1016/S0031-3203(98)00073-9},
file = {:D$\backslash$:/Papers/Documents/1999/Hussein et al. - 1999.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {Automata},
number = {2},
pages = {305--316},
title = {{A knowledge-based segmentation algorithm for enhanced recognition of handwritten courtesy amounts}},
url = {http://www.sciencedirect.com/science/article/B6V14-3W83VC2-1B/2/dd26998d2d5e3249216f915288abeb37},
volume = {32},
year = {1999}
}
@article{Zhang2005,
author = {Zhang, P and Bui, TD and Suen, CY},
file = {:D$\backslash$:/Papers/Documents/2005/Zhang, Bui, Suen - 2005.pdf:pdf},
journal = {Analysis},
keywords = {hybrid feature extraction,random feature},
publisher = {IEEE Computer Society},
title = {{Hybrid feature extraction and feature selection for improving recognition accuracy of handwritten numerals}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICDAR.2005.129},
year = {2005}
}
@inproceedings{ARElAbed2007,
abstract = {Databases enclosing a huge amount of images of handwritten words together
with detailed ground truth information are the most important precondition
for the development of handwritten word recognition systems. The
IFN/ENIT-database of handwritten Tunisian town names is used by many
research groups working on recognition systems. This paper gives
at first a short overview about the most important features of the
IFN/ENIT-database. In the second part an example of using the data
for developing baseline estimation methods is given. In the third
part a recognition system is described and some results are show},
author = {Abed, Haikal El and Margner, Volker},
booktitle = {9th International Symposium on Signal Processing and Its Applications, ISSPA 2007,},
file = {:D$\backslash$:/Papers/Documents/2007/Abed, Margner - 2007.pdf:pdf},
title = {{The IFN/ENIT-database - a tool to develop Arabic handwriting recognition systems}},
year = {2007}
}
@inproceedings{Britto2003,
abstract = {In this paper we combine complementary features based on foreground and background information in an HMM-based classifier to recognize handwritten digits. A zoning scheme based on column and row models provides a way of dividing the digit into zones without making the features size variant. This strategy allows us to avoid the digit normalization, while it provides a way of having information from specific zones of the digit. Recognition rates around 98\% have been achieved using 60,000 digit samples of the NIST SD19 database.},
annote = {===========================================
Paper Index : Jr2003
Date:23-11-2010


Why read paper ?
HMM background.


Paper Overview ?
the hmm on digits with nist database with 98\%


What is these paper about ? (Summary)


Feature extraction:
for each column and row extract both forground and background set of features.
1) circular transiton basedn on R and center of gravity of trantion (from black to white)of each column
2) realative postion of each transition.
3) wether transition outer or inner.
4) vertical projection and deravitive between it ato adjacent column (34 features of ff).
back ground concavity .
info each fatures get number of background pixel that are labeled using specific conacvity configuration.
hmm models used 2 for each digits one for row other for colmn 20 model are used (see fig 5)
the use fo row and column hmm make recognition based on zones.
Result
NIST digits with 60,000 and 10,000  test
Experiements vs. state no. and vs. no of codebook size with 256 codebook size si best with 12 min of state 95.26 95.5\%
combinig column and row 98\%




1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?


2. What can we take from this work  ? what do we learn ? What can be incorporated into our own work ?


3. What are the problems of the paper ?


4. what is lacking from the work ? why does this work knot be the final  research in this subject ?


5. what about the methods causes this lack ? is there a fundamental reason ?


6. Could incremental Changes Fix this lack ? if so, what changes ?




Is there is any question you had about the paper ?




The final conclusion..........


==========================================================================

      },
author = {{Britto Jr}, A.S. and Sabourin, R. and Bortolozzi, F. and Suen, C.Y.},
booktitle = {12th International Conference on Image Analysis and Processing, 2003.Proceedings.},
doi = {10.1109/ICIAP.2003.1234127},
file = {:D$\backslash$:/Papers/Documents/2003/Britto Jr et al. - 2003.pdf:pdf},
isbn = {0-7695-1948-2},
keywords = {Arabic Handwritting recognition,Read,Reference From Doctor,Summarized},
mendeley-tags = {Arabic Handwritting recognition,Read,Reference From Doctor,Summarized},
pages = {670--675},
publisher = {IEEE Computer Society},
title = {{Complementary Features Combined in an HMM-Based System to Recognize Handwritten Digits}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICIAP.2003.1234127},
year = {2003}
}
@article{Gunter2004,
abstract = {In off-line handwriting recognition, classifiers based on hidden Markov models (HMMs) have become very popular.However, while there exist well-established training algorithms which optimize the transition and output probabilities of a given HMM architecture, the architecture itself, and in particular the number of states, must be chosen Ã¢â¬Åby handÃ¢â¬ï¿½. Also the number of training iterations and the output distributions need to be defined by the system designer. In this paper we examine several optimization strategies for an HMM classifier that works with continuous feature values. The proposed optimization strategies are evaluated in the context of a handwritten word recognition task},
author = {Gunter, Simon and Bunke, Horst},
doi = {10.1016/j.patcog.2004.04.006},
file = {:D$\backslash$:/Papers/Documents/2004/Gunter, Bunke - 2004.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {gaussian mixture,handwritten word recognition,hidden markov model,hmm,state number optimization,training strategy},
number = {10},
pages = {2069--2079},
publisher = {Elsevier},
title = {{HMM-based handwritten word recognition: on the optimization of the number of states, training iterations and Gaussian components}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320304001633},
volume = {37},
year = {2004}
}
@article{LOU2008,
author = {LOU, Z. and YANG, J.Y.U. and JIN, Z.},
file = {:D$\backslash$:/Papers/Documents/2008/LOU, YANG, JIN - 2008.pdf:pdf},
journal = {ieeexplore.ieee.org},
keywords = {bank cheque processing,chinese handwritten character,legal amount,pattern recognition},
pages = {30--31},
title = {{RECOGNITION AND CHECKOUT OF LEGAL AMOUNTS ON CHINESE BANK CHEQUES}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4635811},
year = {2008}
}
@article{ARAssaleh2009,
abstract = {This paperproposesanonlinevideo-based approachtohandwrittenArabicalphabetr
cognition. Various temporalandspatialfeature extractiontechniquesareintroduced.
the motion nformation of the handmovementisprojectedontotwostaticaccumulateddifferenceimagesac
ordingto the motion directionality. the temporalanalysisisfollowed
bytwo-dimensionaldiscret cosine transform andZonalcodingorRadon transformation
andlowpassfiltering. the resulting feature vectors are time-independent
thus canbeclassifiedbyasimpleclassificationtechn quesuchasK Nearest
Neighbor(KNN). the solution is further enhanced by introducing the
notionof uperclasses where similar classesaregrouped toge the rfor
the purposeof multiresolutionalcl ssification. Experimental resultsindicateanimpressive
99\% recognitionrateonuser-dependantmode. o validate the proposed
technique,we haveconductedaseriesof experimentsusingHidde Markov
models (HMM),whichis the classicalwayofclassifyingdatawithtemporaldependenc
es. Experimental resultsrevealedthat the proposedfeatureextractionschemecombinedwiths
mple KNN yields superiorresults tothoseobtainedby the classicalHMM-basedscheme},
author = {{Khaled Assaleha}, c and Shanablehb, Tamer and Hajja, Husam},
file = {:D$\backslash$:/Papers/Documents/2009/Khaled Assaleha, Shanablehb, Hajja - 2009.pdf:pdf},
journal = {Journal of theFranklin Institute},
pages = {175Ã¯Â¿Â½189},
title = {{Recognition of handwritten Arabicalphabet via hand motion tracking}},
volume = {346},
year = {2009}
}
@inproceedings{PDBChen2005,
abstract = {Real-time object detection is essential for many computer vision applications.
Many rapid detection algorithms are based on using cascades of tests.
But existing design criteria for cascades either ignore the time
complexity of the tests or make over-simplified assumptions about
them. This paper gives a criterion for designing a time-efficient
cascade that explicitly takes into account the time complexity of
tests (as evaluated by computer run time) including the time for
pre-processing. We design a greedy algorithm to minimize this criterion
(noting that the full problem is NP-complete). Finally, we illustrate
our method on the task of text detection in city scenes. This gives
a text detection algorithm that runs at 0.025 seconds per 320Ã¯Â¿Â½240
image, which is equivalent to 40 frames per second. This is a speed
up factor of 2.5 compared to our previous text detector. It gives
a realtime system which can be used for applications to help the
blind and visually impaired.},
author = {Chen, Xiangrong and Yuille, Alan L},
booktitle = {Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPRÃ¯Â¿Â½05)},
file = {:D$\backslash$:/Papers/Documents/2005/Chen, Yuille - 2005.pdf:pdf},
title = {{A Time-Efficient Cascade for Real-Time Object Detection: With applications for the visually impaired}},
year = {2005}
}
@inproceedings{DSGu2006,
abstract = { In this paper, a novel fusion recognition algorithm of courtesy and
legal amounts in handwritten Chinese bank checks is presented. Unlike
the other fusion methods based on the independent recognition results
of courtesy and legal amount, this proposed fusion algorithm begins
with the segmentation of legal amount with the guide of recognition
candidates of courtesy amount. And then we fuse the recognition candidates
of courtesy and legal amounts. The system is validated with 1053
real bank checks. When the substitution is 0.43\%, the recognition
rate at the amount level can reach 66.10\%},
author = {Gu, Jun-xia and Ding, Xiao-qing},
booktitle = {8th International Conference on Signal Processing, 2006},
doi = {10.1109/ICOSP.2006.345773},
file = {:D$\backslash$:/Papers/Documents/2006/Gu, Ding - 2006.pdf:pdf},
keywords = { ;image segmentation;law administration;,Chinese handwritten bank checks;fusion recognition},
title = {{Fusion Recognition of Courtesy and Legal Amounts on Chinese Handwritten Bank Checks}},
volume = {3},
year = {2006}
}
@article{Mozaffari2009,
author = {Mozaffari, Saeed and Soltanizadeh, Hadi},


isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
keywords = {2009,arabic languages,duplication of efforts,evaluation,farsi,isolated digits and characters,large database,ocr benchmarking,performance,the aim of icdar},
month = jul,
pages = {1413--1417},
publisher = {Ieee},
title = {{ICDAR 2009 Handwritten Farsi/Arabic Character Recognition Competition}},
year = {2009}
}
@article{Masuyama2002,
author = {Masuyama, Takeshi and Nakagawa, H.},
file = {:D$\backslash$:/Papers/Documents/2002/Masuyama, Nakagawa - 2002.pdf:pdf},
journal = {Expert Systems},
pages = {2--6},
publisher = {IEEE COmputer Society},
title = {{Applying cascaded feature selection to SVM text categorization}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/DEXA.2002.1045905},
year = {2002}
}
@inproceedings{DSSaabni2009,
abstract = {The difficulties in segmenting cursive words into individual characters
have shifted the focus of handwriting recognition research from segmentation-based
approaches to segmentation-free (holistic) methods. However, maintaining
and training large number of prototypes (models) that represent the
words in the dictionary make the training process extremely expensive
and difficult in computing resources. In this paper we present an
efficient system that automatically generates prototypes for each
word in a given dictionary using multiple appearance of each letter
shape. Multiple appearance allows for many permutation of shapes
for each word and thus complicates searching for the right prototype.
To simplify the training, reduce the maintained prototypes, and avoid
over fitting, we used dimensionality reduction followed by clustering
techniques to reduce the size of these sets without affecting their
ability to represent the wide variations of the handwriting styles.
A set of generated fonts are created by professional writers imitating
all handwriting styles for each character in each position. These
fonts are used to generate all shapes for writing each word-part
in a comprehensive dictionary. Principal component analysis and k-means
clustering techniques are performed to select the minimal number
of shapes representing the wide variations of handwriting styles
for a word-part. Experimental results using an online recognition
system proves the credibility of this process compared to manually
generated databases.},
author = {Saabni, R and El-Sana, J},
booktitle = {10th International Conference on Document Analysis and Recognition, 2009. ICDAR '09.},
doi = {10.1109/ICDAR.2009.258},
file = {:D$\backslash$:/Papers/Documents/2009/Saabni, El-Sana - 2009.pdf:pdf},
issn = {1520-5363},
keywords = {Kohonen SOM;comprehensive database generation;curs},
month = jul,
pages = {1231--1235},
title = {{Efficient Generation of Comprehensive Database for Online Arabic Script Recognition}},
year = {2009}
}
@inproceedings{PDBYuan2005,
abstract = {Nearest neighbor search is commonly employed in face recognition but
it does not scale well to large dataset sizes. A strategy to combine
rejection classifiers into a cascade for face identification is proposed
in this paper. A rejection classifier for a pair of classes is defined
to reject at least one of the classes with high confidence. These
rejection classifiers are able to share discriminants in feature
space and at the same time have high confidence in the rejection
decision. In the face identification problem, it is possible that
a pair of known individual faces are very dissimilar. It is very
unlikely that both of them are close to an unknown face in the feature
space. Hence, only one of them needs to be considered. Using a cascade
structure of rejection classifiers, the scope of nearest neighbor
search can be reduced significantly. Experiments on Face Recognition
Grand Challenge (FRGC) version 1 data demonstrate that the proposed
method achieves significant speed up and an accuracy comparable with
the brute force Nearest Neighbor method. In addition, a graph cut
based clustering technique is employed to demonstrate that the pairwise
separability of these rejection classifiers is capable of semantic
grouping},
author = {Yuan, Quan and Thangali, Ashwin and Sclaroff, Stan},
booktitle = {Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPRÃ¯Â¿Â½05)},
file = {:D$\backslash$:/Papers/Documents/2005/Yuan, Thangali, Sclaroff - 2005.pdf:pdf},
title = {{Face Identification by a Cascade of Rejection Classifiers}},
year = {2005}
}
@article{Nishimura2003,
abstract = {Recognition of variously deformed character patterns is a salient subject for off-line hand-printed character recognition. Sufficient recognition performance for practical use has not been achieved despite reports of many recognition techniques. Our research examines effective recognition techniques for deformed characters, extending conventional recognition techniques using an on-line character writing information containing writing pressure data. This study extends conventional recognition techniques using on-line character writing information containing writing pressure information. A recognition system using simple pattern matching and HMM was made for evaluation experiments using Common Hand- printed English character patterns from the ETL6 database to determine effectiveness of the proposed extending recognition method. Character recognition performance is increased in both expansion recognition methods using on-line writing information.},
author = {Nishimura, Hiromitsu and Timikawa, Takehiko},
file = {:D$\backslash$:/Papers/Documents/2003/Nishimura, Timikawa - 2003.pdf:pdf},
journal = {Document Analysis and Recognition},
pages = {168},
title = {{Off-line Character Recognition using On-line Character Writing Information}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICDAR.2003.1227653},
volume = {1},
year = {2003}
}
@inproceedings{ARXiu2006,
abstract = {Abstract. The research on offline handwritten Arabic character recognition
has received more and more attention in recent years, because of
the increasing needs of Arabic document digitization. The variation
in Arabic handwriting brings great difficulty in character segmentation
and recognition, eg., the subparts (diacritics) of the Arabic character
may shift away from the main part. In this paper, a new probabilistic
segmentation model is proposed. First, a contourbased over-segmentation
method is conducted, cutting the word image into graphemes. The graphemes
are sorted into 3 queues, which are character main parts, sub-parts
(diacritics) above or below main parts respectively. The confidence
for each character is calculated by the probabilistic model, taking
into account both of the recognizer output and the geometric confidence
besides with logical constraint. Then, the global optimization is
conducted to find optimal cutting path, taking weighted average of
character confidences as objective function. Experiments on handwritten
Arabic documents with various writing styles show the proposed method
is effective},
address = {Nelson, New Zealand},
author = {Xiu, Pingping and Peng, Liangrui and Ding, Xiaoqing and Wang, Hua},
booktitle = {Document Analysis Systems VII, 7th International Workshop},
editor = {Bunke, Horst and Spitz, A Lawrence},
file = {:D$\backslash$:/Papers/Documents/2006/Xiu et al. - 2006.pdf:pdf},
isbn = {3-540-32140-3},
month = feb,
pages = {402--412},
publisher = {Springer},
title = {{Offline Handwritten Arabic Character Segmentation with Probabilistic Model.}},
year = {2006}
}
@inproceedings{Al-Hajj2007,
abstract = {In this paper we present a two-stage system for the off-line recognition of cursive Arabic handwritten words. The proposed method is analytic without segmentation, and is able to cope with handwriting inclination and with shifted positions of diacritical marks. First, the recognition stage relies on 3 classifiers based on hidden Markov modelling (HMM). The second stage depends on the combination of these classifiers. The feature vectors used for recognition are related to pixel density distribution and to local pixel configurations. These vectors are extracted on word binary images by using a sliding window approach with different angles. We have experimented different combination schemes. The neural network-based combined system yields best performance on the IFN- ENIT benchmark data base of handwritten names of Tunisian villages/towns.},
author = {Al-Hajj, R. and Mokbel, Chafic and Likforman-Sulem, L.},
booktitle = {Document Analysis and Recognition, 2007. ICDAR 2007. Ninth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2007/Al-Hajj, Mokbel, Likforman-Sulem - 2007.pdf:pdf},
issn = {1520-5363},
pages = {959--963},
publisher = {IEEE},
title = {{Combination of hmm-based classifiers for the recognition of arabic handwritten words}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4377057},
volume = {2},
year = {2007}
}
@conference{ARSaabni2009,
abstract = {The difficulties in segmenting cursive words into individual characters
have shifted the focus of handwriting recognition research from segmentation-based
approaches to segmentation-free (holistic) methods. However, maintaining
and training large number of prototypes (models) that represent the
words in the dictionary make the training process extremely expensive
and difficult in computing resources. In this paper we present an
efficient system that automatically generates prototypes for each
word in a given dictionary using multiple appearance of each letter
shape. Multiple appearance allows for many permutation of shapes
for each word and thus complicates searching for the right prototype.
To simplify the training, reduce the maintained prototypes, and avoid
over fitting, we used dimensionality reduction followed by clustering
techniques to reduce the size of these sets without affecting their
ability to represent the wide variations of the handwriting styles.
A set of generated fonts are created by professional writers imitating
all handwriting styles for each character in each position. These
Fonts are used to generate all shapes for writing each word-part
in a comprehensive dictionary. Principal component analysis and k-means
clustering techniques are performed to select the minimal number
of shapes representing the wide variations of handwriting styles
for a word-part. Experimental results using an online recognition
system proves the credibility of this process compared to manually
generated databases.},
author = {Saabni, Raid and El-sana, Jihad},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Saabni, El-sana - 2009(3).pdf:pdf},
title = {{Efficient Generation of Comprehensive Database for Online Arabic Script Recognition}},
year = {2009}
}
@article{ARJou2009,
abstract = {Previous handwritten numeral recognition algorithms applied structural
classification to extract geometric primitives that characterize
each image, and then utilized artificial intelligence methods, like
neural network or fuzzy memberships, to classify the images. We propose
a handwritten numeral recognition methodology based on simplified
structural classification, by using a much smaller set of primitive
types, and fuzzy memberships. More specifically, based on three kinds
of feature points, we first extract five kinds of primitive segments
for each image. A fuzzy membership function is then used to estimate
the likelihood of these primitives being close to the two vertical
boundaries of the image. Finally, a tree-like classifier based on
the extracted feature points, primitives and fuzzy memberships is
applied to classify the numerals. With our system, handwritten numerals
in NIST Special Database 19 are recognized with correct rate between
87.33\% and 88.72\%.},
author = {Jou, Chichang and Lee, Hung-Chang},
file = {:D$\backslash$:/Papers/Documents/2009/Jou, Lee - 2009.pdf:pdf},
journal = {Expert Systems with Applications},
keywords = { Feature extraction, Fuzzy memberships, Structural classification,Handwritten numeral recognition},
month = nov,
number = {9},
pages = {11858--11863},
title = {{Handwritten numeral recognition based on simplified structural classification and fuzzy memberships}},
volume = {36},
year = {2009}
}
@incollection{ARAli2008,
abstract = {In this module, Learning Vector Quantization LVQ neural network is
first time introduced as a classifier for Arabic handwritten character.
Classification has been performed in two different strategies, in
first strategy, we use one classifier for all 53 Arabic Character
Basic Shapes CBSs in training and testing phases, in second strategy
we use three classifiers for three subsets of 53 Arabic CBSs, the
three subsets of Arabic CBSs are; ascending CBSs, descending CBSs
and embedded CBSs. Three training algorithms; OLVQ1, LVQ2 and LVQ3
were examined and OLVQ1 found as the best learning algorithm.},
author = {Ali, Mohamed A},
booktitle = {ICISP},
file = {:D$\backslash$:/Papers/Documents/2008/Ali - 2008.pdf:pdf},
keywords = { Classification, Neural Network,Arabic handwritten recognition},
pages = {463 Ã¯Â¿Â½ 470,},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Arabic Handwritten Characters Classification Using Learning Vector Quantization Algorithm}},
year = {2008}
}
@inproceedings{PDB3Zhu2003,
abstract = {Active and semi-supervised learning are important techniques when
labeled data are scarce. We combine the two under a Gaussian random
field model. Labeled and unlabeled data are represented as vertices
in a weighted graph, with edge weights encoding the similarity between
instances. The semi-supervised learning problem is then formulated
in terms of a Gaussian random field on this graph, the mean of which
is characterized in terms of harmonic functions. Active learning
is performed on top of the semisupervised learning scheme by greedily
selecting queries from the unlabeled data to minimize the estimated
expected classification error (risk); in the case of Gaussian fields
the risk is efficiently computed using matrix methods. We present
experimental results on synthetic data, handwritten digit recognition,
and text classification tasks. The active learning scheme requires
a much smaller number of queries to achieve high accuracy compared
with random query selection.},
address = {Washington, DC, USA},
author = {Zhu, Xiaojin and Ghahramani, Zoubin and Lafferty, John D},
booktitle = {Machine Learning, Proceedings of the Twentieth International Conference (ICML 2003)},
editor = {Fawcett, Tom and Mishra, Nina},
file = {:D$\backslash$:/Papers/Documents/2003/Zhu, Ghahramani, Lafferty - 2003.pdf:pdf},
isbn = {1-57735-189-4},
month = aug,
pages = {912--919},
publisher = {AAAI Press},
title = {{Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions.}},
year = {2003}
}
@article{FE2Gader1996,
abstract = {Abstract-An automatic feature generation method for handwritten digit
recognition is described. Two different evaluation measures, orthogonality
and information, are used to guide the search for features. The features
are used in a backpropagation trained neural network. Classification
rates compare favorably with results published in a survey of high-performance
handwritten digit recognition systems. This classifier is combined
with several other high performance classifiers. Recognition rates
of around 98\% are obtained using two classifiers on a test set with
1,000 digits per class.},
annote = {My notes are},
author = {Gader, Paul D and Khabou, Mohamed Ali},
file = {:D$\backslash$:/Papers/Documents/1996/Gader, Khabou - 1996.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = { Handwritten digits,Features Extraction},
month = dec,
number = {12},
pages = {1256--1261},
title = {{Automatic Feature Generation for Handwritten Digit Recognition}},
volume = {18},
year = {1996}
}
@article{Gadat2007,
author = {Gadat, S. and Younes, Laurent},
file = {:D$\backslash$:/Papers/Documents/2007/Gadat, Younes - 2007.pdf:pdf},
journal = {The Journal of Machine Learning Research},
keywords = {clas-,feature selection,pattern recognition,robbins-monro application,sification algorithm,stochastic learning algorithms},
pages = {547},
publisher = {MIT Press},
title = {{A stochastic algorithm for feature selection in pattern recognition}},
url = {http://portal.acm.org/citation.cfm?id=1248659.1248678},
volume = {8},
year = {2007}
}
@inproceedings{Vajda2005,
abstract = {In this paper, an improvement of a 2D stochastic model based handwritten entity recognition system is described. To model the handwriting considered as being a two di- mensional signal, a context based, segmentation-free Hid- den Markov Model (HMM) recognition system was used. The baseline approach combines a Markov Random Field (MRF) and a HMM so-called Non-Symmetric Half Plane HiddenMarkovModel (NSHP-HMM). To improve the results performed by this baseline system operating just on low-level pixel information an extension of the NSHP-HMM is proposed. The mechanism allows to extend the observations of the NSHP-HMM by implanting structural information in the system. At present, the accu- racy of the system on the SRTP1 French postal check data- base is 87.52\%while for the handwritten Bangla city names is 86.80\%. The gain using this structural information for the SRTP dataset is 1.57\%.},
author = {Vajda, S. and Belayd, A.},
booktitle = {Eighth International Conference on Document Analysis and Recognition (ICDAR'05)},
doi = {10.1109/ICDAR.2005.222},
file = {:D$\backslash$:/Papers/Documents/2005/Vajda, Belayd - 2005.pdf:pdf},
isbn = {0-7695-2420-6},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
pages = {1126--1130},
publisher = {Ieee},
title = {{Structural Information Implant in a Context Based Segmentation-Free HMM Handwritten Word Recognition System for Latin and Bangla Script}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1575719},
year = {2005}
}
@inproceedings{Nakai2002,
abstract = {A new method isproposedfor on-line handwriting recog- nition of Kanji characters. The method employs substroke HMMs as minimum units to constitute Japanese Kanji char- acters and utilizes the direction of pen motion. The main motivation is to fully utilize the continuous speech recogni- tion algorithm by relating sentence speech to Kanji charac- te6 phonemes to substrokes, and grammar to Kanji struc- ture. The proposed system consists input feature analysis, substroke HMMs, a character structure dictionary and a de- coder. The present approach has the following advantages over the conventional methods that employ whole charac- ter HMMs. I) Much smaller memory reqiiirenient for dic- tionary and models. 2) Fast recognition by employing e@- cient substroke network search. 3) CapabiliQ of recogniz- ing characters not included in the training data if defined as a sequence of substrokes in the dictionaiy. 4) Capability of recognizing characters written by various diperetit stroke orders with multiple definitions per one character in the dic- tionary. 5) Easiness in HMM adaptation to the user with a few sample character data.},
annote = {===========================================

        Paper Index : Nakai2001

        Date:22-11-2010



        Why read paper ?



Build knowldge on Character recognition by HMM.



        Paper Overview ?

uses Sub stroke online system.
HMM per sub stroke. a combination of hmm create character.
A lot of character as for kanji japanese characters.





What is these paper about ? (Summary)

pen direction and velocity of location pen up is used.
direction of sub strok and substrokes are extracted.
There is HMM model for each direction.
Recognition is used to hmm viterbi algorith to detect sequence of sub stroke that is possible to create a chracter.
Kanji chracter are defined as in hierarchial manar whera a character can be a set of substrokes or [2 different other characters. ]

        Results:

1 , 016 different characters are used to test .
Test done on japanees dataset.
Experiement of using substrok 95.34
 vs. character hmm 95.95.
 the writer vs. independent hmm. analysis



        1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?

The large number of character the system can recognize.

        2. What can we take from this work  ? what do we learn ? What can be incorporated into our own work ?

 The HMM can be part of character not all character.  The features are very simple as they use the directional (curvature of ) online strokes.



        3. What are the problems of the paper ?

the decode system that build characters form recognizied substrokes hmm is complex and speciific for languages.





        4. what is lacking from the work ? why does this work knot be the final  research in this subject ?



A full test on various dataset and various languages. also testing different writing styles and sizes.



5. what about the methods causes this lack ? is there a fundamental reason ?




6. Could incremental Changes Fix this lack ? if so, what changes ?






        Is there is any question you had about the paper ?

the decode system is not presented in details.



The final conclusion..........



May have some ideas but I think hard to use on arabic languages.


==========================================================================

      },
author = {Nakai, Mitsuru and Akira, Naoto and Shimodaira, Hiroshi and Sagayama, Shigeki},
booktitle = {Document Analysis and Recognition, 2001. Proceedings. Sixth International Conference on},
file = {:D$\backslash$:/Papers/Documents/2002/Nakai et al. - 2002.pdf:pdf},
isbn = {0769512631},
keywords = {Arabic Handwritting recognition,HMM,Japanese or Chinese Characters,Online handwriting character recognition,Read,Summarized},
mendeley-tags = {Arabic Handwritting recognition,Read,Summarized},
pages = {491--495},
publisher = {IEEE},
title = {{Substroke approach to HMM-based on-line Kanji handwriting recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=953838},
year = {2002}
}
@article{Almuhtaseb2008,
abstract = {This paper describes a technique for automatic recognition of off-line printed Arabic text using Hidden Markov Models. In this work different sizes of overlapping and non- overlapping hierarchical windows are used to generate 16 features from each vertical sliding strip. Eight different Arabic fonts were used for testing (viz. Arial, Tahoma, Akhbar, Thuluth, Naskh, Simplified Arabic, Andalus, and Traditional Arabic). It was experimentally proven that different fonts have their highest recognition rates at different numbers of states (5 or 7) and codebook sizes (128 or 256). Arabic text is cursive, and each charactermay have up to four different shapes based on its location in a word. This research work considered each shape as a different class, resulting in a total of 126 classes (compared to 28 Arabic letters). The achieved average recognition rates were between 98.08\% and 99.89\% for the eight experimental fonts. The main contributions of this work are the novel hierarchical sliding window technique using only 16 features for each sliding window, considering each shape of Arabic characters as a separate class, bypassing the need for segmenting Arabic text, and its applicability to other languages.},
author = {Almuhtaseb, H and Mahmoud, S and Qahwaji, R},
doi = {10.1016/j.sigpro.2008.06.013},
file = {:D$\backslash$:/Papers/Documents/2008/Almuhtaseb, Mahmoud, Qahwaji - 2008.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Reference From Doctor,arabic text recognition,hidden markov models},
mendeley-tags = {Reference From Doctor},
month = dec,
number = {12},
pages = {2902--2912},
title = {{Recognition of off-line printed Arabic text using Hidden Markov Models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165168408001928},
volume = {88},
year = {2008}
}
@phdthesis{MCZing2006,
abstract = {In this thesis, many efforts were devoted to the recognition and verification
of handwritten numeral recognitions. In pursuit of the highest recognition
accuracy and the lowest misrecognition rate, we introduce a hybrid
feature extraction strategy and a multimodal nonparametric analysis
for feature dimensionality reduction (in order to obtain a faster
and more stable classifier training procedure for verification).
The design of a cascade ensemble classifier recognition system with
rejection strategies is also introduced. From a practical perspective,
the various recognizers and verifiers were designed and implemented
using novel hybrid feature extraction algorithms and a newly designed
ensemble cascade classifier system. The designed OCR engines were
applied to handwritten numeral recognition. A summary of thesis contributions
and discussions on future direction is also addressed.},
author = {Zhang, Ping},
school = {Concordia University},
title = {{Reliable Recognition of Handwritten Digits Using A Cascade Ensemble Classifier System and Hybrid Features}},
year = {2006}
}
@article{Awaidah2009,
abstract = {This paper describes a technique for the recognition of optical off-line handwritten Arabic (Indian) numerals using hidden Markov models (HMM). Features that measure the image characteristics at local, intermediate, and large scales were applied. Gradient, structural, and concavity features at the sub-regions level are extracted and used as the features for the Arabic (Indian) numeral. Several experiments were conducted for estimating the suitable number of image divisions, and the best combination of features using theHMMclassifier. A number of experiments were conducted to estimate the best number of states and codebook sizes in terms of the highest recognition rate possible. In this work, we did not follow the general trend of using the sliding window technique with HMM. Instead, a multi-resolution feature extraction approach was implemented on the whole digit. A database of 44 writers, with 48 samples per digit resulting in a database of 21120 sampleswas used. The achieved average recognition rate is 99\%. The classification errors were analysed and attributed to bad data, different writing styles of some digits, errors between digit pairs, and genuine errors. The presented technique, which is writer independent, proved to be effective in the automatic recognition of Arabic (Indian) numerals.},
annote = {Comments:
Use different segment size ( segment is part of digit).
Extract from each segment GSC features(gradient, structural, concativity))
uses HMM in recognition
99.1\% result achieved.


Details:
The features were chosen because they are somewhat orthogonal and are at different scales to each other. Collectively,these features are known as the gradient, structural, and concavity (GSC)feature set


[ Interesting Dividing digit images into segmetns ... ] The first step in the GSC feature extraction algorithm is to divide the imageinto nXm grids with equal number of foreground pixels for each of n rows,and equal number of foreground pixels for each of m columns. A digit sample is segmented into n horizontal segments with approximately equal number of black(foreground)pixels in each segment. The system then segments the digit into m vertical slices with approximately equal number of black (foreground) pixels. the intersection of horizontal and verticalsegmentation lines define (n*m) non-overlapping segments that are used to extract the features in each segment. the segment sizes and x- and y-coordinates are different for each different sample based on the sample black(foreground)pixelsÃ¢â¬â¢ distribution.


Three set of features is computed for each segment ( Gradiaent features (sobel operator), Structual Featrues ( densisty features , stroke features, ...), Concativity shape features). Table 1 in page 1180 shows the details of each feature.


Different HMM model for each digit and but on same number of states for all digits. USing HKT


Test on The database consists of 21120 samples.


Several expeirments based on segment size and features vector size (Recognition rate between 98\% to 99\%)},
author = {Awaidah, Sameh M. and Mahmoud, Sabri A.},
doi = {10.1016/j.sigpro.2008.12.022},
file = {:D$\backslash$:/Papers/Documents/2009/Awaidah, Mahmoud - 2009(2).pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Arabic optical handwritten,Arabic(Indian) numerals,HMM,Handwritting recognition,Hidden Markov model,Independent writer digit recognition,OCR,Read,Summarized,Writer independent,feature extraction,numeral recognition},
mendeley-tags = {Read,Summarized},
month = jun,
number = {6},
pages = {1176--1184},
title = {{A multiple feature/resolution scheme to Arabic (Indian) numerals recognition using hidden Markov models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S016516840900005X},
volume = {89},
year = {2009}
}
@article{Vinciarelli2002a,
abstract = {This paper presents a surveyon oÃ®â¬Â¡-line Cursive Word Recognition. The approaches to the problem are described in detail. Each step of the process leading from raw data to the Ã®â¬Â¯nal result is analyzed. This survey is divided into two parts, the Ã®â¬Â¯rst one dealing with the general aspects of Cursive Word Recognition, the second one focusing on the applications presented in the literature. ? 2002 Pattern Recognition Society. Published},
author = {Vinciarelli, Alessandro},
file = {:D$\backslash$:/Papers/Documents/2002/Vinciarelli - 2002.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {handwriting recognition,o -line cursive word,recognition,survey},
number = {7},
pages = {1433--1446},
publisher = {Elsevier},
title = {{A survey on off-line cursive word recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320301001297},
volume = {35},
year = {2002}
}
@inproceedings{Methods2009,
author = {Methods, Post-processing and Sundaram, Suresh and Ramakrishnan, A G},
booktitle = {10th International Conference on Document Analysis and Recognition},
doi = {10.1109/ICDAR.2009.65},
file = {:D$\backslash$:/Papers/Documents/2009/Methods, Sundaram, Ramakrishnan - 2009.pdf:pdf},
pages = {1216--1220},
title = {{An Improved Online Tamil Character Recognition Engine using Post Processing Methods}},
year = {2009}
}
@inproceedings{Oliveira2007,
author = {Oliveira, Luciano and Peixoto, Paulo and Nunes, Urbano},
booktitle = {IEEE ICRA 2007 Workshop onÃ¢â¬ï¿½ Planning, perception and navegation for intelligent vehiclesÃ¢â¬ï¿½, Rome},
file = {:D$\backslash$:/Papers/Documents/2007/Oliveira, Peixoto, Nunes - 2007.pdf:pdf},
publisher = {Citeseer},
title = {{A Hierarchical Fuzzy integration of local and global feature-based classifiers to recognize objects in autonomous vehicles}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.118.883\&amp;rep=rep1\&amp;type=pdf},
year = {2007}
}
@article{Boubaker2009,
author = {Boubaker, Houcine and Kherallah, Monji and Alimi, Adel M.},
doi = {10.1109/ICDAR.2009.265},
file = {:D$\backslash$:/Papers/Documents/2009/Boubaker, Kherallah, Alimi - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {778--782},
publisher = {Ieee},
title = {{New Algorithm of Straight or Curved Baseline Detection for Short Arabic Handwritten Writing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277507},
year = {2009}
}
@article{Hassin2004,
abstract = {The Arabic Language has a very rich vocabulary. More than 200 million people speak this language as their native speaking, and over 1 billion people use it in several religion-related activities. In this paper a new technique is presented for recognizing printed Arabic characters. After a word is segmented, each character/word is entirely transformed into a feature vector. The features of printed Arabic characters include strokes and bays in various directions, endpoints, intersection points, loops, dots and zigzags. The word skeleton is decomposed into a number of links in orthographic order, and then it is transferred into a sequence of symbols using vector quan- tization. Single hidden Markov model has been used for recognizing the printed Arabic characters. Experimental results show that the high recognition rate depends on the number of states in each sample.},
author = {Hassin, Abbas H. and Tang, Xiang-Long and Liu, Jia-Feng and Zhao, Wei},
doi = {10.1007/BF02944755},
file = {:D$\backslash$:/Papers/Documents/2004/Hassin et al. - 2004.pdf:pdf},
issn = {1000-9000},
journal = {Journal of Computer Science and Technology},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = jul,
number = {4},
pages = {538--543},
title = {{Printed Arabic character recognition using HMM}},
url = {http://www.springerlink.com/index/10.1007/BF02944755},
volume = {19},
year = {2004}
}
@inproceedings{ARCowell2001,
abstract = {A successful approach to the recognition of Latin characters is to
extract fiatures from that character such as the number of strokes,
stroke intersections and holes, and to use ad-hoc tests to diflerentiate
between characters which have similar features. The first stage in
this process ib to produce thinned 1 pixel thick representations
of the characters to simplifi feature extraction. This approach works
well with printed Latin characters which are of high quality. With
poor quality characters, however, the thinning process itself is
not, straighrfonvard and can introduce errors which clre manfested
in the later stages of the recognition process. The recognition of
poor quality Arabic characters is a particular problem since the
chara(5tet-s are calligraphic with printed characters having widely
varying stroke thicknesses to simulate the drawing of the character
with a calligraphy pen or brush. This paper describes the problems
encountered when thinning large poor quality Arabic characters prior
to the extraction of their features and submission to a syntactic
recognition system.},
author = {Cowell, Dr John and Hussain, Dr Fiaz},
booktitle = {Proceedings of the Fifth International Conference on Information Visualisation},
file = {:D$\backslash$:/Papers/Documents/2001/Cowell, Hussain - 2001.pdf:pdf},
keywords = { OCR, Urdu, characters, optical, thinning,Arabic},
pages = {181},
title = {{Thinning Arabic Characters for Feature Extraction}},
year = {2001}
}
@article{ElAbed2010,
author = {{El Abed}, Haikal},
doi = {10.1007/s10032-010-0117-5},
file = {:D$\backslash$:/Papers/Documents/2010/El Abed - 2010.pdf:pdf},
journal = {International Journal on Document Analysis and Recognition (IJDAR)},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
month = apr,
number = {4},
pages = {724},
title = {{ICDAR 2009-Arabic handwriting recognition competition}},
volume = {19},
year = {2010}
}
@article{Palacios2003,
author = {Palacios, R. and Gupta, a.},
doi = {10.1109/NNSP.2003.1318060},
file = {:D$\backslash$:/Papers/Documents/2003/Palacios, Gupta - 2003.pdf:pdf},
isbn = {0-7803-8177-7},
journal = {2003 IEEE XIII Workshop on Neural Networks for Signal Processing (IEEE Cat. No.03TH8718)},
keywords = {- optical character recognition,check processing,document imaging,neural networks,unconstrained handwritten numerals},
pages = {607--616},
publisher = {Ieee},
title = {{Training neural networks for reading handwritten amounts on checks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1318060},
year = {2003}
}
@article{Bertolami2006,
author = {Bertolami, R and Zimmermann, M and Bunke, H},
doi = {10.1016/j.patrec.2006.06.002},
file = {:D$\backslash$:/Papers/Documents/2006/Bertolami, Zimmermann, Bunke - 2006.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {handwritten text recognition,rejection strategies,statistical language model},
month = dec,
number = {16},
pages = {2005--2012},
title = {{Rejection strategies for offline handwritten text line recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865506001632},
volume = {27},
year = {2006}
}
@inproceedings{Alimoglu96,
author = {Alimoglu, Fevzi and Alpaydin, Ethem},
booktitle = {Proceedings of the Fifth Turkish Artificial Intelligence and Artificial Neural Networks Symposium (TAINN 96},
title = {{Methods of Combining Multiple Classifiers Based on Different Representations for Pen-based Handwritten Digit Recognition}},
year = {1996}
}
@article{ARLiu2008b,
abstract = {Pattern classification methods based on learning-from-examples have
been widely applied to character recognition from the 1990s and have
brought forth significant improvements of recognition accuracies.
This kind of methods include statistical methods, artificial neural
networks, support vector machines, multiple classifier combination,
etc. In this chapter, we briefly review the learning-based classification
methods that have been successfully applied to character recognition,
with a special section devoted to the classification of large category
set. We then discuss the characteristics of these methods, and discuss
the remaining problems in character recognition that can be potentially
solved by machine learning methods.},
author = {Liu, Cheng-Lin and Fujisawa, Hiromichi},
file = {:D$\backslash$:/Papers/Documents/2008/Liu, Fujisawa - 2008.pdf:pdf},
journal = {Studies in Computational Intelligence (SCI)},
pages = {139Ã¯Â¿Â½161},
title = {{Classification and Learning Methods for Character Recognition: Advances and Remaining Problems}},
volume = {90},
year = {2008}
}
@inproceedings{DSMadasu2005,
abstract = { This paper describes a novel method for automatically segmenting
and recognizing the various information fields present on a bank
cheque. The uniqueness of our approach lies in the fact that it doesn
\#146;t necessitate any prior information and requires minimum human
intervention. The extraction of segmented fields is accomplished
by means of a connectivity based approach. For the recognition part,
we have proposed four innovative features, namely; entropy, energy,
aspect ratio and average fuzzy membership values. Though no particular
feature is pertinent in itself but a combination of these is used
for differentiating between the fields. Finally, a fuzzy neural network
is trained to identify the desired fields. The system performance
is quite promising on a large dataset of real and synthetic cheque
images.},
author = {Madasu, V K and Lovell, B C},
booktitle = {Proceedings 2005 of Digital Image Computing: Techniques and Applications, 2005. DICTA '05.},
doi = {10.1109/DICTA.2005.18},
file = {:D$\backslash$:/Papers/Documents/2005/Madasu, Lovell - 2005.pdf:pdf},
pages = {33},
title = {{Automatic Segmentation and Recognition of Bank Cheque Fields}},
year = {2005}
}
@inproceedings{MCSu2007,
abstract = {In the literature of psychophysics and neurophysiology, many studies
have shown that both global and local features are crucial for face
representation and recognition. This paper proposes a novel face
recognition method which combines both global and local discriminative
features. In this method, global features are extracted from whole
face images by Fourier transform and local features are extracted
from some spatially partitioned image patches by Gabor wavelet transform.
After this, multiple classifiers are obtained by applying Fisher
Discriminant Analysis on global Fourier features and local patches
of Gabor features. All these classifiers are combined to form a hierarchical
ensemble by sum rule. We evaluated the proposed method using Face
Recognition Grand Challenge (FRGC) experimental protocols and database
known as the largest data sets available. Experimental results on
FRGC version 2.0 data set have shown that the proposed method achieves
a verification rate of 86\%, while the best reported was 76\%.},
address = {Rio de Janeiro,},
author = {Su, Yu and Shan, Shiguang and Chen, Xilin and Gao, Wen},
booktitle = {IEEE 11th International Conference on Computer Vision, 2007. ICCV 2007},
file = {:D$\backslash$:/Papers/Documents/2007/Su et al. - 2007.pdf:pdf},
keywords = { Classifiers Ensemble,Features Extraction},
pages = {1--8},
publisher = {IEEE},
title = {{Hierarchical Ensemble of Global and Local Classifiers for Face Recognition}},
year = {2007}
}
@article{DSBezerra2008,
abstract = {An approach is proposed for detecting and eliminating invasion in
courtesy amount fields. This is a important step toward automatizing
the bank check process. In a real database, 18\% of handwritten courtesy
amount fields exhibited invasions in the legal amount and signature
fields. Experimental results have shown that the proposed approach
is robust and efficient for improving the automatic recognition of
real Brazilian bank checks},
author = {Bezerra, Byron L D and Cavalcanti, George D C and Zanchettin, Cleber and Rabelo, Juliano C B},
file = {:D$\backslash$:/Papers/Documents/2008/Bezerra et al. - 2008.pdf:pdf},
keywords = { Automatic Check Processing., Courtesy Amount Recognition,Contour Invasion Detection},
title = {{Detecting and treating invasion in the courtesy amount field on bank checks}},
year = {2008}
}
@inproceedings{DSOliveira2002,
abstract = {This paper discusses the use of genetic algorithm for feature selection
for handwriting recognition. Its novelty lies in the use of a multi-objective
genetic algorithms where sensitivity analysis and neural network
are employed to allow the use of a representative database to evaluate
fitness and the use of a validation database to identify the subsets
of selected features that provide a good generalization. Comprehensive
experiments on the NIST database confirm the effectiveness of the
proposed strategy.},
address = {Quebec City},
author = {Oliveira, L S and Sabourin, R and Bortolozzi, F and Suen, C Y},
booktitle = {Proc. Int. Conf. on Pattern Recognition},
file = {:D$\backslash$:/Papers/Documents/2002/Oliveira et al. - 2002(2).pdf:pdf},
month = aug,
pages = {568--571},
title = {{Feature selection using multi-objective genetic algorithms for handwritten digit recognition}},
volume = {1},
year = {2002}
}
@article{Toygar2004,
author = {Toygar, Onsen and {Adnan Acan}},
doi = {10.1016/j.patrec.2004.05.005},
file = {:D$\backslash$:/Papers/Documents/2004/Toygar, Adnan Acan - 2004.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {appearance-based statistical methods,classifier combination,local feature-based face,multiple classifier systems},
month = sep,
number = {12},
pages = {1421--1430},
title = {{Multiple classifier implementation of a divide-and-conquer approach using appearance-based statistical methods for face recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865504001114},
volume = {25},
year = {2004}
}
@article{MCShieh2007,
abstract = {Various form features affect consumer preference regarding product
design. It is, therefore, important that designers identify these
critical form features to aid them in developing appealing products.
However, the problems inherent in choosing product form features
have not yet been intensively investigated. In this paper, an approach
based on multiclass support vector machine recursive feature elimination
(SVM-RFE) is proposed to streamline the selection of optimum product
form features. First, a one-versus-one (OVO) multiclass fuzzy support
vector machines (multiclass fuzzy SVM) model using a Gaussian kernel
was constructed based on product samples from mobile phones. Second,
an optimal training model parameter set was determined using two-step
cross-validation. Finally, a multiclass SVM-RFE process was applied
to select critical form features by either using overall ranking
or class-specific ranking. The weight distribution of each iterative
step can be used to analyze the relative importance of each of the
form features. The results of our experiment show that the multiclass
SVM-RFE process is not only very useful for identifying critical
form features with minimum generalization errors but also can be
used to select the smallest feature subset for building a prediction
model with a given discrimination capability.},
author = {Shieh, Meng-Dar and Yang, Chih-Chieh},
file = {:D$\backslash$:/Papers/Documents/2007/Shieh, Yang - 2007.pdf:pdf},
journal = {Expert Systems with Applications},
pages = {531Ã¯Â¿Â½541},
title = {{Multiclass SVM-RFE for product form feature selection}},
volume = {35},
year = {2007}
}
@article{Pal2004,
abstract = {Intensive research has been done on optical character recognition (OCR) and a large number of articles have been published on this topic during the last few decades. Many commercial OCR systems are now available in the market. But most of these systems work for Roman, Chinese, Japanese andArabic characters. There are no suÃ®â¬Â³cient number of work on Indian language character recognition although there are 12 major scripts in India. In this paper, we present a review of the OCR work done on Indian language scripts. The review is organizedinto 5 sections. Sections 1 and2 cover introduction andproperties on Indian scripts. In Section 3, we discuss diÃ®â¬Â¸erent methodologies in OCR development as well as research work done on Indian scripts recognition. In Section 4, we discuss the scope of future work and further steps needed for Indian script OCR development. In Section 5 we conclude the paper.},
author = {Pal, U and Chaudhuri, BB},
doi = {10.1016/j.patcog.2004.02.003},
file = {:D$\backslash$:/Papers/Documents/2004/Pal, Chaudhuri - 2004.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {indian script,indian script ocr,ocr survey,optical character recognition},
number = {9},
pages = {1887--1899},
publisher = {Elsevier},
title = {{Indian script character recognition: a survey}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S003132030400055X},
volume = {37},
year = {2004}
}
@article{Plamondon2000,
author = {Plamondon, R. and Srihari, S.N.},
doi = {10.1109/34.824821},
file = {:D$\backslash$:/Papers/Documents/2000/Plamondon, Srihari - 2000.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
number = {1},
pages = {63--84},
title = {{Online and off-line handwriting recognition: a comprehensive survey}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=824821},
volume = {22},
year = {2000}
}
@inproceedings{MCLecun1998b,
abstract = {A long and detailed paper on convolutional nets, graph transformer
networks, and discriminative training methods for sequence labeling.
We show how to build systems that integrate segmentation, feature
extraction, classification, contextual post-processing, and language
modeling into one single learning machine trained end-to-end. Applications
to handwriting recognition and face detection are described.},
author = {LeCun, Y and Bottou, L and Bengio, Y and Haffner, P},
booktitle = {Proceedings of the IEEE},
file = {:D$\backslash$:/Papers/Documents/1998/LeCun et al. - 1998.pdf:pdf},
month = nov,
number = {11},
pages = {2278--2324},
title = {{Gradient Based Learning Applied to Document Recognition}},
volume = {86},
year = {1998}
}
@article{Liwicki2009a,
abstract = {In this paper, we describe feature selection experiments for online handwriting recog- nition. We investigated a set of 25 online and pseudo-offline features to find out which features are important and which features may be redundant. To analyze the saliency of the features, we applied a sequential forward and a sequential backward search on the feature set. A hidden Markov model and a neural network based recognizer have been used as recognition engines. In our experiments, we obtained interesting results. Using a set of only five features, we achieved a performance similar to that of the reference system that uses all 25 features. The five selected features have a low correlation and have been the top choices during the first iterations of the forward search with both recognizers. Furthermore, for both recognizers, subsets have been identified that outper- form the reference system with statistical significance. In order to assess the results more rigorously, we have compared our recognizer with the widely used commercial recognizer from Microsoft.},
author = {Liwicki, Marcus and Bunke, Horst},
file = {:D$\backslash$:/Papers/Documents/2009/Liwicki, Bunke - 2009.pdf:pdf},
journal = {International Journal of Pattern Recognition and Artificial Intelligence},
keywords = {bidirectional long,cursive handwritten text recognition,feature selection,hidden markov model,hmm,search,sequential backward search,sequential forward,short-term memory network},
number = {5},
pages = {907--923},
title = {{BASED HANDWRITING RECOGNITION}},
volume = {23},
year = {2009}
}
@inproceedings{ARHachour2006,
abstract = {In this paper Fuzzy Logic (FL) and Expert System (ES) theories are
studied with regard to their contribution to solving the problem
of OCR (Optical Chara cter Recognition). These theories have improved
the learning and adaptation capacities related to varying shapes
where information is qualitative, inaccurate or incomplete. The use
of these technologies FL and ES proves interesting, efficient, and
necessary to recognize all Arabic character. This combination is
very useful to improve the powerful of Hybrid Intelligent Systems
HIS in the field of OCR. The primary goal of this combination (FL,
ES) is to classify and to recognize all presented unknown shapes.
These theories must achieve these tasks: to classify characters,
and to make ones way of intelligent recognition by ES-FL system capturing
the behaviour of a human expert knowledge. The training has used
280 descended pictures of the database of ACR (Arabic Character Recognition).
The Results gotten of ACR databases are promising.},
address = {London},
author = {Hachour, O},
booktitle = {2006 3rd International IEEE Conference on Intelligent Systems},
doi = {10.1109/IS.2006.348415},
file = {:D$\backslash$:/Papers/Documents/2006/Hachour - 2006.pdf:pdf},
pages = {189--191},
title = {{The Combination of Fuzzy Logic and Expert System for Arabic Character Recognition}},
year = {2006}
}
@inproceedings{DSLecce2000,
author = {Lecce, V Di and Dimauro, G and Guerriero, A and Impedovo, S and Pirlo, G and Salzo, A},
booktitle = {In Proceedings of International Workshop on Frontiers in Handwriting Recognition},
file = {:D$\backslash$:/Papers/Documents/2000/Lecce et al. - 2000.pdf:pdf},
pages = {199--208},
title = {{A New Hybrid Approach For Legal Amount Recognition}},
year = {2000}
}
@article{PDB5Yu2004,
abstract = {Feature selection is applied to reduce the number of features in many
applications where data has hundreds or thousands of features. Existing
feature selection methods mainly focus on finding relevant features.
In this paper, we show that feature relevance alone is insufficient
for efficient feature selection of high-dimensional data. We define
feature redundancy and propose to perform explicit redundancy analysis
in feature selection. A new framework is introduced that decouples
relevance analysis and redundancy analysis. We develop a correlation-based
method for relevance and redundancy analysis, and conduct an empirical
study of its efficiency and effectiveness comparing with representative
methods.},
author = {Yu, Lei and Liu, Huan},
doi = {http://www.jmlr.org/papers/volume5/yu04a/yu04a.pdf},
file = {:D$\backslash$:/Papers/Documents/2004/Yu, Liu - 2004.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {Feature selection},
pages = {1205--1224},
title = {{Efficient Feature Selection via Analysis of Relevance and Redundancy.}},
volume = {5},
year = {2004}
}
@article{Liu2004,
author = {Liu, C.L. and Nakashima, Kazuki and Sako, Hiroshi and Fujisawa, Hiromichi},
doi = {10.1016/S0031-3203(03)00224-3},
file = {:D$\backslash$:/Papers/Documents/2004/Liu et al. - 2004.pdf:pdf},
journal = {Pattern Recognition},
keywords = {aspect ratio mapping,direction feature,gradient feature,handwritten digit recognition,ncfe,normalization},
number = {2},
pages = {265--279},
publisher = {Elsevier},
title = {{Handwritten digit recognition: investigation of normalization and feature extraction techniques}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320303002243},
volume = {37},
year = {2004}
}
@inproceedings{PDBZhu2006,
abstract = {We integrate the cascade-of-rejectors approach with the Histograms
of Oriented Gradients (HoG) features to achieve a fast and accurate
human detection system. The features used in our system are HoGs
of variable-size blocks that capture salient features of humans automatically.
Using AdaBoost for feature selection, we identify the appropriate
set of blocks, from a large set of possible blocks. In our system,
we use the integral image representation and a rejection cascade
which significantly speed up the computation. For a 320 Ã¯Â¿Â½ 280 image,
the system can process 5 to 30 frames per second depending on the
density in which we scan the image, while maintaining an accuracy
level similar to existing methods.},
address = {New York, NY, USA},
author = {Zhu, Qiang and Yeh, Mei-Chen and Cheng, Kwang-Ting and Avidan, Shai},
booktitle = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2006)},
doi = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2006.119},
file = {:D$\backslash$:/Papers/Documents/2006/Zhu et al. - 2006.pdf:pdf},
isbn = {0-7695-2597-0},
pages = {1491--1498},
publisher = {IEEE Computer Society},
title = {{Fast Human Detection Using a Cascade of Histograms of Oriented Gradients.}},
year = {2006}
}
@inproceedings{Singh,
author = {Singh, S. and Hewitt, M.},
booktitle = {Proceedings 15th International Conference on Pattern Recognition. ICPR-2000},
doi = {10.1109/ICPR.2000.906138},
file = {:D$\backslash$:/Papers/Documents/2000/Singh, Hewitt - 2000.pdf:pdf},
isbn = {0-7695-0750-6},
keywords = {Reference From Doctor},
mendeley-tags = {Reference From Doctor},
number = {Figure 1},
pages = {569--572},
publisher = {IEEE Comput. Soc},
title = {{Cursive digit and character recognition in CEDAR database}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=906138},
year = {2000}
}
@article{Arica2002,
abstract = {A new analytic scheme, which uses a sequence of image segmentation and recognition algorithms, is proposed for the off-line cursive handwriting recognition problem. First, some global parameters, such as slant angle, baselines, stroke width and height, are estimated. Second, a segmentation method finds character segmentation paths by combining gray-scale and binary information. Third, a hidden Markov model (HMM) is employed for shape recognition to label and rank the character candidates. For this purpose, a string of codes is extracted from each segment to represent the character candidates. The estimation of feature space parameters is embedded in the HMM training stage together with the estimation of the HMM model parameters. Finally, information from a lexicon and from the HMM ranks is combined in a graph optimization problem for word-level recognition. This method corrects most of the errors produced by the segmentation and HMM ranking stages by maximizing an information measure in an efficient graph search algorithm. The experiments indicate higher recognition rates compared to the available methods reported in the literature},
author = {Arica, Nafiz and Yarman-Vural, F.T.},
file = {:D$\backslash$:/Papers/Documents/2002/Arica, Yarman-Vural - 2002.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Lexicon lookup,cursive handwritten text recognition,graph,handwritten word recognition,hidden markov model,optical character recognition,preprocessing,search,segmentation},
number = {6},
pages = {801--813},
publisher = {Published by the IEEE Computer Society},
title = {{Optical character recognition for cursive handwriting}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/TPAMI.2002.1008386},
volume = {24},
year = {2002}
}
@article{Tjan2006,
author = {Tjan, B.S. and Nandy, A.S.},
file = {:D$\backslash$:/Papers/Documents/2006/Tjan, Nandy - 2006.pdf:pdf},
journal = {Journal of vision},
keywords = {classification image,invariance,nonlinearity,reverse correlation,spatial uncertainty},
number = {4},
pages = {387--413},
publisher = {Association for Research in Vision and Ophthalmology},
title = {{Classification images with uncertainty}},
url = {http://www.journalofvision.org/content/6/4/8.full},
volume = {6},
year = {2006}
}
@article{DSKapp2007,
abstract = {The study of handwritten words is tied to the development of recognition
methods to be used in real-world applications involving handwritten
words, such as bank checks, postal envelopes, and handwritten texts,
among others. In this work, the focus is handwritten words in the
context of Brazilian bank checks, specifically the months of the
year, and no restrictions are placed on the types or styles of writing
or the number of writers. A global feature set and two architectures
of artificial neural networks (ANN) are evaluated for classification
of the words. The objectives are to evaluate the performance of conventional
and class-modular multiple-layer perceptron (MLP) architectures,
to develop a rejection mechanism based on multiple thresholds, and
to analyze the behavior of the feature set proposed in the two architectures.
The experimental results demonstrate the superiority of the class-modular
architecture over the conventional MLP architecture. A rejection
mechanism with multiple thresholds demonstrates favorable performance
in both architectures. The feature set analysis shows the importance
of the structural primitives such as concavities and convexities,
and perceptual primitives such as ascenders and descenders. The experimental
results reveal a recognition rate of 81.75\% without the rejection
mechanism, and a reliability rate 91.52\% with a rejection rate of
25.33\%.},
author = {Kappa, Marcelo N and {de A. Freitasb}, Cinthia O and Sabourina, Robert},
file = {:D$\backslash$:/Papers/Documents/2007/Kappa, de A. Freitasb, Sabourina - 2007.pdf:pdf},
journal = {Image and Vision Computing},
keywords = {Neural networks; Rejection; Feature selection; Han},
month = jan,
number = {1},
pages = {40--49},
title = {{Methodology for the design of NN-based month-word recognizers written on Brazilian bank checks}},
volume = {25},
year = {2007}
}
@inproceedings{PDBBritto2004,
abstract = {In this paper we combine complementary features based on foreground
and background information in an HMM-based classifier to recognize
handwritten isolated characters and numeral strings. A zoning scheme
based on column and row models provides a way of dividing the character
into zones without making the features size variant. This strategy
allows us to avoid the character normalization, while it provides
a way of having information from specific zones of the character.
The experimental results on 10 digit classes, 52 character classes
and 6 classes of numeral strings of different lengths have shown
that the proposed features are highly discrimminant.},
author = {{Britto Jr.}, Alceu de S and Sabourin, Robert and Bortolozzi, Flavio and Suen, Ching Y},
booktitle = {IWFHR '04: Proceedings of the Ninth International Workshop on Frontiers in Handwriting Recognition},
doi = {http://dx.doi.org/10.1109/IWFHR.2004.43},
file = {:D$\backslash$:/Papers/Documents/2004/Britto Jr. et al. - 2004.pdf:pdf},
isbn = {0-7695-2187-8},
pages = {371--376},
title = {{Foreground and Background Information in an HMM-Based Method for Recognition of Isolated Characters and Numeral Strings}},
year = {2004}
}
@incollection{DSRomero2007,
abstract = {Bernoulli mixture models have been recently proposed as simple yet
powerful probabilistic models for binary images in which each image
pattern is modelled by a different Bernoulli prototype (component).
A possible limitation of these models, however, is that usual geometric
transformations of image patterns are not explicitly modelled and,
therefore, each natural transformation of an image pattern has to
be independently modelled using a different, rigid prototype. In
this work, we propose a simple technique to make these rigid prototypes
more flexible by explicit modelling of invariances to translation,
scaling and rotation. Results are reported on a task of handwritten
Indian digits recognition.},
author = {Romero, VerÃ¯Â¿Â½nica and GimÃ¯Â¿Â½nez, AdriÃ¯Â¿Â½ and Juan, Alfons},
booktitle = {Pattern Recognition and Image Analysis},
doi = {10.1007/978-3-540-72847-4\_69},
file = {:D$\backslash$:/Papers/Documents/2007/Romero, GimÃ¯Â¿Â½nez, Juan - 2007.pdf:pdf},
pages = {539--546},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Explicit Modelling of Invariances in Bernoulli Mixtures for Binary Images}},
volume = {4477},
year = {2007}
}
@article{ARSu2009,
abstract = {Great challenges are faced in the off-line recognition of realistic Chinese handwriting. This paper presents a segmentation-free strategy based on Hidden Markov Model (HMM) to handle this problem, where character segmentation stage is avoided prior to recognition. Handwritten textlines are first converted to observation sequence by sliding windows. Then embedded BaumÃ¯Â¿Â½Welch algorithm is adopted to train character HMMs. Finally, best character string maximizing the a posteriori is located through Viterbi algorithm. Experiments are conducted on the HIT-MW database written by more than 780 writers. The results show the feasibility of such systems and reveal apparent complementary capacities between the segmentation-free systems and the segmentation-based ones.},
author = {Su, Tong-Hua and Zhang, Tian-Wen and Guan, De-Jun and Huang, Hu-Jie},
file = {:D$\backslash$:/Papers/Documents/2009/Su et al. - 2009.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Chinese handwriting recognition,Classifier combination,Hidden Markov Model,Optical,Segmentation-free strategy,Sliding window},
pages = {167--182},
title = {{Off-line recognition of realistic Chinese handwriting using segmentation-free strategy}},
volume = {42},
year = {2009}
}
@article{Vuong2008647,
abstract = {
Structural analysis in handwritten mathematical expressions focuses on interpreting the recognized symbols using geometrical information such as relative sizes and positions of the symbols. Most existing approaches rely on hand-crafted grammar rules to identify semantic relationships among the recognized mathematical symbols. They could easily fail when writing errors occurred. Moreover, they assume the availability of the whole mathematical expression before being able to analyze the semantic information of the expression. To tackle these problems, we propose a progressive structural analysis (PSA) approach for dynamic recognition of handwritten mathematical expressions. The proposed PSA approach is able to provide analysis result immediately after each written input symbol. This has an advantage that users are able to detect any recognition errors immediately and correct only the mis-recognized symbols rather than the whole expression. Experiments conducted on 57 most commonly used mathematical expressions have shown that the PSA approach is able to achieve very good performance results.},
author = {Vuong, Ba-Quy and Hui, Siu-Cheung and He, Yulan},
doi = {DOI: 10.1016/j.patrec.2007.11.017},
file = {:D$\backslash$:/Papers/Documents/2008/Vuong, Hui, He - 2008.pdf:pdf},
issn = {0167-8655},
journal = {Pattern Recognition Letters},
keywords = {Grouping determination},
number = {5},
pages = {647--655},
title = {{Progressive structural analysis for dynamic recognition of on-line handwritten mathematical expressions}},
url = {http://www.sciencedirect.com/science/article/B6V15-4RC2RV6-3/2/1370388e1650065ef95dd4ea94c12604},
volume = {29},
year = {2008}
}
@article{MCHung2004,
abstract = {Detection of recognition errors is important in many areas, suchas
improving recognition performance, saving manual effort for proof-reading
and post-editing, and assigning appropriate weights for retrieval
in constructing digital libraries.We propose a novel application
of multiple classifiers for the detection of recognition errors.
A need for multiple classifiers emerges when a single classifier
cannot improve recognition-error detection performance compared with
the current detection scheme using a simple threshold mechanism.
Although the single classifier does not improve recognition error
performance, it serves as a baseline for comparison and the related
study of useful features for error detection suggests three distinct
cases where improvement is needed. For eachcase, the multiple classifier
approachassigns a classifier to detect the presence or absence of
errors and additional features are considered for each case. Our
results show that the recall rate (70Ã¯Â¿Â½80\%) of recognition errors,
the precision rate (80Ã¯Â¿Â½90\%) of recognition error detection and the
saving in manual effort (75\%) were better than the corresponding
performance using a single classifier or a simple threshold detection
scheme},
author = {Hunga, K.-Y. and Luka, R W P and D.S.Yeunga and Chung, K F L and Ua, W Sh},
file = {:D$\backslash$:/Papers/Documents/2004/Hunga et al. - 2004.pdf:pdf},
journal = {Pattern Recognition},
pages = {723--738},
title = {{A multiple classifier approach to detect Chinese character recognition errors}},
volume = {38},
year = {2004}
}
@inproceedings{Xiang2010,
abstract = {-Great challenges are faced in the offline recognition of cursive Arabic handwriting. This paper presents a segmentation-free system based on Hidden Markov Model (HMM) to handle this problem, where character segmentation stage is avoided prior to recognition. The system first extracts a set of robust features on binary handwritten images by sliding windows. Then the proposed system builds character HMM models and learns word HMM models using embedded training. Finally, best word maximizing the a posteriori is located through Viterbi Algorithm. Experiments that have been implemented on the benchmark IFNIENIT database show the average recognition rate of this system is 84.09\%.},
author = {Xiang, Dong and Yan, Huahua and Chen, Xianqiao and Cheng, Yanfen},
booktitle = {Computer Science and Information Technology (ICCSIT), 2010 3rd IEEE International Conference on},
file = {:D$\backslash$:/Papers/Documents/2010/Xiang et al. - 2010.pdf:pdf},
keywords = {- pauern recognition,arabic,even in the case,hidden,markov model,offline handwritten,segmentation and recognition,the concatenation of compound,thus,where,words are modeled as},
pages = {526--529},
publisher = {IEEE},
title = {{Offline Arabic handwriting recognition system based on HMM}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5564429},
volume = {1},
year = {2010}
}
@misc{PDB16Pudil1992,
abstract = {The idea on constructing a multi stage pattern clasification system
with reject option is presented and conditions in terms of upper
bounds of the cost of higher stage measurements for a multi stage
classifier to give lower decision risk than a single classifier are
derived.},
author = {Pudil, P and Novoicova, J and Blaha, S and Kittler, J},
file = {:D$\backslash$:/Papers/Documents/1992/Pudil et al. - 1992.pdf:pdf},
title = {{Multistage Pattern Recognition with Rejct Option}},
year = {1992}
}
@article{Benouareth2008,
abstract = {In this paper, we describe an off-line unconstrained handwritten Arabic word recognition system based on segmentation-free approach and semi-continuous hidden Markov models (SCHMMs) with explicit state duration. Character durations play a significant part in the recognition of cursive handwriting. The duration information is still mostly disregarded in HMM-based automatic cursive handwriting rec- ognizers due to the fact that HMMs are deficient in modeling character durations properly. We will show experimentally that explicit state duration modeling in the SCHMM framework can significantly improve the discriminating capacity of the SCHMMs to deal with very difficult pattern recognition tasks such as unconstrained handwritten Arabic recognition. In order to carry out the letter and word model training and recognition more efficiently, we propose a new version of the Viterbi algorithm taking into account explicit state duration modeling. Three distributions (Gamma, Gauss and Poisson) for the explicit state duration modeling have been used and a comparison between them has been reported. To perform word recognition, the described system uses an original sliding window approach based on vertical projection histogram analysis of the word and extracts a new pertinent set of statistical and structural features from the word image. Several experi- ments have been performed using the IFN/ENIT benchmark database and the best recognition perfor- mances achieved by our system outperform those reported recently on the same database.},
author = {Benouareth, a and Ennaji, A and Sellami, M},
doi = {10.1016/j.patrec.2008.05.008},
file = {:D$\backslash$:/Papers/Documents/2008/Benouareth, Ennaji, Sellami - 2008.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Reference From Doctor,off-line handwritten arabic word},
mendeley-tags = {Reference From Doctor},
month = sep,
number = {12},
pages = {1742--1752},
title = {{Semi-continuous HMMs with explicit state duration for unconstrained Arabic word modeling and recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865508001670},
volume = {29},
year = {2008}
}
@inproceedings{ARGolubitsky2008,
abstract = {The process of recognizing individual handwritten characters is one
of classifying curves. Typically, handwriting recognition systemsÃ¯Â¿Â½
even Ã¯Â¿Â½onlineÃ¯Â¿Â½ systemsÃ¯Â¿Â½require entire characters be completed before
recognition is attempted. This paper presents another approach for
real-time recognition: certain characteristics of a curve can be
computed as the curve is being written, and these characteristics
are used to classify the character in constant time when the pen
is lifted. We adapt an earlier approach of representing curves in
a functional basis and reduce real-time stroke modelling to the Hausdorff
moment problem.},
address = {Ontario, Canada},
author = {Golubitsky, Oleg and Watt, Stephen M},
booktitle = {CASCON '08 : Proceedings of the 2008 conference of the center for advanced studies on collaborative research},
file = {:D$\backslash$:/Papers/Documents/2008/Golubitsky, Watt - 2008.pdf:pdf},
pages = {72--80},
title = {{Online Stroke Modeling for Handwriting Recognition}},
year = {2008}
}
@article{DSXu1992,
abstract = {Possible solutions to the problem of combining classifiers can be
divided into three categories according to the levels of information
available from the various classifiers. Four approaches based on
different methodologies are proposed for solving this problem. One
is suitable for combining individual classifiers such as Bayesian,
k -nearest-neighbor, and various distance classifiers. The other
three could be used for combining any kind of individual classifiers.
On applying these methods to combine several classifiers for recognizing
totally unconstrained handwritten numerals, the experimental results
show that the performance of individual classifiers can be improved
significantly. For example, on the US zipcode database, 98.9\% recognition
with 0.90\% substitution and 0.2\% rejection can be obtained, as well
as high reliability with 95\% recognition, 0\% substitution, and 5\%
rejection},
author = {Xu, L and Krzyzak, A and Suen, C Y},
doi = {10.1109/21.155943},
file = {:D$\backslash$:/Papers/Documents/1992/Xu, Krzyzak, Suen - 1992.pdf:pdf},
issn = {0018-9472},
journal = {IEEE Transactions on Systems, Man and Cybernetics},
keywords = {Bayesian classifiers;US zipcode database;distance },
number = {3},
pages = {418--435},
title = {{Methods of combining multiple classifiers and their applications to handwriting recognition}},
volume = {22},
year = {1992}
}
@booklet{PDB9SVM1998,
abstract = {This is different article in IEEE Magazine



My first exposure to Support Vector Machines came this spring when
I heard Sue

Dumais present impressive results on text categorization using this
analysis technique.

This issueÃ¯Â¿Â½s collection of essays should help familiarize our readers
with this interesting

new racehorse in the Machine Learning stable. Bernhard Sch?lkopf,
in an introductory

overview, points out that a particular advantage of SVMs over other
learning

algorithms is that it can be analyzed theoretically using concepts
from computational

learning theory, and at the same time can achieve good performance
when applied to

real problems. Examples of these real-world applications are provided
by Sue Dumais,

who describes the aforementioned text-categorization problem, yielding
the best results

to date on the Reuters collection, and Edgar Osuna, who presents strong
results

on application to face detection. Our fourth author, John Platt, gives
us a practical

guide and a new technique for implementing the algorithm efficiently.

Ã¯Â¿Â½Marti Hearst},
author = {Hearst, Marti A},
file = {:D$\backslash$:/Papers/Documents/1998/Hearst - 1998.pdf:pdf},
howpublished = {IEEE INTELLIGENT SYSTEMS},
keywords = {SVM},
month = jul,
title = {{Trends and controversies, Support vector machines}},
year = {1998}
}
@article{Mozaffari2008,
abstract = {Unlikemanyother languages, 18 out of 32 Farsi characters have dots appearing in groups of one, two or three.Someof these letters share common primary shapes, differing only in the number of dots and whether the dots are above or below the primary shape. In this paper, a new concept of using dots in a cursively handwritten Farsi/Arabic word is introduced for lexicon reduction and a fast method for extracting dots is presented. The technique involves extraction and representation of number and position of dots from off-line handwritten words to eliminate unlikely candidates. Experimental results on a set of 12,000 handwritten word images yield a lexicon reduction of 93\% with accu- racy of 85\%. The proposed lexicon reduction algorithm achieves the speedup factor of 2 as well as 13\% improvement in recognition rate. Ã®â¬â},
author = {Mozaffari, S and Faez, K and Margner, V and Elabed, H},
doi = {10.1016/j.patrec.2007.11.009},
file = {:D$\backslash$:/Papers/Documents/2008/Mozaffari et al. - 2008.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Reference From Doctor,arabic handwritten word recognition,discrete hidden markov model,dot extraction,lexicon reduction,off-line farsi,string matching},
mendeley-tags = {Reference From Doctor},
month = apr,
number = {6},
pages = {724--734},
title = {{Lexicon reduction using dots for off-line Farsi/Arabic handwritten word recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865507003741},
volume = {29},
year = {2008}
}
@article{Morita2003a,
author = {Morita, M. and Sabourin, R. and Bortolozzi, F. and Suen, C.Y.},
doi = {10.1109/ICDAR.2003.1227712},
file = {:D$\backslash$:/Papers/Documents/2003/Morita et al. - 2003.pdf:pdf},
isbn = {0-7695-1960-1},
journal = {Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.},
number = {Icdar},
pages = {482--486},
publisher = {IEEE Comput. Soc},
title = {{A recognition and verification strategy for handwritten word recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1227712},
year = {2003}
}
@electronic{ARBouchain2006,
abstract = {Pattern recognition is one of the traditional uses of neural networks.
When trained with gradient-based learning methods, these networks
can learn the classification of input data by example. An introduction
to classifiers and gradient-based learning is given. It is shown
how several perceptrons can be combined and trained gradient-based.
Furthermore, an overview of convolutional neural networks, as well
as a real-world example, are discussed.},
author = {Bouchain, David},
file = {:D$\backslash$:/Papers/Documents/2006/Bouchain - 2006.pdf:pdf},
howpublished = {Seminar Statistical Learning Theory},
institution = {University of Ulm, Germany},
keywords = { Neural Networks,Character Recognition},
title = {{Character Recognition Using Convolutional Neural Networks}},
year = {2006}
}
@article{Gao2004,
abstract = {In sign language recognition (SLR), the major challenges now are developing methods that solve signer-independent continuous sign problems. In this paper, SOFM/HMM is first presented for modeling signer-independent isolated signs. The proposed method uses the self-organizing feature maps (SOFM) as different signersÃ¢â¬â¢ feature extractor for continuous hidden Markov models (HMM) so as to transform input signs into significant and low-dimensional representations that can be well modeled by the emission probabilities of HMM. Based on these isolated sign models, a SOFM/SRN/HMM model is then proposed for signer-independent continuous SLR. This model applies the improved simple recurrent network (SRN) to segment continuous sign language in terms of transformed SOFM representations, and the outputs of SRN are taken as the HMM states in which the latticeViterbi algorithm is employed to search the best matched word sequence. Experimental results demonstrate that the proposed system has better performance compared with conventional HMM system and obtains a word recognition rate of 82.9\% over a 5113-sign vocabulary and an accuracy of 86.3\% for signer-independent continuous SLR. Ã®â¬ï¿½ 2004 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
author = {Gao, Wen and Fang, Gaolin and Zhao, Debin and Chen, Yiqiang},
doi = {10.1016/j.patcog.2004.04.008},
file = {:D$\backslash$:/Papers/Documents/2004/Gao et al. - 2004.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {chinese sign language,hidden markov model,self-organizing feature map,sign language recognition,simple recurrent network},
number = {12},
pages = {2389--2402},
publisher = {Elsevier},
title = {{A Chinese sign language recognition system based on SOFM/SRN/HMM}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320304001657},
volume = {37},
year = {2004}
}
@conference{PBPan2009,
abstract = {A new isolated handwritten Farsi numeral recognition algorithm is
proposed in this paper, which exploits the sparse and over-complete
structure from the handwritten Farsi numeral data. In this research,
the sparse structure is represented as an over-complete dictionary,
which is learned by the K-SVD algorithm. These atoms in this dictionary
are adopted to initialize the first layer of the Convolutional Neural
Network (CNN), the latter is then trained to do the classification
task. Data distortion techniques are also applied to promote the
generalization capability of the trained classifier. Experiments
have shown that good results have been achieved in CENPARMI handwritten
Farsi numeral database.},
author = {Pan, W M and Bui, T D and Suen, C Y},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Pan, Bui, Suen - 2009.pdf:pdf},
title = {{Isolated Handwritten Farsi numerals Recognition Using Sparse And Over-Complete Representations}},
year = {2009}
}
@article{ARPal2008,
abstract = {Indian pin code is a six-digit string. Because of the writing style
of different individuals some of the digits in a pin code string
may touch with its neighboring digits. Accurate segmentation of such
touching components into individual digits is a difficult task. To
avoid such segmentation, here we consider a pin code string as word
and the pin code recognition problem is treated as lexicon free word
recognition. In the proposed method, at first, binarization of the
input document is done. Next, water reservoir concept is applied
to pre-segment a pin code string into possible primitive components
(individual digits or its parts). Presegmented components of the
pin code are then merged into possible digits to get the best pin
code. In order to merge these primitive components into digits and
to find optimum segmentation, dynamic programming (DP) is applied
using total likelihood of digits as the objective function. To compute
the likelihood of a digit, modified quadratic discriminant function
(MQDF) is used. The features used in the MQDF are based on the directional
information of the components. Our system on handwritten Bangla pin
code shows 99.08\% reliability when rejection and error rates are
19.28\% and 0.74\%, respectively.},
author = {Pal, Umapada and Roy, Kaushik and Kimura, Fumitaka},
file = {:D$\backslash$:/Papers/Documents/2008/Pal, Roy, Kimura - 2008.pdf:pdf},
keywords = { Bangla script, Indian postal automation., Pin code recognition,Handwritten digit recognition},
title = {{Bangla Handwritten Pin Code String Recognition for Indian Postal}},
year = {2008}
}
@inproceedings{Gorgevik2004,
abstract = {This paper proposes an efficient three-stage classifier for handwritten digit recognition based on NN (Neural Network) and SVM (Support Vector Machine) classifiers. The classification is performed by 2 NNs and one SVM. The first NN is designed to provide a low misclassifica- tion rate using a strong rejection criterion. It is applied on a small set of easy to extract features. Rejected pat- terns are forwarded to the second NN that uses addi- tional, more complex features, and utilizes a well- balanced rejection criterion. Finally, rejected patterns from the second NN are forwarded to an optimized SVM that considers only the Ã¢â¬Åtop kÃ¢â¬ï¿½ classes as ranked by the NN. This way a very fast SVM classification is obtained without sacrificing the classifier accuracy. The obtained recognition rate is among the best on the MNIST database and the classification time is much better compared to the single SVM applied on the same feature set.},
author = {Gorgevik, Dejan and Cakmakov, D.},
booktitle = {Pattern Recognition},
file = {:D$\backslash$:/Papers/Documents/2004/Gorgevik, Cakmakov - 2004.pdf:pdf},
pages = {507--510},
title = {{An efficient three-stage classifier for handwritten digit recognition}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICPR.2004.1333822},
volume = {4},
year = {2004}
}
@article{Hu2000,
abstract = {n this paper we describe a Hidden Markov Model (HMM) based writer independent handwriting recognition system. A combination of signal normalization preprocessing and the use of invariant features makes the system robust with respect to variability among di!erent writers as well as di!erent writing environments and ink collection mechanisms. A combination of point oriented and stroke oriented features yields improved accuracy. Language modeling constrains the hypothesis space to manageable levels in most cases. In addition a two-pass N-best approach is taken for large vocabularies. We report experimental results for both character and word recognition on several UNIPEN datasets, which are standard datasets of English text collected from around the world.},
author = {Hu, Jianying and Lim, Sok Gek and Brown, Michael K.},
doi = {10.1016/S0031-3203(99)00043-6},
file = {:D$\backslash$:/Papers/Documents/2000/Hu, Lim, Brown - 2000.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Reference From Doctor,handwriting recognition,hidden markov models,invariant features,n-best decoding,segmental features,unipen},
mendeley-tags = {Reference From Doctor},
month = jan,
number = {1},
pages = {133--147},
title = {{Writer independent on-line handwriting recognition using an HMM approach}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320399000436},
volume = {33},
year = {2000}
}
@article{PDB8AlOmari2004,
abstract = {This paper presents a system for the recognition of the handwritten
Indian numerals one to nine (1Ã¯Â¿Â½9) using a probabilistic neural network
(PNN) approach. The process involved extracting a feature vector
to represent the handwritten digit based on the center of gravity
and a set of vectors to the boundary points of the digit object.
The feature vector is scale-, translation-, and rotation-invariant.
The extracted feature vector is fed to a PNN, which in turn classifies
it as one of the nine digits. A set of experiments were conducted
to test the performance of the system under different angles between
the vectors from the centroid to the boundary of the digit object.
A 308 angle results in a 99.72\% recognition rate with a short feature
vector of 12 entries. This study is meant to be a seed toward building
a recognition system for Arabic language characters.},
author = {Al-Omari, Faruq A and Al-Jarrah, Omar M},
doi = {http://dx.doi.org/10.1016/j.aei.2004.02.001},
file = {:D$\backslash$:/Papers/Documents/2004/Al-Omari, Al-Jarrah - 2004.pdf:pdf},
journal = {Advanced Engineering Informatics},
keywords = { Handwritten digits, Neural Networks, Pattern Recognition, Probabilistic},
number = {1},
pages = {9--16},
title = {{Handwritten Indian numerals recognition system using probabilistic neural networks.}},
volume = {18},
year = {2004}
}
@article{Vinciarelli2004,
abstract = {This paper presents a system for the offline recognition of large vocabulary unconstrained handwritten texts. The only assumption made about the data is that it is written in English. This allows the application of Statistical Language Models in order to improve the performance of our system. Several experiments have been performed using both single and multiple writer data. Lexica of variable size (from 10,000 to 50,000 words) have been used. The use of language models is shown to improve the accuracy of the system (when the lexicon contains 50,000 words, the error rate is reduced by approximately 50 percent for single writer data and by approximately 25 percent for multiple writer data). Our approach is described in detail and compared with other methods presented in the literature to deal with the same problem. An experimental setup to correctly deal with unconstrained text recognition is proposed.},
author = {Vinciarelli, Alessandro and Bengio, Samy and Bunke, Horst},
doi = {10.1109/TPAMI.2004.14},
file = {:D$\backslash$:/Papers/Documents/2004/Vinciarelli, Bengio, Bunke - 2004.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automatic Data Processing,Automatic Data Processing: methods,Biometry,Biometry: methods,Computer Graphics,Documentation,Handwriting,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Markov Chains,Models, Statistical,Numerical Analysis, Computer-Assisted,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reference From Doctor,Reproducibility of Results,Sensitivity and Specificity,Signal Processing, Computer-Assisted,Subtraction Technique,User-Computer Interface},
mendeley-tags = {Reference From Doctor},
month = jun,
number = {6},
pages = {709--20},
pmid = {18579932},
title = {{Offline recognition of unconstrained handwritten texts using HMMs and statistical language models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18579932},
volume = {26},
year = {2004}
}
@inproceedings{Zhao2003,
abstract = {In this paper, a Cascade Connection Hidden Markov Model (CCHMM) method for on-line English word recognition is propawd. This model, which allows state transition, skip and duration, extends the way of HMM pattern description of handwriting English words. According to the statistic probabilities, the behavior of handwriting CUN\~{} may he depictedÃ¢â¬â¢more precisely. The Viterhi algorithm for the cascade connection model may be applied after the whole sample series of a word is input. Compared with the method of creating models for each word in lexicon, this method gives a faster recognition speed. Experiments show that CCHMM approach could obtain 89.26\% recognition rate for the first candidate, while the combination. of character and ligature HMM methodÃ¢â¬â¢s first candidate is 82.34\%},
author = {Zhao, W. and Liu, J.F. and Tang, X.L.},
booktitle = {Machine Learning and Cybernetics, 2002. Proceedings. 2002 International Conference on},
file = {:D$\backslash$:/Papers/Documents/2003/Zhao, Liu, Tang - 2003.pdf:pdf},
isbn = {0780375084},
keywords = {cascade connection hidden,handwritten word recognition,inter-model state transition probability,markov model},
number = {November},
pages = {1758--1761},
publisher = {IEEE},
title = {{Online handwritten English word recognition based on cascade connection of character HMMs}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1175338},
volume = {4},
year = {2003}
}
@inproceedings{Alimoglu1996,
author = {Alimoglu, Fevzi and Alpaydin, E.},
booktitle = {Proceedings of the Fifth Turkish Artificial Intelligence and Artificial Neural Networks Symposium (TAINN 96},
file = {:D$\backslash$:/Papers/Documents/1996/Alimoglu, Alpaydin - 1996:},
publisher = {Citeseer},
title = {{Methods of Combining Multiple Classifiers Based on Different Representations for Pen-based Handwritten Digit Recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.6383},
year = {1996}
}
@article{DSPalacios2008,
abstract = {In the US and many other countries, bank previous termchecksnext term
are preprinted with the account number and the previous termchecknext
term number in special ink and format; as such, these two numeric
fields can be easily read and processed using automated techniques.
However, the amount fields on a filled-in previous termchecknext
term is usually read by human eyes, and involves significant time
and cost, especially when one considers that over 50 billion previous
termchecksnext term are processed per annum in the US alone. The
system described in this paper uses the scanned image of a bank previous
termchecknext term to Ã¯Â¿Â½readÃ¯Â¿Â½ the previous termcheck.next term It
includes three main modules that allow for fully automated bank previous
termchecknext term processing.

These three modules are described in the paper; they focus sequentially
on: the detection of strings within the image; the segmentation and
previous termrecognitionnext term of string in a feedback loop; and
the post-processing issues that help to ensure higher accuracy of
previous termrecognition.next term The major benefit of the integrated
system is the ability to address the complex problem of reading handwritten
bank previous termchecksnext term by implementing efficient algorithms
for each processing step. All modules have been implemented and subsequently
tested for reading the value of the previous termchecknext term using
different image databases. Due to the particular requirements of
this application, the system can be tuned to yield low levels of
incorrect readings; this, in turn, leads to higher levels of rejection
than the levels encountered in other handwritten previous termrecognitionnext
term applications. A Ã¯Â¿Â½rejectedÃ¯Â¿Â½ previous termchecknext term can be
read subsequently by human eyes or other more advanced automated
approaches. However, a previous termchecknext term Ã¯Â¿Â½readÃ¯Â¿Â½ incorrectly
is more difficult to deal with, in terms of costs and time involved
to rectify the mistake. As such, our architecture can be geared towards
producing the most suitable balance between inaccurate readings and
rejection level, in accordance with user preferences. The experimental
results presented in the paper do not focus on the best possible
results for a particular database of previous termchecks;next term
instead, they show the benefits attained independently by each of
the modules proposed.},
author = {Palaciosa, Rafael and Guptab, Amar},
file = {:D$\backslash$:/Papers/Documents/2008/Palaciosa, Guptab - 2008.pdf:pdf},
journal = {Image and Vision Computing},
keywords = {Handwritten previous termchecksnext term; Reading },
month = oct,
number = {10},
pages = {1297--1313},
title = {{A system for processing handwritten bank checks automatically}},
volume = {26},
year = {2008}
}
@article{Camastra2001,
author = {Camastra, F},
doi = {10.1016/S0167-8655(01)00008-3},
file = {:D$\backslash$:/Papers/Documents/2001/Camastra - 2001.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Reference From Doctor,cross-validation,cursive character recognition,feature extraction,learning vector quantization},
mendeley-tags = {Reference From Doctor},
month = may,
number = {6-7},
pages = {625--629},
title = {{Cursive character recognition by learning vector quantization}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865501000083},
volume = {22},
year = {2001}
}
@article{MCKharma2001,
abstract = {This paper describes an application of a novel mapping, one that is
intended for use in on-line hand-written character recognition. This
mapping produces the same output pattern regardless of the orientation,
position, and size of the input pattern. The mapping has the advantage
of being simple. This makes it computationally ecient and fast,
which in turn makes it appropriate for on-line implementations. To
demonstrate the usefulness of this mapping, a recognition system
utilizing it has been developed for hand-written Arabic characters.
The performance of this system is shown to be comparable to that
of the existing on-line Arabic character recognition systems.},
author = {Kharma, Nawwaf N and Ward, Rabab K},
file = {:D$\backslash$:/Papers/Documents/2001/Kharma, Ward - 2001.pdf:pdf},
journal = {Pattern Recognition},
pages = {2115--2120},
title = {{A novel invariant mapping applied to hand-written arabic character recognition}},
volume = {34},
year = {2001}
}
@article{Oliveira2002,
author = {Oliveira, L.S. and Sabourin, R. and Bortolozzi, F. and Suen, C.Y.},
file = {:D$\backslash$:/Papers/Documents/2002/Oliveira et al. - 2002.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {11},
pages = {1438--1454},
publisher = {Citeseer},
title = {{Automatic recognition of handwritten numerical strings: A recognition and verification strategy}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.4.4101\&amp;rep=rep1\&amp;type=pdf},
volume = {24},
year = {2002}
}
@inproceedings{Mozaffari2004,
author = {Mozaffari, Saeed and Faez, K. and Kanan, HR},
booktitle = {Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004},
file = {:D$\backslash$:/Papers/Documents/2004/Mozaffari, Faez, Kanan - 2004.pdf:pdf},
title = {{Feature comparison between fractal codes and wavelet transform in handwritten alphanumeric recognition using SVM classifier}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1334199},
volume = {2},
year = {2004}
}
@article{Solimanpour2006,
abstract = {This paper describes an important step towards the standardization of the research on Optical Character Recognition (OCR) in Farsi language. It describes formations of novel and standard handwritten databases including isolated digits, letters, numerical strings, Legal amounts (used for cheques), and dates. Despite conventional research and an Internet search, no publicly accessible Farsi database was found. Hence, it was decided that it would be a worthwhile academic effort to create several Farsi databases that could stand on their own merit functioning as useful tools for OCR researchers. Also, in order to show the potential uses of our new databases we also conducted some experiments on the recognition of handwritten isolated Farsi digits},
author = {Solimanpour, Farshid and Sadri, J. and Suen, C.Y.},
file = {:D$\backslash$:/Papers/Documents/2006/Solimanpour, Sadri, Suen - 2006.pdf:pdf},
journal = {Pattern Recognition},
keywords = {arabic handwritten databases,farsi,farsi handwritten databases,farsi ocr,handwritten recognition,indian digits database,standard databases in order,to improve research on},
title = {{Standard databases for recognition of handwritten digits, numerical strings, legal amounts, letters and dates in Farsi language}},
url = {http://hal.inria.fr/inria-00103983/},
year = {2006}
}
@article{ARFarooq2009,
abstract = {We propose a method for increasing word recognition accuracies by
correcting the output of a handwriting recognition system. We treat
the handwriting recognizer as a black box, such that there is no
access to its internals. This enables us to keep our algorithm general
and independent of any particular system. We use a novel method for
correcting the output based on a Ã¯Â¿Â½phrase-basedÃ¯Â¿Â½ system in contrast
to traditional source-channel models. We report the accuracies of
two in-house handwritten word recognizers before and after the correction.
We achieve highly encouraging results for a large synthetically generated
dataset. We also report results for a commercially available OCR
on real data.},
author = {Farooq, Faisal and Jose, Damien and Govindaraju, Venu},
doi = {http://dx.doi.org/10.1016/j.patcog.2008.12.014},
file = {:D$\backslash$:/Papers/Documents/2009/Farooq, Jose, Govindaraju - 2009.pdf:pdf},
journal = {Pattern Recognition},
keywords = { Error correction, Handwriting recognition, Noisy channel, Viterbi decoding,Post-processing},
number = {12},
pages = {3271--3277},
title = {{Phrase-based correction model for improving handwriting recognition accuracies}},
volume = {42},
year = {2009}
}
@article{Huang2008,
abstract = {In this paper a hidden Markov model (HMM)-based binarization algorithm is presented. This algorithm performs well for images with nonuniform background. To test the usefullness of the proposed technique some images of composite documents of printed characters were used. These characters were extracted through the proposed binarization algorithms and used in a commercial OCR. A comparative study of various binarization techniques is also presented},
author = {Huang, Songtao and Ahmadi, Majid and Sid-Ahmed, MA},
doi = {10.1016/j.patcog.2008.03.004},
file = {:D$\backslash$:/Papers/Documents/2008/Huang, Ahmadi, Sid-Ahmed - 2008.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {binarization,hmm,ocr,stroke,thresholding},
number = {9},
pages = {2890--2900},
publisher = {Elsevier},
title = {{A hidden Markov model-based character extraction method}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308000885},
volume = {41},
year = {2008}
}
@article{FE5Yang2002,
abstract = {In this paper, we combine two kinds of features together by virtue
of complex vectors and then use the developed generalized KÃ¯Â¿Â½L transform
(or expansion) for feature extraction. The experiments on NUST603
handwritten Chinese character database and CENPARMI handwritten digit
database indicate that the proposed method can improve the recognition
rate significantly.},
author = {Yang, Jian and yu Yang, Jing},
file = {:D$\backslash$:/Papers/Documents/2002/Yang, yu Yang - 2002.pdf:pdf},
journal = {Pattern Recognition},
keywords = {Features Extraction},
pages = {295--297},
title = {{Generalized KÃ¯Â¿Â½L transform based combined feature extraction}},
volume = {35},
year = {2002}
}
@inproceedings{DSSantos2002,
abstract = { The most common goal of automatic bank cheque treatment systems is
the recognition of handwritten information. However, in order to
do this, it is necessary to use a reliable and efficient process
able to identify and to extract the information, which can then be
submitted to a further recognition phase. We present a process for
identifying and distinguishing between handwritten information and
machine printed text based on a set of local features. This process
is based on the characterization of textual elements via properties
derived from their content and their shape. The main advantage of
this process compared with other similar approaches is that no a
priori information of the treated document is used, thus making it
more generic and effective.},
author = {{Eduardo Bastos Dos Santos}, J and Dubuisson, B and Bortolozzi, F},
booktitle = {Computer Graphics and Image Processing, 2002. Proceedings. XV Brazilian Symposium on},
doi = {10.1109/SIBGRA.2002.1167144},
file = {:D$\backslash$:/Papers/Documents/2002/Eduardo Bastos Dos Santos, Dubuisson, Bortolozzi - 2002.pdf:pdf},
issn = {1530-1834},
keywords = { ;, ;image segmentation;machine printed text;text rec, ;image segmentation;optical,automatic bank cheque treatment systems;bank chequ},
pages = {203--209},
title = {{Characterizing and distinguishing text in bank cheque images}},
year = {2002}
}
@article{Mahmoud2009,
abstract = {This paper describes a technique for automatic recognition of off-line handwritten Arabic (Indian) numerals using Support Vector Machines (SVM) and Hidden Markov Models (HMM). Local, intermediate, and large scale features are used. SVM parameters, producing the highest recognition rates, are experimentally found by using an exhaustive search algorithm. In addition, SVM classifier results are compared to those of the HMM classifier. The present research uses a database of 44 writers with 48 samples of each digit totaling 21120 samples. The SVM and HMM classifiers were trained with 75\% of the data and tested with the remaining data. Other divisions of data for training and testing were performed and resulted in comparable performance. The achieved average recognition rates were 99.83\% and 99.00\% using, respectively, the SVM and HMM classifiers. SVM recognition rates proved to be better for all digits. Comparison at the writerÃ¢â¬â¢s level (Writers 34 to 44) showed that SVM results outperformed HMM results for all tested writers. The classification errors of the SVM classifier were analyzed. The presented technique, using the powerful set of features and the SVM classifier, proved to be effective in the recognition of independent writer Arabic (Indian) numerals and was shown to be superior to the HMM classifier.},
annote = {==========================================

        Paper Index : Mahmoud2009

        Date:23-11-2010



Why read paper ?



Svm and hmm with digit comparision.



        Paper Overview ?

it is arabic digits offlin system uses different types of features (gradient, concavity and density ) then use either SVM and HMM classifiers.



What is these paper about ? (Summary)



First

        preprocessing:

The image is binirized using threshold algorithm,
Segment division:
the binarized image is divided into segments of 3X3 or nXm grid.
The size of each segment is not equal, nxn grid is generted with equal number of pixle in each column or row (see figure 3).
The image is divided that In each n row the number of black pixels  are the same. (same is done for column)



        Features extraction:

Features is computed for each segment as following:
a) gradinet features
Sobel operator is used to get the directional grandient of the direction. Then direction is divided into 12 regions (degree). the histogram of each region is computed for each segment based on the calculated gradient direction.
b) structural features
A set of 12  rules that capture the mini strokes features are computed. ( each rule check the neighbourhood of each pixel and there shapes).
(see table 1. )
c) concavity features
 consist of segment desnity of black segments ,  maximum vertical and horizontal strokes
and  concavity featuers

        Classification and recognition:

Two classifier were experiement SVM and HMM
the SVM RBF model was used to recognize the characters
as for  HMM , model for each digit is used with viterbi algorithm to get max likely segment (digit).  As the system use no sliding windows ,  and the features are computed on the whole image, the features set is split into 10 observation sequence. and presented to the HMM in sequence.



        Result:

Dataset of 44 writers with 10 digits and 48 sample per user. so 21,000  nearly samples.
SVM (99.83\%) result better than HMM (99.0\%)
 A comparison with different features vectors are used and the best result with using all features (GSC)..
different result based on number of states in HMM and SVM paramters.
Seperate dcigits analysis to wrong digits.



        1. what are some advantages of this work ? What did you  find intersting (in a positive sense ) in the paper ?



Using previouly simple image based features with HMM by spliting the feature vectors and using one HMM per digit.
also a good comparision betweeen HMM and RBF SVM.



2. What can we take from this work  ? what do we learn ?  What can be incorporated into our own work ?

 We can use the image based features used on character recognition with HMM. ( same feature used in SVM).
The division of grid based on number of pixel captures the location of interest (gives a good division than equal distance grid).



3. What are the problems of the paper ?



Maybe the division of digits ( is it better than equal distance or is it better based on number of pixels ) it need more investigation.



        4. what is lacking from the work ? why does this work knot be the final  research in this subject ?



It is good paper nearly lacking nothing.  It may need some testing on other dataset and other languages and application on chracters not digits.



        5. what about the methods causes this lack ? is there a fundamental reason ?




        6. Could incremental Changes Fix this lack ? if so, what changes ?






        Is there is any question you had about the paper ?






The final conclusion..........



Good paper with good analysis of error and final result of 99.83\%  on arabic digits.
Also the basic idea of spliting feature vector to present it to HMM, and the use of same feature for both SVM and HMM.
==========================================================================

      },
author = {Mahmoud, S.A. and Awaida, S.M.},
file = {:D$\backslash$:/Papers/Documents/2009/Mahmoud, Awaida - 2009.pdf:pdf},
journal = {Arabian Journal for Science and Engineering},
keywords = {Arabic (Indian) automatic numeral recognition,Arabic Handwritting recognition,HMM,Intelligent Character Recognition (ICR),Read,Reference From Doctor,SVM,Summarized,feature extraction,handwritten digit recognition,normalization},
mendeley-tags = {Arabic Handwritting recognition,Read,Reference From Doctor,Summarized},
number = {2B},
pages = {430},
title = {{RECOGNITION OF OFF-LINE HANDWRITTEN ARABIC (INDIAN) NUMERALS USING MULTI-SCALE FEATURES AND SUPPORT VECTOR MACHINES VS. HIDDEN MARKOV MODELS}},
url = {http://ajse.kfupm.edu.sa/articles/342B\_P.11.pdf},
volume = {34},
year = {2009}
}
@article{MCSingh2005,
abstract = {In this paper we propose a Ã¯Â¿Â½bank of classifiersÃ¯Â¿Â½ approach to image
region labelling and evaluate dynamic classifier selection and classifier
combination approaches against a baseline approach that works with
a single best classifier chosen using a validation set. In this analysis,image
segmentation,feature extraction, and classification are treated as
three separate steps of analysis. The classifiers used are each trained
with a different texture feature representation of training images.
The paper proposes a new knowledge-based predictive approach based
on estimating the Mahalanobis distance between test sample feature
values and the corresponding probability distribution function from
training data that selectively triggers classifiers. This approach
is shown to perform better than probability-based classifier combination
(all classifiers are triggered but their decisions are fused with
combination rules),and single classifier, respectively,based on classification
rates and confusion matrices. The experiments are performed on the
natural scene analysis application.},
author = {Singh, Sameer and Singh, Maneesha},
file = {:D$\backslash$:/Papers/Documents/2005/Singh, Singh - 2005.pdf:pdf},
journal = {Signal Processing: Image Communication},
keywords = {Scene analysis; Texture analysis; Image segmentati},
pages = {219Ã¯Â¿Â½231},
title = {{A dynamic classifier selection and combination approach to image region labelling}},
volume = {20},
year = {2005}
}
@article{Wshah2009,
author = {Wshah, Safwan and Shi, Zhixin and Govindaraju, Venu},
doi = {10.1109/ICDAR.2009.152},
file = {:D$\backslash$:/Papers/Documents/2009/Wshah, Shi, Govindaraju - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {793--797},
publisher = {Ieee},
title = {{Segmentation of Arabic Handwriting Based on both Contour and Skeleton Segmentation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277512},
year = {2009}
}
@article{Rodriguez-Serrano2010,
abstract = {In this paper we propose a novel approach for writer adaptation in a handwritten word-spotting task. The method exploits the fact that the semi-continuous hidden Markov model separates the word model parameters into (i) a codebook of shapes and (ii) a set of word-specific parameters. Our main contribution is to employ this property to derive writer-specific word models by statistically adapting an initial universal codebook to each document. This process is unsupervised and does not even require the appearance of the keyword(s) in the searched document. Experimental results show an increase in performance when this adaptation technique is applied. To the best of our knowledge, this is the first work dealing with adaptation for word-spotting. The preliminary version of this paper obtained an IBM Best Student Paper Award at the 19th International Conference on Pattern Recognition.},
author = {Rodr\'{\i}guez-Serrano, Jos\'{e} a. and Perronnin, Florent and S\'{a}nchez, Gemma and Llad\'{o}s, Josep},
doi = {10.1016/j.patrec.2010.01.007},
file = {:D$\backslash$:/Papers/Documents/2010/Rodr\'{\i}guez-Serrano et al. - 2010.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
month = jun,
number = {8},
pages = {742--749},
publisher = {Elsevier B.V.},
title = {{Unsupervised writer adaptation of whole-word HMMs with application to word-spotting}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865510000097},
volume = {31},
year = {2010}
}
@article{MCGutta1997,
abstract = {We address the problem of surveillance and contents-based image retrieval
(CBIR) for large image databases consisting of face images. The corresponding
face recognition tasks considered herein include (i) surveying a
gallery of images for the presence of specific probes, (ii) CBIR,
and (iii) CBIR subject to correct ID ("match") displaying specific
facial landmarks such as wearing glasses. We developed robust matching
("classification") and retrieval schemes based on hybrid classifiers
and showed their feasibility using the FERET database. The hybrid
classifier architecture consists of an ensemble of connectionist
networks--radial basis functions (RBF)--and inductive decision trees
(DT). The specific characteristics of our hybrid architecture include
(a) query by consensus as provided by ensembles of networks for coping
with the inherent variability of the image formation and data acquisition
process, (b) categorical classifications using decision trees, (c)
flexible and adaptive thresholds as opposed to ad hoc and hard thresholds,
and (d) interpretability of the way classification and retrieval
are eventually achieved. Experimental results, proving the feasibility
of our approach, yield (i) 96\% accuracy, using cross validation,
for surveillance on a database consisting of 904 images corresponding
to 350 subjects (of whom 102 are duplicates), (ii) 97\% accuracy for
CBIR tasks, such as "find all subjects wearing glasses", on a database
of 1084 images (including noisy versions) of 350 subjects (of whom
102 are duplicates), and (iii) 93\% accuracy, using cross validation,
for CBIR subject to correct ID match tasks, such as "find Joe Smith
with/without glasses", on a database of 200 images..},
author = {GUTTA, SRINIVAS and WECHSLER, HARRY},
file = {:D$\backslash$:/Papers/Documents/1997/GUTTA, WECHSLER - 1997.pdf:pdf},
journal = {Pattern Recognition},
number = {4},
pages = {539--553},
title = {{FACE RECOGNITION USING HYBRID CLASSIFIERS}},
volume = {30},
year = {1997}
}
@inproceedings{ARSturgill2008,
abstract = {Pre-processing for raster image based document segmentation begins
with image thresholding, which is a binarization proces separating
foreground from background. In this paper, we compare an existing
(Otsu), modified existing (Kittler-Illingworth) and simple peak-based
thresholding approach on a set of 982 documents for which existing
ground truth (full text) is available. We use the output of an open
source OCR engine which incorporates an adaptive/dynamic thresholder
that can be bypassed by one of the three global thresholds we tested.
This allowed comparison of these three approaches in the aggregate.
We then used an independently generated dictionary as a means of
characterizing thresholder efficacy. Such an approach, if successful,
will provide the means for selecting an optimal thresholder in the
absence of a large set of ground truthed documents. Our preliminary
findings here indicate that this approach may provide a reliable
means for thresholder comparison and eventually preclude the need
for time-intensive human ground truthing.},
address = {Sao Paulo, Brazil},
author = {Sturgill, Margaret and Simske, Steven J},
booktitle = {DocEng '08: Proceeding of the eighth ACM symposium on Document engineering},
doi = {http://doi.acm.org/10.1145/1410140.1410197},
file = {:D$\backslash$:/Papers/Documents/2008/Sturgill, Simske - 2008.pdf:pdf},
isbn = {978-1-60558-081-4},
keywords = { Accuracy, Kittler-Illingworth, Meta-Algorithms., OCR, Otsu, Testing,Threshold},
pages = {263--266},
publisher = {ACM},
title = {{An Optical Character Recognition Approach to Qualifying Thresholding Algorithms}},
year = {2008}
}
@article{MCLecun1998a,
abstract = {Multilayer Neural Networks trained with the backpropa- gation algorithm
constitute the best example of a successful Gradient-Based Learning
technique.Given an appropriate network architecture, Gradient-Based
Learning algorithms can be used to synthesize a complex decision
surface that can classify high-dimensional patterns such as handwritten
char- acters, with minimal preprocessing.This paper reviews var-
ious methods applied to handwritten character recognition and compares
them on a standard handwritten digit recog- nition task.Convolutional
Neural Networks, that are specif- ically designed to deal with the
variability of shapes, are shown to outperform all other techniques.Real-life
document recognition systems are composed of multiple modules including
eld extraction, segmenta- tion, recognition, and language modeling.A
new learning paradigm, called Graph Transformer Networks (GTN), al-
lows such multi-module systems to be trained globally using Gradient-Based
methods so as to minimize an overall per- formance measure.Two systems
for on-line handwriting recognition are de- scribed.Experiments demonstrate
the advantage of global training, and the exibility of Graph Transformer
Networks.A Graph Transformer Network for reading bank check is also
described.It uses Convolutional Neural Network char- acter recognizers
combined with global training techniques to provides record accuracy
on business and personal checks.It is deployed commercially and reads
several million checks per day},
author = {LeCun, Yann and Bottou, Leon and Bengio, Yoshua and Haffner, Patrick},
file = {:D$\backslash$:/Papers/Documents/1998/LeCun et al. - 1998(2).pdf:pdf},
journal = {PROC OF THE IEEE},
keywords = { Convolutional Neural Networks , Document Recognition , Finite State Transducers, GradientBased Learning, OCR,Graph Transformer Networks,Machine Learning,Neural Networks},
month = nov,
pages = {1--10},
title = {{GradientBased Learning Applied to Document Recognition}},
volume = {8},
year = {1998}
}
@inproceedings{DSTang2004c,
abstract = {This paper presents the spiral recognition methodology with its application
in unconstrained handwritten Chinese legal amount recognition in
a practical environment of a CheckReader trade;. This paper first
describes the failed application of neural network - hidden Markov
model hybrid recognizer on Chinese bank check legal amount recognition,
and explains the reasons for the failure: the neural network - hidden
Markov model hybrid recognizer cannot handle the complexity in the
training for Chinese legal amounts. Then a spiral recognition methodology
is presented. This methodology enables the system to increase its
recognition power (both the recognition rate and the number of recognized
characters) during the training iterations. Some experiments were
done to show that the spiral recognition methodology has a high performance
in the recognition of unconstrained handwritten Chinese legal amounts.
The recognition rate at the character level is 93.5\%, and the recognition
rate at the legal amount level is 60\%. Combined with the recognition
of courtesy amount, the overall error rate is less than 1\%.},
author = {Tang, Hanshen and Augustin, E and Suen, C Y and Baret, O and Cheriet, M},
booktitle = {Ninth International Workshop on Frontiers in Handwriting Recognition, 2004. IWFHR-9 2004.},
doi = {10.1109/IWFHR.2004.96},
file = {:D$\backslash$:/Papers/Documents/2004/Tang et al. - 2004.pdf:pdf},
issn = {1550-5235},
keywords = { ; hidden Markov models; natural languages; neural,Chinese bank checks recognition; handwritten Chine},
pages = {263--268},
title = {{Spiral recognition methodology and its application for recognition of Chinese bank checks}},
year = {2004}
}
@phdthesis{ThesisAlOhali2002,
abstract = {This thesis presents a study to process Arabic handwritten cheques. It includes the development of a unique set of databases that constitute a solid base for research in this domain. The databases are unique in terms of their source, domain and tags validation process. First, they are originated from real-world bank cheques, which, to the best of our knowledge, has never been reached in a university setting. Second, it constitutes the only databases in the domain of Arabic handwritten cheques so far. To the best of our knowledge, there is no database that provides training and testing samples for Arabic cheques. Third, it involved a unique tagging validation process that takes advantage of the embedded redundancy in the format of the cheque to verify the tagging process. A grammar to validate Arabic legal amounts and translate them to numerical values is also included. This work includes an efficient method to derive one-dimensional feature sequence that preserves the dynamics of the original two-dimensional images. This is very important to accommodate small variations while modeling two-dimensional signals. The thesis provides a detailed description of an improved graph representation of sub-word images, a more efficient method to extract dynamic information from two-dimensional images and a clear positioning of the applicability of other curve-ordering criteria, e.g. vision rules. In addition, this thesis includes a significant improvement in the discrimination power of HMM which allows the differentiation between short sub-words and longer ones that share significant initial observation sequences. It also allows the HMM to properly classify incomplete observation sequences. The improvement is achieved by introducing a new parameter to the HMM called the termination probability. Included in this work are tests that prove the applicability and efficiency of the above contributions. At the time of this dissertation, our survey indicates that this work is the only research in the literature which handles images of handwritten sub-words extracted from Arabic cheques. The results of this study show a 94.36\% sub-word recognition rate on the top 10 choices. Error analysis indicates some errors caused by the pre-processing (48\%), feature extraction (28\%) and classification (24\%) modules},
annote = {Thesis Advisor:Suen, Ching Y},
author = {Al-ohali, Yousef},
file = {:D$\backslash$:/Papers/Documents/2002/Al-ohali - 2002.pdf:pdf},
school = {Concordia University.},
title = {{Handwritten word recognition : application to Arabic cheque processing}},
year = {2002}
}
@conference{PBAlaei2009,
abstract = {In this paper, we propose two types of feature sets based on modified
chain-code direction frequencies in the contour pixels of input image
and modified transition features (horizontally and vertically). A
multi-level support vector machine (SVM) is proposed as classifier
to recognize Persian isolated digits. In first level, we combine
similar shaped numerals into a single group and as result; we obtain
7 classes instead of 10 classes. We compute 196-dimension chain-code
direction frequencies as features to discriminate 7 classes. In the
second level, classes containing more than one numeral because of
high resemblance in their shapes are considered. We use modified
transition features (horizontally and vertically) for discriminating
between two overlapping classes (0 and 1). To separate another overlapping
group containing three numerals 2, 3 and 4 we first eliminate common
parts of these digits (tail) and then compute chain code features.
We employ SVM classifier for the classification and evaluate our
scheme on 80,000 handwritten samples of Persian numerals [10]. Using
60,000 samples for training, we tested our scheme on other 20,000
samples and obtained 99.02\% accuracy.},
author = {Alaei, Alireza and Nagabhushan, P and Pal, Umapada},
booktitle = {10th International Conference on Document Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2009/Alaei, Nagabhushan, Pal - 2009.pdf:pdf},
keywords = { Chain Code, Handwritten, SVM.,Persian Numeral Recognition},
title = {{Fine Classification of Unconstrained Handwritten Persian/Arabic Numerals by Removing Confusion amongst Similar Classes}},
year = {2009}
}
@article{Arica2002a,
abstract = {Character recognition (CR) has been extensively studied in the last half century and progressed to a level sufficient to produce tech- nology driven applications. Now, the rapidly growing computational power enables the implementation of the presentCRmethodologies and creates an increasing demand on many emerging application domains, which require more advanced methodologies. This material serves as a guide and update for readers working in the CR area. First, the historical evolution of CR systems is presented. Then, the available CR techniques with their superiorities and weaknesses are reviewed. Finally, the current status of CR is discussed, and directions for future research are suggested. Special attention is given to the off-line hand- writing recognition since this area requires more research to reach the ul- timate goal of machine simulation of human reading},
author = {Arica, Nafiz and Yarman-Vural, F.T.},
file = {:D$\backslash$:/Papers/Documents/2002/Arica, Yarman-Vural - 2002.pdf:pdf},
issn = {1094-6977},
journal = {Systems, Man, and Cybernetics, Part C: Applications and Reviews, IEEE Transactions on},
keywords = {Character recognition (CR),feature extraction,off-line handwriting recognition,segmentation,training and recognition},
number = {2},
pages = {216--233},
publisher = {IEEE},
title = {{An overview of character recognition focused on off-line handwriting}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=941845\&amp;amp;isnumber=20390},
volume = {31},
year = {2002}
}
@inproceedings{DSCheriet2007,
abstract = {Automatic recognition of Arabic handwritten text is a problem worth
solving; it gained more and more interest in recent years, for various
reasons. In this paper we address the most frequently encountered
problems when dealing with Arabic handwriting recognition and we
briefly present lessons learnt from several serious attempts that
have been undertaken in this regard. We give a summary of techniques
concerning Arabic handwriting recognition research. We will end by
a case study, recognition of Tunisian city names, emphasizing on
visual-based strategies for Arabic handwriting recognition (AHR).},
author = {Cheriet, M},
booktitle = {Signal Processing and Its Applications, 2007. ISSPA 2007. 9th International Symposium on},
file = {:D$\backslash$:/Papers/Documents/2007/Cheriet - 2007.pdf:pdf},
keywords = { Arabic handwritten text recognition , Tunisian city name recognition , automatic recognition , visual-based strategies,Arabic handwriting recognition },
title = {{Strategies for visual arabic handwriting recognition: Issues and case study}},
year = {2007}
}
@incollection{ARAbdelRaouf2008,
abstract = {Electronic Document Management (EDM) technology is being widely adopted
as it makes for the efficient routing and retrieval of documents.
Optical Character Recognition (OCR) is an important front end for
such technology. Excellent OCR now exists for Latin based languages,
but there are few systems that read Arabic, which limits the penetration
of EDM into Arabicspeaking countries. In developing an OCR system
for Arabic it is necessary to create a database of Arabic words.
Such a database has many uses as well as in training and testing
a recognition system. This paper provides a comprehensive study and
analysis of Arabic words and explains how such a database was constructed.
Unlike earlier studies, this paper describes a database developed
using a large number of collected Arabic words (6 million). It also
considers connected segments or Pieces of Arabic Words (PAWs) as
well as Naked Pieces of Arabic Word (NPAWs); PAWS without diacritic
Background information concerning the Arabic language is also presented.},
author = {AbdelRaouf, Ashraf and Higgins, Colin A and Khalil, Mahmoud},
booktitle = {Image Analysis and Recognition},
file = {:D$\backslash$:/Papers/Documents/2008/AbdelRaouf, Higgins, Khalil - 2008.pdf:pdf},
keywords = { Arabic Characters, Database,Character Recognition},
pages = {567--578},
publisher = {Springer-Verlag Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Database for Arabic Printed Character Recognition}},
url = {http://www.springerlink.com/content/p567835u6l07k418/},
volume = {5112},
year = {2008}
}
@article{Camastra2007,
abstract = {This paper presents a cursive character recognizer, a crucial module in any cursive word recognition system based on a segmentation and recognition approach. The character classification is achieved by using support vector machines (SVMs) and a neural gas. The neural gas is used to verify whether lower and upper case version of a certain letter can be joined in a single class or not. Once this is done for every letter, the character recognition is performed by SVMs. A database of 57 293 characters was used to train and test the cursive character recognizer. SVMs compare notably better, in terms of recognition rates, with popular neural classifiers, such as learning vector quantization and multi-layer-perceptron. SVM recognition rate is among the highest presented in the literature for cursive character recognition},
author = {Camastra, F},
doi = {10.1016/j.patcog.2007.03.014},
file = {:D$\backslash$:/Papers/Documents/2007/Camastra - 2007.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Reference From Doctor,crossvalidation,cursive character recognition,learning vector quantization,multi-layer-perceptron,neural gas,support vector machines},
mendeley-tags = {Reference From Doctor},
month = dec,
number = {12},
pages = {3721--3727},
title = {{A SVM-based cursive character recognizer}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320307001409},
volume = {40},
year = {2007}
}
@inproceedings{DSMarisa2002,
abstract = {This paper presents an HMM-MLP hybrid system to process complex date
images written on Brazilian bank cheques. The system first segments
implicitly a date image into sub-fields through the recognition process
based on anHMMapproach. Afterwards, a recognition and verification
strategy is proposed to recognize the three obligatory date sub-fields
(day, month and year) using different classifiers. Markovian and
neural approaches have been adopted to recognize and verify words
and strings of digits respectively. We also introduce the concept
of meta-classes of digits, which is used to reduce the lexicon size
of the day and year and improve the precision of their segmentation
and recognition. Experiments show interesting results on date recognition.},
address = {Honolulu, USA},
author = {M, Morita and L.S., Oliveira and R., Sabourin and F., Bortolozzi and C.Y., Suen},
booktitle = {International Joint Conference on Neural Networks (IJCNN 2002)},
file = {:D$\backslash$:/Papers/Documents/2002/M et al. - 2002.pdf:pdf},
month = may,
pages = {867--872},
publisher = {IEEE Computer Society Press},
title = {{An HMM-MLP Hybrid System to Recognize Handwritten Dates}},
year = {2002}
}
@article{Beldjehem2009,
abstract = {We propose a novel cognitively motivated unifying framework for Arabic handwriting recognition that takes into account the nature of the human reading process of Arabic handwriting. This Modular Granular Architecture tackles the problem by observing Arabic handwriting from both perceptual and linguistic points of view and hence analyzes the underlying input signal from different granularity levels. It is based on three levels of abstraction: a low granularity level that uses perceptual features called global visual indices, a medium granularity level that is the conventional recognition stage and a high granularity level that consists on morphological analysis dedicated to segmentation/recognition. The original idea is the effective use of Arabic wordÃ¢â¬â¢s morphology in the recognition not only in post-processing. This architecture carries well around the Arabic wordÃ¢â¬â¢s morphology, as typically in Arabic, the Arabic wordÃ¢â¬â¢s morphology is by excellence the logical structure (even semantic) of a given Arabic word, whereas the visual data constitute the physical geometric (topological) structure of a given word. We need to integrate both of them for an effective cooperative recognition of Arabic Handwriting. This framework subsumes the lexicon-driven approaches; in that it can recognize a word that does not exist within the lexicon.},
author = {Beldjehem, Mokhtar},
file = {:D$\backslash$:/Papers/Documents/2009/Beldjehem - 2009.pdf:pdf},
journal = {Computational Intelligence},
keywords = {and soft computing,approximate fault tol-,cooperative,fuzzy,granular arab handwriting recognition,morphological analysis,morphological-guided recognition},
number = {5},
pages = {512--513},
title = {{A Granular Framework for Recognition of Arabic Handwriting}},
volume = {13},
year = {2009}
}
@article{Haboubi2009,
author = {Haboubi, Sofiene and Maddouri, Samia and Ellouze, Noureddine and El-Abed, Hailkal},
doi = {10.1109/ICDAR.2009.281},
file = {:D$\backslash$:/Papers/Documents/2009/Haboubi et al. - 2009.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
month = jul,
pages = {691--697},
publisher = {Ieee},
title = {{Invariant Primitives for Handwritten Arabic Script: A Contrastive Study of Four Feature Sets}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277482},
year = {2009}
}
